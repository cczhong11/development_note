<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><link rel="icon" href="/favicon.ico"/><title>LLM</title><meta name="robots" content="index,follow"/><meta name="googlebot" content="index,follow"/><meta name="description" content="Personal knowledge space"/><meta property="og:title" content="LLM"/><meta property="og:description" content="Personal knowledge space"/><meta property="og:url" content="https://notes.tczhong.com/notes/cki43m8kwb6iflb2de61itq/"/><meta property="og:type" content="article"/><meta property="article:published_time" content="3/9/2023"/><meta property="article:modified_time" content="9/7/2025"/><link rel="canonical" href="https://notes.tczhong.com/notes/cki43m8kwb6iflb2de61itq/"/><meta name="next-head-count" content="14"/><link rel="preload" href="/_next/static/css/8e7b7e4bce421c0a.css" as="style"/><link rel="stylesheet" href="/_next/static/css/8e7b7e4bce421c0a.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-3d209faeb64f2f97.js" defer=""></script><script src="/_next/static/chunks/framework-28c999baf2863c3d.js" defer=""></script><script src="/_next/static/chunks/main-104451f3d1a5c4bc.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6b338472289fe290.js" defer=""></script><script src="/_next/static/chunks/935-4dee79e80b8641c6.js" defer=""></script><script src="/_next/static/chunks/6-50972def09142ee2.js" defer=""></script><script src="/_next/static/chunks/pages/notes/%5Bid%5D-78d472fa3b924116.js" defer=""></script><script src="/_next/static/NuX3eScCWIVmkVcvE2z7c/_buildManifest.js" defer=""></script><script src="/_next/static/NuX3eScCWIVmkVcvE2z7c/_ssgManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><section class="ant-layout" style="width:100%;min-height:100%"><header class="ant-layout-header" style="position:fixed;isolation:isolate;z-index:1;width:100%;border-bottom:1px solid #d4dadf;height:64px;padding:0 24px 0 2px"><div class="ant-row ant-row-center" style="max-width:992px;justify-content:space-between;margin:0 auto"><div style="display:flex" class="ant-col ant-col-xs-20 ant-col-sm-4"></div><div class="ant-col gutter-row ant-col-xs-0 ant-col-sm-20 ant-col-md-20 ant-col-lg-19"><div class="ant-select ant-select-lg ant-select-auto-complete ant-select-single ant-select-allow-clear ant-select-show-search" style="width:100%"><div class="ant-select-selector"><span class="ant-select-selection-search"><input type="search" autoComplete="off" class="ant-select-selection-search-input" role="combobox" aria-haspopup="listbox" aria-owns="undefined_list" aria-autocomplete="list" aria-controls="undefined_list" aria-activedescendant="undefined_list_0" value=""/></span><span class="ant-select-selection-placeholder">For full text search please use the &#x27;?&#x27; prefix. e.g. ? Onboarding</span></div></div></div><div style="display:none;align-items:center;justify-content:center" class="ant-col ant-col-xs-4 ant-col-sm-4 ant-col-md-0 ant-col-lg-0"><span role="img" aria-label="menu" style="font-size:24px" tabindex="-1" class="anticon anticon-menu"><svg viewBox="64 64 896 896" focusable="false" data-icon="menu" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M904 160H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0 624H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0-312H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8z"></path></svg></span></div></div></header><section class="ant-layout" style="margin-top:64px;display:flex;flex-direction:row"><div class="site-layout-sidebar" style="flex:0 0 auto;width:calc(max((100% - 992px) / 2, 0px) + 200px);min-width:200px;padding-left:calc((100% - 992px) / 2)"><aside class="ant-layout-sider ant-layout-sider-dark" style="position:fixed;overflow:auto;height:calc(100vh - 64px);background-color:transparent;flex:0 0 200px;max-width:200px;min-width:200px;width:200px"><div class="ant-layout-sider-children"></div></aside></div><main class="ant-layout-content side-layout-main" style="max-width:1200px;min-width:0;display:block"><div style="padding:0 24px"><div class="main-content" role="main"><div class="ant-row"><div class="ant-col ant-col-24"><div class="ant-row" style="margin-left:-10px;margin-right:-10px"><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-24 ant-col-md-18"><div><h1 id="llm">LLM<a aria-hidden="true" class="anchor-heading icon-link" href="#llm"></a></h1>
<p>大语言模型是一种基于深度学习技术的自然语言处理模型，它能够学习和生成自然语言文本。大语言模型通常由多层神经网络组成，可以根据历史文本数据预测下一个单词或一段文本的概率。大语言模型的应用包括语言翻译、问答系统、自动摘要、语音识别等领域。其中最著名的大语言模型是Google的BERT、OpenAI的GPT-3等。大语言模型的优点是可以在大规模数据上进行训练，支持生成高质量的自然语言文本，但是也存在一些问题，比如需要大量的计算资源和数据、对于少见的单词或短语容易出现错误等。</p>
<ol>
<li>AI 技术栈概览
•	应用开发层：如何使用大模型（如 GPT、PaLM 等），构建 Agent，聚焦 Prompt Engineering 与 Context Engineering。
•	模型开发层：涉及模型的训练、微调、评估及部署。
•	基础设施层：包括 Serving Infra、数据管理（Data Ops）与模型运行监控（Monitoring）。</li>
</ol>
<p>⸻</p>
<ol start="2">
<li>应用开发层（Application Development）
<ol>
<li>大模型使用
•	选型：接口调用 vs. 本地部署
•	性能与成本权衡</li>
<li>Agent 设计
•	单任务 Agent vs. 多任务 Agent
•	模块化思路：Planner → Executor → Verifier</li>
<li>Prompt Engineering
•	技术手段：零样本、少样本、链式思维（Chain-of-Thought）
•	动态上下文筛选与检索增强（Retrieval-Augmented Generation）</li>
<li>Context Engineering
•	上下文窗口管理
•	长文档检索与摘要拼接</li>
</ol>
</li>
</ol>
<p>⸻</p>
<ol start="3">
<li>模型开发层（Model Development）</li>
</ol>
<p>3.1 数据来源与处理
•	Common Crawl / C4：大规模互联网网页抓取数据集，涵盖多语种
•	Domain-Specific Corpora：如医学（PubMed）、法律（CourtListener）、金融（SEC filings）等
•	开源语料：Wikipedia、OpenWebText、The Pile
•	数据清洗与预处理：去重、过滤低质量、子词切分（BPE/WordPiece）</p>
<p>3.2 模型架构（Transformer）
•	核心思想：自注意力（Self-Attention）
•	Attention 公式（LaTeX）：
<span class="math math-inline"><span class="katex-error" title="ParseError: KaTeX parse error: Can&#x27;t use function &#x27;$&#x27; in math mode at position 89: …d_k}}\Bigr)\,V $̲  • Q, K, V 分别为…" style="color:#cc0000">\mathrm{Attention}(Q, K, V) = \mathrm{softmax}\Bigl(\frac{QK^\top}{\sqrt{d_k}}\Bigr)\,V $  • Q, K, V 分别为查询（Query）、键（Key）、值（Value）矩阵  • $\sqrt{d_k}</span></span> 为缩放因子
•	多头注意力（Multi-Head Attention）：并行多组 Q,K,V，再拼接投影
•	位置编码（Positional Encoding）：Sin/Cos 或可学习向量
•	前馈网络：两层线性层 + 激活（GELU/ReLU）
•	残差连接 &#x26; LayerNorm</p>
<p>3.3 模型训练与微调</p>
<pre><code>1.	预训练（Pre-Training）
•	自监督目标：Masked Language Modeling（如 BERT）／自回归（如 GPT）
•	大规模分布式训练：数据并行 + 模型并行
2.	微调（Fine-Tuning）
•	全量微调 vs. 参数高效方法（PEFT）
•	LoRA、Adapter、Prefix-Tuning
•	强化学习 + 人类反馈（RLHF）
</code></pre>
<p>3.4 模型评估
•	自动化指标：Perplexity、BLEU、ROUGE、F1
•	基准测试：GLUE、SuperGLUE、MMLU、SQuAD
•	人类评估：流畅度、相关性、安全性</p>
<p>3.5 模型服务（Serving）
•	推理框架：TensorFlow Serving、TorchServe、NVIDIA Triton
•	优化手段：量化（Quantization）、剪枝（Pruning）、蒸馏（Distillation）、ONNX
•	高可用设计：负载均衡、水平扩展、冷/热启动</p>
<p>⸻</p>
<ol start="4">
<li>基础设施层（Infra）
<ol>
<li>Serving Infra
•	Kubernetes + Helm 部署
•	服务网格（Istio）</li>
<li>数据管理（Data Ops）
•	版本控制：DVC、Git-LFS
•	元数据管理：MLflow、Weights &#x26; Biases</li>
<li>监控与告警
•	指标收集：Prometheus
•	可视化：Grafana
•	日志与追踪：ELK Stack、Jaeger</li>
</ol>
</li>
</ol>
<hr>
<strong>Children</strong>
<ol>
<li><a href="/notes/qzhktnz6o28v08msov6iph3">Evaluation</a></li>
<li><a href="/notes/mtcseghv7a6x4cqeoyqxgrv">Model</a></li>
<li><a href="/notes/s07zvgrc9ml2ld5difpj0jg">agent</a></li>
<li><a href="/notes/pzsuculkyms2gvuotyaykab">instructGPT</a></li>
<li><a href="/notes/9cp08wuyd7t35jzracxxqbv">llama</a></li>
<li><a href="/notes/vlbjb19104pkzyg8nmai5pa">machine_memory</a></li>
<li><a href="/notes/282jaazafck51k0dd93k6wu">memory</a></li>
<li><a href="/notes/82undztzy7arc9g53jgjoas">tool</a></li>
<li><a href="/notes/orvk6ml0kophjt1oddyzcs7">transformer</a></li>
</ol></div></div><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-0 ant-col-md-6"><div><div class=""><div class="ant-anchor-wrapper dendron-toc" style="max-height:calc(100vh - 64px);z-index:1"><div class="ant-anchor"><div class="ant-anchor-ink"><span class="ant-anchor-ink-ball"></span></div></div></div></div></div></div></div></div></div></div></div><div class="ant-divider ant-divider-horizontal" role="separator"></div><footer class="ant-layout-footer" style="padding:0 24px 24px"></footer></main></section></section></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"note":{"id":"cki43m8kwb6iflb2de61itq","title":"LLM","desc":"","updated":1757213819234,"created":1678338043210,"custom":{},"fname":"development.ml.LLM","type":"note","vault":{"fsPath":"repos/dendron-aws-vault","remote":{"type":"git","url":"https://github.com/cczhong11/my_note.git"},"name":"my_note"},"contentHash":"6826f99cc5cd03c2661c0a953d3fe6a9","links":[],"anchors":{},"children":["s07zvgrc9ml2ld5difpj0jg","pzsuculkyms2gvuotyaykab","9cp08wuyd7t35jzracxxqbv","vlbjb19104pkzyg8nmai5pa","282jaazafck51k0dd93k6wu","82undztzy7arc9g53jgjoas","orvk6ml0kophjt1oddyzcs7","qzhktnz6o28v08msov6iph3","mtcseghv7a6x4cqeoyqxgrv"],"parent":"09d9081f-3dff-453d-8488-7d2344cc8895","data":{}},"body":"\u003ch1 id=\"llm\"\u003eLLM\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#llm\"\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003cp\u003e大语言模型是一种基于深度学习技术的自然语言处理模型，它能够学习和生成自然语言文本。大语言模型通常由多层神经网络组成，可以根据历史文本数据预测下一个单词或一段文本的概率。大语言模型的应用包括语言翻译、问答系统、自动摘要、语音识别等领域。其中最著名的大语言模型是Google的BERT、OpenAI的GPT-3等。大语言模型的优点是可以在大规模数据上进行训练，支持生成高质量的自然语言文本，但是也存在一些问题，比如需要大量的计算资源和数据、对于少见的单词或短语容易出现错误等。\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003eAI 技术栈概览\n•\t应用开发层：如何使用大模型（如 GPT、PaLM 等），构建 Agent，聚焦 Prompt Engineering 与 Context Engineering。\n•\t模型开发层：涉及模型的训练、微调、评估及部署。\n•\t基础设施层：包括 Serving Infra、数据管理（Data Ops）与模型运行监控（Monitoring）。\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e⸻\u003c/p\u003e\n\u003col start=\"2\"\u003e\n\u003cli\u003e应用开发层（Application Development）\n\u003col\u003e\n\u003cli\u003e大模型使用\n•\t选型：接口调用 vs. 本地部署\n•\t性能与成本权衡\u003c/li\u003e\n\u003cli\u003eAgent 设计\n•\t单任务 Agent vs. 多任务 Agent\n•\t模块化思路：Planner → Executor → Verifier\u003c/li\u003e\n\u003cli\u003ePrompt Engineering\n•\t技术手段：零样本、少样本、链式思维（Chain-of-Thought）\n•\t动态上下文筛选与检索增强（Retrieval-Augmented Generation）\u003c/li\u003e\n\u003cli\u003eContext Engineering\n•\t上下文窗口管理\n•\t长文档检索与摘要拼接\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e⸻\u003c/p\u003e\n\u003col start=\"3\"\u003e\n\u003cli\u003e模型开发层（Model Development）\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e3.1 数据来源与处理\n•\tCommon Crawl / C4：大规模互联网网页抓取数据集，涵盖多语种\n•\tDomain-Specific Corpora：如医学（PubMed）、法律（CourtListener）、金融（SEC filings）等\n•\t开源语料：Wikipedia、OpenWebText、The Pile\n•\t数据清洗与预处理：去重、过滤低质量、子词切分（BPE/WordPiece）\u003c/p\u003e\n\u003cp\u003e3.2 模型架构（Transformer）\n•\t核心思想：自注意力（Self-Attention）\n•\tAttention 公式（LaTeX）：\n\u003cspan class=\"math math-inline\"\u003e\u003cspan class=\"katex-error\" title=\"ParseError: KaTeX parse error: Can\u0026#x27;t use function \u0026#x27;$\u0026#x27; in math mode at position 89: …d_k}}\\Bigr)\\,V $̲  • Q, K, V 分别为…\" style=\"color:#cc0000\"\u003e\\mathrm{Attention}(Q, K, V) = \\mathrm{softmax}\\Bigl(\\frac{QK^\\top}{\\sqrt{d_k}}\\Bigr)\\,V $  • Q, K, V 分别为查询（Query）、键（Key）、值（Value）矩阵  • $\\sqrt{d_k}\u003c/span\u003e\u003c/span\u003e 为缩放因子\n•\t多头注意力（Multi-Head Attention）：并行多组 Q,K,V，再拼接投影\n•\t位置编码（Positional Encoding）：Sin/Cos 或可学习向量\n•\t前馈网络：两层线性层 + 激活（GELU/ReLU）\n•\t残差连接 \u0026#x26; LayerNorm\u003c/p\u003e\n\u003cp\u003e3.3 模型训练与微调\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e1.\t预训练（Pre-Training）\n•\t自监督目标：Masked Language Modeling（如 BERT）／自回归（如 GPT）\n•\t大规模分布式训练：数据并行 + 模型并行\n2.\t微调（Fine-Tuning）\n•\t全量微调 vs. 参数高效方法（PEFT）\n•\tLoRA、Adapter、Prefix-Tuning\n•\t强化学习 + 人类反馈（RLHF）\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e3.4 模型评估\n•\t自动化指标：Perplexity、BLEU、ROUGE、F1\n•\t基准测试：GLUE、SuperGLUE、MMLU、SQuAD\n•\t人类评估：流畅度、相关性、安全性\u003c/p\u003e\n\u003cp\u003e3.5 模型服务（Serving）\n•\t推理框架：TensorFlow Serving、TorchServe、NVIDIA Triton\n•\t优化手段：量化（Quantization）、剪枝（Pruning）、蒸馏（Distillation）、ONNX\n•\t高可用设计：负载均衡、水平扩展、冷/热启动\u003c/p\u003e\n\u003cp\u003e⸻\u003c/p\u003e\n\u003col start=\"4\"\u003e\n\u003cli\u003e基础设施层（Infra）\n\u003col\u003e\n\u003cli\u003eServing Infra\n•\tKubernetes + Helm 部署\n•\t服务网格（Istio）\u003c/li\u003e\n\u003cli\u003e数据管理（Data Ops）\n•\t版本控制：DVC、Git-LFS\n•\t元数据管理：MLflow、Weights \u0026#x26; Biases\u003c/li\u003e\n\u003cli\u003e监控与告警\n•\t指标收集：Prometheus\n•\t可视化：Grafana\n•\t日志与追踪：ELK Stack、Jaeger\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003chr\u003e\n\u003cstrong\u003eChildren\u003c/strong\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"/notes/qzhktnz6o28v08msov6iph3\"\u003eEvaluation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/notes/mtcseghv7a6x4cqeoyqxgrv\"\u003eModel\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/notes/s07zvgrc9ml2ld5difpj0jg\"\u003eagent\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/notes/pzsuculkyms2gvuotyaykab\"\u003einstructGPT\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/notes/9cp08wuyd7t35jzracxxqbv\"\u003ellama\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/notes/vlbjb19104pkzyg8nmai5pa\"\u003emachine_memory\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/notes/282jaazafck51k0dd93k6wu\"\u003ememory\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/notes/82undztzy7arc9g53jgjoas\"\u003etool\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/notes/orvk6ml0kophjt1oddyzcs7\"\u003etransformer\u003c/a\u003e\u003c/li\u003e\n\u003c/ol\u003e","noteIndex":{"id":"0f1b48c7-3a25-4016-83a5-15864d7803ad","title":"Development","vault":{"fsPath":"repos/dendron-aws-vault","remote":{"type":"git","url":"https://github.com/cczhong11/my_note.git"},"name":"my_note"},"type":"note","desc":"","links":[{"from":{"fname":"root","id":"c95dc4f5-23db-45e7-a15b-64582a183ccc","vaultName":"my_note"},"type":"backlink","position":{"start":{"line":8,"column":3,"offset":63},"end":{"line":8,"column":21,"offset":81},"indent":[]},"value":"development"}],"anchors":{},"fname":"development","updated":1618381238346,"created":1612940782409,"parent":null,"children":["400115e9-30f7-4a13-9776-db059bc9cd42","xsX5v3ZsyJ0i6gf9","1bc3b45a-b6f4-4150-87d3-5bd5b6eb8c24","6cea4852-6e7c-4140-b476-85c07b48a642","a40ef849-d301-4d74-a778-e6d9469dfb5d","09d9081f-3dff-453d-8488-7d2344cc8895","p11phg7nb10yw0wck1fyagq","92917ea3-452e-48dc-875e-5cd0002041db","2e151826-cb22-4d89-8ce0-71dad7204ce8","baa39444-0da9-4c55-8df7-2a6f8f787fa4","q4um3bc3st86ilkkvdjom6x","62daf50d-a39e-463f-aabd-be53790281fd","3524d0a7-be73-45d6-847e-c970f5c1c760","eac0f243-05b3-4b95-bec3-848e33edbc40","zrjuka02gkzrqxt5djp2aws"],"data":{},"custom":{"nav_order":0,"permalink":"/"},"body":"\n","contentHash":"38357962f5a50c6fd7d318dfa66bea90"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"previewV2Enabled":false,"enablePreviewV2":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":false,"leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2,"vaultSelectionModeOnCreate":"smart"}},"insertNote":{"initialValue":"templates"},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"randomNote":{},"copyNoteLink":{"aliasMode":"title"},"templateHierarchy":"template"},"workspace":{"dendronVersion":"0.90.0","vaults":[{"fsPath":"repos/dendron-aws-vault","remote":{"type":"git","url":"https://github.com/cczhong11/my_note.git"},"name":"my_note"},{"fsPath":"vault"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":true,"maxPreviewsCached":10,"maxNoteLength":204800,"enableUserTags":true,"enableHashTags":true,"task":{"name":"","dateFormat":"","addBehavior":"childOfCurrent","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link","taskCompleteStatus":["done","x"]},"enableEditorDecorations":true,"enableHandlebarTemplates":true,"enableFullHierarchyNoteTitle":false,"enablePersistentHistory":false},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"automaticallyShowPreview":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"siteHierarchies":["development","life"],"writeStubs":false,"siteRootDir":"docs","seo":{"title":"my_note","description":"Personal knowledge space"},"github":{"enableEditLink":true,"editLinkText":"Edit this page on GitHub","editBranch":"main","editViewMode":"tree"},"enableSiteLastModified":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"enableTaskNotes":true,"enablePrettyLinks":true,"searchMode":"lookup","enableMermaid":true,"siteUrl":"https://notes.tczhong.com","siteFaviconPath":"favicon.ico","siteIndex":"development"}}},"__N_SSG":true},"page":"/notes/[id]","query":{"id":"cki43m8kwb6iflb2de61itq"},"buildId":"NuX3eScCWIVmkVcvE2z7c","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>