<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><link rel="icon" href="/favicon.ico"/><title>Pattern</title><meta name="robots" content="index,follow"/><meta name="googlebot" content="index,follow"/><meta name="description" content="Personal knowledge space"/><meta property="og:title" content="Pattern"/><meta property="og:description" content="Personal knowledge space"/><meta property="og:url" content="https://notes.tczhong.com/notes/afdca563-1075-4f32-8569-76abb00d833d/"/><meta property="og:type" content="article"/><meta property="article:published_time" content="5/11/2021"/><meta property="article:modified_time" content="5/11/2021"/><link rel="canonical" href="https://notes.tczhong.com/notes/afdca563-1075-4f32-8569-76abb00d833d/"/><meta name="next-head-count" content="14"/><link rel="preload" href="/_next/static/css/35c8e98bba5d4075.css" as="style"/><link rel="stylesheet" href="/_next/static/css/35c8e98bba5d4075.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-378e68e29c265886.js" defer=""></script><script src="/_next/static/chunks/framework-dc33c0b5493501f0.js" defer=""></script><script src="/_next/static/chunks/main-a7fe8c0ea9a0f989.js" defer=""></script><script src="/_next/static/chunks/pages/_app-fdb9297d37c44607.js" defer=""></script><script src="/_next/static/chunks/155-4c900bf5c5278e05.js" defer=""></script><script src="/_next/static/chunks/pages/notes/%5Bid%5D-ebe33fbe56ae1215.js" defer=""></script><script src="/_next/static/qHbm4vS5s7hFBo6UvcS91/_buildManifest.js" defer=""></script><script src="/_next/static/qHbm4vS5s7hFBo6UvcS91/_ssgManifest.js" defer=""></script><script src="/_next/static/qHbm4vS5s7hFBo6UvcS91/_middlewareManifest.js" defer=""></script></head><body><div id="__next"><section class="ant-layout" style="width:100%;min-height:100%"><header class="ant-layout-header" style="position:fixed;isolation:isolate;z-index:1;width:100%;border-bottom:1px solid #d4dadf;height:64px;padding:0 24px 0 2px"><div class="ant-row ant-row-center" style="max-width:992px;justify-content:space-between;margin:0 auto"><div class="ant-col"></div><div class="ant-col gutter-row ant-col-xs-0 ant-col-sm-20 ant-col-md-20 ant-col-lg-19"></div><div style="margin-left:4px;display:none;align-items:center;justify-content:center" class="ant-col ant-col-xs-4 ant-col-sm-4 ant-col-md-0 ant-col-lg-0"><span role="img" aria-label="menu" style="font-size:24px" tabindex="-1" class="anticon anticon-menu"><svg viewBox="64 64 896 896" focusable="false" data-icon="menu" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M904 160H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0 624H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0-312H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8z"></path></svg></span></div></div></header><section class="ant-layout site-layout" style="margin-top:64px"><section class="ant-layout site-layout" style="flex-direction:row"><section class="ant-layout site-layout-sidebar" style="flex:0 0 auto;width:calc((100% - 992px) / 2 + 200px);min-width:200px;padding-left:calc((100% - 992px) / 2)"><aside class="ant-layout-sider ant-layout-sider-dark" style="position:fixed;overflow:auto;height:calc(100vh - 64px);flex:0 0 200px;max-width:200px;min-width:200px;width:200px"><div class="ant-layout-sider-children"></div></aside></section><section class="ant-layout side-layout-main" style="max-width:960px;display:initial"><main class="ant-layout-content main-content" role="main" style="padding:0 24px"><div class="ant-row"><div class="ant-col ant-col-24"><div class="ant-row" style="margin-left:-10px;margin-right:-10px"><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-24 ant-col-md-20"><div><h1 id="pattern"><a aria-hidden="true" class="anchor-heading" href="#pattern"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Pattern</h1>
<h1 id="asynchronous-request-reply"><a aria-hidden="true" class="anchor-heading" href="#asynchronous-request-reply"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Asynchronous Request-Reply</h1>
<p>Decouple backend processing from a frontend host, where backend processing needs to be asynchronous, but the frontend still needs a clear response.</p>
<p>One solution to this problem is to use HTTP polling. Polling is useful to client-side code, as it can be hard to provide call-back endpoints or use long running connections. Even when callbacks are possible, the extra libraries and services that are required can sometimes add too much extra complexity.</p>
<ul>
<li>The client application makes a synchronous call to the API, triggering a long-running operation on the backend.</li>
<li>The API responds synchronously as quickly as possible. It returns an HTTP 202 (Accepted) status code, acknowledging that the request has been received for processing.</li>
<li>The response holds a location reference pointing to an endpoint that the client can poll to check for the result of the long running operation.</li>
<li>The API offloads processing to another component, such as a message queue.</li>
<li>While the work is still pending, the status endpoint returns HTTP 202.</li>
</ul>
<p><img src="/assets/images/2021-05-10-22-21-30.png"></p>
<ul>
<li>At some point, the work is complete and the status endpoint returns 302 (Found) redirecting to the resource.</li>
<li>The client fetches the resource at the specified URL.</li>
</ul>
<p><img src="/assets/images/2021-05-10-22-21-54.png"></p>
<h1 id="claim-check"><a aria-hidden="true" class="anchor-heading" href="#claim-check"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Claim Check</h1>
<p>Split a large message into a claim check and a payload. Send the claim check to the messaging platform and store the payload to an external service. This pattern allows large messages to be processed, while protecting the message bus and the client from being overwhelmed or slowed down. This pattern also helps to reduce costs, as storage is usually cheaper than resource units used by the messaging platform.</p>
<p><img src="/assets/images/2021-05-10-22-26-15.png"></p>
<p>Store the entire message payload into an external service, such as a database. Get the reference to the stored payload, and send just that reference to the message bus. The reference acts like a claim check used to retrieve a piece of luggage, hence the name of the pattern. Clients interested in processing that specific message can use the obtained reference to retrieve the payload, if needed.</p>
<h1 id="choreography"><a aria-hidden="true" class="anchor-heading" href="#choreography"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Choreography</h1>
<p>Have each component of the system participate in the decision-making process about the workflow of a business transaction, instead of relying on a central point of control.</p>
<p><img src="/assets/images/2021-05-10-22-27-37.png"></p>
<p>A client request publishes messages to a message queue. As messages arrive, they are pushed to subscribers, or services, interested in that message. Each subscribed service does their operation as indicated by the message and responds to the message queue with success or failure of the operation. In case of success, the service can push a message back to the same queue or a different message queue so that another service can continue the workflow if needed. If an operation fails, the message bus can retry that operation.</p>
<h1 id="competing-consumers"><a aria-hidden="true" class="anchor-heading" href="#competing-consumers"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Competing Consumers</h1>
<p>Enable multiple concurrent consumers to process messages received on the same messaging channel. This enables a system to process multiple messages concurrently to optimize throughput, to improve scalability and availability, and to balance the workload.</p>
<p><img src="/assets/images/2021-05-10-22-30-54.png"></p>
<p>The application posts requests in the form of messages to the queue, and the consumer service instances receive messages from the queue and process them. This approach enables the same pool of consumer service instances to handle messages from any instance of the application.</p>
<p>This solution has the following benefits:</p>
<p>It provides a load-leveled system that can handle wide variations in the volume of requests sent by application instances. The queue acts as a buffer between the application instances and the consumer service instances. This can help to minimize the impact on availability and responsiveness for both the application and the service instances, as described by the Queue-based Load Leveling pattern. Handling a message that requires some long-running processing doesn't prevent other messages from being handled concurrently by other instances of the consumer service.</p>
<p>It improves reliability. If a producer communicates directly with a consumer instead of using this pattern, but doesn't monitor the consumer, there's a high probability that messages could be lost or fail to be processed if the consumer fails. In this pattern, messages aren't sent to a specific service instance. A failed service instance won't block a producer, and messages can be processed by any working service instance.</p>
<p>It doesn't require complex coordination between the consumers, or between the producer and the consumer instances. The message queue ensures that each message is delivered at least once.</p>
<p>It's scalable. The system can dynamically increase or decrease the number of instances of the consumer service as the volume of messages fluctuates.</p>
<p>It can improve resiliency if the message queue provides transactional read operations. If a consumer service instance reads and processes the message as part of a transactional operation, and the consumer service instance fails, this pattern can ensure that the message will be returned to the queue to be picked up and handled by another instance of the consumer service.</p>
<h1 id="priority-queue"><a aria-hidden="true" class="anchor-heading" href="#priority-queue"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Priority Queue</h1>
<p>Prioritize requests sent to services so that requests with a higher priority are received and processed more quickly than those with a lower priority. This pattern is useful in applications that offer different service level guarantees to individual clients.</p>
<p><img src="/assets/images/2021-05-10-22-33-12.png"></p>
<p>A queue is usually a first-in, first-out (FIFO) structure, and consumers typically receive messages in the same order that they were posted to the queue. However, some message queues support priority messaging. The application posting a message can assign a priority and the messages in the queue are automatically reordered so that those with a higher priority will be received before those with a lower priority</p>
<h1 id="publisher-subscriber"><a aria-hidden="true" class="anchor-heading" href="#publisher-subscriber"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Publisher-Subscriber</h1>
<p>Enable an application to announce events to multiple interested consumers asynchronously, without coupling the senders to the receivers.</p>
<p><img src="/assets/images/2021-05-10-22-34-05.png"></p>
<h1 id="queue-based-load-leveling"><a aria-hidden="true" class="anchor-heading" href="#queue-based-load-leveling"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Queue-Based Load Leveling</h1>
<p>Use a queue that acts as a buffer between a task and a service it invokes in order to smooth intermittent heavy loads that can cause the service to fail or the task to time out. This can help to minimize the impact of peaks in demand on availability and responsiveness for both the task and the service.</p>
<p><img src="/assets/images/2021-05-10-22-35-25.png"></p>
<h1 id="scheduler-agent-supervisor"><a aria-hidden="true" class="anchor-heading" href="#scheduler-agent-supervisor"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Scheduler Agent Supervisor</h1>
<p>Coordinate a set of distributed actions as a single operation. If any of the actions fail, try to handle the failures transparently, or else undo the work that was performed, so the entire operation succeeds or fails as a whole. This can add resiliency to a distributed system, by enabling it to recover and retry actions that fail due to transient exceptions, long-lasting faults, and process failures.</p>
<p><img src="/assets/images/2021-05-10-22-36-25.png"></p>
<ul>
<li>The Scheduler arranges for the steps that make up the task to be executed and orchestrates their operation. </li>
<li>The Agent contains logic that encapsulates a call to a remote service, or access to a remote resource referenced by a step in a task. </li>
<li>The Supervisor monitors the status of the steps in the task being performed by the Scheduler. It runs periodically (the frequency will be system-specific), and examines the status of steps maintained by the Scheduler. If it detects any that have timed out or failed, it arranges for the appropriate Agent to recover the step or execute the appropriate remedial action</li>
</ul>
<p><img src="/assets/images/2021-05-10-22-37-41.png"></p>
<h1 id="sequential-convoy"><a aria-hidden="true" class="anchor-heading" href="#sequential-convoy"><svg aria-hidden="true" viewBox="0 0 16 16"><use xlink:href="#svg-link"></use></svg></a>Sequential Convoy</h1>
<p>Process a set of related messages in a defined order, without blocking processing of other groups of messages.</p>
<p>Push related messages into categories within the queuing system, and have the queue listeners lock and pull only from one category, one message at a time.</p>
<p><img src="/assets/images/2021-05-10-22-38-54.png"></p>
<p>In the queue, messages for different categories may be interleaved, as shown in the following diagram:</p>
<p><img src="/assets/images/2021-05-10-22-39-00.png"></p></div></div><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-0 ant-col-md-4"><div><div class=""><div class="ant-anchor-wrapper" style="max-height:calc(100vh - 64px);z-index:1"><div class="ant-anchor"><div class="ant-anchor-ink"><span class="ant-anchor-ink-ball"></span></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#asynchronous-request-reply" title="Asynchronous Request Reply">Asynchronous Request Reply</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#claim-check" title="Claim Check">Claim Check</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#choreography" title="Choreography">Choreography</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#competing-consumers" title="Competing Consumers">Competing Consumers</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#priority-queue" title="Priority Queue">Priority Queue</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#publisher-subscriber" title="Publisher Subscriber">Publisher Subscriber</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#queue-based-load-leveling" title="Queue Based Load Leveling">Queue Based Load Leveling</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#scheduler-agent-supervisor" title="Scheduler Agent Supervisor">Scheduler Agent Supervisor</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#sequential-convoy" title="Sequential Convoy">Sequential Convoy</a></div></div></div></div></div></div></div></div></div></main><div class="ant-divider ant-divider-horizontal" role="separator"></div><footer class="ant-layout-footer" style="padding:0 24px 24px"></footer></section></section></section></section></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"note":{"id":"afdca563-1075-4f32-8569-76abb00d833d","title":"Pattern","vault":{"fsPath":"repos/dendron-aws-vault","remote":{"type":"git","url":"https://github.com/cczhong11/my_note.git"},"name":"my_note"},"type":"note","desc":"","links":[],"anchors":{"asynchronous-request-reply":{"type":"header","value":"asynchronous-request-reply","line":8,"column":0},"claim-check":{"type":"header","value":"claim-check","line":27,"column":0},"choreography":{"type":"header","value":"choreography","line":35,"column":0},"competing-consumers":{"type":"header","value":"competing-consumers","line":44,"column":0},"priority-queue":{"type":"header","value":"priority-queue","line":65,"column":0},"publisher-subscriber":{"type":"header","value":"publisher-subscriber","line":74,"column":0},"queue-based-load-leveling":{"type":"header","value":"queue-based-load-leveling","line":80,"column":0},"scheduler-agent-supervisor":{"type":"header","value":"scheduler-agent-supervisor","line":86,"column":0},"sequential-convoy":{"type":"header","value":"sequential-convoy","line":100,"column":0}},"fname":"development.cloud.messaging.pattern","updated":1620711827891,"created":1620710001469,"parent":"7f67fdcf-10d9-43e4-841c-a129a21aa69f","children":[],"data":{},"custom":{},"contentHash":"9e44d022bcbee3f81370fa3bb3e2b652"},"body":"\u003ch1 id=\"pattern\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#pattern\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003ePattern\u003c/h1\u003e\n\u003ch1 id=\"asynchronous-request-reply\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#asynchronous-request-reply\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eAsynchronous Request-Reply\u003c/h1\u003e\n\u003cp\u003eDecouple backend processing from a frontend host, where backend processing needs to be asynchronous, but the frontend still needs a clear response.\u003c/p\u003e\n\u003cp\u003eOne solution to this problem is to use HTTP polling. Polling is useful to client-side code, as it can be hard to provide call-back endpoints or use long running connections. Even when callbacks are possible, the extra libraries and services that are required can sometimes add too much extra complexity.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe client application makes a synchronous call to the API, triggering a long-running operation on the backend.\u003c/li\u003e\n\u003cli\u003eThe API responds synchronously as quickly as possible. It returns an HTTP 202 (Accepted) status code, acknowledging that the request has been received for processing.\u003c/li\u003e\n\u003cli\u003eThe response holds a location reference pointing to an endpoint that the client can poll to check for the result of the long running operation.\u003c/li\u003e\n\u003cli\u003eThe API offloads processing to another component, such as a message queue.\u003c/li\u003e\n\u003cli\u003eWhile the work is still pending, the status endpoint returns HTTP 202.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/assets/images/2021-05-10-22-21-30.png\"\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAt some point, the work is complete and the status endpoint returns 302 (Found) redirecting to the resource.\u003c/li\u003e\n\u003cli\u003eThe client fetches the resource at the specified URL.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/assets/images/2021-05-10-22-21-54.png\"\u003e\u003c/p\u003e\n\u003ch1 id=\"claim-check\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#claim-check\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eClaim Check\u003c/h1\u003e\n\u003cp\u003eSplit a large message into a claim check and a payload. Send the claim check to the messaging platform and store the payload to an external service. This pattern allows large messages to be processed, while protecting the message bus and the client from being overwhelmed or slowed down. This pattern also helps to reduce costs, as storage is usually cheaper than resource units used by the messaging platform.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/images/2021-05-10-22-26-15.png\"\u003e\u003c/p\u003e\n\u003cp\u003eStore the entire message payload into an external service, such as a database. Get the reference to the stored payload, and send just that reference to the message bus. The reference acts like a claim check used to retrieve a piece of luggage, hence the name of the pattern. Clients interested in processing that specific message can use the obtained reference to retrieve the payload, if needed.\u003c/p\u003e\n\u003ch1 id=\"choreography\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#choreography\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eChoreography\u003c/h1\u003e\n\u003cp\u003eHave each component of the system participate in the decision-making process about the workflow of a business transaction, instead of relying on a central point of control.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/images/2021-05-10-22-27-37.png\"\u003e\u003c/p\u003e\n\u003cp\u003eA client request publishes messages to a message queue. As messages arrive, they are pushed to subscribers, or services, interested in that message. Each subscribed service does their operation as indicated by the message and responds to the message queue with success or failure of the operation. In case of success, the service can push a message back to the same queue or a different message queue so that another service can continue the workflow if needed. If an operation fails, the message bus can retry that operation.\u003c/p\u003e\n\u003ch1 id=\"competing-consumers\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#competing-consumers\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eCompeting Consumers\u003c/h1\u003e\n\u003cp\u003eEnable multiple concurrent consumers to process messages received on the same messaging channel. This enables a system to process multiple messages concurrently to optimize throughput, to improve scalability and availability, and to balance the workload.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/images/2021-05-10-22-30-54.png\"\u003e\u003c/p\u003e\n\u003cp\u003eThe application posts requests in the form of messages to the queue, and the consumer service instances receive messages from the queue and process them. This approach enables the same pool of consumer service instances to handle messages from any instance of the application.\u003c/p\u003e\n\u003cp\u003eThis solution has the following benefits:\u003c/p\u003e\n\u003cp\u003eIt provides a load-leveled system that can handle wide variations in the volume of requests sent by application instances. The queue acts as a buffer between the application instances and the consumer service instances. This can help to minimize the impact on availability and responsiveness for both the application and the service instances, as described by the Queue-based Load Leveling pattern. Handling a message that requires some long-running processing doesn't prevent other messages from being handled concurrently by other instances of the consumer service.\u003c/p\u003e\n\u003cp\u003eIt improves reliability. If a producer communicates directly with a consumer instead of using this pattern, but doesn't monitor the consumer, there's a high probability that messages could be lost or fail to be processed if the consumer fails. In this pattern, messages aren't sent to a specific service instance. A failed service instance won't block a producer, and messages can be processed by any working service instance.\u003c/p\u003e\n\u003cp\u003eIt doesn't require complex coordination between the consumers, or between the producer and the consumer instances. The message queue ensures that each message is delivered at least once.\u003c/p\u003e\n\u003cp\u003eIt's scalable. The system can dynamically increase or decrease the number of instances of the consumer service as the volume of messages fluctuates.\u003c/p\u003e\n\u003cp\u003eIt can improve resiliency if the message queue provides transactional read operations. If a consumer service instance reads and processes the message as part of a transactional operation, and the consumer service instance fails, this pattern can ensure that the message will be returned to the queue to be picked up and handled by another instance of the consumer service.\u003c/p\u003e\n\u003ch1 id=\"priority-queue\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#priority-queue\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003ePriority Queue\u003c/h1\u003e\n\u003cp\u003ePrioritize requests sent to services so that requests with a higher priority are received and processed more quickly than those with a lower priority. This pattern is useful in applications that offer different service level guarantees to individual clients.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/images/2021-05-10-22-33-12.png\"\u003e\u003c/p\u003e\n\u003cp\u003eA queue is usually a first-in, first-out (FIFO) structure, and consumers typically receive messages in the same order that they were posted to the queue. However, some message queues support priority messaging. The application posting a message can assign a priority and the messages in the queue are automatically reordered so that those with a higher priority will be received before those with a lower priority\u003c/p\u003e\n\u003ch1 id=\"publisher-subscriber\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#publisher-subscriber\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003ePublisher-Subscriber\u003c/h1\u003e\n\u003cp\u003eEnable an application to announce events to multiple interested consumers asynchronously, without coupling the senders to the receivers.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/images/2021-05-10-22-34-05.png\"\u003e\u003c/p\u003e\n\u003ch1 id=\"queue-based-load-leveling\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#queue-based-load-leveling\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eQueue-Based Load Leveling\u003c/h1\u003e\n\u003cp\u003eUse a queue that acts as a buffer between a task and a service it invokes in order to smooth intermittent heavy loads that can cause the service to fail or the task to time out. This can help to minimize the impact of peaks in demand on availability and responsiveness for both the task and the service.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/images/2021-05-10-22-35-25.png\"\u003e\u003c/p\u003e\n\u003ch1 id=\"scheduler-agent-supervisor\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#scheduler-agent-supervisor\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eScheduler Agent Supervisor\u003c/h1\u003e\n\u003cp\u003eCoordinate a set of distributed actions as a single operation. If any of the actions fail, try to handle the failures transparently, or else undo the work that was performed, so the entire operation succeeds or fails as a whole. This can add resiliency to a distributed system, by enabling it to recover and retry actions that fail due to transient exceptions, long-lasting faults, and process failures.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/images/2021-05-10-22-36-25.png\"\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eThe Scheduler arranges for the steps that make up the task to be executed and orchestrates their operation. \u003c/li\u003e\n\u003cli\u003eThe Agent contains logic that encapsulates a call to a remote service, or access to a remote resource referenced by a step in a task. \u003c/li\u003e\n\u003cli\u003eThe Supervisor monitors the status of the steps in the task being performed by the Scheduler. It runs periodically (the frequency will be system-specific), and examines the status of steps maintained by the Scheduler. If it detects any that have timed out or failed, it arranges for the appropriate Agent to recover the step or execute the appropriate remedial action\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/assets/images/2021-05-10-22-37-41.png\"\u003e\u003c/p\u003e\n\u003ch1 id=\"sequential-convoy\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading\" href=\"#sequential-convoy\"\u003e\u003csvg aria-hidden=\"true\" viewBox=\"0 0 16 16\"\u003e\u003cuse xlink:href=\"#svg-link\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003eSequential Convoy\u003c/h1\u003e\n\u003cp\u003eProcess a set of related messages in a defined order, without blocking processing of other groups of messages.\u003c/p\u003e\n\u003cp\u003ePush related messages into categories within the queuing system, and have the queue listeners lock and pull only from one category, one message at a time.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/images/2021-05-10-22-38-54.png\"\u003e\u003c/p\u003e\n\u003cp\u003eIn the queue, messages for different categories may be interleaved, as shown in the following diagram:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/images/2021-05-10-22-39-00.png\"\u003e\u003c/p\u003e","noteIndex":{"id":"0f1b48c7-3a25-4016-83a5-15864d7803ad","title":"Development","vault":{"fsPath":"repos/dendron-aws-vault","remote":{"type":"git","url":"https://github.com/cczhong11/my_note.git"},"name":"my_note"},"type":"note","desc":"","links":[{"from":{"fname":"root","vaultName":"my_note"},"type":"backlink","position":{"start":{"line":8,"column":3,"offset":63},"end":{"line":8,"column":21,"offset":81},"indent":[]},"value":"development"}],"anchors":{},"fname":"development","updated":1618381238346,"created":1612940782409,"parent":null,"children":["400115e9-30f7-4a13-9776-db059bc9cd42","xsX5v3ZsyJ0i6gf9","1bc3b45a-b6f4-4150-87d3-5bd5b6eb8c24","6cea4852-6e7c-4140-b476-85c07b48a642","a40ef849-d301-4d74-a778-e6d9469dfb5d","09d9081f-3dff-453d-8488-7d2344cc8895","92917ea3-452e-48dc-875e-5cd0002041db","2e151826-cb22-4d89-8ce0-71dad7204ce8","baa39444-0da9-4c55-8df7-2a6f8f787fa4","62daf50d-a39e-463f-aabd-be53790281fd","3524d0a7-be73-45d6-847e-c970f5c1c760","eac0f243-05b3-4b95-bec3-848e33edbc40"],"data":{},"custom":{"nav_order":0,"permalink":"/"},"body":"\n","contentHash":"38357962f5a50c6fd7d318dfa66bea90"},"collectionChildren":null,"customHeadContent":null,"config":{"version":4,"useFMTitle":true,"useNoteTitleForLink":true,"mermaid":true,"useKatex":true,"dev":{"previewV2Enabled":false,"enablePreviewV2":true},"site":{"copyAssets":true,"siteHierarchies":["development","life"],"siteRootDir":"docs","usePrettyRefs":true,"title":"my_note","siteUrl":"https://notes.tczhong.com","description":"Personal knowledge space","siteLastModified":true,"gh_edit_branch":"main","usePrettyLinks":true,"siteNotesDir":"notes","siteFaviconPath":"favicon.ico","gh_edit_link":true,"gh_edit_link_text":"Edit this page on GitHub","gh_root":"docs/","gh_edit_view_mode":"edit","writeStubs":true,"siteIndex":"development"},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":false,"leaveTrace":false,"bubbleUpCreateNew":true}},"insertNote":{"initialValue":"templates"},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"randomNote":{}},"workspace":{"dendronVersion":"0.70.0","vaults":[{"fsPath":"repos/dendron-aws-vault","remote":{"type":"git","url":"https://github.com/cczhong11/my_note.git"},"name":"my_note"},{"fsPath":"vault"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"graph":{"zoomSpeed":1},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":true,"maxPreviewsCached":10,"maxNoteLength":204800,"enableUserTags":true,"enableHashTags":true,"task":{"name":"","dateFormat":"","addBehavior":"childOfCurrent","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link"}},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true}}},"__N_SSG":true},"page":"/notes/[id]","query":{"id":"afdca563-1075-4f32-8569-76abb00d833d"},"buildId":"qHbm4vS5s7hFBo6UvcS91","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>