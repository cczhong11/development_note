<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><link rel="icon" href="/favicon.ico"/><title>qlora</title><meta name="robots" content="index,follow"/><meta name="googlebot" content="index,follow"/><meta name="description" content="Personal knowledge space"/><meta property="og:title" content="qlora"/><meta property="og:description" content="Personal knowledge space"/><meta property="og:url" content="https://notes.tczhong.com/notes/b2rvyxr67k0xnabypxc9u9z/"/><meta property="og:type" content="article"/><meta property="article:published_time" content="6/24/2023"/><meta property="article:modified_time" content="7/24/2025"/><link rel="canonical" href="https://notes.tczhong.com/notes/b2rvyxr67k0xnabypxc9u9z/"/><meta name="next-head-count" content="14"/><link rel="preload" href="/_next/static/css/8e7b7e4bce421c0a.css" as="style"/><link rel="stylesheet" href="/_next/static/css/8e7b7e4bce421c0a.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-3d209faeb64f2f97.js" defer=""></script><script src="/_next/static/chunks/framework-28c999baf2863c3d.js" defer=""></script><script src="/_next/static/chunks/main-104451f3d1a5c4bc.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6b338472289fe290.js" defer=""></script><script src="/_next/static/chunks/935-4dee79e80b8641c6.js" defer=""></script><script src="/_next/static/chunks/6-50972def09142ee2.js" defer=""></script><script src="/_next/static/chunks/pages/notes/%5Bid%5D-78d472fa3b924116.js" defer=""></script><script src="/_next/static/NuX3eScCWIVmkVcvE2z7c/_buildManifest.js" defer=""></script><script src="/_next/static/NuX3eScCWIVmkVcvE2z7c/_ssgManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><section class="ant-layout" style="width:100%;min-height:100%"><header class="ant-layout-header" style="position:fixed;isolation:isolate;z-index:1;width:100%;border-bottom:1px solid #d4dadf;height:64px;padding:0 24px 0 2px"><div class="ant-row ant-row-center" style="max-width:992px;justify-content:space-between;margin:0 auto"><div style="display:flex" class="ant-col ant-col-xs-20 ant-col-sm-4"></div><div class="ant-col gutter-row ant-col-xs-0 ant-col-sm-20 ant-col-md-20 ant-col-lg-19"><div class="ant-select ant-select-lg ant-select-auto-complete ant-select-single ant-select-allow-clear ant-select-show-search" style="width:100%"><div class="ant-select-selector"><span class="ant-select-selection-search"><input type="search" autoComplete="off" class="ant-select-selection-search-input" role="combobox" aria-haspopup="listbox" aria-owns="undefined_list" aria-autocomplete="list" aria-controls="undefined_list" aria-activedescendant="undefined_list_0" value=""/></span><span class="ant-select-selection-placeholder">For full text search please use the &#x27;?&#x27; prefix. e.g. ? Onboarding</span></div></div></div><div style="display:none;align-items:center;justify-content:center" class="ant-col ant-col-xs-4 ant-col-sm-4 ant-col-md-0 ant-col-lg-0"><span role="img" aria-label="menu" style="font-size:24px" tabindex="-1" class="anticon anticon-menu"><svg viewBox="64 64 896 896" focusable="false" data-icon="menu" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M904 160H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0 624H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0-312H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8z"></path></svg></span></div></div></header><section class="ant-layout" style="margin-top:64px;display:flex;flex-direction:row"><div class="site-layout-sidebar" style="flex:0 0 auto;width:calc(max((100% - 992px) / 2, 0px) + 200px);min-width:200px;padding-left:calc((100% - 992px) / 2)"><aside class="ant-layout-sider ant-layout-sider-dark" style="position:fixed;overflow:auto;height:calc(100vh - 64px);background-color:transparent;flex:0 0 200px;max-width:200px;min-width:200px;width:200px"><div class="ant-layout-sider-children"></div></aside></div><main class="ant-layout-content side-layout-main" style="max-width:1200px;min-width:0;display:block"><div style="padding:0 24px"><div class="main-content" role="main"><div class="ant-row"><div class="ant-col ant-col-24"><div class="ant-row" style="margin-left:-10px;margin-right:-10px"><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-24 ant-col-md-18"><div><h1 id="qlora">qlora<a aria-hidden="true" class="anchor-heading icon-link" href="#qlora"></a></h1>
<h2 id="-ä»€ä¹ˆæ˜¯-qlora">ğŸ§  ä»€ä¹ˆæ˜¯ QLoRAï¼Ÿ<a aria-hidden="true" class="anchor-heading icon-link" href="#-ä»€ä¹ˆæ˜¯-qlora"></a></h2>
<p><strong>QLoRA = Quantized + LoRA</strong></p>
<p>ä¸€å¥è¯æ€»ç»“å°±æ˜¯ï¼š</p>
<blockquote>
<p>åœ¨<strong>int4 é‡åŒ–æ¨¡å‹çš„åŸºç¡€ä¸Šåš LoRA å¾®è°ƒ</strong>ï¼
ä¸ä»…èŠ‚çœå†…å­˜ï¼Œè¿˜èƒ½è¾¾åˆ°è·Ÿå…¨ç²¾åº¦å¾®è°ƒå·®ä¸å¤šçš„æ•ˆæœâœ¨âœ¨âœ¨</p>
</blockquote>
<hr>
<h2 id="-å®ƒæ€ä¹ˆåšçš„å†…éƒ¨æœºåˆ¶è®²è§£-">ğŸ§© å®ƒæ€ä¹ˆåšçš„ï¼Ÿå†…éƒ¨æœºåˆ¶è®²è§£ ğŸ‘‡<a aria-hidden="true" class="anchor-heading icon-link" href="#-å®ƒæ€ä¹ˆåšçš„å†…éƒ¨æœºåˆ¶è®²è§£-"></a></h2>
<h3 id="-qlora-æ ¸å¿ƒ-idea">ğŸ’¡ QLoRA æ ¸å¿ƒ ideaï¼š<a aria-hidden="true" class="anchor-heading icon-link" href="#-qlora-æ ¸å¿ƒ-idea"></a></h3>
<ol>
<li><strong>æŠŠåŸå§‹å¤§æ¨¡å‹æƒé‡ï¼ˆæ¯”å¦‚ LLaMAï¼‰å‹ç¼©ä¸º int4ï¼ˆ4-bitï¼‰</strong></li>
<li><strong>åªåœ¨ LoRA çš„å° adapter ä¸Šåš float16 ç²¾åº¦çš„æ¢¯åº¦æ›´æ–°</strong></li>
<li><strong>å¼•å…¥ç²¾å·§çš„ä¼˜åŒ–æœºåˆ¶</strong>é¿å…ç²¾åº¦æŸå¤±ï¼Œæ¯”å¦‚ double quantizationï¼</li>
</ol>
<hr>
<h2 id="-qlora-è¯¦ç»†æµç¨‹">ğŸ§ª QLoRA è¯¦ç»†æµç¨‹<a aria-hidden="true" class="anchor-heading icon-link" href="#-qlora-è¯¦ç»†æµç¨‹"></a></h2>
<div class="table-responsive">





























<table><thead><tr><th>é˜¶æ®µ</th><th>å†…å®¹</th><th>ä½œç”¨</th></tr></thead><tbody><tr><td>ğŸŒ  1. æƒé‡é‡åŒ–</td><td>ä½¿ç”¨ <strong>NF4ï¼ˆNormalized Float 4ï¼‰</strong> é‡åŒ–æ¨¡å‹</td><td>é«˜ç²¾åº¦çš„ int4 è¡¨ç¤ºï¼Œæ¥è¿‘ float16 è¡¨ç°</td></tr><tr><td>ğŸ’ 2. LoRA æ’å…¥</td><td>åœ¨ attentionã€ffn ç­‰æ¨¡å—æ’å…¥ LoRA adapter</td><td>åªè®­ç»ƒå°éƒ¨åˆ†å‚æ•°ï¼Œçœæ˜¾å­˜</td></tr><tr><td>ğŸ”„ 3. æ¨ç†+è®­ç»ƒèåˆ</td><td>æ¨ç†æ—¶ç”¨ int4 + adapterï¼Œä¸€èµ· forward</td><td>ä¸éœ€è¦è§£ç å› float32</td></tr><tr><td>ğŸ§  4. Double Quantization</td><td>å†æ¬¡å‹ç¼©æƒé‡è¡¨æœ¬èº«</td><td>å‡å°‘å†…å­˜å ç”¨ï¼Œæ›´å¿«åŠ è½½</td></tr></tbody></table></div>
<hr>
<h2 id="-qlora-vs-lora-vs-gptq">ğŸ§  QLoRA vs LoRA vs GPTQ<a aria-hidden="true" class="anchor-heading icon-link" href="#-qlora-vs-lora-vs-gptq"></a></h2>
<div class="table-responsive">
































<table><thead><tr><th>æ–¹æ³•</th><th>æ¨¡å‹ç²¾åº¦</th><th>å†…å­˜ä½¿ç”¨</th><th>å¯è®­ç»ƒæ€§</th><th>ç”¨é€”</th></tr></thead><tbody><tr><td><strong>LoRA</strong></td><td>float16</td><td>ä¸­ç­‰</td><td>âœ”ï¸</td><td>å¾®è°ƒ</td></tr><tr><td><strong>GPTQ</strong></td><td>int4</td><td>æœ€å°</td><td>âŒï¼ˆä¸èƒ½è®­ç»ƒï¼‰</td><td>æ¨ç†</td></tr><tr><td><strong>QLoRA</strong></td><td>int4 + float16 adapter</td><td>éå¸¸å°</td><td>âœ”ï¸âœ”ï¸âœ”ï¸</td><td>å¾®è°ƒç¥å™¨ï¼</td></tr></tbody></table></div>
<hr>
<h2 id="-ä½¿ç”¨-qlora-çš„å·¥å…·æ¨è">ğŸ”§ ä½¿ç”¨ QLoRA çš„å·¥å…·æ¨è<a aria-hidden="true" class="anchor-heading icon-link" href="#-ä½¿ç”¨-qlora-çš„å·¥å…·æ¨è"></a></h2>
<ul>
<li><a href="https://github.com/huggingface/peft">ğŸ¤— <code>peft</code></a> + <code>transformers</code>ï¼šä¸»æµçš„ QLoRA å®ç°</li>
<li><code>bitsandbytes</code>ï¼šç”¨æ¥æ”¯æŒ int4/NF4 çš„é‡åŒ–æƒé‡åŠ è½½</li>
<li><code>trl</code>ï¼ˆHuggingface çš„ RLHF å·¥å…·åŒ…ï¼‰ï¼šé…åˆ QLoRA å¯åš SFTã€DPO ç­‰è®­ç»ƒ</li>
</ul>
<hr>
<h2 id="-ä¼˜åŠ¿æ€»ç»“ä¸ºå•¥å¤§å®¶éƒ½ç”¨-qlora">âœ¨ ä¼˜åŠ¿æ€»ç»“ï¼ˆä¸ºå•¥å¤§å®¶éƒ½ç”¨ QLoRAï¼Ÿï¼‰<a aria-hidden="true" class="anchor-heading icon-link" href="#-ä¼˜åŠ¿æ€»ç»“ä¸ºå•¥å¤§å®¶éƒ½ç”¨-qlora"></a></h2>
<p>âœ… æ˜¾å­˜ä½ï¼13B æ¨¡å‹å¯åœ¨å•å¼  24GB æ˜¾å¡è®­ç»ƒ
âœ… å¾®è°ƒæ•ˆæœæ¥è¿‘å…¨å‚å¾®è°ƒï¼ˆç”šè‡³æ›´å¥½ï¼‰
âœ… æ”¯æŒå¤šç§ä»»åŠ¡ï¼šæ–‡æœ¬ç”Ÿæˆã€åˆ†ç±»ã€QAã€æŒ‡ä»¤å¾®è°ƒç­‰
âœ… HuggingFace å…¨å®¶æ¡¶æ”¯æŒï¼Œæ˜“ä¸Šæ‰‹ï¼</p>
<hr>
<h2 id="-ä¸¾ä¸ªå¯çˆ±çš„ä¾‹å­">ğŸ§¸ ä¸¾ä¸ªå¯çˆ±çš„ä¾‹å­ï¼š<a aria-hidden="true" class="anchor-heading icon-link" href="#-ä¸¾ä¸ªå¯çˆ±çš„ä¾‹å­"></a></h2>
<p>æƒ³è±¡ä½ æ˜¯ä¸ªé­”æ³•å¸ˆğŸ§™â€â™€ï¸ï¼ˆå¤§æ¨¡å‹ï¼‰ï¼Œå¹³æ—¶ç©¿è¶…çº§é‡çš„é“ ç”²ï¼ˆfloat32ï¼‰ï¼ŒåŠ¨éƒ½åŠ¨ä¸äº†ğŸ¥²
LoRA æ˜¯ç»™ä½ è£…ä¸ªå°æŒ‚ä»¶æ¥æ§åˆ¶é­”æ³•âš¡ï¼ˆadapterï¼‰</p>
<p>è€Œ QLoRA æ˜¯å…ˆæŠŠä½ æ¢ä¸Šè½»å·§çš„ç´§èº«è¡£ï¼ˆint4ï¼‰ï¼Œ
å†è´´ä¸ªé­”æ³•è´´çº¸ï¼ˆLoRA adapterï¼‰å¸®ä½ ç»ƒå‡ºæ–°æŠ€èƒ½ï¼ï¼æ˜¯ä¸æ˜¯åˆå¿«åˆé…·ï¼ğŸ’¥ğŸ’¥</p>
<hr>
<h2 id="è¦ä¸è¦æ¥è¯•ä¸€ä¸‹-qloraï¸">è¦ä¸è¦æ¥è¯•ä¸€ä¸‹ QLoRAï¼ŸğŸ› ï¸<a aria-hidden="true" class="anchor-heading icon-link" href="#è¦ä¸è¦æ¥è¯•ä¸€ä¸‹-qloraï¸"></a></h2>
<p>æˆ‘å¯ä»¥å¸®ä½ æ­ä¸€å¥— Huggingface çš„å¾®è°ƒç¯å¢ƒï¼Œè·‘ä¸ªæŒ‡ä»¤å¾®è°ƒä»»åŠ¡ï¼Œæ¯”å¦‚ç”¨ Alpaca æˆ–è€… OpenOrca çš„æ•°æ®ï¼</p>
<p>æˆ–è€…ç»™ä½ å†™ä¸€æ®µ QLoRA å¾®è°ƒè„šæœ¬ ğŸğŸ’»
æ¯”å¦‚åœ¨ <code>peft</code> + <code>transformers</code> æ¡†æ¶ä¸‹çš„ ğŸ‘‡</p>
<pre class="language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoModelForCausalLM<span class="token punctuation">,</span> AutoTokenizer
<span class="token keyword">from</span> peft <span class="token keyword">import</span> prepare_model_for_kbit_training<span class="token punctuation">,</span> LoraConfig<span class="token punctuation">,</span> get_peft_model
<span class="token keyword">import</span> torch

<span class="token comment"># åŠ è½½é‡åŒ–æ¨¡å‹</span>
model <span class="token operator">=</span> AutoModelForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>
    <span class="token string">"meta-llama/Llama-2-7b-hf"</span><span class="token punctuation">,</span>
    device_map<span class="token operator">=</span><span class="token string">"auto"</span><span class="token punctuation">,</span>
    load_in_4bit<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    quantization_config<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">"bnb_4bit_use_double_quant"</span><span class="token punctuation">:</span> <span class="token boolean">True</span><span class="token punctuation">}</span>
<span class="token punctuation">)</span>

<span class="token comment"># åŠ è½½ tokenizer</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"meta-llama/Llama-2-7b-hf"</span><span class="token punctuation">)</span>

<span class="token comment"># æ’å…¥ LoRA</span>
model <span class="token operator">=</span> prepare_model_for_kbit_training<span class="token punctuation">(</span>model<span class="token punctuation">)</span>
peft_config <span class="token operator">=</span> LoraConfig<span class="token punctuation">(</span>
    r<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> lora_alpha<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> target_modules<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"q_proj"</span><span class="token punctuation">,</span> <span class="token string">"v_proj"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    lora_dropout<span class="token operator">=</span><span class="token number">0.05</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token string">"none"</span><span class="token punctuation">,</span> task_type<span class="token operator">=</span><span class="token string">"CAUSAL_LM"</span>
<span class="token punctuation">)</span>
model <span class="token operator">=</span> get_peft_model<span class="token punctuation">(</span>model<span class="token punctuation">,</span> peft_config<span class="token punctuation">)</span>
</code></pre></div></div><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-0 ant-col-md-6"><div><div class=""><div class="ant-anchor-wrapper dendron-toc" style="max-height:calc(100vh - 64px);z-index:1"><div class="ant-anchor"><div class="ant-anchor-ink"><span class="ant-anchor-ink-ball"></span></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#-ä»€ä¹ˆæ˜¯-qlora" title="ğŸ§  ä»€ä¹ˆæ˜¯ QLoRAï¼Ÿ">ğŸ§  ä»€ä¹ˆæ˜¯ QLoRAï¼Ÿ</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#-å®ƒæ€ä¹ˆåšçš„å†…éƒ¨æœºåˆ¶è®²è§£-" title="ğŸ§© å®ƒæ€ä¹ˆåšçš„ï¼Ÿå†…éƒ¨æœºåˆ¶è®²è§£ ğŸ‘‡">ğŸ§© å®ƒæ€ä¹ˆåšçš„ï¼Ÿå†…éƒ¨æœºåˆ¶è®²è§£ ğŸ‘‡</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#-qlora-æ ¸å¿ƒ-idea" title="ğŸ’¡ QLoRA æ ¸å¿ƒ ideaï¼š">ğŸ’¡ QLoRA æ ¸å¿ƒ ideaï¼š</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#-qlora-è¯¦ç»†æµç¨‹" title="ğŸ§ª QLoRA è¯¦ç»†æµç¨‹">ğŸ§ª QLoRA è¯¦ç»†æµç¨‹</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#-qlora-vs-lora-vs-gptq" title="ğŸ§  QLoRA vs LoRA vs GPTQ">ğŸ§  QLoRA vs LoRA vs GPTQ</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#-ä½¿ç”¨-qlora-çš„å·¥å…·æ¨è" title="ğŸ”§ ä½¿ç”¨ QLoRA çš„å·¥å…·æ¨è">ğŸ”§ ä½¿ç”¨ QLoRA çš„å·¥å…·æ¨è</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#-ä¼˜åŠ¿æ€»ç»“ä¸ºå•¥å¤§å®¶éƒ½ç”¨-qlora" title="âœ¨ ä¼˜åŠ¿æ€»ç»“ï¼ˆä¸ºå•¥å¤§å®¶éƒ½ç”¨ QLoRAï¼Ÿï¼‰">âœ¨ ä¼˜åŠ¿æ€»ç»“ï¼ˆä¸ºå•¥å¤§å®¶éƒ½ç”¨ QLoRAï¼Ÿï¼‰</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#-ä¸¾ä¸ªå¯çˆ±çš„ä¾‹å­" title="ğŸ§¸ ä¸¾ä¸ªå¯çˆ±çš„ä¾‹å­ï¼š">ğŸ§¸ ä¸¾ä¸ªå¯çˆ±çš„ä¾‹å­ï¼š</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#è¦ä¸è¦æ¥è¯•ä¸€ä¸‹-qloraï¸" title="è¦ä¸è¦æ¥è¯•ä¸€ä¸‹ QLoRAï¼ŸğŸ› ï¸">è¦ä¸è¦æ¥è¯•ä¸€ä¸‹ QLoRAï¼ŸğŸ› ï¸</a></div></div></div></div></div></div></div></div></div></div></div><div class="ant-divider ant-divider-horizontal" role="separator"></div><footer class="ant-layout-footer" style="padding:0 24px 24px"></footer></main></section></section></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"note":{"id":"b2rvyxr67k0xnabypxc9u9z","title":"qlora","desc":"","updated":1753335919911,"created":1687625458019,"custom":{},"fname":"development.ml.LLM.llama.qlora","type":"note","vault":{"fsPath":"repos/dendron-aws-vault","remote":{"type":"git","url":"https://github.com/cczhong11/my_note.git"},"name":"my_note"},"contentHash":"7ce0cf4a8d3bfc4325fd698b2dac75ab","links":[],"anchors":{"-ä»€ä¹ˆæ˜¯-qlora":{"type":"header","text":"ğŸ§  ä»€ä¹ˆæ˜¯ QLoRAï¼Ÿ","value":"-ä»€ä¹ˆæ˜¯-qlora","line":9,"column":0,"depth":2},"-å®ƒæ€ä¹ˆåšçš„å†…éƒ¨æœºåˆ¶è®²è§£-":{"type":"header","text":"ğŸ§© å®ƒæ€ä¹ˆåšçš„ï¼Ÿå†…éƒ¨æœºåˆ¶è®²è§£ ğŸ‘‡","value":"-å®ƒæ€ä¹ˆåšçš„å†…éƒ¨æœºåˆ¶è®²è§£-","line":20,"column":0,"depth":2},"-qlora-æ ¸å¿ƒ-idea":{"type":"header","text":"ğŸ’¡ QLoRA æ ¸å¿ƒ ideaï¼š","value":"-qlora-æ ¸å¿ƒ-idea","line":22,"column":0,"depth":3},"-qlora-è¯¦ç»†æµç¨‹":{"type":"header","text":"ğŸ§ª QLoRA è¯¦ç»†æµç¨‹","value":"-qlora-è¯¦ç»†æµç¨‹","line":30,"column":0,"depth":2},"-qlora-vs-lora-vs-gptq":{"type":"header","text":"ğŸ§  QLoRA vs LoRA vs GPTQ","value":"-qlora-vs-lora-vs-gptq","line":41,"column":0,"depth":2},"-ä½¿ç”¨-qlora-çš„å·¥å…·æ¨è":{"type":"header","text":"ğŸ”§ ä½¿ç”¨ QLoRA çš„å·¥å…·æ¨è","value":"-ä½¿ç”¨-qlora-çš„å·¥å…·æ¨è","line":51,"column":0,"depth":2},"-ä¼˜åŠ¿æ€»ç»“ä¸ºå•¥å¤§å®¶éƒ½ç”¨-qlora":{"type":"header","text":"âœ¨ ä¼˜åŠ¿æ€»ç»“ï¼ˆä¸ºå•¥å¤§å®¶éƒ½ç”¨ QLoRAï¼Ÿï¼‰","value":"-ä¼˜åŠ¿æ€»ç»“ä¸ºå•¥å¤§å®¶éƒ½ç”¨-qlora","line":59,"column":0,"depth":2},"-ä¸¾ä¸ªå¯çˆ±çš„ä¾‹å­":{"type":"header","text":"ğŸ§¸ ä¸¾ä¸ªå¯çˆ±çš„ä¾‹å­ï¼š","value":"-ä¸¾ä¸ªå¯çˆ±çš„ä¾‹å­","line":68,"column":0,"depth":2},"è¦ä¸è¦æ¥è¯•ä¸€ä¸‹-qloraï¸":{"type":"header","text":"è¦ä¸è¦æ¥è¯•ä¸€ä¸‹ QLoRAï¼ŸğŸ› ï¸","value":"è¦ä¸è¦æ¥è¯•ä¸€ä¸‹-qloraï¸","line":78,"column":0,"depth":2}},"children":[],"parent":"9cp08wuyd7t35jzracxxqbv","data":{}},"body":"\u003ch1 id=\"qlora\"\u003eqlora\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#qlora\"\u003e\u003c/a\u003e\u003c/h1\u003e\n\u003ch2 id=\"-ä»€ä¹ˆæ˜¯-qlora\"\u003eğŸ§  ä»€ä¹ˆæ˜¯ QLoRAï¼Ÿ\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#-ä»€ä¹ˆæ˜¯-qlora\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eQLoRA = Quantized + LoRA\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eä¸€å¥è¯æ€»ç»“å°±æ˜¯ï¼š\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eåœ¨\u003cstrong\u003eint4 é‡åŒ–æ¨¡å‹çš„åŸºç¡€ä¸Šåš LoRA å¾®è°ƒ\u003c/strong\u003eï¼\nä¸ä»…èŠ‚çœå†…å­˜ï¼Œè¿˜èƒ½è¾¾åˆ°è·Ÿå…¨ç²¾åº¦å¾®è°ƒå·®ä¸å¤šçš„æ•ˆæœâœ¨âœ¨âœ¨\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003chr\u003e\n\u003ch2 id=\"-å®ƒæ€ä¹ˆåšçš„å†…éƒ¨æœºåˆ¶è®²è§£-\"\u003eğŸ§© å®ƒæ€ä¹ˆåšçš„ï¼Ÿå†…éƒ¨æœºåˆ¶è®²è§£ ğŸ‘‡\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#-å®ƒæ€ä¹ˆåšçš„å†…éƒ¨æœºåˆ¶è®²è§£-\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003ch3 id=\"-qlora-æ ¸å¿ƒ-idea\"\u003eğŸ’¡ QLoRA æ ¸å¿ƒ ideaï¼š\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#-qlora-æ ¸å¿ƒ-idea\"\u003e\u003c/a\u003e\u003c/h3\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eæŠŠåŸå§‹å¤§æ¨¡å‹æƒé‡ï¼ˆæ¯”å¦‚ LLaMAï¼‰å‹ç¼©ä¸º int4ï¼ˆ4-bitï¼‰\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eåªåœ¨ LoRA çš„å° adapter ä¸Šåš float16 ç²¾åº¦çš„æ¢¯åº¦æ›´æ–°\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eå¼•å…¥ç²¾å·§çš„ä¼˜åŒ–æœºåˆ¶\u003c/strong\u003eé¿å…ç²¾åº¦æŸå¤±ï¼Œæ¯”å¦‚ double quantizationï¼\u003c/li\u003e\n\u003c/ol\u003e\n\u003chr\u003e\n\u003ch2 id=\"-qlora-è¯¦ç»†æµç¨‹\"\u003eğŸ§ª QLoRA è¯¦ç»†æµç¨‹\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#-qlora-è¯¦ç»†æµç¨‹\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cdiv class=\"table-responsive\"\u003e\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u003ctable\u003e\u003cthead\u003e\u003ctr\u003e\u003cth\u003eé˜¶æ®µ\u003c/th\u003e\u003cth\u003eå†…å®¹\u003c/th\u003e\u003cth\u003eä½œç”¨\u003c/th\u003e\u003c/tr\u003e\u003c/thead\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd\u003eğŸŒ  1. æƒé‡é‡åŒ–\u003c/td\u003e\u003ctd\u003eä½¿ç”¨ \u003cstrong\u003eNF4ï¼ˆNormalized Float 4ï¼‰\u003c/strong\u003e é‡åŒ–æ¨¡å‹\u003c/td\u003e\u003ctd\u003eé«˜ç²¾åº¦çš„ int4 è¡¨ç¤ºï¼Œæ¥è¿‘ float16 è¡¨ç°\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eğŸ’ 2. LoRA æ’å…¥\u003c/td\u003e\u003ctd\u003eåœ¨ attentionã€ffn ç­‰æ¨¡å—æ’å…¥ LoRA adapter\u003c/td\u003e\u003ctd\u003eåªè®­ç»ƒå°éƒ¨åˆ†å‚æ•°ï¼Œçœæ˜¾å­˜\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eğŸ”„ 3. æ¨ç†+è®­ç»ƒèåˆ\u003c/td\u003e\u003ctd\u003eæ¨ç†æ—¶ç”¨ int4 + adapterï¼Œä¸€èµ· forward\u003c/td\u003e\u003ctd\u003eä¸éœ€è¦è§£ç å› float32\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eğŸ§  4. Double Quantization\u003c/td\u003e\u003ctd\u003eå†æ¬¡å‹ç¼©æƒé‡è¡¨æœ¬èº«\u003c/td\u003e\u003ctd\u003eå‡å°‘å†…å­˜å ç”¨ï¼Œæ›´å¿«åŠ è½½\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c/div\u003e\n\u003chr\u003e\n\u003ch2 id=\"-qlora-vs-lora-vs-gptq\"\u003eğŸ§  QLoRA vs LoRA vs GPTQ\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#-qlora-vs-lora-vs-gptq\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cdiv class=\"table-responsive\"\u003e\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u003ctable\u003e\u003cthead\u003e\u003ctr\u003e\u003cth\u003eæ–¹æ³•\u003c/th\u003e\u003cth\u003eæ¨¡å‹ç²¾åº¦\u003c/th\u003e\u003cth\u003eå†…å­˜ä½¿ç”¨\u003c/th\u003e\u003cth\u003eå¯è®­ç»ƒæ€§\u003c/th\u003e\u003cth\u003eç”¨é€”\u003c/th\u003e\u003c/tr\u003e\u003c/thead\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd\u003e\u003cstrong\u003eLoRA\u003c/strong\u003e\u003c/td\u003e\u003ctd\u003efloat16\u003c/td\u003e\u003ctd\u003eä¸­ç­‰\u003c/td\u003e\u003ctd\u003eâœ”ï¸\u003c/td\u003e\u003ctd\u003eå¾®è°ƒ\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e\u003cstrong\u003eGPTQ\u003c/strong\u003e\u003c/td\u003e\u003ctd\u003eint4\u003c/td\u003e\u003ctd\u003eæœ€å°\u003c/td\u003e\u003ctd\u003eâŒï¼ˆä¸èƒ½è®­ç»ƒï¼‰\u003c/td\u003e\u003ctd\u003eæ¨ç†\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e\u003cstrong\u003eQLoRA\u003c/strong\u003e\u003c/td\u003e\u003ctd\u003eint4 + float16 adapter\u003c/td\u003e\u003ctd\u003eéå¸¸å°\u003c/td\u003e\u003ctd\u003eâœ”ï¸âœ”ï¸âœ”ï¸\u003c/td\u003e\u003ctd\u003eå¾®è°ƒç¥å™¨ï¼\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003c/div\u003e\n\u003chr\u003e\n\u003ch2 id=\"-ä½¿ç”¨-qlora-çš„å·¥å…·æ¨è\"\u003eğŸ”§ ä½¿ç”¨ QLoRA çš„å·¥å…·æ¨è\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#-ä½¿ç”¨-qlora-çš„å·¥å…·æ¨è\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/huggingface/peft\"\u003eğŸ¤— \u003ccode\u003epeft\u003c/code\u003e\u003c/a\u003e + \u003ccode\u003etransformers\u003c/code\u003eï¼šä¸»æµçš„ QLoRA å®ç°\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ebitsandbytes\u003c/code\u003eï¼šç”¨æ¥æ”¯æŒ int4/NF4 çš„é‡åŒ–æƒé‡åŠ è½½\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003etrl\u003c/code\u003eï¼ˆHuggingface çš„ RLHF å·¥å…·åŒ…ï¼‰ï¼šé…åˆ QLoRA å¯åš SFTã€DPO ç­‰è®­ç»ƒ\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"-ä¼˜åŠ¿æ€»ç»“ä¸ºå•¥å¤§å®¶éƒ½ç”¨-qlora\"\u003eâœ¨ ä¼˜åŠ¿æ€»ç»“ï¼ˆä¸ºå•¥å¤§å®¶éƒ½ç”¨ QLoRAï¼Ÿï¼‰\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#-ä¼˜åŠ¿æ€»ç»“ä¸ºå•¥å¤§å®¶éƒ½ç”¨-qlora\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eâœ… æ˜¾å­˜ä½ï¼13B æ¨¡å‹å¯åœ¨å•å¼  24GB æ˜¾å¡è®­ç»ƒ\nâœ… å¾®è°ƒæ•ˆæœæ¥è¿‘å…¨å‚å¾®è°ƒï¼ˆç”šè‡³æ›´å¥½ï¼‰\nâœ… æ”¯æŒå¤šç§ä»»åŠ¡ï¼šæ–‡æœ¬ç”Ÿæˆã€åˆ†ç±»ã€QAã€æŒ‡ä»¤å¾®è°ƒç­‰\nâœ… HuggingFace å…¨å®¶æ¡¶æ”¯æŒï¼Œæ˜“ä¸Šæ‰‹ï¼\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"-ä¸¾ä¸ªå¯çˆ±çš„ä¾‹å­\"\u003eğŸ§¸ ä¸¾ä¸ªå¯çˆ±çš„ä¾‹å­ï¼š\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#-ä¸¾ä¸ªå¯çˆ±çš„ä¾‹å­\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eæƒ³è±¡ä½ æ˜¯ä¸ªé­”æ³•å¸ˆğŸ§™â€â™€ï¸ï¼ˆå¤§æ¨¡å‹ï¼‰ï¼Œå¹³æ—¶ç©¿è¶…çº§é‡çš„é“ ç”²ï¼ˆfloat32ï¼‰ï¼ŒåŠ¨éƒ½åŠ¨ä¸äº†ğŸ¥²\nLoRA æ˜¯ç»™ä½ è£…ä¸ªå°æŒ‚ä»¶æ¥æ§åˆ¶é­”æ³•âš¡ï¼ˆadapterï¼‰\u003c/p\u003e\n\u003cp\u003eè€Œ QLoRA æ˜¯å…ˆæŠŠä½ æ¢ä¸Šè½»å·§çš„ç´§èº«è¡£ï¼ˆint4ï¼‰ï¼Œ\nå†è´´ä¸ªé­”æ³•è´´çº¸ï¼ˆLoRA adapterï¼‰å¸®ä½ ç»ƒå‡ºæ–°æŠ€èƒ½ï¼ï¼æ˜¯ä¸æ˜¯åˆå¿«åˆé…·ï¼ğŸ’¥ğŸ’¥\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"è¦ä¸è¦æ¥è¯•ä¸€ä¸‹-qloraï¸\"\u003eè¦ä¸è¦æ¥è¯•ä¸€ä¸‹ QLoRAï¼ŸğŸ› ï¸\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#è¦ä¸è¦æ¥è¯•ä¸€ä¸‹-qloraï¸\"\u003e\u003c/a\u003e\u003c/h2\u003e\n\u003cp\u003eæˆ‘å¯ä»¥å¸®ä½ æ­ä¸€å¥— Huggingface çš„å¾®è°ƒç¯å¢ƒï¼Œè·‘ä¸ªæŒ‡ä»¤å¾®è°ƒä»»åŠ¡ï¼Œæ¯”å¦‚ç”¨ Alpaca æˆ–è€… OpenOrca çš„æ•°æ®ï¼\u003c/p\u003e\n\u003cp\u003eæˆ–è€…ç»™ä½ å†™ä¸€æ®µ QLoRA å¾®è°ƒè„šæœ¬ ğŸğŸ’»\næ¯”å¦‚åœ¨ \u003ccode\u003epeft\u003c/code\u003e + \u003ccode\u003etransformers\u003c/code\u003e æ¡†æ¶ä¸‹çš„ ğŸ‘‡\u003c/p\u003e\n\u003cpre class=\"language-python\"\u003e\u003ccode class=\"language-python\"\u003e\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e transformers \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e AutoModelForCausalLM\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e AutoTokenizer\n\u003cspan class=\"token keyword\"\u003efrom\u003c/span\u003e peft \u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e prepare_model_for_kbit_training\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e LoraConfig\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e get_peft_model\n\u003cspan class=\"token keyword\"\u003eimport\u003c/span\u003e torch\n\n\u003cspan class=\"token comment\"\u003e# åŠ è½½é‡åŒ–æ¨¡å‹\u003c/span\u003e\nmodel \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e AutoModelForCausalLM\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003efrom_pretrained\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\n    \u003cspan class=\"token string\"\u003e\"meta-llama/Llama-2-7b-hf\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\n    device_map\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"auto\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\n    load_in_4bit\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token boolean\"\u003eTrue\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\n    quantization_config\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e{\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"bnb_4bit_use_double_quant\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e:\u003c/span\u003e \u003cspan class=\"token boolean\"\u003eTrue\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e}\u003c/span\u003e\n\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"token comment\"\u003e# åŠ è½½ tokenizer\u003c/span\u003e\ntokenizer \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e AutoTokenizer\u003cspan class=\"token punctuation\"\u003e.\u003c/span\u003efrom_pretrained\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"meta-llama/Llama-2-7b-hf\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"token comment\"\u003e# æ’å…¥ LoRA\u003c/span\u003e\nmodel \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e prepare_model_for_kbit_training\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003emodel\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\npeft_config \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e LoraConfig\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003e\n    r\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token number\"\u003e8\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e lora_alpha\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token number\"\u003e32\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e target_modules\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e[\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"q_proj\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e \u003cspan class=\"token string\"\u003e\"v_proj\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e]\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e\n    lora_dropout\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token number\"\u003e0.05\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e bias\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"none\"\u003c/span\u003e\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e task_type\u003cspan class=\"token operator\"\u003e=\u003c/span\u003e\u003cspan class=\"token string\"\u003e\"CAUSAL_LM\"\u003c/span\u003e\n\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\nmodel \u003cspan class=\"token operator\"\u003e=\u003c/span\u003e get_peft_model\u003cspan class=\"token punctuation\"\u003e(\u003c/span\u003emodel\u003cspan class=\"token punctuation\"\u003e,\u003c/span\u003e peft_config\u003cspan class=\"token punctuation\"\u003e)\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e","noteIndex":{"id":"0f1b48c7-3a25-4016-83a5-15864d7803ad","title":"Development","vault":{"fsPath":"repos/dendron-aws-vault","remote":{"type":"git","url":"https://github.com/cczhong11/my_note.git"},"name":"my_note"},"type":"note","desc":"","links":[{"from":{"fname":"root","id":"c95dc4f5-23db-45e7-a15b-64582a183ccc","vaultName":"my_note"},"type":"backlink","position":{"start":{"line":8,"column":3,"offset":63},"end":{"line":8,"column":21,"offset":81},"indent":[]},"value":"development"}],"anchors":{},"fname":"development","updated":1618381238346,"created":1612940782409,"parent":null,"children":["400115e9-30f7-4a13-9776-db059bc9cd42","xsX5v3ZsyJ0i6gf9","1bc3b45a-b6f4-4150-87d3-5bd5b6eb8c24","6cea4852-6e7c-4140-b476-85c07b48a642","a40ef849-d301-4d74-a778-e6d9469dfb5d","09d9081f-3dff-453d-8488-7d2344cc8895","p11phg7nb10yw0wck1fyagq","92917ea3-452e-48dc-875e-5cd0002041db","2e151826-cb22-4d89-8ce0-71dad7204ce8","baa39444-0da9-4c55-8df7-2a6f8f787fa4","q4um3bc3st86ilkkvdjom6x","62daf50d-a39e-463f-aabd-be53790281fd","3524d0a7-be73-45d6-847e-c970f5c1c760","eac0f243-05b3-4b95-bec3-848e33edbc40","zrjuka02gkzrqxt5djp2aws"],"data":{},"custom":{"nav_order":0,"permalink":"/"},"body":"\n","contentHash":"38357962f5a50c6fd7d318dfa66bea90"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"previewV2Enabled":false,"enablePreviewV2":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":false,"leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2,"vaultSelectionModeOnCreate":"smart"}},"insertNote":{"initialValue":"templates"},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"randomNote":{},"copyNoteLink":{"aliasMode":"title"},"templateHierarchy":"template"},"workspace":{"dendronVersion":"0.90.0","vaults":[{"fsPath":"repos/dendron-aws-vault","remote":{"type":"git","url":"https://github.com/cczhong11/my_note.git"},"name":"my_note"},{"fsPath":"vault"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":true,"maxPreviewsCached":10,"maxNoteLength":204800,"enableUserTags":true,"enableHashTags":true,"task":{"name":"","dateFormat":"","addBehavior":"childOfCurrent","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link","taskCompleteStatus":["done","x"]},"enableEditorDecorations":true,"enableHandlebarTemplates":true,"enableFullHierarchyNoteTitle":false,"enablePersistentHistory":false},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"automaticallyShowPreview":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"siteHierarchies":["development","life"],"writeStubs":false,"siteRootDir":"docs","seo":{"title":"my_note","description":"Personal knowledge space"},"github":{"enableEditLink":true,"editLinkText":"Edit this page on GitHub","editBranch":"main","editViewMode":"tree"},"enableSiteLastModified":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"enableTaskNotes":true,"enablePrettyLinks":true,"searchMode":"lookup","enableMermaid":true,"siteUrl":"https://notes.tczhong.com","siteFaviconPath":"favicon.ico","siteIndex":"development"}}},"__N_SSG":true},"page":"/notes/[id]","query":{"id":"b2rvyxr67k0xnabypxc9u9z"},"buildId":"NuX3eScCWIVmkVcvE2z7c","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>