<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><link rel="icon" href="/favicon.ico"/><title>Filesystem</title><meta name="robots" content="index,follow"/><meta name="googlebot" content="index,follow"/><meta name="description" content="Personal knowledge space"/><meta property="og:title" content="Filesystem"/><meta property="og:description" content="Personal knowledge space"/><meta property="og:url" content="https://notes.tczhong.com/notes/1f47041a-df34-437a-9e59-c4ed0fd44232/"/><meta property="og:type" content="article"/><meta property="article:published_time" content="4/13/2021"/><meta property="article:modified_time" content="4/13/2021"/><link rel="canonical" href="https://notes.tczhong.com/notes/1f47041a-df34-437a-9e59-c4ed0fd44232/"/><meta name="next-head-count" content="14"/><link rel="preload" href="/_next/static/css/cc2307f6fd3a2fec.css" as="style"/><link rel="stylesheet" href="/_next/static/css/cc2307f6fd3a2fec.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-12bed1ba7c2cb43d.js" defer=""></script><script src="/_next/static/chunks/framework-bb5c596eafb42b22.js" defer=""></script><script src="/_next/static/chunks/main-c4b0e551a2150d17.js" defer=""></script><script src="/_next/static/chunks/pages/_app-590e5781c8a45815.js" defer=""></script><script src="/_next/static/chunks/155-3a6c02d7e042edb7.js" defer=""></script><script src="/_next/static/chunks/373-9c38fabb487d5920.js" defer=""></script><script src="/_next/static/chunks/pages/notes/%5Bid%5D-b20175c77adb354a.js" defer=""></script><script src="/_next/static/UUJdio6C3W6Tdvs3lwZ8T/_buildManifest.js" defer=""></script><script src="/_next/static/UUJdio6C3W6Tdvs3lwZ8T/_ssgManifest.js" defer=""></script><script src="/_next/static/UUJdio6C3W6Tdvs3lwZ8T/_middlewareManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><section class="ant-layout" style="width:100%;min-height:100%"><header class="ant-layout-header" style="position:fixed;isolation:isolate;z-index:1;width:100%;border-bottom:1px solid #d4dadf;height:64px;padding:0 24px 0 2px"><div class="ant-row ant-row-center" style="max-width:992px;justify-content:space-between;margin:0 auto"><div style="display:flex" class="ant-col ant-col-xs-20 ant-col-sm-4"></div><div class="ant-col gutter-row ant-col-xs-0 ant-col-sm-20 ant-col-md-20 ant-col-lg-19"><div class="ant-select ant-select-lg ant-select-auto-complete ant-select-single ant-select-allow-clear ant-select-show-search" style="width:100%"><div class="ant-select-selector"><span class="ant-select-selection-search"><input type="search" autoComplete="off" class="ant-select-selection-search-input" role="combobox" aria-haspopup="listbox" aria-owns="undefined_list" aria-autocomplete="list" aria-controls="undefined_list" aria-activedescendant="undefined_list_0" value=""/></span><span class="ant-select-selection-placeholder">For full text search please use the &#x27;?&#x27; prefix. e.g. ? Onboarding</span></div></div></div><div style="display:none;align-items:center;justify-content:center" class="ant-col ant-col-xs-4 ant-col-sm-4 ant-col-md-0 ant-col-lg-0"><span role="img" aria-label="menu" style="font-size:24px" tabindex="-1" class="anticon anticon-menu"><svg viewBox="64 64 896 896" focusable="false" data-icon="menu" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M904 160H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0 624H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0-312H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8z"></path></svg></span></div></div></header><section class="ant-layout site-layout" style="margin-top:64px"><section class="ant-layout site-layout" style="flex-direction:row"><section class="ant-layout site-layout-sidebar" style="flex:0 0 auto;width:calc(max((100% - 992px) / 2, 0px) + 200px);min-width:200px;padding-left:calc((100% - 992px) / 2)"><aside class="ant-layout-sider ant-layout-sider-dark" style="position:fixed;overflow:auto;height:calc(100vh - 64px);flex:0 0 200px;max-width:200px;min-width:200px;width:200px"><div class="ant-layout-sider-children"></div></aside></section><section class="ant-layout side-layout-main" style="max-width:1200px;display:initial"><main class="ant-layout-content main-content" role="main" style="padding:0 24px"><div class="ant-row"><div class="ant-col ant-col-24"><div class="ant-row" style="margin-left:-10px;margin-right:-10px"><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-24 ant-col-md-18"><div><h1 id="filesystem"><a aria-hidden="true" class="anchor-heading icon-link" href="#filesystem"></a>Filesystem</h1>
<h1 id="file-system"><a aria-hidden="true" class="anchor-heading icon-link" href="#file-system"></a>file system</h1>
<ul>
<li><strong>what</strong>: a file is a unit of data organized by user. a service responsible for managing files</li>
<li><strong>why</strong>: key is robust and high-throughput</li>
<li><strong>how</strong>: name, access, physical allocation, security and protection, resource administration.</li>
</ul>
<h2 id="nfs-and-afs"><a aria-hidden="true" class="anchor-heading icon-link" href="#nfs-and-afs"></a>NFS and AFS</h2>
<ol>
<li>NFS has no client caching, cliented cached anyway, central system</li>
<li>AFS is stateful server and has cache protocol. called to have data client there is an update, their cache is invalid. Whole file semantic</li>
<li>CODA, add replication and added weakly connected mode.</li>
</ol>
<h1 id="raids-and-hdfs"><a aria-hidden="true" class="anchor-heading icon-link" href="#raids-and-hdfs"></a>RAIDS and HDFS</h1>
<h2 id="normal-disk"><a aria-hidden="true" class="anchor-heading icon-link" href="#normal-disk"></a>Normal disk</h2>
<ul>
<li>An error-correcting code (ECC) or forward error correction (FEC) code is a process of adding <strong>redundant</strong> data, or parity data, to a message, such that it can be recovered by a receiver even when a number of errors (up to the capability of the code being used) were introduced, either during the process of transmission, or on storage.</li>
<li>RAM could cache the data. It will only read data from disks. If there was error, disk will return nothing.</li>
</ul>
<h2 id="raids"><a aria-hidden="true" class="anchor-heading icon-link" href="#raids"></a>RAIDS</h2>
<ul>
<li><strong>what</strong>:Redundant Array of Independent Disks,combines multiple physical disk drive components into one or more logical units for the purposes of data redundancy, performance improvement, or both.</li>
<li><strong>why</strong>: more rebust, larger volume,higher throughput</li>
<li><strong>how</strong>:
<ul>
<li>RAID 0 它將兩个以上的磁盘並联起来，<strong>成为一个大容量的磁盘</strong>。在存放数据时，分段后分散儲存在这些磁盘中，因為读写時都可以并行處理，所以在所有的级别中，RAID 0的<strong>速度</strong>是最快的。no redundancy,just split into serveral disks</li>
<li>RAID 1: mirroring,disk0=disk1,在一些多线程操作系统中能有很好的<strong>读取</strong>速度,replication，理論上读取速度等於硬盘數量的倍數，与RAID 0相同</li>
<li>RAID 2:这是RAID 0的改良版，以汉明码（Hamming Code）的方式将数据进行编码后分割为独立的位元，并将数据分别写入硬盘中。因为在数据中加入了错误修正码（ECC，Error Correction Code），所以数据整体的容量会比原始数据大一些. log2. Have disks save error correction code for each partition.</li>
<li>RAID3: a disk save <strong>parity</strong>. 採用Bit－interleaving（数据交错儲存）技術，它需要通过编码再将数据位元分割後分别存在硬盘中，而将同位元检查後单独存在一个硬盘中，但由于数据内的位元分散在不同的硬盘上，因此就算要读取一小段数据资料都可能需要所有的硬盘进行工作，所以这种规格比较适于读取大量数据时使用。</li>
<li>RAID4:它与RAID 3不同的是它在分割时是以block为单位分别存在硬盘中</li>
<li>RAID5:RAID Level 5是一种储存性能、数据安全和存储成本兼顾的存储解决方案。它使用的是Disk Striping（硬盘分割）技术。RAID 5至少需要三块硬碟，RAID 5不是对存储的数据进行备份，而是把数据和相对应的奇偶校验信息存储到组成RAID5的各个磁盘上，并且奇偶校验信息和相对应的数据分别存储於不同的磁盘上。<strong>当RAID5的一个磁盘数据发生损坏後，可以利用剩下的数据和相应的奇偶校验信息去恢复被损坏的数据</strong>。<img src="https://en.wikipedia.org/wiki/File:RAID_5.svg"></li>
<li>RAID6:与RAID 5相比，RAID 6增加第二个独立的奇偶校验信息块</li>
<li>RAID10 = RAID0+RAID1</li>
</ul>
</li>
</ul>
<h2 id="lustre"><a aria-hidden="true" class="anchor-heading icon-link" href="#lustre"></a>LUSTRE</h2>
<ul>
<li><strong>what</strong>:a type of parallel distributed file system, generally used for large-scale cluster computing</li>
<li><strong>why</strong>: used for supercomputing, network RAID</li>
<li><strong>how</strong>:
<ul>
<li>Files are broken into objects, very similar to stripes. These stripes can be stored by different nodes.</li>
<li>One or more metadata servers (MDS) nodes that has one or more metadata target (MDT) devices per Lustre filesystem that stores namespace metadata, such as filenames, directories, access permissions, and file layout(different access pattern,data is small)</li>
<li>One or more object storage server (OSS) nodes that store file data on one or more object storage target (OST) devices.(enable either OSS talk to either OST)</li>
<li>Client(s) that access and use the data. Lustre presents all clients with a unified namespace for all of the files and data in the filesystem</li>
<li>high performance network to transfer data and manage network to manage data</li>
</ul>
</li>
</ul>
<h2 id="mogilefs"><a aria-hidden="true" class="anchor-heading icon-link" href="#mogilefs"></a>MOGILEFS</h2>
<ul>
<li><strong>what</strong>:distributed filesystem</li>
<li><strong>why</strong>:no editing, whole file,fast deliver to clients</li>
<li><strong>how</strong>:
<ul>
<li>replicated storage:it replicates objects across servers. The number of replicas is associated with the class of the file, so, for example, photos might have three replicas, each, but thumbnails, which can be recreated from the original photos, might only have one replica of each. this reduces the cost of the storage by allowing less expensive components.</li>
<li>http+MySQL:MogileFS uses HTTP to server objects from each replica, as opposed to a home-grown protocol, for portability. For the same reason, it keeps its metadata in a standard MySQL database. </li>
<li>portable</li>
<li>no hierachy: it maintains simple namespaces, rather than directory trees,  is much simpler and more efficient than a full-blown directory system</li>
</ul>
</li>
</ul>
<h2 id="hdfs"><a aria-hidden="true" class="anchor-heading icon-link" href="#hdfs"></a>HDFS</h2>
<h3 id="assumption"><a aria-hidden="true" class="anchor-heading icon-link" href="#assumption"></a>assumption</h3>
<ul>
<li>failure is a norm, especially on datanode. It is used to handle streaming data. </li>
<li>emphasis is on throughput not on latency</li>
<li>large data sets</li>
<li>simple coherency model: write once and read many</li>
<li>moving computation is cheaper than moving data</li>
<li>The good news is that it won't be edited in place. We'll just be collecting it, adding to it.</li>
<li><img src="/assets/images/2021-04-12-19-59-50.png"></li>
</ul>
<h2 id="namenode"><a aria-hidden="true" class="anchor-heading icon-link" href="#namenode"></a>namenode</h2>
<ul>
<li><strong>what</strong>: master-slave architecture</li>
<li><strong>why</strong>: manage namespace as coordinator, only 1</li>
<li><strong>how</strong>: block to DataNodes mapping</li>
<li>data never go to namenode</li>
<li>hierarchical name space: maybe not needed, low overhead</li>
</ul>
<h2 id="datanode"><a aria-hidden="true" class="anchor-heading icon-link" href="#datanode"></a>datanode</h2>
<ul>
<li>manage storage attached to node</li>
<li>create and delete block, replicate blocks</li>
</ul>
<h2 id="access-mode"><a aria-hidden="true" class="anchor-heading icon-link" href="#access-mode"></a>access mode</h2>
<ul>
<li>read anywhere</li>
<li>write only at end(append)</li>
<li>no edit/random write</li>
</ul>
<h2 id="replication"><a aria-hidden="true" class="anchor-heading icon-link" href="#replication"></a>replication</h2>
<ul>
<li>blocks are all same size</li>
<li>fault tolerance</li>
<li>namenode managed replication</li>
<li>pipelining
<ul>
<li>When a client is writing data to an HDFS file, its data is first written to a local file as explained in the previous section.</li>
<li>The <strong>first</strong> DataNode starts receiving the data in small portions (4 KB), writes each portion to its local repository and transfers that portion to the <strong>second</strong> DataNode in the list. The second DataNode, in turn starts receiving each portion of the data block, writes that portion to its repository and then flushes that portion to the <strong>third</strong> DataNode.</li>
<li>less bandwidth and less hot-spot</li>
</ul>
</li>
</ul></div></div><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-0 ant-col-md-6"><div><div class=""><div class="ant-anchor-wrapper dendron-toc" style="max-height:calc(100vh - 64px);z-index:1"><div class="ant-anchor"><div class="ant-anchor-ink"><span class="ant-anchor-ink-ball"></span></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#file-system" title="file system">file system</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#nfs-and-afs" title="NFS and AFS">NFS and AFS</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#raids-and-hdfs" title="RAIDS and HDFS">RAIDS and HDFS</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#normal-disk" title="Normal disk">Normal disk</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#raids" title="RAIDS">RAIDS</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#lustre" title="LUSTRE">LUSTRE</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#mogilefs" title="MOGILEFS">MOGILEFS</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#hdfs" title="HDFS">HDFS</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#assumption" title="assumption">assumption</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#namenode" title="namenode">namenode</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#datanode" title="datanode">datanode</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#access-mode" title="access mode">access mode</a></div><div class="ant-anchor-link"><a class="ant-anchor-link-title" href="#replication" title="replication">replication</a></div></div></div></div></div></div></div></div></div></main><div class="ant-divider ant-divider-horizontal" role="separator"></div><footer class="ant-layout-footer" style="padding:0 24px 24px"></footer></section></section></section></section></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"note":{"id":"1f47041a-df34-437a-9e59-c4ed0fd44232","title":"Filesystem","vault":{"fsPath":"repos/dendron-aws-vault","remote":{"type":"git","url":"https://github.com/cczhong11/my_note.git"},"name":"my_note"},"type":"note","desc":"","links":[],"anchors":{"file-system":{"type":"header","text":"file system","value":"file-system","line":9,"column":0,"depth":1},"nfs-and-afs":{"type":"header","text":"NFS and AFS","value":"nfs-and-afs","line":16,"column":0,"depth":2},"raids-and-hdfs":{"type":"header","text":"RAIDS and HDFS","value":"raids-and-hdfs","line":22,"column":0,"depth":1},"normal-disk":{"type":"header","text":"Normal disk","value":"normal-disk","line":24,"column":0,"depth":2},"raids":{"type":"header","text":"RAIDS","value":"raids","line":29,"column":0,"depth":2},"lustre":{"type":"header","text":"LUSTRE","value":"lustre","line":43,"column":0,"depth":2},"mogilefs":{"type":"header","text":"MOGILEFS","value":"mogilefs","line":54,"column":0,"depth":2},"hdfs":{"type":"header","text":"HDFS","value":"hdfs","line":64,"column":0,"depth":2},"assumption":{"type":"header","text":"assumption","value":"assumption","line":66,"column":0,"depth":3},"namenode":{"type":"header","text":"namenode","value":"namenode","line":78,"column":0,"depth":2},"datanode":{"type":"header","text":"datanode","value":"datanode","line":86,"column":0,"depth":2},"access-mode":{"type":"header","text":"access mode","value":"access-mode","line":91,"column":0,"depth":2},"replication":{"type":"header","text":"replication","value":"replication","line":97,"column":0,"depth":2}},"fname":"development.database.distributed_system.filesystem","updated":1618282837925,"created":1618282755948,"parent":"00876989-d1a6-423c-96c5-efc3b87de2b4","children":[],"data":{},"custom":{},"contentHash":"46b6800bb98be0e7327489bdde943434"},"body":"\u003ch1 id=\"filesystem\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#filesystem\"\u003e\u003c/a\u003eFilesystem\u003c/h1\u003e\n\u003ch1 id=\"file-system\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#file-system\"\u003e\u003c/a\u003efile system\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003ewhat\u003c/strong\u003e: a file is a unit of data organized by user. a service responsible for managing files\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ewhy\u003c/strong\u003e: key is robust and high-throughput\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ehow\u003c/strong\u003e: name, access, physical allocation, security and protection, resource administration.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"nfs-and-afs\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#nfs-and-afs\"\u003e\u003c/a\u003eNFS and AFS\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003eNFS has no client caching, cliented cached anyway, central system\u003c/li\u003e\n\u003cli\u003eAFS is stateful server and has cache protocol. called to have data client there is an update, their cache is invalid. Whole file semantic\u003c/li\u003e\n\u003cli\u003eCODA, add replication and added weakly connected mode.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch1 id=\"raids-and-hdfs\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#raids-and-hdfs\"\u003e\u003c/a\u003eRAIDS and HDFS\u003c/h1\u003e\n\u003ch2 id=\"normal-disk\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#normal-disk\"\u003e\u003c/a\u003eNormal disk\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eAn error-correcting code (ECC) or forward error correction (FEC) code is a process of adding \u003cstrong\u003eredundant\u003c/strong\u003e data, or parity data, to a message, such that it can be recovered by a receiver even when a number of errors (up to the capability of the code being used) were introduced, either during the process of transmission, or on storage.\u003c/li\u003e\n\u003cli\u003eRAM could cache the data. It will only read data from disks. If there was error, disk will return nothing.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"raids\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#raids\"\u003e\u003c/a\u003eRAIDS\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003ewhat\u003c/strong\u003e:Redundant Array of Independent Disks,combines multiple physical disk drive components into one or more logical units for the purposes of data redundancy, performance improvement, or both.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ewhy\u003c/strong\u003e: more rebust, larger volume,higher throughput\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ehow\u003c/strong\u003e:\n\u003cul\u003e\n\u003cli\u003eRAID 0 它將兩个以上的磁盘並联起来，\u003cstrong\u003e成为一个大容量的磁盘\u003c/strong\u003e。在存放数据时，分段后分散儲存在这些磁盘中，因為读写時都可以并行處理，所以在所有的级别中，RAID 0的\u003cstrong\u003e速度\u003c/strong\u003e是最快的。no redundancy,just split into serveral disks\u003c/li\u003e\n\u003cli\u003eRAID 1: mirroring,disk0=disk1,在一些多线程操作系统中能有很好的\u003cstrong\u003e读取\u003c/strong\u003e速度,replication，理論上读取速度等於硬盘數量的倍數，与RAID 0相同\u003c/li\u003e\n\u003cli\u003eRAID 2:这是RAID 0的改良版，以汉明码（Hamming Code）的方式将数据进行编码后分割为独立的位元，并将数据分别写入硬盘中。因为在数据中加入了错误修正码（ECC，Error Correction Code），所以数据整体的容量会比原始数据大一些. log2. Have disks save error correction code for each partition.\u003c/li\u003e\n\u003cli\u003eRAID3: a disk save \u003cstrong\u003eparity\u003c/strong\u003e. 採用Bit－interleaving（数据交错儲存）技術，它需要通过编码再将数据位元分割後分别存在硬盘中，而将同位元检查後单独存在一个硬盘中，但由于数据内的位元分散在不同的硬盘上，因此就算要读取一小段数据资料都可能需要所有的硬盘进行工作，所以这种规格比较适于读取大量数据时使用。\u003c/li\u003e\n\u003cli\u003eRAID4:它与RAID 3不同的是它在分割时是以block为单位分别存在硬盘中\u003c/li\u003e\n\u003cli\u003eRAID5:RAID Level 5是一种储存性能、数据安全和存储成本兼顾的存储解决方案。它使用的是Disk Striping（硬盘分割）技术。RAID 5至少需要三块硬碟，RAID 5不是对存储的数据进行备份，而是把数据和相对应的奇偶校验信息存储到组成RAID5的各个磁盘上，并且奇偶校验信息和相对应的数据分别存储於不同的磁盘上。\u003cstrong\u003e当RAID5的一个磁盘数据发生损坏後，可以利用剩下的数据和相应的奇偶校验信息去恢复被损坏的数据\u003c/strong\u003e。\u003cimg src=\"https://en.wikipedia.org/wiki/File:RAID_5.svg\"\u003e\u003c/li\u003e\n\u003cli\u003eRAID6:与RAID 5相比，RAID 6增加第二个独立的奇偶校验信息块\u003c/li\u003e\n\u003cli\u003eRAID10 = RAID0+RAID1\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"lustre\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#lustre\"\u003e\u003c/a\u003eLUSTRE\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003ewhat\u003c/strong\u003e:a type of parallel distributed file system, generally used for large-scale cluster computing\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ewhy\u003c/strong\u003e: used for supercomputing, network RAID\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ehow\u003c/strong\u003e:\n\u003cul\u003e\n\u003cli\u003eFiles are broken into objects, very similar to stripes. These stripes can be stored by different nodes.\u003c/li\u003e\n\u003cli\u003eOne or more metadata servers (MDS) nodes that has one or more metadata target (MDT) devices per Lustre filesystem that stores namespace metadata, such as filenames, directories, access permissions, and file layout(different access pattern,data is small)\u003c/li\u003e\n\u003cli\u003eOne or more object storage server (OSS) nodes that store file data on one or more object storage target (OST) devices.(enable either OSS talk to either OST)\u003c/li\u003e\n\u003cli\u003eClient(s) that access and use the data. Lustre presents all clients with a unified namespace for all of the files and data in the filesystem\u003c/li\u003e\n\u003cli\u003ehigh performance network to transfer data and manage network to manage data\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"mogilefs\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#mogilefs\"\u003e\u003c/a\u003eMOGILEFS\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003ewhat\u003c/strong\u003e:distributed filesystem\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ewhy\u003c/strong\u003e:no editing, whole file,fast deliver to clients\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ehow\u003c/strong\u003e:\n\u003cul\u003e\n\u003cli\u003ereplicated storage:it replicates objects across servers. The number of replicas is associated with the class of the file, so, for example, photos might have three replicas, each, but thumbnails, which can be recreated from the original photos, might only have one replica of each. this reduces the cost of the storage by allowing less expensive components.\u003c/li\u003e\n\u003cli\u003ehttp+MySQL:MogileFS uses HTTP to server objects from each replica, as opposed to a home-grown protocol, for portability. For the same reason, it keeps its metadata in a standard MySQL database. \u003c/li\u003e\n\u003cli\u003eportable\u003c/li\u003e\n\u003cli\u003eno hierachy: it maintains simple namespaces, rather than directory trees,  is much simpler and more efficient than a full-blown directory system\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"hdfs\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#hdfs\"\u003e\u003c/a\u003eHDFS\u003c/h2\u003e\n\u003ch3 id=\"assumption\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#assumption\"\u003e\u003c/a\u003eassumption\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003efailure is a norm, especially on datanode. It is used to handle streaming data. \u003c/li\u003e\n\u003cli\u003eemphasis is on throughput not on latency\u003c/li\u003e\n\u003cli\u003elarge data sets\u003c/li\u003e\n\u003cli\u003esimple coherency model: write once and read many\u003c/li\u003e\n\u003cli\u003emoving computation is cheaper than moving data\u003c/li\u003e\n\u003cli\u003eThe good news is that it won't be edited in place. We'll just be collecting it, adding to it.\u003c/li\u003e\n\u003cli\u003e\u003cimg src=\"/assets/images/2021-04-12-19-59-50.png\"\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"namenode\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#namenode\"\u003e\u003c/a\u003enamenode\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003ewhat\u003c/strong\u003e: master-slave architecture\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ewhy\u003c/strong\u003e: manage namespace as coordinator, only 1\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ehow\u003c/strong\u003e: block to DataNodes mapping\u003c/li\u003e\n\u003cli\u003edata never go to namenode\u003c/li\u003e\n\u003cli\u003ehierarchical name space: maybe not needed, low overhead\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"datanode\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#datanode\"\u003e\u003c/a\u003edatanode\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003emanage storage attached to node\u003c/li\u003e\n\u003cli\u003ecreate and delete block, replicate blocks\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"access-mode\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#access-mode\"\u003e\u003c/a\u003eaccess mode\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eread anywhere\u003c/li\u003e\n\u003cli\u003ewrite only at end(append)\u003c/li\u003e\n\u003cli\u003eno edit/random write\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"replication\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#replication\"\u003e\u003c/a\u003ereplication\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eblocks are all same size\u003c/li\u003e\n\u003cli\u003efault tolerance\u003c/li\u003e\n\u003cli\u003enamenode managed replication\u003c/li\u003e\n\u003cli\u003epipelining\n\u003cul\u003e\n\u003cli\u003eWhen a client is writing data to an HDFS file, its data is first written to a local file as explained in the previous section.\u003c/li\u003e\n\u003cli\u003eThe \u003cstrong\u003efirst\u003c/strong\u003e DataNode starts receiving the data in small portions (4 KB), writes each portion to its local repository and transfers that portion to the \u003cstrong\u003esecond\u003c/strong\u003e DataNode in the list. The second DataNode, in turn starts receiving each portion of the data block, writes that portion to its repository and then flushes that portion to the \u003cstrong\u003ethird\u003c/strong\u003e DataNode.\u003c/li\u003e\n\u003cli\u003eless bandwidth and less hot-spot\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e","noteIndex":{"id":"0f1b48c7-3a25-4016-83a5-15864d7803ad","title":"Development","vault":{"fsPath":"repos/dendron-aws-vault","remote":{"type":"git","url":"https://github.com/cczhong11/my_note.git"},"name":"my_note"},"type":"note","desc":"","links":[{"from":{"fname":"root","vaultName":"my_note"},"type":"backlink","position":{"start":{"line":8,"column":3,"offset":63},"end":{"line":8,"column":21,"offset":81},"indent":[]},"value":"development","alias":"开发"}],"anchors":{},"fname":"development","updated":1618381238346,"created":1612940782409,"parent":null,"children":["400115e9-30f7-4a13-9776-db059bc9cd42","xsX5v3ZsyJ0i6gf9","1bc3b45a-b6f4-4150-87d3-5bd5b6eb8c24","6cea4852-6e7c-4140-b476-85c07b48a642","a40ef849-d301-4d74-a778-e6d9469dfb5d","774ndd6du53l5k1awv074r0","09d9081f-3dff-453d-8488-7d2344cc8895","92917ea3-452e-48dc-875e-5cd0002041db","2e151826-cb22-4d89-8ce0-71dad7204ce8","baa39444-0da9-4c55-8df7-2a6f8f787fa4","62daf50d-a39e-463f-aabd-be53790281fd","3524d0a7-be73-45d6-847e-c970f5c1c760","eac0f243-05b3-4b95-bec3-848e33edbc40"],"data":{},"custom":{"nav_order":0,"permalink":"/"},"body":"\n","contentHash":"38357962f5a50c6fd7d318dfa66bea90"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"previewV2Enabled":false,"enablePreviewV2":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":false,"leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2,"vaultSelectionModeOnCreate":"smart"}},"insertNote":{"initialValue":"templates"},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"randomNote":{},"copyNoteLink":{},"templateHierarchy":"template"},"workspace":{"dendronVersion":"0.90.0","vaults":[{"fsPath":"repos/dendron-aws-vault","remote":{"type":"git","url":"https://github.com/cczhong11/my_note.git"},"name":"my_note"},{"fsPath":"vault"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":true,"maxPreviewsCached":10,"maxNoteLength":204800,"enableUserTags":true,"enableHashTags":true,"task":{"name":"","dateFormat":"","addBehavior":"childOfCurrent","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link","taskCompleteStatus":["done","x"]},"enableEditorDecorations":true,"enableHandlebarTemplates":true,"enableFullHierarchyNoteTitle":false,"enableSmartRefs":false},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"automaticallyShowPreview":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"siteHierarchies":["development","life"],"enableSiteLastModified":true,"siteRootDir":"docs","siteUrl":"https://notes.tczhong.com","enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"writeStubs":false,"seo":{"title":"my_note","description":"Personal knowledge space"},"github":{"enableEditLink":true,"editLinkText":"Edit this page on GitHub","editBranch":"main","editViewMode":"tree"},"enablePrettyLinks":true,"enableTaskNotes":true,"siteFaviconPath":"favicon.ico","siteIndex":"development"}}},"__N_SSG":true},"page":"/notes/[id]","query":{"id":"1f47041a-df34-437a-9e59-c4ed0fd44232"},"buildId":"UUJdio6C3W6Tdvs3lwZ8T","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>