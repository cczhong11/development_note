<h1 id="memory">memory<a aria-hidden="true" class="anchor-heading icon-link" href="#memory"></a></h1>
<h1 id="memory-1">Memory<a aria-hidden="true" class="anchor-heading icon-link" href="#memory-1"></a></h1>
<p>感官记忆： 这是记忆的最早阶段，能够在原始刺激结束后保留对感官信息（视觉、听觉等）的印象。感官记忆通常只能持续几秒钟。其子类别包括图标记忆（视觉）、回声记忆（听觉）和触觉记忆（触觉）。</p>
<p>短时记忆（STM）或工作记忆： 它存储我们当前意识到的信息，以及执行学习和推理等复杂认知任务所需的信息。据信，短时记忆的容量约为 7 个项目（米勒，1956 年），持续时间为 20-30 秒。</p>
<p>长时记忆（LTM）： 长时记忆可以将信息存储很长时间，从几天到几十年不等，存储容量基本上是无限的。长时记忆有两种亚型：</p>
<p>显性/陈述性记忆： 这是对事实和事件的记忆，指那些可以有意识地回忆起的记忆，包括外显记忆（事件和经历）和语义记忆（事实和概念）。
内隐/程序性记忆： 这类记忆是无意识的，涉及自动执行的技能和例行程序，如骑车或在键盘上打字。</p>
<p><img src="/assets/images/2023-09-21-22-47-03.png"></p>
<h2 id="maximum-inner-product-search-mips">Maximum Inner Product Search (MIPS)<a aria-hidden="true" class="anchor-heading icon-link" href="#maximum-inner-product-search-mips"></a></h2>
<ul>
<li>LSH（位置敏感散列）： 它引入了一种散列函数，使相似的输入项以高概率映射到相同的桶中，其中桶的数量远远小于输入项的数量。</li>
<li>ANNOY（Approximate Nearest Neighbors Oh Yeah）： 其核心数据结构是随机投影树，这是一组二叉树，其中每个非叶节点代表一个超平面，将输入空间分成两半，每个叶节点存储一个数据点。树是独立随机建立的，因此在某种程度上，它模仿了哈希函数。ANNOY 搜索会在所有树中反复搜索最接近查询的那一半，然后汇总结果。这个想法与 KD 树很相似，但扩展性更强。</li>
<li>HNSW（层次导航小世界）： 它受到小世界网络理念的启发，在小世界网络中，任何其他节点都可以在少量步骤内到达大多数节点；例如，社交网络的 "六度分隔 "特征。HNSW 为这些小世界图建立了分层，其中底层包含实际数据点。中间层则创建快捷方式，以加快搜索速度。在执行搜索时，HNSW 从顶层的随机节点开始，向目标导航。当它无法再靠近目标时，就会向下移动到下一层，直到到达底层。在上层的每次移动都有可能覆盖数据空间中的较大距离，而在下层的每次移动都会提高搜索质量。</li>
<li>FAISS（Facebook 人工智能相似性搜索）： 它的运行假设是，在高维空间中，节点之间的距离遵循高斯分布，因此数据点应该存在聚类。FAISS 通过将向量空间划分为簇来应用向量量化，然后在簇内细化量化。搜索时，首先用粗量化寻找候选簇，然后用更精细的量化进一步搜索每个簇。</li>
<li>ScaNN（可扩展的最近邻域）： ScaNN 的主要创新是各向异性向量量化。</li>
</ul>
<p><img src="/assets/images/2023-09-21-22-47-58.png"></p>
<p><a href="https://ann-benchmarks.com/">https://ann-benchmarks.com/</a></p>