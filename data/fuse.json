{"keys":[{"path":["title"],"id":"title","weight":1,"src":"title"},{"path":["body"],"id":"body","weight":1,"src":"body"}],"records":[{"i":0,"$":{"0":{"v":"This page has not yet sprouted","n":0.408},"1":{"v":"[Dendron](https://dendron.so/) (the tool used to generate this site) lets authors selective publish content. You will see this page whenever you click on a link to an unpublished page\n\n![](https://foundation-prod-assetspublic53c57cce-8cpvgjldwysl.s3-us-west-2.amazonaws.com/assets/images/not-sprouted.png)","n":0.189}}},{"i":1,"$":{"0":{"v":"Life","n":1},"1":{"v":"\n# 生活\n\n- [[亲密关系|life.love]]\n- [[人际沟通|life.communication]]\n- [[厨艺|life.cooking]]\n\n# 娱乐\n\n- [[摄影|life.photo]]\n- ","n":0.378}}},{"i":2,"$":{"0":{"v":"Time_management","n":1},"1":{"v":"\n时间管理，精力管理的第一原则：比做什么更重要的是决定不做什么。\n\n","n":1}}},{"i":3,"$":{"0":{"v":"Sport","n":1}}},{"i":4,"$":{"0":{"v":"Rockclimb","n":1},"1":{"v":"\n\n# 如何攀岩\n\n- 一定要穿专业的鞋子。\n- 攀岩的重点是把重心都放在脚趾上。\n- 在向上爬的时候要先思考好你的手怎么放。\n- 手是支点和引导点，帮助你往上爬的。脚帮你站起来\n","n":0.408}}},{"i":5,"$":{"0":{"v":"Social","n":1},"1":{"v":"\n\n# 核心的社会动机\n\n## 归属\n\n在支配社会生活的所有动机中，最重要的是归属：我们渴望与他人建立稳定、有意义的联系。 51 在与两个彼此看不见的陌生人玩网络球时，即使是轻微的排斥也会在我们的大脑中触发类似于身体疼痛的警报。那些回忆起被排除在外的事件，或者在实验室的一场短暂的游戏中被排除在外的大学生，后来评价自己比那些没有被排除在外的人更差。\n\n长时间的非自愿隔离不仅会令人感到不愉快，而且在心理上是有害的，会产生抑郁、焦虑和自我毁灭的冲动。\n\n## 理解他人和准确预测\n\n人类有强烈的动机来准确地感知和理解周围的人和情境，准确地把握人生的航向，并确保我们的人际关系得以优化。我们期盼能够预测将会发生什么，并对所发生的事情做出解释。\n\n## 控制\n\n确定性甚至是不幸的确定性，满足了第三种强烈的社会动机：控制的需要。我们希望拥有指导我们行动的自主感和能力并确保事情成功。控制感会让我们体验到幸福，因为它让我们感到自己可以主动且有能力去完成事情。缺乏控制的感觉会令我们不愉快，从长远来看，也是不健康的。\n\n对许多人而言，控制感是幸福的核心。当他们不能进行控制的时候，他们的行为却在显示仿佛他们仍然具有控制的能力。\n\n\n## 被重视需要\n\n人类具有让自己感到有价值的强烈动机，希望自己在所在社区中有社会地位、有积极的声誉。信任作为社会性动物，我们不相信别人就无法生存。尽管进化赋予了我们消极的偏见，出现“坏事比好事更有威力”的效果，但我们有强烈的动力去相信世界是安全的、仁慈的和公平的。\n\n信任别人会使互动更简单、更愉快；它让我们不用担心别人会来找我们麻烦；或者不用担心如果我们暴露了真实的自我，会招致他们的非议。\n\n\n# 狩猎 — 采集者思维\n\n## 社交人数\n\n邓巴发现，我们的大脑容量似乎可以容纳大约 150 人，我们可以与他们建立起稳定、有意义的关系；当人类群体的数量不超过 150 人时，他们的功能会达到最佳状态。事实证明，很少有人能与超过 150 人进行双向通信。了解 150 人限制的一个有用的含义是，当人类组织不再变得更大时，其功能会更好 —— 他们可以像社区那样运作，而不会像行政机构那样运作。小型学校的暴力和旷课率较大型公立学校要低，人际关系会更好，学习质量会更高。 注意到我们进化中狩猎 — 采集者思维的性质和局限，可以优化我们的生活和制度。\n\n## 我们 — 他们”的部落心态\n\n进化将我们的思想塑造成部落心态，巧妙地将所有人归类为我们的一部分或他们的一部分。最后，我们要问：他是我们中的一员还是他们中的一员？\n\n泰菲尔的研究揭示，一旦把人们分成了不同的类别，我们的头脑就会自动地夸大我们和他们之间的差异，而不是注意那些相似之处。我们倾向于把我们群体中的人“群中人”视为一个独特个体的集合，而倾向于把那些“群外人”看作更为相似的人 ——“ 他们都是一样的”，人们经常说，或者“他们看起来都很像”。事实上，“他们”看起来的确很像。这是一个常见的感知缺陷：如果一组照片是亚洲人的或者黑人的脸，那么评价这组照片的白人要比他们是白人时要更难分辨。亚洲人在区分黑人和白人的面孔时也存在同样的困难。你可以想象这种偏见会如何影响对目击证人的准确辨认：白人目击证人更有可能错误地将一个黑人和另一个黑人混为一谈。\n\n我们对自己部落中成员的评判也比对“他们”的评判要宽容得多。我们不仅认为我们部落中的人更加多样化，而且我们认为我们部落更优秀、更值得。这种偏见带来了骄傲和尊重的感觉：我们扭曲了自己对世界的看法，这样我们的部落看起来比其他人更好，我们感觉会更好，因为我们是它的一部分。\n\n为什么我们倾向于基于如此细微的差别作出如此巨大的区分？原因在于我们的 DNA 。对于狩猎 — 采集者来说，他们需要对自己部落成员之间的差异保持警惕，这些成员可能是竞争者，而对于局外人，则可能是攻击者。当一个共同的目标对每个成员也都有利时自然会形成联盟，将个人组合成团队。我们自己的部落或团队之间的凝聚力是高度适应性的，因为我们共享资源，享受团队的保护以抵御来自外部持续不断的威胁。\n\n","n":0.171}}},{"i":6,"$":{"0":{"v":"Pursuade","n":1},"1":{"v":"\n说服一个人有多容易？答案在一定程度上取决于我们所要面对的是人们的看法还是态度。看法指的是一个人认为是真的.它们是短暂的；它们可以通过很好的证据来加以改变。\n\n包含情感和评价成分的观点被称为态度。与看法相比，态度是极难改变的 —— 正如我们在讨论称为偏见的复杂态度时所看到的。当你阅读本章中关于影响策略的讨论时，你可能会记住看法和态度之间的区别。对某个人而言容易改变的看法，对另一个人则可能是根深蒂固的态度。\n\n# 现代科技的影响\n\n人们容易因为手机分心。与先前的研究一样，手机具有破坏性；当它出现在房间里时，人们认为他们的同伴不太容易沟通且值得信赖，并且认为花更多的时间在一起也不太可能成为朋友。其他类似的研究发现，在社交互动过程中使用手机会减少眼神交流、参与度、对同伴的同理心关怀以及谈话的乐趣。\n\n除了剥夺我们发展社交技能的机会外，深入社交网站还可以促使人们变得更加自我中心和自恋，并相信名声、财富、人气比友谊、慷慨、社区更重要。\n\n通过我们在线时的积极参与，以及对我们所使用的操作终端可能上瘾保持警觉和超然，我们可以获得巨大的好处和乐趣，而不会挤出或分散我们对宝贵的离线体验的注意力。\n\n## 媒体\n\n获取信息是一件好事，媒体在让我们了解情况方面发挥着至关重要的作用。然而，这种媒体曝光也可能存在不利因素。无论是有意还是无意，这种栩栩如生的画面塑造了人们的态度和意见。\n\n**强烈的情绪**，例如新闻媒体唤起的情绪，常常会妨碍理性的决策。人们总是被教导要听从领袖们的命令 …… 你必须做的只是告诉人们，他们正面临着攻击，而去指责那些主张和解的人缺乏爱国心并可能会将国家置于危险之中。在任何一个国家这一招都会奏效。”\n\n媒体感染媒体也通过一种称为情绪感染的现象发挥其力量，这种现象发生在一个人的情绪行为引发观察者的类似情绪和行为之时。\n\n## 广告\n\n在面对许多消费品的情况下，假如没有铺天盖地的广告，公众会倾向于购买某个特定的品牌。当我们处理相同或非常相似的产品时，仅仅熟悉品牌名称就会带来巨大的差别对待。在所有其他条件相同的情况下，项目越被人们所熟悉，它就越有吸引力，即使该项目只是一个愚蠢的无意义单词。我们接触得越多，就会越喜欢它。\n\n和那些不容易想到的品牌相比，某种广告品牌的易得性足以向我们暗示其优越性。当然，一旦我们购买了产品并发现我们喜欢它，我们就培养了品牌忠诚度。因此，尽管我们很少意识到自己接受了广告的影响 —— 我们不会在看过广告之后立刻从椅子上跳起来，冲到超市去买艾德熊乐啤露 —— 但它可以启动一个长期的过程，在我们今后进行选择的时候，间接地促使我们购买大量的广告产品。\n\n# 说服\n\n如果我们具备所需的专业知识，我们倾向于深入思考一个与自己相关的问题。在这种情况下，我们会对论点进行认真的审查。但有时，即便这个问题很重要，我们也可能不会认真地面对某个观点，因为我们会分心或疲倦，我们缺乏对它进行批判性评估的知识，或者交流会以一种诱使我们接受的方式进行。\n\n说服的中心途径（ the central route to persuasion ）指的是对观点加以权衡，对相关的事实或数据加以考虑，在对问题进行系统思考的基础上作出决定。相比之下，说服的外围路径（ the peripheral route to persuasion ）则没有经过多少深思熟虑；人们并非依据对观点说服力的权衡和思考过程，而是不做过多思考地依据那些简单的、往往不太相关的线索对观点做出正确与错误或者是否有吸引力的反应。\n\n如果您的目标是为了说服，您需要知道问题对您的受众有多重要以及他们的知情程度。如果他们知识渊博且积极主动，那么您需要在有说服力的诉求中加入强有力的逻辑论证。如果他们不关心问题或无法完全理解它，您便需要使用附加到信息的高质量外围线索来说服他们。这可能短时内奏效，但如果你需要有说服力的信息，实验表明，让人们得到系统的论证说服比仅基于边缘线索的说服更容易达到目的。\n\n它们可以提高沟通或说服尝试的有效性：（ 1 ）沟通的来源（谁说的）；（ 2 ）沟通的性质（他或她如何说的）；（ 3 ）听众（他或她对谁说的）的特点和心态。换句话讲：谁对谁说什么？我们将分别对这些要素进行考察。\n\n## 沟通者的可信度\n\n传播者如何让自己看起来值得信赖呢？一种方法是反对自己的自身利益。如果人们在说服我们时没有得到任何好处（也许还会失去一些东西），我们便会信任他们，他们的说服会更有效。\n\n另一种提高可信性的方法是创造一种人们认为你没有试图说服他们的情境。\n\n首先，我们倾向于喜欢和信任自己认为有吸引力的人，所以除非我们认真评估有人为自己所认可的产品支付报酬的事实，否则我们很可能会被外围信息所说服。我们将沟通者的吸引力与信息的可取性联系起来。我们受我们喜欢的人的影响，也受我们感知相似性的人的影响。当我们喜欢沟通者时，我们的行为就好像我们试图通过改变自己的观点来取悦那个人\n\n在大多数情况下，人们信任自信的演讲者，而不是那些支支吾吾的人；人们将自信作为专业知识和真实性的指标。然而，如果我们怀疑受到了欺骗 —— 如果我们意识到有人试图说服我们相信某件事或诱导我们购买某件产品并从中获利的可能性（“这种神奇的补药一定能够提高你的成绩！”） —— 这种极端的自信则会引起我们的怀疑。\n\n## 沟通的性质\n\n- 逻辑诉求还是情感诉求, 情感诉求 —— 尤其是那些引起恐惧的诉求 —— 将比理性诉求更有效。\n  - 对自己评价很高的人最有可能在恐惧的时候立即采取行动。然而，对自己评价不高的人最不可能立即采取行动，但是（有趣的是）如果延迟一段时间，他们知道可以稍后采取行动，那么他们的行为就很像那些具有高度自尊心的被试。自尊心低的人可能难以应对威胁，这就解释了为什么唤起高恐惧的沟通会压垮他们\n  - 我们的大脑会因明显的和当前的危险（如老虎、蛇或携带武器的敌人）受到惊吓并被激怒 —— 而不是之后可能发生的渐进性危险（如干旱、流感或更频繁的飓风）。我们倾向于应对人类的威胁（如恐怖主义），这些威胁是蓄意而为的，因此会在我们心中引起一种道德上的愤慨。\n- **道德情感** 是一种具有规范性判断的情感 —— 你所做的是错误的、令人厌恶的或邪恶的。\n  - 在推特上，含有与道德情感相关词语的推文（如无耻的、恶心的或坏的）往往比非道德情感词语更容易被转发。\n  - 成为具有高度说服力的修辞手段 —— 它们往往会激发行动，团结志同道合的群体 —— 而且它们往往具有传染性\n  - 我们也可以通过道德提升来诱发人们更多的“天使举动”，即人们的亲社会动机，这是我们在他人身上看到美德时所感受到的情感。\n- 统计与个别案例\n  - 一般来说，人们会利用他人的经验和意见来决定什么是一种好的行为准则。这就是为什么，作为一般规则，我们会相信群体而不是个人，并且与标新立异的人相比，我们更倾向于追随人群。但是，当我们面对一个令人信服的故事或案例时，这种合理的逻辑往往会失效。\n  - 因为大多数人受到一个个具体案例的影响要比接受大量统计数据的影响更大\n- 认同诉求\n  - 如果这些事情与我们的自我认同产生共鸣，说服者便可能促使我们去行动。\n  - 唤起一个人的身份认同可以产生微妙但强大的效果\n  - 通过让人们从他们更高的身份角度去思考某个行为是好是坏，他们会把这一行为看作是“自己是谁”的核心，而不是一个偶然的行为。这就是身份的力量\n- 单向与双向观点\n  - 如果听众对这个话题越了解，那么他们被单向观点说服的可能性就越小，此时提出重要的对立观点然后继续反驳这些观点，则会提高说服的可能性。\n  - 一个见多识广的人更有可能知道一些对立的观点。当沟通者避免提及这类观点时，知识渊博的听众很可能会得出这样的结论：沟通者要么不公平，要么无法反驳他们。相反，一个事前不了解的人，对对立的观点知之甚少或一无所知，因此他们很可能被他们所听到的一方观点所说服；如果听到了相反的观点，他们则可能会对自己到底赞同哪一种观点感到困惑。\n  - 另一个因素是听众最初的观点。如果观众已经倾向于相信传播者的观点，那么单向的陈述对他们的观点产生的影响要大于双向陈述。然而，如果听众倾向于相反的观点，那么双面驳斥就会更有说服力\n- 沟通者和听众之间的差异程度假\n  - 当传播者具有很高的可信度时，如果传播者的观点与听众的观点存在很大的差异，那么他们更有可能说服听众。但是，当沟通者的可信度很低时，他们唯一能让听众接受的条件，就是他们的观点与听众的观点只有适度差异。\n\n## 接受者的特征\n\n- 人格与政治\n  - 与说服力最为相关的一个人格特征是自尊。自我评价低的人比自我评价高的人更容易被说服性的沟通所影响。\n  - 保守自由主义会在促进稳定、传统、秩序和等级制度方面维护我们的利益，而自由主义则会在促进求异、变革、灵活性和平等方面维护我们的利益。保守主义者更喜欢熟悉的人；自由主义者更喜欢与众不同的人。\n- 接受者的情绪与心态\n  - 另一个影响接受者对沟通信息反应的因素是他们的心态\n  - 他认为，如何让人们准备好接受说服性信息，是说服是否有效的一个关键因素：“通过策略性地引导接受者从一开始便加以关注，沟通者有可能在接受者接触信息之前便促使他们与信息达成一致。\n  - 假如听众吃饱喝足、放松、快乐、自我感觉良好，他们也更容易接受有说服力的交流。\n  - 听众的接受度和说服力也可能被降低。有一种方法就是简单地警告他们即将发生的事情。这样的预警似乎是在说：“当心，我将试图说服你。”人们往往会通过对消息进行防御来作出反应。\n\n## 说服的抗拒\n\n抗拒理论，当我们的自由感受到威胁时，我们会努力去恢复它。当人们认为某个人传递的信息过于明目张胆或者具有强制性，从而侵犯了他们的选择自由时，他们很可能会激活防御来抵抗它\n\n接种效应（ inoculation effect ）：如果让人们先接触某一简短的宣传，而且接着他们能够对其加以反驳，人们就会对后来大规模出现的同样观点产生“免疫”，这就如同在人体内注入少量经过稀释的病毒可以帮助人们对这种病毒的大规模进攻产生“免疫”\n\n相反，如果人们对某个问题没有太多的思考 —— 也就是说，如果他们通过外围路径形成了自己的态度，比如通过情感、熟悉度或同龄人 —— 他们特别容易受到对自己观点的全面攻击。他们在捍卫自己的观点时将缺乏现实依据。\n\n在我看来，这里值得强调的一点对于教育目的的实现至关重要：如果我们想减少单纯宣传的影响，就没有什么可以替代对各种思想的自由探索。最容易被洗脑的人，是那些信仰基于从未受到过严重挑战的口号的人","n":0.096}}},{"i":7,"$":{"0":{"v":"Follow_others","n":1},"1":{"v":"\n\n# 从众\n\n从众可以定义为一个人的行为或意见的改变，受到了来自另一个人或一群人的真实或想象的压力的结果。\n\n当人们互相交谈时，他们会经常模仿对方的非语言行为和举止，这种现象被称为变色龙效应（ chameleon effect ）\n\n镜像系统的主要功能之一是促进社会学习（ social learning ），即人们通过观察来学习的过程。\n\n只要其他人在笑，就可以起到这样的效果。很多从众行为都是这样产生的；环境中的社会暗示告诉我们其他人的感觉、想法或行为，而这些又会反过来影响我们的感觉、想法和行为\n\n## 动机\n\n从众的主要原因有两个：因为别人是有价值信息的来源，或者因为与别人相差太大令人感到不适；\n\n从众通过表达我们的相似性和思想上的亲近关系，来确保我们在某个群体中的地位。前一个原因基于丰富的信息：人们面对采取一致意见的多数人，会认为自己的观点因某种原因而出现了错误。后一个原因则基于规范：人们会“随大流”，但内心相信他们最初的判断是正确的，以求被大多数人所接受或避免因意见不同而被他们所厌恶。坚持正确意见与迎合群体之间的这种基本困境，是导致我们一些最大失败的核心所在。\n\n为了获得有关适当行为的信息而观察他人所产生的从众，往往比为了被接纳或避免处罚所产生的从众具有更强大的力量。我认为，如果我们发现自己处于一种模棱两可的境地，我们必须使用他人的行为作为自己行为的模板，我们很可能在随后的类似场合重复我们新学到的行为，而没有任何暗示\n\n## 榜样\n\n榜样的声望与受欢迎程度 当我们不清楚在某种情况下究竟发生了什么事情时，我们最有可能同那些行为可以提供最可靠信息的人保持一致。当受人尊敬、关系密切的人恰巧在正确的时间出现在正确的地点时，主要的社会趋势往往会通过从众机制突然发生戏剧性的变化。\n\n## 一致同意\n\n一致同意 当群体成员面对面时，像阿希研究的情况一样，决定一个人是否会从众的关键因素之一是其他人是否都持有相同的意见。“其他所有人”的群体中实际人数不需要太多，但需要获得最大程度的一致性；当达成一致的群体规模只有3人时，人们会像群体规模达到16人时一样顺从于群体压力。表态 通过诱导一个人对他（她）最初的判断作出某种承诺，也可以减少对群体压力的顺从。\n\n担责 假设你正在参与一个解决问题的小组讨论，而其他人正在向你施加压力，让你同意他们的决定。另外，假设你知道，在会议结束时，你必须向小组的其他成员证明你的决定是正确的。你觉得这对你的判断会产生什么影响？研究表明，在大多数情况下，这样的责任会增加你从众的倾向\n\n## 自尊\n\n一般来说，自尊心较低的人比自尊心较高的人更容易屈服于群体压力。如果让人们相信自己手头的任务根本不需要什么能力（比如判断直线的长度），他们的从众倾向就会增加。如果人们有机会在完成一项任务之前已经获得成功，从而对自己的能力充满自信，那么他们会比那些误打误撞的人更不容易从众。\n\n## 年龄 \n\n正如我们所看到的，即便是幼儿也会本能地顺应同龄人的行为。这是我们学习很多东西的途径，包括我们的说话方式和口音类型。39而对于10到25岁的年轻人来说，从众压力最为强烈。在此之前，大脑的自我控制系统——控制计划、思考未来、评估风险和抑制冲动——仍在发育。\n\n## 认同的群体\n\n我们所归属以及所认同的群体（即我们的参照群体，reference groups）既反映又塑造我们的身份和行为。通常，当我们改变参照群体时，我们也会改变我们的行为和态度以与之相符。总而言之，当人们偏离自己所属群体的规范、特别是当他们对所属群体重视或认同时，他们会从别人那里得到暗示，并且通常会体验到不适。\n\n## 不同的水平\n\n由此而区分出从众的三种水平：依从、认同和内化\n\n- 依从（compliance）这一术语能够最恰当地用来表示一个人为了获得奖励或者避免惩罚而做出某种行为\n- 认同（identification）一词描述了一个人渴望成为他们所钦佩的群体或角色榜样所带来的从众水平\n- 最后，基于价值或信念的内化（Internalization）是最持久的从众。将特定信念内化的动机，是希望自己正确。因此对这种信念的奖赏是内在的","n":0.204}}},{"i":8,"$":{"0":{"v":"Bias","n":1},"1":{"v":"\n这里的偏见是社会心理学的偏见和歧视。\n\n偏见定义为对一个可区分的群体中的所有成员的一种消极态度 —— 仅仅依据的是他们是该群体的成员。偏见是复杂的，就像任何态度一样，它部分是认知的，部分是情感的，部分是行为的。他（她）对他们有先入为主的看法，对他们有负面的情感，并且倾向于带着成见或敌意来对待他们\n\n# 刻板印象\n\n刻板印象（ stereotype ）反映了这样一种信念：一个特定的属性是群体整体的特征，而不管群体成员之间的实际差异如何。\n\n因为这个世界太复杂了，我们不能对任何事物和任何人都有高度分辨性的态度，所以我们对我们自己的群体以及我们所看到的其成员的所有变化进行优雅、准确的叙述，同时对其他群体形成简单、粗略的想法。刻板印象往往是准确的，因此可以是一种适应的、简短的处理复杂问题的办法\n\n一旦我们掌握了关于某个人的明确的和具体的信息，我们就会轻易地抛弃用那些刻板印象来引导对这个人的看法。\n\n## 刻板印象、性别歧视和性别\n\n每个人都持有对男性和女性的刻板印象 —— 有些是积极的，有些是消极的。女性被认为更有同情心、更为健谈，男性更具能力和攻击性。\n\n在 1950 年至 2012 年间，在以女性命名的飓风中死亡的人数是以男性命名的飓风中死亡人数的两倍。\n\n## 刻板印象与归因\n\n刻板印象是一种特殊的归因形式。我们是能够进行解释的物种；我们一直在通过归因来解释我们自己和他人的行为。在模棱两可的情况下，人们倾向于按照自己的偏见来构建叙事逻辑。\n\n不仅偏见会影响他的归因和结论，而且他的错误结论也会证明和加剧他的负面情绪。因此，整个归因过程得以螺旋式上升。\n\n### 归因模糊性\n\n解释别人的行为往往充满了不确定性。那个人喜欢我还是他们想从我这里得到什么？偏见使这个问题复杂化，因为我们的社会身份为一个特定个体的行为设定了更多的潜在原因。它给少数派群体成员解释自己得到的工作反馈带来了困难。\n\n那些被告知是因为性别（而非成绩）而被选中的女性后来贬低了自己的能力 —— 更糟糕的是，她们不再像那些相信自己是根据成绩被选中的女性一样，努力地在一项艰巨的任务上取得成功。\n\n### 自证预言\n\n我们对他人的刻板印象不仅影响我们对他们的行为，而且使我们的行为方式能够从其他人那里获得我们所期望的特征和行为。想象一下你和我从未见过面，但是我对你所属群体的偏见让我怀疑你会充满敌意或冷漠。当我们终于有机会见面时，我可能会保持距离，不愿尝试和你进行生动的交谈。\n\n### 刻板印象的威胁\n\n具有讽刺意义的是，自证预言的一个意想不到的结果是，那些消极刻板印象的目标人群最终会通过试图让偏见落空反而将这些偏见坐实。\n这就是刻板印象的力量；当人们认为自己的行为可能证实他们自身或他们所属团队的负面声誉时，由此产生的焦虑会影响他们的表现。\n\n\n### 指责受害者\n\n对于从未经历过偏见的人来说，完全理解成为偏见的目标并不是一件容易的事情。那些占多数的相对安全的成员，并不容易产生同情心。\n自相矛盾的是，把受害者的困境归因于受害者的个性和缺点，这种倾向往往是受到一种将世界视为公平公正愿望的驱使。人们倾向于将任何不公平的结果归因于个人责任，否则便很难解释。\n\n当一个人伤害另一个人时，攻击者倾向于责怪攻击目标，将受害者非人化并再次对其伤害。现在我们看到，如果一个人注意到另一个人是仇恨信息和其他偏见表达的接受者，他（她）不知何故觉得受害者一定做了他们值得受惩罚的事情。\n\n# 偏见的情感成分：直觉和仇恨\n\n偏见的第二个成分是情感，植根于抵制理性论据的直觉。这就是为什么试图说服人们摆脱偏见往往是徒劳的。事实上，偏见的情感根源往往导致刻板印象和相互矛盾的归因\n\n因此，刻板印象可以被认为有两个截然不同的目的：它们提供快捷的信息渠道，并在事实发生后对偏见情绪加以合理化。\n\n# 偏见的行为\n\n偏见往往会导致对受鄙视群体成员的歧视和不公平对待。\n\n性别歧视就像种族问题一样，许多人认为在美国性别歧视已不再是女性的障碍。毕竟，与大多数发达国家的情况一样，女孩在学校的大多数科目中的表现都比男孩好，而且更有可能上大学并顺利毕业。 50 尽管如此，她们仍然受到歧视，因为人们有偏见地认为她们比男性能力差。\n\n# 内隐偏见\n\n我们知道，许多真诚地认为自己没有偏见的人，在某些情况下，他们的行为会带有偏见.人们更容易暴露他们偏见的一个条件是精神疲劳，也就是当人们**疲倦、喝醉、分心、害怕、愤怒或做任何消耗或分散他们认知资源的事情的时候**。在这种情况下，人们倾向于借助他们的刻板印象 —— 即使他们有很强的动机去做正确的事情。\n\n\n证明我们持有偏见的另一个关键因素是，我们是否相信一个人可以控制他（她）的处境。反肥胖偏见是最后一种“可接受”的偏见，因为大多数人相信肥胖的人可以控制自己的体重. \n\n另一种可以接受的说法是“容易合理化”。我们越容易使我们的偏见合理化，我们就越有可能坚持并采取行动。\n\n# 减少偏见\n\n关键因素似乎是在实现共同目标方面的相互依存：这是一种个人需要彼此才能走向成功的局面。在一个群体内部建立起来的合作关系常常会在该群体后来被要求与另一个群体互动时继续存在。\n\n拼图教学：现在，已经不是只有一位专家（老师）了，每个学生都是他（她）自己的专家。他们没有相互嘲弄，而是开始互相鼓励，因为确保他们的同学能够以最佳方式传达他们的材料符合每个学生的最佳利益。\n拼图方法发生作用的原因为什么拼图方法会产生如此积极的效果？这项技术成功的一个原因在于，参与合作的过程打破了内群体与外群体的感知，并允许个体发展“一体”的认知范畴：我们是一体的。一个群体中的每个人，通过与其他成员分享他（她）的知识，会向他们提供帮助。\n\n\n","n":0.186}}},{"i":9,"$":{"0":{"v":"Reason","n":1},"1":{"v":"\n群体保护机制和由此产生的群体偏见是一种生物的生存机制，促使我们偏爱自己的亲属和部落，并对外人保持警惕。\n\n# 经济与政治竞争\n\n\n偏见往往是经济和政治力量造成的。根据这一观点，由于资源有限，占支配地位的群体可能试图剥削少数群体以获取某种物质利益。当群体为相互排斥的目标发生冲突时，会导致偏见的增加。\n\n竞争和冲突会滋生偏见。\n\n# 替代性攻击：替罪羊理论\n\n攻击行为部分是由挫折和其他诸如痛苦或无聊的厌恶状态引起的.受挫的人有一种强烈的倾向，他们会猛烈抨击导致自己受挫的原因。然而，通常情况下，一个人遭受挫折的原因要么太强大，要么太模糊，不可能直接报复。在现代，“寻找替罪羊”一词指的是把我们的麻烦归咎于无辜和无能为力的人的过程\n\n个人，特别是当他们感受到挫折时，会把攻击性转移到那些不受欢迎的、可以接触到的、相对无力的群体身上.\n\n1949 年，两位社会心理学家分析了历史上许多煽动者所发表的大量演讲。 他们发现这些人的演讲中有着惊人的规律性：\n ● 你被骗了。你在社会中的地位是不安全的，这并非因为你个人的过错。\n ● 存在着一个广泛的阴谋，这个系统是针对我们的。\n ● 像我们这样的好人总是被愚弄。\n ● 我们的敌人是低等动物：爬行动物、昆虫、非人。\n ● 我们不能相信外国人，他们抢走了我们所有的工作。\n ● 我们也不能相信我们自己的政府，它是腐败的。公民自由其实是“愚蠢的自由”。\n ● 我们正在走向灾难，厄运即将来临。像你这样真诚、单纯、善良的人需要一位领导者。看呐，那就是我！我要改变这一切！\n ● 所有人都反对我 —— 媒体、犹太人、臭名昭著的官僚们都试图让我闭嘴。敌人密谋夺走我的生命，但上帝会保佑我。让我来引导你。\n\n\n# 自我形象和地位的维持\n\n偏见的一个强有力的决定因素是我们需要为我们的行为和自我意识辩护。如果我们对一个人或一群人做了一些残忍的事情，我们中的大多数人都会试图责怪或诽谤那个人以证明我们的残忍是正当的。如果我们能说服自己，一个群体是无用的、不人道的、愚蠢的或不道德的，我们就可以任意地去奴役该群体的成员，剥夺他们接受体面教育的权利，或对他们进行攻击，而不去质疑我们自己的道德感。对他人持有偏见会增强我们的自尊心。\n\n# 从众导致的偏见\n\n许多有偏见的行为都是由人们对社会规范的从众所驱动的。我们如何来确定从众所发挥的作用呢？一种方法是观察当人们移居到这个国家的不同地区时，他们的偏见会发生什么变化。\n\n最后，偏见也可能源自基于社会制度的法律和习俗。一个倡导种族隔离的社会，会支持某个群体劣于另外一个群体的观点。","n":0.2}}},{"i":10,"$":{"0":{"v":"Attack","n":1},"1":{"v":"\n# 人类的攻击性\n\n我将攻击定义为旨在造成伤害或造成身体或心理痛苦的故意行为。攻击行为可能是身体上的，也可能是口头上的。\n\n人类社会并非都富有攻击性。 在依赖合作促进群体生存的紧密文化中，愤怒和攻击被认为是危险的和破坏性的，罪犯将被排斥或受到惩罚.攻击是一种可供选择的策略\n\n## 荣誉文化\n\n在这种文化中，即使是很小的争议也会使一个人不可摧毁的荣誉受到影响，这就要求他作出积极的回应，以恢复他的名声\n我们可以看到，虽然攻击的生理成分存在于人类和其他灵长类动物中，但攻击并不是一种反射性的“本能”。文化影响已经“浸入我们的皮肤之下”，塑造我们对情境的反应和社交活动，从而决定我们是否采用攻击性反应。\n\n## 性别\n\n当“作为一个男人”由竞争力和力量来定义时，男人总是试图通过表现出攻击性来“证明”他们的男性气质和地位。 相反，当男性生活在对他们的生存缺乏内部和外部威胁的文化中时 —— 不可否认的是，没有多少文化会如此幸运 —— 他们便不会被培养成好斗的人，在那里性别差异被最小化，并且鼓励合作。\n\n暴力的首要预测因素是性别。作为成年人，男性比女性更容易发生自发的、无端的攻击陌生人的行为，刺激男性攻击的激素是睾酮，尽管男女都有睾酮，但男性体内睾酮的比例较高。\n\n发生在家庭中的大多数极端暴力事件都是由男性实施的。例如，每 10 个杀死家庭成员的杀人犯中有 8 个是男性。当男性殴打受害者时，他们通常会比女性施虐者造成更严重的伤害。 然而，当涉及比谋杀和残忍殴打稍逊的身体攻击形式时，男性和女性之间往往存在很大的重叠 —— 这与性别刻板印象相反。在很多两性关系中，双方都具有同样的攻击性。\n\n对于那些与伴侣有身体攻击的男性和女性而言， 29 他们的行为也是出于同样的原因：嫉妒、愤怒、报复和自卫。\n\n## 关系性攻击\n\n作者把攻击定义为伤害他人的意图, 女性比男性更容易参与更具社会性的攻击行为. 关系性攻击，即通过破坏他人的名誉和关系来伤害他人。回避、散布虚假谣言和恶意流言蜚语、诽谤以及“荡妇羞辱”都是最好的例子，其后果可能是毁灭性的\n\n关系性攻击的一种特别有害的形式是网络欺凌。\n\n# 攻击的作用\n\n某些类型的攻击行为可以起到有用的、也许是必要的作用：它们“释放了能量”。这种看法源于精神分析的宣泄或能量释放的概念\n\n人们越是用攻击性的行为发泄愤怒，他们便会越加愤怒，也就会变得越有攻击性。直接或间接、口头或身体上发泄愤怒并不能减少敌意，反而会增加敌意。\n\n报复、行为过度与升级为什么表达愤怒会导致更大的敌意？一旦我们对他人表达了负面的感觉，一旦我们给前老板贴上了一个“没有良心的混蛋”的标签，那么用前后一致的声明和行动来跟进就会变得更加容易 —— 尤其是当我们在公开场合报复的时候。此外，报复通常比最初的侮辱或攻击更为严重；我们倾向于行为过度，这为减少失调奠定了基础。\n\n行为过度会导致失调最大化。犯事者对你的所作所为和你的报复之间的差异越大，心理失调就会越大。\n\n## 攻击的原因\n\n### 酗酒\n\n世界上许多人会高兴地摄入酒精这种药物。酒精会降低我们的抑制力，使喝酒的人更友好、更合群，但也会放松对实施攻击行为的限制，包括性侵犯。酒精减少了社会抑制，使我们不那么谨慎，更容易冲动。但它不仅仅如此：酒精也会破坏我们通常处理信息的方式。醉酒的人通常会专注于社会状况最早和最明显的方面，并对其做出反应，而往往会忽略其中的细微之处。\n\n### 痛苦、不适与饥饿\n\n因此，其他形式的身体不适，如酷热、潮湿、空气污染和难闻的气味，会增加愤怒，从而降低攻击性行为的门槛。 61 一种强有力的不适形式是伴随着低血糖的饥饿。\n\n已经证实，一天中温度越高，人们实施暴力犯罪的可能性就越大。气温升高会大大增加从家庭暴力、谋杀、强奸到暴乱和内战许多类型冲突的风险\n\n### 拒绝、排斥与嘲弄\n\n遭到拒绝会产生过多的负面影响，尤其是攻击性的急剧增强。被拒绝者”在随后有机会攻击他人时，对拒绝者和中立者表现出比未被排斥者强烈得多的敌意\n\n### 挫折、剥夺与攻击\n\n如果一个人在实现目标的进程上遭遇到挫折，那么由此而产生的挫折会增加攻击反应的可能性。总而言之，当目标近在眼前，或者当期望很高，或者当公平规则被违反，或者当目标没有令人信服的理由而受阻时，挫折最为明显。挫折往往不是简单剥夺的结果；而是**相对剥夺**（ relative deprivation ）的结果，当我们看到别人享有更好的条件，或者当我们失去了与我们期望相关的东西时，我们会感到被剥夺。\n\n相对剥夺解释了大多数社会革命中由来已久的一个谜团：它们通常不是从那些生活在最底层的人开始的。最常见的是那些最近摆脱了生活困境，环顾四周，发现有人生活得比他们更好而且感觉自己系统地受到不公平对待的人。\n\n## 攻击的模仿，学习\n\n现在我们来看看社会认知学习理论的一些发现。社会认知学习理论认为，人们通过诸如他们的信仰和对事件的感知等认知过程，以及通过观察和模仿他人，学习如何去行动 —— 包括攻击行为或有益行为。\n\n### 武器效应\n\n实验发现，如果漫不经心把步枪（而不是网球拍）放在乘客座位上，人们开车时会更具攻击性。\n\n### 匿名\n\n社会学习的某个方面往往会抑制攻击性，那就是大多数人必须对自己行为负责的倾向。但是，如果这种责任感被削弱了，会发生什么事情呢？菲利普 · 津巴多 89 已经证明，匿名的人由于无法加以识别，往往比不匿名的人更具攻击性。匿名会导致去个性化（ deindividuation ），这是一种自我意识减弱的状态，减少了人们对他人如何看待自己的担忧，并削弱了对被禁止的行为方式的限制。\n\n### 大众媒体\n\n随着时间的推移，不断推出的有关暴力的图片和描述会让我们麻木。当我们看到人们受到越来越多的伤害时，我们所感受到的痛苦却会相对减少，这就是所谓的脱敏过程。人们可以通过收看晚间新闻的战争场景、每天玩几个小时的偷车游戏，或者通过目睹发生在父母之间的现实暴力，来让自己变得麻木。\n\n随着时间的推移，那些玩过许多不同暴力游戏的人，更容易发展出被称为敌意归因偏见（ hostile attribution bias ）的倾向，以敌对的方式解释他人模棱两可的行为的倾向 —— 而不是给予他人善意的怀疑\n\n频繁地接触暴力媒体，尤其是暴力视频游戏，确实会对许多儿童和青少年产生影响，当然这种影响对那些已经形成暴力行为倾向的儿童和青少年影响最大。观看暴力似乎对那些易受伤害的观众影响更大，原因有以下五个：\n\n（ 1 ）它会增强生理性唤起（“我想我真的很生气，而不是紧张”）；\n（ 2 ）它会诱导人们模仿敌对或暴力人物的倾向，削弱以往习得的禁忌（“如果他们能做到，我也能做到”）；\n（ 3 ）它会引发潜在的愤怒、恐惧或挫败感（“我最好在他抓住我之前抓住他！”）；\n（ 4 ）它能促进人的心理麻木，减少移情（“呵呵，再来一次，还有什么？”）\n（ 5 ）当我们感到沮丧、愤怒或受伤时，它通常会示范我们认可的行为方式（“哦，你就是这样做的！”）。\n\n## 攻击的要素\n\n\n### 性脚本和同意难题\n\n理解最令人不安和最持久的攻击类型之一：强奸和其他形式的性侵\n\n\n一个答案可能在于：作为性别角色的一部分，生活在美国社会中的男性和女性学习了不同的性脚本。 113 性脚本因文化、性取向、种族、年龄以及地域的差异而有所不同，而且会随着时间的推移而发生变化。\n\n在美国，对于年轻、异性恋的女性和男性来说，一个主要的脚本是女性的角色是拒绝男性的性行为，而男性的角色是坚持不懈去追求。这个脚本或许可以解释为什么许多人对“不”这个词的含义争论得如此之多。\n\n# 如何减少暴力\n\n## 惩罚\n\n对于普通公民来说，减少攻击的一个明显方法就是惩罚。如果人们要建立长期的非攻击性行为模式，作为孩子，他们必须内化一套反对攻击性反应的价值观。总的来说，这项研究表明，如果对攻击性行为的惩罚既及时又适度，那么尚未形成价值观的儿童更容易对攻击性产生厌恶。\n\n这些研究似乎意味着：（ 1 ）看到攻击者得到奖励会增加儿童的攻击行为；（ 2 ）看到攻击者受到惩罚不会增加或减少儿童的攻击行为。完全不让孩子接触攻击性榜样也会起到同样的效果。\n\n提供非攻击性榜样遏制攻击的一种重要手段就是清楚地表明这样做是不适当的。最有效的标准是社会 —— 也就是说，在同样的情况下，其他人选择和解而不是报复。\n\n培养同情心：同情心对人类生活至关重要，它是非人性化的解药。已经证明在儿童的同情心和攻击性之间存在着负相关：同情心的强度越高，表现出攻击性行为的可能性就越小\n\n培养利他主义和专注力\n\n利他主义 —— 为他人做一些事情，即使是以我们自己直接的舒适或快乐为代价 —— 是对付攻击的一剂强力解药。利他主义会给人们带来很好的感受。\n\n冥想也可以帮助","n":0.113}}},{"i":11,"$":{"0":{"v":"Skill","n":1}}},{"i":12,"$":{"0":{"v":"Knowledge_management","n":1},"1":{"v":"\n# P.A.R.A\n\n[link](https://fortelabs.co/blog/para/)\n\n- project\n  - a series of tasks linked to a **goal**, with a **deadline**\n- area\n  - a long term activities with standard to be maintained over time\n- resource\n  - a topic of them of ongoing interest\n- archive\n  - inactive iterms from the other three categories\n\n![](/assets/images/2021-11-16-10-14-39.png)\n\n![](/assets/images/2021-11-16-10-14-49.png)\n\n\n# project\n\n- 整理知识库\n  \n\n# area\n\n- finances\n- health\n- time management\n- house\n- relationship\n- professional development\n- humor\n- food\n- knowledge management\n\n# resource\n\n- blockchain\n- EV\n- 直播\n- metaverse\n- search engine\n- mlops\n- work_relationship\n- project_management\n\n\n# 自己的已知存储内容\n\n- onenote\n- 有道\n- Evernote\n- inoreader\n- pocket\n- workflowy\n- 收趣\n- 简悦\n- kindle\n- omnifocus\n\ninoreader -> google sheet -> 整理到resource/area -> 保存网页到dropbox\n\n已有的都整理到dendron里\n\n手机看到的到inoreader\n电脑看到的到简悦。\n\n不同的平台有不同的好处，但还是需要最后合并。","n":0.105}}},{"i":13,"$":{"0":{"v":"Decision","n":1},"1":{"v":"\n\n# 10-10-10\n\n- How will we feel about it 10 minutes from now?\n- How about 10 months from now?\n- How about 10 years from now?","n":0.204}}},{"i":14,"$":{"0":{"v":"Rules","n":1},"1":{"v":"\n\n知道做什么会出错，不要去做！\n\n\n# 底层规律\n\n- 人类\n  - 生存\n  - 社交\n\n人类的神经是受外界的影响而改变的，每个人的经历形成了每个人独特的世界观\n\n## 心理学\n\n认知吝啬者：我们总是寻求保存认知（心理）能量并**将复杂事物简单化处理**的方法。我们会**利用经验法则**去走捷径。我们会忽略一些信息以减少认知负担；我们会过度利用一些信息以避免去寻找更多的信息；或者我们只是按照最初的直觉，接受一个不够完美的选择，因为它已经足够好了。\n\n### 倾向\n\n\n- 可得性\n  - 峰终原理\n  - 锚定效应\n  - 简单联想\n- 损失厌恶，害怕小概率事件\n  - 奖惩机制\n- 寻求解释\n  - 避免怀疑，消除不确定性\n- 快速分类\n- 性别的关注点不同\n  - 男性和其他男性竞争\n  - 女性挑选男性，关注自己的孩子\n- 自己\n  - 注重自己的利益\n  - 高估自己\n  - 自我欺骗\n- 社会\n  - 寻求社交认同\n  - 权威\n  - 注重声誉\n  - 互惠原理\n  - 一致性原理\n","n":0.147}}},{"i":15,"$":{"0":{"v":"Vivid","n":1},"1":{"v":"\n# 生动形象\n\n- 当一件事情越生动，越个人，越有趣，越有情感。我们越容易受他的影响\n- 我们也会高估于事件发生的可能性。当这件事非常形象生动的时候。\n- 我们对于自己亲身经历的事情，会给予过多的权重，认为他们会再次发生。\n- 对于一些证据表明的长期变化，而会低估作用\n- 我们更倾向于相信具体的事情，而忽略一些抽象的概念。我们更关注现在的信息，而不是可能没有提到的信息。\n","n":0.378}}},{"i":16,"$":{"0":{"v":"Social","n":1},"1":{"v":"\n# 社会接纳\n\n - 人会倾向于被喜欢，被社会认同\n - 喜欢表扬我们的人。\n - 会有强烈的倾向来避免被羞辱，失去自己的名誉\n\n\n# 权威\n - 我们倾向于服从权威，特别是当我们不确定被管理，或者当周围的人都做同样的事情的时候。\n - 专家也会犯错，重要的是弄清楚是哪一个专家可信。","n":0.277}}},{"i":17,"$":{"0":{"v":"Self","n":1},"1":{"v":"\n# 自己的利益带来的偏见\n\n因为做的事情会为自己带来收益，所以自己就会产生一定的偏见，做出的预测就不可信。\n\n对于他人的决策思考：什么是利益，谁收益。\n\n# 乐观\n\n认为自己是独一无二的，对于自己的未来十分乐观。当我们失败，我们会责怪外界环境和坏运气\n\n# 自我欺骗\n\n我们会骗自己，将现实歪曲成一个更舒服的世界，特别是危害到自己的利益\n","n":0.5}}},{"i":18,"$":{"0":{"v":"Rewards","n":1},"1":{"v":"\n# 奖励\n\n人只会去做有用的事情，设定奖励的目标会使人的行为向其优化。有奖励就会强化行为。\n\n不要过度的从别人那里学习，因为不一定同样的行为带来同样的回报。\n\n建立系统和规则来鼓励你希望的行为。\n","n":0.707}}},{"i":19,"$":{"0":{"v":"Impatience","n":1},"1":{"v":"\n\n\n# 缺乏耐心\n\n⁃ 对于比较近的事情会赋予更高的权重\n⁃ 我们倾向于立刻的奖赏。\n- 追求短期回报\n\n","n":0.447}}},{"i":20,"$":{"0":{"v":"Consistence","n":1},"1":{"v":"\n\n# 一致性\n\n\n当我们做出承诺之后，我们就会保持一致。我们的行为也会很难改变。我们更容易去寻找支持自己观点的证据。我们很容易去解释新的信息来支持和符合自己的观点。我们并不想放弃自己的努力。\n\n当我们做出一个公开，自愿的承诺。我们就很难去改变它，很容易坚持下去。\n\n当我们先同意一个小的请求之后。别人就可以一步一步地增大要求，因为我们一开始作出的承诺，所以后面我们会保持一致。\n\n强烈的意识形态也利用这一点来增强人们的一致性，让人失去理智，跟着领袖行动。\n\n避免这一点最好的方法就是当你发现自己在动一个洞里的时候，你就要停止挖洞。决定应该是由我决定去哪儿做出的，而不是因为我做过什么\n\n我们更喜欢默认的选项，我们倾向于让事情不改变。\n","n":0.707}}},{"i":21,"$":{"0":{"v":"Bias","n":1},"1":{"v":"\n# 偏见盲点\n\n认为我们自己比大多数人更客观、更少偏差。\n\n# 证实偏见\n\n在所有的认知偏见中，证实偏见是最主要的。它关系到我们如何看待世界和处理信息。我们注意、记住、接受各类信息，这些信息证实了我们已经相信的事情，并且倾向于忽视、遗忘、拒绝那些与我们的观点相悖的信息。\n\n证实偏见有助于解释为什么人们顽固地坚守那些牢不可破的信仰。他们会寻找一切可能的证据来支持他们所期待的是正确的，所以他们不必“改变主意”。\n\n# 自我中心偏见\n\n自我中心偏见人类是一种社会性种群，但我们也是以自我为中心的：我们倾向于把自己置于宇宙的中心。这就是为什么当人们能够将新信息应用到自己身上时，会比认为它只会影响到别人时更能记住新信息的原因。\n\n巴纳姆效应指的是，当人们被赋予可以适用于几乎所有人的模糊、万能的自我描述时，他们通常会说“难以置信！那就是我！”。\n\n# 消极偏见\n\n为什么坏事比好事具有更大的威力人类进化的一个奇怪的特点是它倾向于消极：我们倾向于关注潜在的威胁而不是祝福，这种倾向通常被称为消极偏见。消极反馈比积极反馈对情绪的影响更大。坏消息比好消息更容易、更经常地被分享。\n\n# 预测未来和回忆过去的偏见\n\n无论是积极的还是消极的，我们都会高估未来发生事件可能带来的情感影响，以及我们所做反应持续的时间。\n\n- 我们的记忆是有选择的，我们倾向于记住一些带有强烈感情色彩的事情。\n- 童年的回忆是不可靠的。\n\n# 重构记忆\n\n记忆是一个重构的过程。对我们记忆最为强烈的影响不是过去实际发生的事件，而是我们现在对那些事件的思考。我们构建的记忆更为符合我们自己的想象。正是因为证实偏见的存在，我们更有可能回想起那些证实我们看法的记忆。\n\n\n# 容易相信\n\n- 我们不是天生的质疑者，我们更容易相信，更难去怀疑。\n- 当我们想去理解一些信息的时候，我们必须先相信他。\n\n# 做事情的倾向\n - 人是坐不住的，如果感觉无聊失去耐心，总是想做一些事情，我们希望获得刺激和兴奋。\n - 但是一旦方向不对的时候，做什么都是错的\n - 当没什么话可说的时候，我们也会想讲话。\n\n# 情景的影响\n\n - 对于坏运气的发生的失败会给更多的指责，而对于有幸运的人给予态度的奖赏。\n - 极端的情况会使人做出在正常情况下永远不会做的事情。把人置于极端情况就会改变他们正常的行为。\n - 匿名的环境下，人们就会做出破坏的行为。","n":0.196}}},{"i":22,"$":{"0":{"v":"Bad","n":1},"1":{"v":"\n# 损失厌恶\n\n⁃ 我们对于自己拥有的东西会给他赋予更高的价值。\n⁃ 我们对于负面信息会更加敏感。\n⁃ 禁止某项东西，反而会让他变得更有吸引力。\n⁃ 我们会给更加稀缺的东西，赋予更多的价值。","n":0.408}}},{"i":23,"$":{"0":{"v":"Availability","n":1},"1":{"v":"# 可得性\n## 峰终原理\n## 锚定效应\n## 简单联想\n\n人们很容易将单一事件和其他的事件联系起来，产生不好或好的感受，这往往是不可靠的。\n\n要乐于接受坏消息，这样才能更好的客观认识事物","n":0.447}}},{"i":24,"$":{"0":{"v":"Photo","n":1},"1":{"v":"\n- scn\n  - 人像：远摄端使被摄体上半身充满画面\n  - 摇摄：想要拍摄在被摄体的背景带有速度和虚化移动效果的照片\n  - 手持夜景 \n  - 夜景人像：建议在拍摄后当场回放拍摄的图像以检查图像亮度。如果被摄体 显得较暗，靠近被摄体并重新拍摄。\n  - 逆光场景：在 此模式下拍摄一张照片时，会以不同的曝光连续拍摄三次。这会生成一张具 有宽广色调范围的图像，可最大程度地减少因逆光导致的限幅阴影。\n- P档\n  - 相机自动设置快门速度和光圈值以适应被摄体的亮度\n  - 您可以随意设定自动对焦方式、测光模式和其他功能\n- Tv 快门优先自动曝光\n  - 较快的快门速度会冻结移动被摄体的 动作。较低的快门速度可以产生模糊的效果，给人以动感。\n  - 如果最低的f/值闪烁，表示曝光不足。转动拨盘设 置较低的快门速度直到光圈值停止闪烁，或者设置较高 的ISO感光度。\n  - 如果最高的f/值闪烁，表示曝光过度。转动< 6 >拨盘设 置较高的快门速度直到光圈值停止闪烁，或者设置较低 的ISO感光度。\n- 光圈优先自动曝光 Av\n  - 较大的f/值(较小的光圈孔径) 会将更多的前景和背景纳入可接受的对焦范围。相反，较小的f/值(较大的光 圈孔径)会将更少的前景和背景纳入可接受的对焦范围。\n  - 如果快门速度“30\"”闪烁，表示曝光不足。 转动拨盘设定较大的光圈(较低f/值)直到快门速度 停止闪烁或设定更高的ISO感光度。\n  - 如果快门速度“1/4000”闪烁，表示曝光过度。 转动拨盘设定较小的光圈(较高f/值)直到快门速度 停止闪烁或设定更低的ISO感光度。\n  - f/值越高，光圈开口将越小。根据镜头的不同，所显示的f/值会有所不同。如果 相机没有安装镜头，则光圈值将显示为“F00”。\n  - 光圈值越大，从前景到背景合焦的区域就越广。\n\n![](https://tczimg.s3.amazonaws.com/vscode/450011983b674263b838a2ce1fa3fad2.png)\n\n- M 手动曝光\n  - 要设定快门速度，转动< 6 >拨盘。要设 定光圈值时，转动< 5 >转盘。\n![](https://tczimg.s3.amazonaws.com/vscode/7cf031b511694b9b909a9bb937144b36.png)\n\n- 灵活优先自动曝光 Fv\n  - 闪烁的值表示设定的值将导致曝光不足或曝光过度。调整曝光直到数值停止闪烁。\n\n![](https://tczimg.s3.amazonaws.com/vscode/4b4e3cf6eece4c09b105d82f9492111b.png)\n\n- 长时间(B门)曝光\n  - 在此模式下，持续地完全按下快门按钮期间快门保持打开，松开快门按钮时 快门关闭。此摄影技术称为“B门曝光”。B门曝光用于拍摄夜景、焰火、天空以及其他需要长时间曝光的被摄体。\n  - 设定所需的光圈值。\n  - 长时间B门曝光比通常在图像中产生更多噪点。\n  - ![](https://tczimg.s3.amazonaws.com/vscode/1d0bb4a4bef9490cacdfae58229b1be0.png)\n-\t测光 18%灰度\n![](https://tczimg.s3.amazonaws.com/vscode/b9ba7a172d734b2bb4d38e5563466ed7.png)\n- 自拍\n  - ![](https://tczimg.s3.amazonaws.com/vscode/e1a296f376ce48218cc4877d3cd15860.png)","n":0.11}}},{"i":25,"$":{"0":{"v":"Video","n":1},"1":{"v":"\n## iphone\n\n1.  虽然人眼在 24 FPS 的时候就会认为是动态影片，但是并不说明更高的帧率人眼无法分辨。一般来说越高的帧率就意味着画面会更加的细腻流畅。所以这也是为什么李安最近开始使用 120FPS 来进行电影拍摄的原因，你会有更加身临其境的感觉。\n2.  更高的帧率可以通过后期慢放为低帧率。我们管这种方式叫做「升格」，也就是我们俗称的慢镜头，比如说你拍摄了一个 1 秒钟的画面是 240 FPS，那么我们可以后期每秒钟播放 24 帧，这样就意味着我们把 1 秒钟发生的事拉伸到了 10 秒，这就是慢动作的基本原理。\n\n## 慢动作\n\n拍摄拍摄慢动作的精髓在于一定要是本身画面中有高速运动的物体才会比较震撼。更加重要的是，拍摄的时候时间不要过长。因为 10 倍慢动作的话，一秒钟就是播放 10 秒钟，如果你拍摄 10 秒就是 100 秒。\n\n高帧率拍摄的普遍特点是对于光线环境要求比较高，所以如果你是在弱光下拍摄，那么就会发现画质下降得非常迅速。所以如果你要是想要拍摄高帧率，最好是在光线环境较好的情况下拍摄。如果是小物体，最好是可以补充一定的光线进行拍摄。\n\n## 延时摄影\n\n所谓的延时视频就可以理解为「抽掉正常拍摄之间的一些帧，在组合到一起进行播放就会实现一种快进的效果」。\n\n「它可以让本来几小时甚至是几天发生的画面，仅仅在几秒钟就可以展现。」\n\n延时摄影保证画面的稳定非常重要。因为画面一旦产生非常轻微的晃动都会导致素材不可用。因此一般来说，如果是定机位的延时摄影都需要一个三脚架配合。\n\n### 远景类\n\n远景基本上都是用在一些空镜中，用来交代场景。比如如果你的主题是「秋日之旅」，那你就可以拍摄一些秋叶纷纷落下的大场景。你可以放在影片的开始做铺垫，也可以放在影片的中间做转折。\n\n### 中景类\n\n这一类镜头最为常见，尤其是中特写几乎是所有的 VLog 都会使用的镜头（大部分的手持自拍就属于这个类别）。这类镜头的好处就是可以交代主角的动作，完成叙事任务。\n\n### 特写类\n\n基本上特写都是用来交代人物的表情，可以展现人物的心理状态。你的开心快乐都可以使用特写来表达。\n\n## 过程\n \n对于刚刚入门拍摄的用户来说，我们只需要知道 6 个字即可：推、拉、摇、移、俯、仰。\n\n*   推：直接靠近画面主体，让场景逐渐聚焦在某一个部分。\n*   拉：逐渐远离主题，逐渐展现主体所在的环境。\n*   摇、移：画面从一个方向移动到另一个方向。\n*   俯镜头：从上向下拍摄，一般用来体现主体的卑微。\n*   仰镜头：从下向上拍摄，一般用来体现主体的高地位。\n\n*   正确的握持姿势，双手握持手机拍摄。\n*   拍摄 4K 60FPS 后期回放为 4K 30FPS。因为慢镜头可以缓解镜头的抖动状况，所以一般来说我喜欢拍摄 4K 60 FPS 的原因就是可以慢放让画面更加顺滑，不过前提是对应的画面是没有对白。","n":0.136}}},{"i":26,"$":{"0":{"v":"Sun","n":1},"1":{"v":"\n# 落日\n\n\n「太阳落山前后，才是夜景拍摄的最佳时机。」\n\n# 逆光拍摄\n\n首先要有太阳，时间是太阳刚刚出来或太阳快要落山光线很柔和的时候。\n1.举起的手机，打开 HDR 模式。\n2.调节位置，使被拍对象遮住太阳的一部分，具体看图（注意是一部分！）\n3.调节对焦点，使画面中得人不会一片漆黑（可以稍微有点暗）或者后面的天空一片白。\n4.拍照。\n5.后期用 VSCOcam 把阴影和高光调节一下（把阴影调节亮，高光的地方调暗），其他的按需调节。\n\n![](/assets/images/2021-09-09-23-14-53.png)\n\n# tip\n\n头顶光，可以理解为从上照射下来的光，比如中午的太阳，屋顶的灯，不建议使用这种光线拍照，无论是人还是景物都会缺乏立体感，拍人的话，头发，鼻子，美股，帽子什么的容易在脸上留下杂乱的阴影，很容易拍出大花脸。\n\n\n# 种类\n\n摄影是光影的艺术，有了好的光线，就可以轻松出大片。常见的光线有顺光，逆光，侧光，头顶光这 4 种。\n\n![](/assets/images/2021-10-04-22-37-56.png)\n\n顺光，就是光线从摄影师背后射过来的光，特点是很亮，可以保证清晰度，缺点是画面显得死板，没有明暗对比，因为顺光也叫平面光。\n\n逆光，是指镜头正对着光线拍摄，特点是，可以拍出唯美剪影和轮廓光，缺点是，掌握不好很容易过曝，手机比不了相机，所以对手机摄影要合理期待。\n\n侧光，是指从你和被摄者侧面照射过来的光，户外的话一般日出后日落前都是都是拍侧光的好时机，优势就是侧光能够很好的凸显明暗对比和立体感，缺点就是掌握不好会拍出阴阳脸。\n\n头顶光，可以理解为从上照射下来的光，比如中午的太阳，屋顶的灯，不建议使用这种光线拍照，无论是人还是景物都会缺乏立体感，拍人的话，头发，鼻子，美股，帽子什么的容易在脸上留下杂乱的阴影，很容易拍出大花脸。","n":0.302}}},{"i":27,"$":{"0":{"v":"People","n":1},"1":{"v":"\n# 拍全身\n\n把双脚放到画面下边缘，因为手机镜头是定焦的缘故，镜头边缘会产生拉伸的畸变，所以看起来腿会长一些，而且拍摄的时候手机最好平视或者低角度仰拍，因为近大远小的透视原理，会在视觉上显得腿更长，脸更小。\n\n![](/assets/images/2021-10-04-22-33-55.png)\n\n# 拍半身\n\n不要把画面边缘截取在颈部，胸部，腰部，膝关节这些部位，因为会有一种截肢的感觉，应该在肩部，胸部以下，胯部，和膝盖上方，看起来会自然一点。\n\n![](/assets/images/2021-10-04-22-35-08.png)\n\n# 坐着拍\n\n双腿不要内收，因为肌肉挤压会显得腿粗，而且短，要像左前方或者右前方伸出去，而且脚踝要伸直，让脚面充当小腿的延长线，因为伸直，肌肉绷紧，所以腿会显得细长。\n\n![](/assets/images/2021-10-04-22-35-42.png)\n\n# 自拍\n\n想自拍脸小，可以用遮挡的方法，用手，胳膊，衣服，帽子，围巾各种各样的东西都可以。\n\n![](/assets/images/2021-10-04-22-36-39.png)","n":0.447}}},{"i":28,"$":{"0":{"v":"Lightroom","n":1},"1":{"v":"\n调整一张照片的基础后期一共有两个重要部分：一个是光线、一个是色彩。所以你首先要知道的是，不同的调节工具不过是为了调整这两个部分即可。\n\n### 曝光\n\n这一参数基本上大部分人都知道，直接控制画面的明暗，用来控制一张照片的整体影调。\n\n### iphone鲜明度\n\n这个调节功能，绝对值得一吹。不仅仅是我自己，身边的很多摄影师都对这个调节选项赞不绝口。更重要的是，这个鲜明度仅此一家。我没有在任何后期软件上看到过这个调整功能，就算有也是指颜色。而在这里，你可以理解为：「智能 HDR 的后期调整。」\n\n### 高光\n\n高光是指调整画面中亮度较高的部分。如果画面中有过亮的地方可以通过高光进行调节。很多人会喜欢用这个工具压曝光。但是其实数码摄影的特点就是一旦过曝就会损失很多细节。所以其实大多数情况如果画面中出现过曝的情况，想要拉回很多细节是很难得。\n\n不过，还是会有效果。而且实际使用中，因为这一代的 iPhone 智能 HDR 已经非常好，照片高光过曝基本上只会在超广角镜头中出现。我更喜欢使用这个工具增加高光，因为这样很多时候可以给画面中带来光线感。\n\n### 阴影\n\n阴影是指调节画面较暗的部分。一般如果你拍摄的画面中较暗的部分较多，想要更多细节，可以通过提升阴影获得。而且数码相机的特点是，阴影中往往会包含很多细节。但是需要注意的是，如果没有节制的提升阴影，会使画面出现很多噪点，所以一定要控制好量。\n\n### 对比度\n\n对比度可以让画面中暗的地方更暗，亮的地方更亮。这种调节方式可以让画面直接变的更加立体。也会更加具有层次感，如果因为天气等原因你拍摄的照片有些偏灰，那么对比度调节可以让画面更加通透。\n\n### 亮度\n\n亮度调节主要是调节照片的中间调。如果你想保护好阴影或者是曝光不要受过多的改变，那么调节亮度是一个很好的选择。不过我基本上很少使用，因为我认为中间调对于照片的整体色彩和层次还是影响比较大的。\n\n### 黑点\n\n简单来说就是可以让画面的阴影从某一个亮度开始全部变黑。正常后期很少修饰，如果拍到了很灰的照片那么这个功能可以让照片更有对比。\n\n### 饱和度\n\n调整照片的整体颜色浓度。如果是在一些风光作品、或者是静物作品中，我建议使用饱和度进行颜色的调整。一般来说大家都会喜欢让照片的饱和度更高一些，这样更加吸引眼球。但是高饱和度往往不耐看，相反，一些低饱和度的照片反而能够经久耐看，所以这也是什么很多经典的摄影作品都是低饱和度的原因。\n\n### 自然饱和度\n\n我自己其实很少调节饱和度，如果是想要照片的饱和度更高一些我会使用自然饱和度。自然饱和度一般来说都会提升画面中相对中性的颜色。更加关键的是，自然饱和度会适当的保证肤色不受影响，这对一些人像照片来说是非常重要的，因为很多人增加饱和度都会发现肤色变的很奇怪。\n\n色温\n\n而且后期也有很大的调整空间，比如色温调节。你只要知道这个参数可以让你的画面偏蓝还是偏黄，从而整体影响画面的冷暖调即可。\n\n### 色调\n\n你只要知道这个参数可以让你的画面偏绿或者是偏洋红即可，也是整体上影响画面的冷暖调。\n\n### 锐度和清晰度\n\n其实这两个参数从原理上来说，区别并不大，只不过是一个作用范围的问题。锐度更像是强化画面中边缘线条之间的过渡，而清晰度则是画面整体的对比度。这两者都可以让你的画面看起来更加清晰，你可以按照自己的喜好调节就好。\n\n### 噪点消除\n\n噪点消除一般都是用在弱光照片中，用来提升画面的纯净度，但是有一点要说明的是：\n\n「噪点消除的使用一定要有度，如果过度的使用会让画面的清晰度直线下降。」\n\n所以一般来说，如果我使用了噪点消除我还会给画面增加一点清晰度。\n\n### 晕影\n\n这是一个在人文纪实作品中经常使用的后期手法，即通过四周的曝光减淡，从而突出画面中央的主体。简单来说，就像是一个聚焦的过程。不过还是那句话，一定要适可而止。\n\n大家可能也注意到顶部的「自动」功能，这个功能其实是很强大的，我们在打开「视觉透视剪裁的调整」，通常它会直接进行自动调整。在前期拍摄了一些有一定视角歪斜的照片，绝大部分时候可以非常完美的一键式的完成校正、水平和垂直，当然你也可以关闭「自动」，然后手动进行调整。\n\n还有两个很重要却容易被忽略的独门秘技值得分享，首先是：\n\n1. 所有我们上述提到的参数调整，不仅仅适用于照片，也同样适用于视频。是的，这些参数调整很多后期软件在照片上都很常见。但是这么丰富的视频调整工具，很少有软件具备。所以如果你想要给自己的视频进行调整那么 iPhone 相册目前看来竟然是最佳选择。\n\n我就拿我自己非常喜欢的 Retouch 这个软件举例，这款软件可以是快速地消除画面中不必要的部分\n\n「自己先想好需要怎样的画面，再使用工具进行实现。」","n":0.2}}},{"i":29,"$":{"0":{"v":"Lens","n":1},"1":{"v":"\n# 焦距\n\n可以看出影像就是光线通过一个透光的小孔进入一个黑盒并被相机的传感器（或者是胶片）记录下来，这其中小孔就是我们所说的镜头。\n\n焦距是指镜头的光学中心点和传感器的距离\n\n## 广角\n\n超广角（13mm 定焦镜头）很多人对于超广角的第一印象肯定是「广」，这个「广」包含的是拍摄足够多的画面内容，其实对于超广角来说摄影师看中的是**夸张的透视效果**。\n\n越是广的镜头，越会有非常强烈的空间感，因为在超广角中透视强烈，会遵循「近大远小」的规则\n\n其实本质上这种拍摄手法恰恰是合理利用了超广角的空间感。把画面分为了「前景」「中景」「远景」三个不同的组成部分。我们要做的就是合理的把这些景物填充进去。\n\n超广角照片中低角度远远多于高角度。也就是说，使用超广角仰视拍摄往往更容易出现好照片\n\n## 长焦镜头\n\niphone的 所谓的数字变焦虽然听起来是比较高级的，但其实本质上就是一种裁切放大","n":0.408}}},{"i":30,"$":{"0":{"v":"Iphone_setting","n":1},"1":{"v":"\n# 夜景模式 \n\niPhone 的夜景模式不可以主动打开，手机会自行判断是不是需要夜景模式，但可以强制关闭，只要点击画面的左上角夜景图标就可以看到。\n\n夜景模式的最长时间是 30s，这种情况前提是手机必须判定你的手机在三脚架上或者是足够稳定的环境，这样你就可以拍摄到星星\n\niPhone 夜景模式的核心在于颜色还原。其实我们很多时候觉得夜晚拍照不好看，亮度只是一方面，其实颜色还原才是关键，这也是 iPhone 的夜景模式和其它手机一个夜景模式比较核心的区别—色彩还原\n\n# 手电筒\n\n这就是其实在日常拍摄时，我们不能忽略了「补光」的作用。目前我们的 iPhone 都已经具备了手电筒的功能，在拍摄一些主体相对较近的画面时，我们可以使用另一部 iPhone 的手电筒打开进行光源的补充。我们不仅仅可以通过手部的位置移动改变光源的方向，我们也可以通过重按手电筒进行光源强度的调整。\n\n# 实况照片\n\n实况照片的本质含义是给每一个瞬间更好的容错率。这个功能原理也是非常简单，就是每一次按下快门瞬间前后各 1.5 秒都记录下来。你可以简单的理解为直接拍摄了一个「动图」\n\n进入编辑界面，可以重新选择照片。因为实况照片本身拍摄了对应前 1.5 秒和后 1.5 秒的图像，所以如果我们想要更好的瞬间就可以重新寻找。这对一些合影留念的照片有着非常好的使用场景。拍摄一张人像，可能会出现表情包或者是闭眼的情况，此时就可以使用实况照片重新找到一张表情更好的。\n\n实况照片可以演化为不同的效果。这里你可以直接理解为动图制作。打开相册以后，找到对应的实况照片，上滑就可以进入到效果界面。坦率地说，我认为苹果在这里的设计还是有点深，导致很多用户并不知道这里还有一个效果的功能。\n\n## 长曝光\n\niPhone 也是有长曝光功能的。只不过这项功能是在实况照片中隐藏。但是需要说明的是，因为这里的长曝光是一种多张合成，所以想要获得清晰锐利的照片最好在按下快门前后各 1.5 秒保持手部的稳定\n\n# 快捷键\n\n只需要「向下滑动快门」即可。也就是说，现在横拍的拍摄界面快门键是「向下是高速连拍、向上是视频快录」，竖向拍摄时则变为向左和向右。\n\n# 滤镜\n\niPhone 本身的滤镜是可以直接前期使用的。我们可以在拍摄界面就直接选择滤镜，预览画面就可以直接看到滤镜效果。而且有一点需要说明的是，iPhone 的拍摄效果都是可逆的。比如你使用一个滤镜以后，如果不喜欢了，只要在相册里直接复原即可，所以你可以大胆地在前期使用任何你想要的滤镜，不需要有任何的顾虑。","n":0.189}}},{"i":31,"$":{"0":{"v":"Food","n":1},"1":{"v":"\n# 食物\n\n\n1，如果在普通餐厅，大排档这些地方拍照，因为环境很乱，适合近距离拍特写，突出食物本身，忽略杂乱的环境。\n\n![](/assets/images/2021-09-09-23-34-17.png)\n\n2. 如果是圆盘子，适合垂直俯拍，而且要使用正方形构图，不要只关注食物，餐具也很重要。\n\n![](/assets/images/2021-09-09-23-34-37.png)\n\n3. 常见拍实物的角度有垂直 90°，适合摆盘造型好看，食物比较扁平的，斜上 45° 能够很好地展现食物的层次感和周围的环境氛围，水平 0° 适合层次很多的食物，比如汉堡，蛋糕，马卡龙之类的食物。\n\n![](/assets/images/2021-09-09-23-35-01.png)\n\n4. 如果主体环境过于混乱，那么就要在画面中留白。注意想表达的主题\n\n\n5. 而区别于大量纯色的另一种干净是空间感。上图中的柠檬鸡无论是前景还是背景都色彩繁杂，但前景与观者之间空隙带来的距离感，和被虚化的背景都在强调主角的同时还减轻了观者的视觉压力，我认为它同样也是一张「干净」的照片。\n\n![](/assets/images/2021-10-04-22-51-23.png)\n\n6. 拍出场景感，比食物本身更诱人\n\n![](/assets/images/2021-10-04-22-52-47.png)\n\n还有一种非常值得分享的场景是朋友聚会，其实在很多时候我们分享一次尽兴的聚会时不一定非得是最后的丰盛一桌，这个过程其实更有趣，上图是在朋友家包饺子的时候随手一拍，最后竟发现它是我对今晚最满意的一张照片。\n","n":0.289}}},{"i":32,"$":{"0":{"v":"Focus","n":1},"1":{"v":"\n# 光圈\n\n我们前面说到光圈通过变大缩小可以改变画面的亮度，但是在相机上，因为光圈都是可以改变的，光圈带来的不仅仅是画面的明暗，还有「虚化效果」\n\n光圈：光圈越大，景深越小；光圈越小，景深越大。\n\n焦距：焦距越长，景深越小；焦距越短，景深越大。这也为是为什么 85mm，70-200mm 等焦距适合人像的原因，因为虚化好。\n\n# 对焦\n\n我们在拍摄的预览画面里点击会出现一个方框，这个方框就是所谓的对焦框。我几乎所有的照片都会主动点击对焦框拍摄\n\n我们很多时候拍摄照片不够有趣，是因为没有尝过更近的拍摄，很多场景如果能够更近一点会有着很不错的效果。\n\n\n## iphone\n\n在打开 iPhone 的人像模式以后，我们需要点击画面右上角的一个 f 形的图标。点击图标以后，我们的画面正下方就会出现一个调节光圈的界面。我需要在这里说明一下，这里的光圈仅仅是模拟了虚化效果，而不是改变真正的进光量，所以文章前面提到的光圈改变曝光在这里不适用。\n\n\n### 摄影室灯光\n\n你可以完全理解为这个光效就是为你的面部进行补光，尤其是适合一些注意自己肤质的女孩子。基本上我给我们家领导拍摄人像的时候基本上都是默认开启这个光效的，差距非常明显，所以一定要打开。\n\n### 轮廓光\n \n如果说摄影室灯光是给女孩子的，那么轮廓光就是给男孩子的。因为轮廓光会强化你面部的光线效果。让你的面部阴影更黑，高光更亮。也正是因为如此，会给人非常硬朗的感觉。所以这也是为什么说，这个光效更适合男孩子的原因。\n\n从我的实际使用经验来看，人像模式在半身人像以上有最好的表现。全身人像因为目前的算法局限会显得视觉上不真实。","n":0.277}}},{"i":33,"$":{"0":{"v":"Exposure","n":1},"1":{"v":"\n摄影是用光的技术\n\n# 原理\n\n- 快门时间\n  - 通过小孔打开的时间长短。小孔打开的时间越长，孔径不变的情况下进光的时间越长，自然光线就会越多，画面就会越亮，这就是我们所说的快门速度。\n- 光圈大小\n  - 通过小孔的孔径大小。小孔的孔径越大，那么单位时间内，自然光线就会越多，画面就会越亮，这就是我们所说的光圈。一般来说，光圈的数值为 f1.8、f2.8、f8、f16。并且数值越小，才意味着光圈越大，也就是孔径越大，进光越多。\n- 感光值\n  - 对于光线感受的能力越好，画面越亮。但这里有一个重要前提，随着感光值的提升，画面质量会开始下降。因此想要很好的画面效果，那么就需要尽可能地降低感光值。\n\n所谓的测光模式，不过是在计算画面中的曝光时针对重点的曝光对象有更多的加权。\n\n## iphone 拍摄\n\n所以我们在进行 iPhone 拍摄的时候，可以通过以下两种方式进行曝光的干预：\n\n01 点按画面\n\n02 调节滑杆\n\n我们可以在点击画面以后，看到一个对焦框，在对焦框的旁边有一个滑杆。拖动滑杆进行曝光调整，向上滑动提升画面亮度，向下滑动降低画面亮度。","n":0.236}}},{"i":34,"$":{"0":{"v":"Composition","n":1},"1":{"v":"\n1. 一幅好照片要有一个鲜明的主题（有时也称之为题材）;\n2. 一幅好照片必须能把注意力引向被摄主体;\n3. 一幅好照片必须画面简洁。\n\n\n摄影师的画面中没有「多余的事物」。画面中的每一个元素都是为了画面的表达，即使有多余的也会通过事物的摆放或者是裁切等方式去掉。而这一切，也属于构图。\n\n当我们构图的时候，就是通过对画面中元素的选择，布局从而能够达到：「让照片读者的视线引导向被摄体，以及简化画面中没有必要的元素的效果」。\n\n构图方式的选择没有对不对一说，更多的只能是适合不适合。所以，这就需要我们可以自行检验自己的构图方式。那么检验方式是什么呢？\n\n检验的方式就是我前面提到的，构图的意义是不是每一条都符合，怎么样，是不是很简单。\n\n\n## 三分法\n\n三分法，又称井字构图法。这是几乎每一个摄影师都需要掌握的构图方式。在这种构图方法中，我们需要在拍摄画面中抽象出两横两纵的线。因为这样其实特别像是一个井字，所以我们也叫井字构图法（以下全部统称为三分构图法）。\n\n非常多的影视作品中经常会使用黄金螺线法则这种方式进行构图。但是需要说明的是，一般来说只有在 16:9 的画面中，我们才会使用这种黄金比例分割。如果不是，效果反而适得其反。而如果不是 16:9 的比例我们就会对这种内容进行演化，演化的结果自然是三分法。\n\n### 居中\n\n居中构图是一种最正经的布局方式，很多时候也就意味着「威严」。所以，一些严肃人物的肖像照片几乎都是使用居中构图的方式。尤其是，当你的拍摄主题在画面中的元素比较大的时候，选择居中构图没有什么不妥的。\n\n\n### 对称\n\n对称构图是一件比较「形式化」的构图\n\n#### 镜面对称\n\n我们可以找到生活中各种各样的反射面。这些反射面是最为简单的产生对称的方式，比如水面的倒影就是一个最为简单的对称构图方式。如果是很大的水面，我们在拍摄镜面对称的时候，只要稍微放低角度就可以轻松完成拍摄。\n\n但是当你实际操作的时候，就会发现有的时候即使手机已经贴紧地面了，但是角度仍然不够低。这个时候，我们仅仅需要把我们的手机倒转一下，这个时候镜头几乎已经完全贴近地面的时候，就可以轻轻松松的完成拍摄。不要小看这种拍摄方式，这很多时候可以让你的照片增添很多光彩。\n\n#### 元素对称\n\n最为简单的就是我们在画面中绘制一条线\n\n对角线构图的本质是一种均衡感，其实从视觉服务上跟对称还是有些神似，但是其实还是有着本质不同的。因为在对角线构图中，我们的元素不需要「呼应」关系，需要的是「对立」关系\n\n![](/assets/images/2021-09-09-23-08-04.png)\n\n### 黄金螺旋\n\n黄金螺旋：在矩形中按照黄金比率旋进渐进无限分割，切点的连线形成对数螺旋线。　　\n首先，将要拍摄的图片的主体作为起点，就是黄金螺旋线的绕得最紧的那一端。这种类型的构图通过那条无形的螺旋线条，会吸引住观察者的视线，创造出一个更为对称的视觉线条和一个全面引人注目的视觉体验。\n\n## 引导线构图\n\n需要我们细致的聊一聊。因为在所有的构图方式中，如果能够用好引导线构图绝对会让你的作品脱颖而出。\n\n如果你走在路上，你会发现脚下在向前延伸的同时会逐渐交汇并消失在一点上，那么这个点就是叫做灭点。\n\n引导线是一种非常直接的引导我们视线的方式。通过引导线可以让我们的视线在画面中流动，从而展现画面中的不同主体。\n> \n这也是为什么，我们今天去看，非常多的风光摄影佳作，几乎随手可以看到风光摄影作品中使用引导线构图的原因。\n> \n当然，引导线构图绝不仅仅是只有线条的这样一个方式。其实，只要是画面中，任何具有指引含义的物体，都可以算作是引导线构图。\n\n\n## 前景\n\n是不是能够利用好前景，目前已经是一个合格的风光摄影师的必备技能\n\n为什么我们需要前景。一般来说，我们的照片都是二维的。但是本质上并非如此。我们在前面的对焦部分了解过这里的知识。大部分的拍摄都是主体和背景两个部分来完成。基本上，画面的空间感只能来自于主体和背景之间的距离。\n\n我们的空间开始加入了第三个层次。那这第三个层次就会极大地丰富整个画面的空间感，这也是前景最为基本的作用，或者说是最重要的作用。\n\n前景的好处远不止提高空间感中这样一件事。如果你是大面积使用前景时，还起到了简化画面的作用。例如，很多时候我们会使用一些植物花朵进行遮挡，让整个画面更加干净。所以，如果下次你的画面比较杂乱，不妨就可以使用这种方式来简化画面。\n\n前景仍然需要低调。很多人使用的前景过于明显，这种明显可能是来自于颜色，明暗等等。所以大多情况下需要记住前景是为了主体服务的，不能够喧宾夺主。\n\n## 寻找画框\n\n框式构图，就是尽可能地使用生活中一切可能的「框」把我们的主体，框在其中的方式。本质上，其实框式构图的好处和前景非常相似。首先是依然会营造一种独特的空间感。这种空间感和前景不同的是通过营造画框外和画框里两个世界来进行。也就是说，框外一个世界，框内一个世界。让我们照片有更加丰富的层次。\n\n### 质感构图\n\n说到质感，是一件值得仔细探讨的内容。当然，这种质感有很多的元素一起组成。而我们这里讨论的质感是最为直观的一种。摄影是一种视觉为主的艺术，这里面是所以使用了「为主」这个词是因为，其实摄影可以不仅仅是视觉。我们所有的构图技法都是服务于视觉上的刺激。但人对这世界上的事物很多时候时候是一个综合感官的产物，例如我们可以闻到气味，吃到味道以及摸到的手感等等。\n\n### 重复构图\n \n我们都知道重要的事情说三遍，本质上是因为在语言上，重复就意味着一种强调，其视觉上也是如此。这也就是重复这种构图形式的基本意义。其实想要拍摄到重复的构图需要取决于景物本身，因为只有景物本身具有重复特性，才能进行拍摄。\n\n# 拍人\n\n![](/assets/images/2021-09-09-23-31-25.png)\n\n如果太胖，太丑，可以用头发，帽子，书本，包包，树枝树叶，等物品遮挡脸部，腰部，而且最好拍侧身，叉腰或把胳膊抬起来，让肌肉绷紧。想自拍脸小，可以用遮挡的方法，用手，胳膊，衣服，帽子，围巾各种各样的东西都可以。","n":0.209}}},{"i":35,"$":{"0":{"v":"Color","n":1},"1":{"v":"\n# 色彩\n\n","n":0.707}}},{"i":36,"$":{"0":{"v":"Negotiation","n":1},"1":{"v":"\n# 说不 \n\n- 不要随便答应除非你真的想做","n":0.5}}},{"i":37,"$":{"0":{"v":"Movie","n":1}}},{"i":38,"$":{"0":{"v":"Love","n":1},"1":{"v":"\n- [[Basic|life.love.basic]]\n- [[分手的理由|life.love.breakup]]","n":0.577}}},{"i":39,"$":{"0":{"v":"Woman_type","n":1},"1":{"v":"\n# 分类\n\n- 家庭 vs 个人\n- 保守 vs 开放\n\n\n性开放和保守看上床时间\n家庭和个体看家里谁说了算\n\n## 开放 个体 （白左女权）\n\n- 割腕女\n  - 纹身多\n  - 性开放\n  - 拥有自己身体的自治权\n  - 抛开被男人的束缚\n- 女猎手\n  - 行为主动\n  - 温柔\n  - 家庭母亲主导\n  - 主动推动关系\n\n## 保守 个体 （田园女权）\n\n- 田园女权\n  - 相信婚姻关系\n  - 认为自己的身体价值是最重要的\n  - 推迟上床\n  - 母亲主导\n  - 向男方索取利益\n- 拜金女\n  - 可能找不到1对1\n  - 只认钱\n  - 多个男人对自己投资\n  - 短期租赁\n\n## 开放 家庭 （自由保守）\n\n- 女玩家\n  - 夜店\n  - 父亲主导\n  - 男生做决定\n  - 在意男性的看法\n  - 在不同男生中游走\n  - 女性特征让男性主动\n- 灰姑娘\n  - 坠入爱河很快\n  - 容易变心\n  - 很难不理会前男友\n  - 不会自己做决定\n  - 会被男人牵着走\n  - 立规矩\n\n\n## 保守 家庭 （传统保守）\n\n- 浪漫女\n  - 父亲主导\n  - 追求1对1\n  - 渴望理想伴侣\n  - 自带剧本，迎合剧本\n- 混圈女\n  - 1对多\n  - 通过男人上位\n  - 依附男人\n\n延缓做爱时间，不会劈腿，会隐藏自己\n\n女人不希望男人出轨，但她们喜欢一个可能出轨的男人。","n":0.1}}},{"i":40,"$":{"0":{"v":"Understand","n":1},"1":{"v":"\n# 了解一个人的话题\n\n合适\n身体维度、工作维度、人际交往维度和未来 / 精神维度 \n\n 第一组\n1. 如果可以在世界上所有人中任意选择，你想邀请谁共进晚餐？\n2. 你想成名吗？想以什么方式成名？\n3. 打电话之前你会先排练一下要说什么吗，为什么？\n4. 对你来说，“完美”的一天是什么样的？\n5. 你上次自己唱起歌来是在什么时候，给别人唱呢？\n6. 如果你能活到90岁，同时可以一直保持30岁时的心智或身体，你会选择保持哪一种呢，心智还是身体？\n7. 你是否曾经秘密地预感到自己会以怎样的方式死去？\n8. 说出三件你和你的伴侣看上去相同的特征。\n9. 人生中的什么东西最令你感激？\n10. 如果你能改变被抚养成人过程中的一件事，会是哪一件。\n11. 花四分钟时间，尽可能详细告诉伴侣你的人生经历。\n12. 如果你明天一觉醒来就能拥有某种才能或能力，你希望那会是什么能力呢？\n\n第二组\n\n13. 如果有一个水晶球可以告诉你关于自己、人生，未来乃至任何事情的真相，你会想知道吗？\n14. 有没有什么事是你一直梦想去做而没有去做的，为什么没有做？\n15. 你人生中最大的成就是什么？\n16. 在一段友谊之中你最珍视的是什么？\n17. 你最宝贵的记忆是什么？\n18. 你最糟糕的记忆是什么？\n19. 假如你知道自己在一年内就会突然死去，你会改变现在的生活方式吗？为什么？\n20. 友谊对于你来说意味着什么？\n21. 爱与情感在你生活中扮演着什么样的角色？\n22. 和你的伴侣轮流说出心目中对方的一个好品质，每人说五条。\n23. 你的家人之间关系是否亲密而温暖，你觉得自己的童年比其他人更快乐吗？\n24. 你和母亲之间的关系是怎样的？\n\n\n第三组\n\n1.  每人用“我们”造三个句子，并含有实际情况，比如“我们俩在屋子里，感觉……”\n2.  补完这个句子：“我希望和某人在一起，分享……”\n3.  如果你想和对方成为亲近的朋友，请告诉对方有什么重要的事情是他或她需要知道的。\n4.  告诉对方你喜欢他或她身上的什么东西，要非常诚实，说些你不会对萍水之交说的东西。\n5.  和对方分享生命中那些尴尬的时刻。\n6.  你上次在别人面前哭是什么时候？自己哭呢？\n7.  告诉对方，你已经喜欢上了他或她身上的什么品质。\n8.  你觉得什么东西是严肃到不能开玩笑的，假如有的话。\n9.  如果你今晚就将死去，而且没有机会同任何人联络，你会因为之前没有对别人说什么话而感到遗憾，你为什么到现在都没有对他们说这些话呢？\n10. 假设你拥有的全部东西都在你的房子里，现在房子着了火，救出家人和宠物之后，你还有机会安全地冲进去最后一次，取出最后一件东西，你会拿什么，为什么？\n11. 你的家人中，谁去世了会令你最难过，为什么？\n12. 说出一件你的个人问题，问对方如果遇到此事要如何解决。另外，也要让对方如实告诉你，在他或她眼中，你对于这个问题的感受是怎样的。\n\n\n- 什么使你现在的生活开心\n- “If you could predict the future how would you want it to look?”\n- “What is your biggest fear?\n- “How was your childhood?” \n- “What makes you feel special?” \n- “What is a quality you look for in a man?\n- “If you had a million dollars what would you spend it on and why\n- “What is your greatest passion?” \n- “Are you a spiritual person?” \n- “How often do you see your best friend ?” \n- “Who is the biggest influence in your life?”\n- “What do you value most in life?” \n- “What’s the hardest thing you have ever been through?” \n- “What are you grateful for in life?” \n- “If you could change one thing about the world, what  would it be?\n- “If you could go back to your childhood, what is one thing you’ve learned that you would teach another child?” \n- “What are your top priorities in life right now?” \n- “How do you react when someone makes you angry ?”\n- “What is your favorite attribute?” \n- “You know you’re beautiful, right?” \n","n":0.068}}},{"i":41,"$":{"0":{"v":"Type","n":1},"1":{"v":"\n几乎所有的爱情研究人员都将两种基本类型的浪漫爱情区分开来：激情型和陪伴型。 激情型爱情的特点是强烈的情感、兴奋、无法抑制的性欲和对所爱的人的强烈关注。如果这段关系是牢固的，陪伴型爱情就会取代它，这是一种更温和、更稳定的体验，以相互信任、可靠和温暖的感觉为特征。与通常短暂的浪漫激情相比，陪伴型爱情通常持续时间更长，并随着时间的推移而加深。陪伴型爱情的双方可以自由地谈论任何事情，并感到彼此之间深深地理解。因此，如果激情型爱情像可卡因，那么陪伴型爱情就更像一杯美酒 —— 美味可口，令人愉悦，很少有心悸和躁狂。\n\n# 过程\n\n在他的《幸福假说》一书中指出了每段浪漫关系中的两个危险点。第一个危险点在激情之爱阶段的顶峰，此时处于极度兴奋状态的伴侣们会一头扎进去。充满激情的爱，每一秒都想待在一起，他们会闪电般地搬到一起同居乃至结婚。有时，这些夫妻能够从激情阶段过渡到陪伴阶段。但是，如果在这个关键时刻，他们相信唯一真正的爱是由痴迷、性刺激和激情所定义的，他们可能会在最初阶段的吸引力消退时（这最终是必然的）便决定不再相爱了 —— 他们会不断地处于失望之中。\n\n第二个危险点出现在热恋开始消退的时候。当情侣们从最初的兴奋中走出来时，他们开始注意到心爱伴侣的缺点，而不知何故，他们之前竟然设法忽略了这些缺点。他们不再发送调情或充满激情的短信，只是提醒她要喂猫之类的琐事。海特认为，当一对夫妇到了这个阶段，他们必须要有足够的耐心。幸运的是，如果他们允许自己在他人身上投入更多，他们可能会发现自己有了一个真正美好的生活伴侣\n\n我们的内隐爱情观念的影响；我们是否有能力发展成安全型依恋关系的影响；我们能做些什么来弥补最初阶段的强烈欲望的丧失。\n\n## 内隐爱情观念\n\n对于那些相信浪漫命运的人来说，满足感和在一起的时间长短之间联系更强，但它也与应对压力时的逃避策略有关。“命中注定”的关系在风平浪静的时候是最幸福的，但当狂风暴雨袭来时，他们的爱情小舟却会搁浅。这些夫妻发现，当他们的伴侣不可避免地不再符合他们的理想标准时，他们很难在关系中保持满意。相比之下，那些认为爱情是随着年龄增长而增长的夫妻在应对策略上投入了更多的努力。随着时间的推移，他们会更满意 —— 即使他们的伴侣不再满足他们最初的理想。他们期望自己的伴侣随着时间的推移而改进和变化，他们对关系衰退的暂时性有更好的理解。对于“让我们一起解决”的夫妻来说，冲突与他们对关系质量的评估没有关系；相反，他们会积极地与伴侣讨论问题，并修复彼此之间的裂痕。\n\n## 安全性依恋\n\n没有安全依恋的人对真诚的赞美持怀疑态度，并倾向于对轻微的过失进行猛烈抨击。随着时间的推移，他们的伴侣往往会厌倦重复听到那些没有保证的承诺。通过这些自我实现的动力，对被拒绝的恐惧进而增加了被拒绝的机会，这反过来又强化了这个人不值得去爱的观点。\n\n他们发现了信任伴侣的能力 ——“ 相信他（她）会在我们脆弱的时候，以一种对我们的需要的方式来对待我们”，预示着随着时间的推移，逃避倾向会减少。芬克尔的例子得到了许多研究的支持，表明对于不安全的人来说，找到一个有安全依恋史的伴侣是一个不错的选择，但正如我们将看到的，这并不是他们唯一的补救办法。\n\n刺猬困境：与一段充满激情的恋情的起起落落相比，一段伙伴关系中更稳定、更可预测的节奏会带来特别的回报。一段历久弥坚的长期关系带来的好处包括情感上的安全感，以及被一个既了解你的优点也了解你的缺点的人接受所带来的可贵的舒适感。\n\n长期亲密的关系也有潜在的黑暗面。 有句经典的讽刺：“你总是伤害你所爱的人。”为什么会这样呢？回想一下我们之前对得失理论的讨论，一个相当令人惊讶的事实是，当一个人最初对我们的消极情绪逐渐变得积极时，我们会发现这种情况比那个人对我们的感觉一直都是完全积极更有价值。相反，当一个曾经积极评价我们的人慢慢地以消极的眼光来看待我们时，我们往往会发现，这比他（她）自始至终地表达对我们的负面情绪更有害。这一过程表明，一旦我们对长期伴侣的奖励行为有了一定的了解，作为奖励来源的那个人可能会变得不如陌生人那么重要。**这一过程表明，一旦我们对长期伴侣的奖励行为有了一定的了解，作为奖励来源的那个人可能会变得不如陌生人那么重要**。这种关系越紧密，过去那种长期的尊重和回报的历史越久远，他们的退缩就越具有毁灭性。事实上，长期的恋人更有能力造成损失，而不是提供额外的收益，从而伤害他（她）所爱的人。\n\n哈维（ O.J.Harvey ） 89 发现人们对陌生人的恭维反应比对朋友的恭维反应更积极，为什么会这样呢？来自陌生人的认可是一种收益，根据得失理论，它会让我们感觉更好。我们似乎总是在陌生人的眼中寻求帮助，而对我们最亲密的朋友和爱人的熟悉却使我们受到伤害或失望。正如罗马政治家西塞罗（ Cicero ）早在公元前 46 年所建议的，解决办法是将这些损失和伤害的感情转化为令人兴奋的收获和新的理解。那么，怎样才能做到呢？\n\n我们想要感觉到我们的伴侣真正地、深深地理解和接受我们；并且知道这一点的同时不用担心，如果他们“真的”了解了我们最深层、最卑鄙的缺点和错误，我们会被拒绝或抛弃。缺乏安全感的人很难找到这种平衡。那些自尊心低、对拒绝高度敏感、因而觉得自己不值得被爱的配偶也会这样。由于这些人害怕被拒绝，他们倾向于将自我保护置于自我表露之上；他们竖起了“刚毛”，因此失去了他们渴望拥有的那种温暖关系。我们对伴侣对我们的看法会影响到我们的反应：后退一步，保护自己的利益，还是承认自己的脆弱，寻求沟通？情侣们必须在两种选择之间作出选择，一种是走一条风险更大但更诚实的道路，加深与伴侣的关系，并带来许多新的情感收获；另一种是走一条保护自己免受进一步伤害的道路，但会增加进一步受损的可能性。在人际关系中，就像生活中的许多事情一样，风险越大，潜在回报就越多。\n\n在这个过程中，真实性 —— 与伴侣自由分享真实感受和看法（甚至是负面的）是避免陷入停滞的关键。它减少了一段关系最终陷于停滞的可能性，就像多汀夫妇所追求的那样。当人们压抑自己的烦恼，把自己的负面情绪和真实想法隐藏起来时，他们往往会陷入一个看似稳定和积极的脆弱平台，但这一平台可能会被情绪的突然反转所摧毁。\n\n**维持爱的一个重要因素是相信我们的伴侣理解和支持我们；他们信任我们，关心我们，和我们在一起会感到安全，知道什么对我们重要，并积极帮助我们满足需要，最为根本的是，对我们的内心了如指掌**。这使我们不仅能够爱对方，而且能够以一种方式感受到对方的爱，即使对方不在我们身边，我们也能与对方建立联系。这种被理解的基本感觉比实际的行为指标（如谁在家里做什么）可以更好地预测幸福感、安全感和舒适感\n\n在被需要和有压力的时候互相支持的人比不支持的人，更有可能建立起一种健康的关系。但是如果事情进展顺利呢？事实证明，对处于亲密关系中伴侣的幸福感的一个强有力的预测因素是，无论是困难还是成功的时候彼此都能守在对方身边。雪莱 · 盖博（ Shelley Gable ）和她的同事 96 发现，当人们描述最近的一次成功时，从他们的浪漫伴侣那里得到了积极的回应（“多么棒的消息啊！我知道你能做到！我们马上去庆祝吧！”）。几个月后，他们的关系比那些得到不太热情回应的人（“干得好，亲爱的。晚餐吃什么呢？”）更幸福。这是有道理的。在许多关系中，伴侣的成功会带来复杂的情感；这种喜悦可能带有一丝嫉妒。盖博的研究表明，当夫妻之间的快乐远远地掩盖了嫉妒时，他们才是最幸福的。\n\n随着一段关系朝着更亲密的方向发展，真实性对于持续的激情、承诺和成长变得越来越重要：即便不情愿，我们也会放弃努力给人留下好印象的能力，并开始揭示有关我们自身的诚实的关系。真实性意味着愿意在适当的情况下，以表露出我们关心的方式，向我们的朋友和所爱的人表达各种各样的感情。\n\n大多数人都会接受并对爱人的直言不讳做出反应。直言不讳，我指的是一个人在不指责、不抱怨、不评判或不嘲笑另一个人的情况下，清楚地表达出自己的感受和关切。直言不讳之所以有效，就是因为直言不讳能让接受者无偏见地倾听。","n":0.18}}},{"i":42,"$":{"0":{"v":"Past","n":1},"1":{"v":"# 聊天学到的\n\n- 分享情绪\n- 分享生活的点滴\n- 不要说太多\n- 感觉自己失败的原因就是除了lrq 我的付出比对方多，不是很平衡。\n- 说的太多 缺乏神秘感了\n- 对方如果不主动那我宁可放弃\n\n# lrq\n\n- 对方比较主动\n- 我一直被引领 被安排 被教导\n- 对于我来说是一个很习惯的方式，因为这是我和父亲的关系\n\n\n# lz\n\n- 一开始算是两情相悦的，一起出去玩也比较开心\n- 中间说没感觉让我伤心了很久\n- 其实主要原因是我逼得太紧了，让人想逃离，需求感太强了\n- 没有激情也是真的，我给的安全感太多了\n\n# wbw\n\n- 总体来说一直是我在找话题\n- 时间久了就形成了习惯\n- 毫无疑问wbw不是那种你对她好她就会一直和你在一起，她是想和自己喜欢的人在一起的类型\n\n\n\n","n":0.2}}},{"i":43,"$":{"0":{"v":"My_point","n":1},"1":{"v":"\n# 我注意的点\n\n- 不强迫别人去做我想做的事\n- 接受对方的好意\n- 理解尊重对方的观点，不说“废话”, 不说脏话666\n- 感情中没有对错，我保留自己的想法就好\n- 对方想说自然会说\n- 注意细节\n\n# 我不想找的对象\n\n- 回避问题，拒绝沟通\n- 没有上进心\n- 不喜欢户外运动，旅游\n- 时间观念淡薄 \n- 太瘦\n- 不健康\n- 家庭差距大\n\n# 我的评价标准\n\n1. 你最看重她的一项品质是什么？（善良、诚实、 善解人意、 会照顾人等）\n\n聊得来\n\n善解人意, 聪明， 有上进心，对于事物充满好奇\n\n2. 为什么这项品质对你很重要？ （可以帮你判断她人格是否健全、 世界观是否正确）\n\n好相处，自己在相处的时候可以放松自己\n\n3. 列出那些你不能去容忍／忍受对方做的事情。（欺骗、 嫉妒、 颐指气使、无理取闹等）\n\n- 出轨\n- 不诚实\n- 忽略事实\n- 情绪化\n- 冷暴力 拒绝沟通\n- 不在乎我的感受\n\n4. 你能为她提供什么？ （时间、金钱、物质、感情支持、安全感等）\n\n- 成长\n- 陪伴\n- 安全感\n- 提高效率\n\n5. 你最喜欢做的事情或爱好是什么？ (你的爱好或癖好，运动、绘画、音乐、表演等)\n\n- 跑步\n- hiking\n- 写代码\n- 看书\n- 看动漫\n\n\n6. 你最欣赏自己的地方是？（自信、乐观、 运动健将、 烹饪高手、 工作才干等）\n\n- 自律\n- 时间管理\n- 上进心\n- 愿意尝试新鲜事物\n\n7. 你的缺点是什么？\n\n![[thinking.shortcoming]]\n\n8. 在恋爱关系中， 你认为最重要的东西有哪些？（对我来说是三个： 坦诚、 专一和尊重）\n\n- 专一\n- 良性沟通\n- 尊重\n\n\n9. 想找的对象\n\n- 聊得来 \n- 主动一点\n- 可以一起出去玩\n- 喜欢动漫\n- 可以理性的讨论问题\n- 聪明 ","n":0.116}}},{"i":44,"$":{"0":{"v":"Make_love","n":1},"1":{"v":"\n# 练习\n\n- 龟头按摩\n- 冠状沟按摩\n- 反手撸\n\n# 等级\n\n- level 0 疲软：前两个练习\n- level 2 半勃：反手撸\n- level 3 持续勃起：快感期\n- level 5：收缩pc肌，睾丸抬起，准备射\n- level 6：射\n\n练习找准level 3的感觉\n\n# 延时技巧\n\n- 先停留\n- 慢插 1s 1下\n- 切换频率\n- 拍打式，不是幅度大\n- 拔出一半，旋转式，可以慢，摩擦yd\n- 女上前后，把控幅度，不要上下\n- 注意力，注意对方的快感\n- 一拍吸气 7拍呼气\n- pc肌，1s推1s放，往外推\n","n":0.174}}},{"i":45,"$":{"0":{"v":"Live_together","n":1},"1":{"v":"\n1，买套，几盒几盒的买。 最好去正规店里，或者各大药店，尽量不要网上。不要体外，中招的不在少数。\n\n2，两个人租房子，不要住到对方家里去。\n\n3，做好因鸡毛蒜皮的事吵架的准备。\n\n4，明确规划好双方要做的家务问题。因为家务问题而分手吵架的也不在少数，不要以为仅仅是做饭，洗衣服等等，细节打败爱情。\n\n5，不要一起洗澡，因为，emmmm……不仅会啪啪啪，更是因为女生开很烫的水都不会觉得热，男生：哎呀妈呀你要烫死我！！！！\n\n6.同居也不要着急见父母，请再深入了解一下对方的人品，不管之前的缺点隐藏的再好，一再同居几个月，都会原形毕露，这个时候再看看，你是否真的可以接受对方的缺点。\n\n7，规定好双方最晚回家的时间。除非真的有其他急事。一来可以推掉不必要的应酬，二来也可以养成良好的习惯。\n\n8.如果争吵的非常激烈，不要轻易离家出走，也不要因为气愤砸家里的东西，这也是我需要改正的地方，我总是容易情绪上来，晚上离家出走，其实很不安全。最后对方也会疲惫。\n\n9，备一些常用药品在家里。比如拉肚子的，感冒的，发烧的等等。\n\n10，每天给对方一个小时的自由时间。打游戏也好，安静的看书也好。给对方一点空间，不要逼的太紧。\n\n11，不太建议钱放在一起，避免未来一旦没修成正果，引发一些不必要的争端。\n\n12，不要参与对方的家事。除非主动和你商量对策。\n","n":0.707}}},{"i":46,"$":{"0":{"v":"Investment","n":1},"1":{"v":"\n\n# 投资\n\n- 时间投资\n  - **偶尔找对方擅长的事帮忙，并且用正面回馈来强化**，让对方主动乐于为你做这些，而不是去提要求，也不是占便宜。\n- 情绪投资\n  - 爱情产生关键在于引起对方情绪波动。你可以先把对方捧到天上去，再通过调侃或忽冷忽热的方式让对方情绪下跌，再上再跌\n  - 你要不卑不亢，敢说敢作。**对于不满意的地方，该说就说，该怼就怼**。只是要注意语气和尺度，不要开那种有伤大雅的玩笑。\n- 物质投资\n  - 利用他之前在自己身上付出的资源\n  - 习惯成自然，利用惯性，让他习惯于为自己付出。\n\n- 引导投资的技巧一定要配合一个节奏。\n  - 你需要不断的保持一个微妙的节奏，有一个形象的比喻——驴前面的胡萝卜。要保持将要吃到但吃不到的状态，不要让对方吃死了。要保持一定的自我，太顺从，对方会觉得总能够轻易吃到“胡萝卜”，也就自然而言不想动了，会让他可能还喜欢你却也失去付出动力。\n  - 你既然要对方持续的为你付出，那么你就要长期的保持你的魅力和价值，甚至不断的换着法子吸引他，让对方长期愿意投资你。\n\n不要骚扰，也不要怕太麻烦对方。关系都是麻烦出来的。其实**让对方愿意和你接触有两个维度：一是能看到你本身的价值；二是和你接触他自己能获得价值感**。\n\n你之前可能就有些付出太多，这没有关系，你从现在开始，把重心从“付出”转移到“吸引”和“引导”上来。**你对他的好不是他的，你是有主导权的，随时可以收回。人都是怕失去的。**\n\n他对你不好，是你允许的；他对你好，是你可以引导的\n\n","n":0.224}}},{"i":47,"$":{"0":{"v":"Health","n":1},"1":{"v":"\n从生物力学的角度来看，有迹象表明，持续手淫的男性基本上是在宣传他们作为费洛蒙贝塔的地位，而女性的生化机制会下意识地登记他们的情况。睾丸激素较高的男性在性自信和气味方面都表现出他们的性能力。\n\n如果你长期缺乏睾丸激素，和/或受到催产素的镇静作用，你的性能力就处于不利地位。事实上，从进化的角度来看，我们野蛮的狩猎采集者开始时的Beta型男性会更容易将手淫作为一种性释放，因为从理论上讲，他们比Alpha型男性获得的繁殖机会少。\n\n对男人来说，手淫是一种变态行为。它意味着没有能力成为 \"足够的男人 \"去干一个真正的女人；打飞机对男人来说是失败的，但对女人来说是一种权力。\n\n手淫化解了这种冲动。它杀死了这种冲动，或者至少是升华了它。因此，有理由认为，一个以手淫为耻的全球社会惯例，对一个有兴趣扩展的社会来说是有益的吗？\n\n# sex\n\n一个健康的男性产生的睾丸激素是女性的12至17倍。女人想要和男人一样多的性生活，或者像男人一样频繁的性生活，这在生物学上是不可能的。相信当一个女人说：\"我不明白为什么性对男人如此重要 \"时，她说的是字面上的事实。没有一个女人会经历17倍于她自己的睾丸激素水平（除非有类固醇）。\n\n女性的性欲也是周期性的。即使在她的排卵周期的高峰期，当她处于最饥渴的时候，她也不会体验到男人一天24小时都在做的事情。这就是神话的根源，也是社会习俗的来源。\n\n性欲取决于雄性激素水平，而不是雌性激素水平。","n":0.447}}},{"i":48,"$":{"0":{"v":"Get_back","n":1},"1":{"v":"\n# 挽回\n\n当你穷追猛打时，你的需求感太强，降低了自身的价值。\n\n需要断联来改变两人的心理差距。\n\n- 切忌急躁、患得患失。\n- 不要被对方忽冷忽热，忽左忽右的态度和情绪干扰。你大可以把他当做重新恋爱的对象，这期间你们之间保持距离感，我认为暧昧是最合适的！\n- 不要在去想对方为什么这样那样，对方在想什么等等。\n- 不要给对方压力，不要纠缠对方\n\n## 心态\n\n1. 首先，挽回的过程中你要有坚定的信念，相信我是可以挽回的她（他）的，我们现在只是暂时分开而已，你要坚定的相信这个世界上没什么不可能的，我不是在做成功学培训，也不是销售培训，但是你必须有这样的心态\n2. 再次，千万不要有种我错了，都是我不好的这种心态，我建议你们强烈克服这样的心态。呵呵，你这样做就是在不停的给自己减分，最后直到减分到0，如果让对方感到我们相处的时候你不珍惜，现在分手了，你居然……那么这样的话，我很明确的告诉你，你没戏了，会让对方觉得你不值得挽留，如果在心态上和姿态上让对方高出一等，嗯，嗯，男女通用，那么你注定要失去这段感情！但是我只是让你们克服这样的心态，我是让你们的之间的感情建立在平等地位，每个人都有自己明显的缺点，或者脾气不够好，或者生活太邋遢，或者给予的关心和关注不够等等，这些是需要我们改正的，只要我们改正就好，而且做到真真正正的改变！\n3. 就是你要挽回的那个她（他）从心里上要做到，她（他）不是最好的，她（他）不是我的真命天女或者真命天子. 不要一定，放平心态\n4. 想清楚自己在这段关系的控制能力，应该是我设置的自己的期望\n5. 不要觉得对方比自己好，所以就低她一等，尽力去讨好她。\n\n## 冷处理\n\n如果对方想冷静，想要你不再纠缠，你此时的冷处理，正和对方的心意，冷处理的过程中，甚至还会出现对方很好奇你怎么样。\n\n冷处理的时间里，要简单梳理一下自己，积极的改变自己，提升自己，做一个新的自己。这段期间不妨和自己谈一场恋爱，摆脱一下烦恼，不去想“能不能挽回”、“再联系时如果拒绝我怎么办”等这样的想法。这段期间内，相信自己，提升自己才是正确的解决方式。\n\n【冷处理期间，对方忘了我怎么办】实际上这个问题问的很没有必要，为什么这么说，既然你决定要冷处理，一定是对方对你排斥、拒绝、冷漠，冷处理也是迫不得已而为之；如果此时你再继续联系、纠缠对方，我想换成是你也很烦躁！既然对方不想与你联系，对你的感情已经在变淡，你还问不联系对方会不会感情变淡这样的问题，是不是很没有意义？\n\n【冷处理需要多长时间】冷处理的时间里，可以消除对方对你的否定态度，对你的否定态度越小，就越容易改变对你的想法！这个时候你再以朋友身份介入，不唐突的顺其自然的交往，我相信，对方对你的排斥就不会那么强烈了，这就是一个好的开始~~\n\n有人说，我冷了一段时间，尝试联系对方还是拒绝我！嗯，这个没什么怎么办，我只能说太正常了，有些人冷了一段时间会态度缓和，而有的就不会。再次联系都是从进攻开始，那么你碰钉子很正常，对方还是以往的态度，证明你根本没有消除对方的顾虑，对方对你还是有不满意的地方！你的主动没效果，继续被动，暂时消失一下，看看对方是否能尝试找你？不要指望迅速的见效。\n\n这条规则很简单，简单得不用去过多解释。你必须记住：在分手发生后接下来的至少4个星期内，不要主动跟她联系，包括打电话、发微信、发短信等等。没有任何例外的情况可以破坏这条规则！你一定、必须成为那个不去主动联系她的人。切断联系这条规则是有心理学和生理学理论做基础的。\n\n千万要记住：无论发生任何事，也不管你有多担心、多沮丧、多想她，你都不能是那个首先去联系她的人！\n\n如果她主动联系，你不可以有下面这类行为：\n\n- 对她生气\n- 情绪沮丧或悲伤\n- 对她言语粗鲁\n- 炫耀或吹嘘。有些男人会去吹嘘在分手期间他跟多少女人睡过或者是约会过等等。（就算那是事实，她也不会相信你，只会让自己显得更可悲。）\n- 讨论以前的关系（争论当时谁对谁错等等）。\n- 暗示或直接问她是否已经跟其他男人约会过或者睡过。（问这类问题是极最蠢的，除了让自己更失落外，还能有什么其他帮助吗？）\n- 央求她再给你一次机会\n\n\n## 重塑自我\n\n心态改善是挽回过程中有利于你的行动方向，冷处理之后，双方保持交集情况下，再次接触，要让对方感受到你的与之前的不同和改变，如果对方认可你的改变，对方越认可越有利于挽回，当然挽回的时机当然是越早越好。\n\n一定要搞懂或者清楚他为什么和我分开？心里要做到明明白白，其实许多分开的理由都是借口，如果你连分开的理由都不清楚，或者错误的把对方的借口当做分手的真正理由，那么说明你们彼此不是真正的了解，也许这样的挽回是否有价值值得商榷。\n\n其实这就是你们之间平时情感需求不一致积累的结果，没有给予对方的情感需求导致对方分手，这种情况还分为很多种，有的人其实没有做错什么，只是性格原因而已，这种则不必去花时间自我反思做错了什么，而有的人需要考虑一下是不是在这段感情中过于以自己我为中心而忽略了对方情感，导致对方逃离。\n\n## 如何突破对方防御\n\n所以不是三言两语、轻而易举就能挽回的，你要正视分手的事实，不能还总想着曾经的过往，甜蜜，这样你越想越痛苦，心里越焦躁，越着急挽回，越拼命的想为对方付出一切，以祈求对方能和自己复合，这样的心态没错吧？那么结果只是你俩之间的距离越来越远。\n\n此时我认为你们俩人的状态，以朋友这个角度接触是最好不过，有的则两人可以继续联系，甚至对你的关心不是特别排斥和反感，这样的情况就好不少，此时你们之间保持着小小暧昧的关系再恰当不过了。\n\n但是接触中要顺其自然，千万不能提及感情，不要再把对方当成你的恋人，你在联系对方，其实你想做什么，大家心知肚明，何必又要刻意提出来呢？你不说对方也知道你是怎么想的，但是你一说出来挑明，可就不一样了，对方会本能的心理防御，一提到感情，对方一定会排斥你，对你的态度立马转变，而此时的你身处情感煎熬中，一定会被对方忽冷忽热的情绪左右，你此时也根本冷静不下来，患得患失！\n\n循序渐进，顺其自然！在双方的接触中以很自然的状态进行，不要突然对方回复你几个短信，你就突然要约对方吃饭，谈谈怎么怎么样，这样做只能前功尽弃，状况进一步恶化!\n\n## 吸引力缺失\n\n吸引力的直接衡量标准是从智力、受欢迎程度、和自我价值、三观等方面的多个标准体现的综合价值\n\n在一个恰当的时间出现。具体时间男女生不太一样、性格也会有不同反应，在对方后悔怀念你的时候出现最佳，有时候都不需要你做什么自然而然就和好了，不知道该怎么办的时候，先从朋友做起。这时候一定不能再作、再去逼别人，那就连最后的希望都没了，凡事要注意方法。\n\n情感疲倦：累觉不爱、\n\n- 解决方式：暂时没感觉了，其实这种只是没有新鲜感了，一直在重复一样的相处方式和生活内容，久而久之就会觉得腻了，这种情况下其实分手一段时间反而是好事，因为提分手的一方冷静下来之后容易后悔。可尝试用朋友的身份继续相处就行，照样吃饭聊天看电影，该干嘛干嘛，或者先不见面也行，但一定做好沟通，不然对方容易真的死心放弃了，等到两个人心情都恢复好了，负面情绪消除得差不多再恢复情侣关系。同时可以尝试做一些不同的事，或者给对方一些小惊喜，互相承诺一些以后相处模式，定期做些特别的事，感情就可以长期甜甜蜜蜜了。\n\n供需失衡\n\n- 两个人的关系核心需求是女生需要宠、男生需要理解。\n- 从根本原因上来说，分手的人都是因为情绪价值得不到满足，或者说没有得到自己付出没有得到想要的回报。不同类型的人不自由各种各样的需求，因为每个人在亲密关系中需要的东西是不一样的，这些都是由一个人从小到大的成长所决定的，不管自己能不能意识到，都很难改变。\n\n因为在成长的经历中，有一些需求没被满足，少了这样那样的体验，长大以后在亲密关系当中就会下意识的去寻找和满足自己内心深处的东西，那些投射到心灵深处的特质，就是人在亲密关系当中寻找的吸引点，这是人性使然。\n\n\n## 破冰聊天\n\n破冰聊天的内容\n\n- 从生活话题入手，不要谈感情。\n- 从自身角度或者ta身边的人和事切入，不要谈及当事人。\n- 多谈论积极的生活状态，令人愉快的话题，向前看，不要谈过去。\n\n①引导聊天法\n\n不要说“最近过的怎么样”“你还好吗”“有时间吗”……诸如此类的“不专业的”聊天话术，把自己整的和推销员一样。这种就是典型的“纠缠话语”。另外还包括“你为什么不回我”“不能做恋人难道不能做朋友吗”“我放不下你”这样的话，雷区，不要踩。\n\n不过引导聊天法需要你能充分调动对方的好奇心，如果你俩交流还正常，你可以发个有关联的朋友圈，比如你们一起养了一只猫（别的根据情况自己想），或者展示她知道你以前从来不会做的事情，引导评论。\n\n或者发一些生活上她擅长你不擅长的东西去问她，还是拿猫举例，“怎么给猫洗澡”“猫不吃饭怎么办”之类的，还有送妈妈礼物送什么，女生可以问电脑出故障了怎么办……（其它生活上的自己想）\n \n②“三三聊天法”\n\n何解？就是你联系她，不管她理不理你，你就联系她三次，每次隔三天，每次发三句话。点到为止，及时结束话题也不要让对方感到有压力，不要聊太多。\n\n可以真诚自然，装作不经意的表达你对她的习惯性思念。但是一定不要表现情绪波动，并且说完马上岔开话题，表示自己也不想再感情话题上停留，但可以给她造成一定的情绪波动，触动旧情。\n \n③新话题切入法\n\n你们恋爱的时候肯定关于家庭、情感经历、人生观世界观、兴趣爱好之类的都聊过了，以前说过的在没老师的监督指导下就不要说了，可能引起她对你的负面记忆。少谈过去。\n\n所谓新话题，就是曾经没有跟她说过的生活细节部分，或者分手后你一个人做了哪些事，学会了做什么菜，看了什么电影什么书，打算去哪儿旅游……反正要是新鲜的话题，能引起她兴趣，不听完睡不着觉（但是你不一定要说完哦，可以愉快结束，为下次聊天打下伏笔）\n\n","n":0.174}}},{"i":49,"$":{"0":{"v":"Faq","n":1},"1":{"v":"\n# FAQ\n\n这里记录一下我在亲密关系中的一些常态以及自己的分析\n\n## 老是在脑海中跟对方对话\n\n可以看出我在情感关系中处于焦虑依恋，所以当我得不到对方的回应后就会十分焦虑。\n\n因为缺乏了对方的反馈，于是我只能在大脑中和对方对话。这样的后果就是我会花很多时间在这个事情上，但是这样其实也是一种逃避，我应该直面对方去问这些问题。不过由于现实的限制，有些话并不能直白的表达出来。\n\n- 解决办法：把想说的写下来，想到什么就写什么, 至少以后就不会再想一遍\n- 和伴侣约定好合理的讨论时机\n\n## 经常check对方的社交网络\n\ncheck对方的社交网络是为了更好的了解对方，但是我在短时间会check太多次，完全没有必要.\n\n我之所以会这么做的原因还是**闲**吧。我把重心放在了对方身上，而不是自己身上。\n\n- 对方发的内容90%都不是和我相关的，我完全不需要那么关注。\n- 和我相关的我又看不到就当不存在。\n\n做好我自己\n\n## 反复上知乎或者Google看一些别人的经验或者没有科学依据的东西\n\n这么做还是因为我想找到一个解决方案，我还是潜意识把感情当做是解题。但是很多情况下，感情不是努力了就有结果，还是需要找一个合适的人在一起。\n\n没有科学依据是我想通过出生时间确定对方的性格，这我也知道是不合理的，但是却发现他们总是可以说对。也许只是把一些大家都有的特点总结起来的吧。\n\n- 把看过的总结好，知道的就不需要看了","n":0.302}}},{"i":50,"$":{"0":{"v":"Comfort","n":1},"1":{"v":"\n# 哄女友\n\n别哭（别怕），什么事儿都有我呢。（陪伴是最暖心的事情）\n \n没事，交给我就行，我来解决。（真的很酷！）\n\n你是最棒的+（你怎么可以这么优秀）（这件事你居然能想到这样做，好厉害）（你比她们都棒）+就是夸啊，使劲夸阿，夸到她心烦都没有理由。\n \n只要你表现得在乎而且不让她太烦。有主动去解决问题的意识而不只是一味地问她该怎么做。\n像个成熟男人一样担起责任来（是我让你不开心的，我要负责让你开心起来）\n一般女孩子很快就会好起来的。\n\n最好是能发现自己错了主动认错然后哄一哄。\n最好能给个大大的拥抱，死死抱住那种，然后带着去吃好吃的玩好玩的。\n最好能耐心谈一谈，一定要耐心。\n最不济的，把她放到一边不要管，这样也有可能自己消气的。但首先得认错。\n\n最重要的一点，让她明白，你是理解她的。\n\n第一，一定要顺着她的意思，辩解只会使事情变得越来越复杂。\n第二，如果这件事跟你有关，不要试图将事情表述清楚，目的、方式、经过……这些都不重要，重要的是你知道这一切都是你的错了。\n第三，如果这件事跟你无关，一定不要试图站在道德制高点来讨论这件事，一定要站在她的角度安慰她。\n第四，所有看起来很弱智的安慰方式都是可取的，所有看起来毫无道理的语言都可以用来哄她。不用担心没有解释和说明的机会，她度过了这段时期冷静下来会愿意听你之前没说的话的。\n\n请按如下操作步骤：\nA、暂时关闭你大脑里的理性和逻辑模块进程；\nB、与女友待在一起（做什么看人看事儿）；\nC、闲聊，反复强调她（你女友）是对的《- 循环 直到她开始敞开心扉；\nD、由少到多的身体接触；\nE、承诺她一件“女友一直想做或喜欢做的并且可以马上开始的事”；\nF、做这件事，直到她开心；\nG、重启你的大脑。\n\n![[life.communication.hard#安慰]]","n":0.408}}},{"i":51,"$":{"0":{"v":"Chat","n":1},"1":{"v":"\n[[两性|life.communication#两性]]\n\n# 聊天模型\n\n女生的回应\n\n## 积极\n\n- 讲自己的状态\n- 回复字数比较多\n- 主动聊天\n- 有情绪\n\n### 做法\n\n- 提问\n- 邀约\n  - 先模糊邀约\n  - 再具体\n- 要求\n- 调情\n\n\n## 普通\n\n- 平淡\n- 无话题\n- 无情绪\n- 废测，一致性测试\n\n### 废测的解决办法\n\n废物测试是确认你的价值，是一个展现价值的机会。\n\n核心就是不要解题，跳出女生的框架。\n\n- 情绪不要受影响\n- 不要产生对抗\n- 不要在乎结果\n- 荒谬性，往有趣的地方引导，夸张\n\n想象高价值的人会怎么回应。\n\n1. 直接回应，**不要解释**，转移话题\n2. 忽略问题\n3. 橡皮泥理论，接话，重新塑造，丢回去（荒谬）开玩笑\n\n\n## 消极\n\n- 敷衍\n- 已读不回\n\n\n### 怎么办\n\n因为没有看到价值\n\n1. 说话简短、及时止损\n2. 好奇心打开：创造聊天机会\n3. 朋友圈发动态，激发好奇心\n\n聊天可以让对方看到自己的价值，但不要自我赋格\n\n保持更新朋友圈\n\n# 核心指标\n\n- 价值\n- **性张力**\n  - 起伏\n- **购买欲**\n  - 客户购买的欲望\n  - 女生想得到你\n\n## 情绪原则\n\n聊天聊得是情绪，不是逻辑。当出现争吵，改变逻辑是没有用的。\n\n- 上策: 瞬间改变情绪，亲吻\n- 中策: 哄女友开心\n- 下策：讲道理\n\n而真正的应该是聊天要传递情绪，因为没有触达你的情绪，就没有触达到你，没有走进你的心里。所以，要感受对方的情绪，接收对方的情绪，并尽量去感同身受，这样会让对方有一种“你很懂我”的感觉，从而会在心里把你划入到“自己人阵营”。\n\n\n\n## 目的\n\n推进关系\n\n“愉快聊天”容易让女生产生一定的“亲密提升”和“情感依赖”，而对于大部分男生来说，“聊天”并不是“刚需”，也并不擅长。\n恋爱中的“男女差异”源自女生更注重“抽象情感”的感受，男生更注重实际交互、一起做事的体验\n\n## 制造氛围\n\n- 挑战\n  - 有点否定，表现自己的喜好，展现个性样本，不要平淡\n  - 会有废测\n- 曲解\n  - 发散思维\n  - 曲解对方的意图\n  - **想象女生的行为是为了得到我**\n\n\n\n## 展现价值\n\n表现性格样本和生活模式的一小部分，利用只言片语的力量，所以女生想要了解更多\n说一点点，营造神秘感\n\n## 角色扮演\n\n开玩笑，升级关系无风险\n\n假定两人去做什么事情\n\n## 被拒绝\n\n注意有拒绝阶梯，会形成惯性，所以需要有框架，下一次你有为我做一件事\n\n这次的拒绝成为下一次的邀约\n\n# 沟通\n\n大多数人都会接受并对爱人的直言不讳做出反应。直言不讳，我指的是一个人在不指责、不抱怨、不评判或不嘲笑另一个人的情况下，清楚地表达出自己的感受和关切。直言不讳之所以有效，就是因为直言不讳能让接受者无偏见地倾听。\n\n即时反馈的重要性\n\n为了能够在亲密关系中有效地进行沟通，我们必须就我们的言语和行为如何被理解给予并接受即时的反馈。这将为我们提供所需要的信息，以洞察我们的行动和表达的影响，并考虑我们满足自己和合作伙伴需求的选择。\n\n## 错误的方法\n\n人们往往不知道如何提供建设性的反馈，而是以一种激怒或惹恼接受者的方式来进行反馈，从而导致出现比他们需要解决的问题更多的问题。对于我们所有人来说，听到用感觉来表达的反馈（“我很难过。”）比听到用判断或指控来表达的反馈（“你是个轻佻的混蛋！”）更容易\n\n# 观察\n\n与众不同在于你观察女生的方式：所有的男人看脸看胸看腿看穿着，你看她聊天时候后仰的姿态。看着你微笑的眼睛，偶尔露出的小虎牙。\n\n之后是行为方式的认同：她等待你的样子，吃饭的样子，跟你出去玩的样子，坐在你旁边唱歌的样子，蹦迪的样子，渐渐从外到内，你认同她的越深入，深刻，女生会觉得你越懂她。\n\n再之后是对她生活方式的认同：她在做一份什么样的工作，为什么做这个工作，以及她之后想要干什么。她的兴趣、爱好、梦想，她做的每一件事，每一个举动每一个行为都有背后的逻辑，你需要挖掘出来，然后给与认同。每一个女生都有她活着的意义，找出来，如果她自己都不知道，你就帮她找出来。\n\n镜像式聊天。有时候我们不需要输出什么观点，只要顺着他的话题展开，并认同他说的话，让他有一种和你就像是在跟他自己聊天的感觉。那么，他的聊天体验就棒极了，而且会有一种你很懂他的感觉，从而赢得他的好感。\n\n# 注意\n\n1. 女生也有状态不佳、心情不好的时候，当遇到女生反馈不好或者态度冷淡的时候，找个台阶直接结束聊天就好了\n2. 聊天过程中话不要太多，交流还是跟女生互动为主，如果另一方如果成为了你倾听者，那么这段对话是你很失败的\n3. 你最主要的还是表达自己的诚意，表达自己对她的关切，多嘘寒问暖，恋爱时最忌讳清高孤傲，很闷很冷淡。\n4. 传递有用信息、发表观点，先认可再提建议\n5. 在跟女生聊天调情的时候，一样的，如果你逻辑了，就没有情绪流动，你逻辑了，就没办法打开她的情感开关，没有情感开关，哪里来的我们常说的感觉呢","n":0.113}}},{"i":52,"$":{"0":{"v":"Topic","n":1},"1":{"v":"\n[[Understand|life.love.understand]]\n\n\n# 一开始\n\n多聊她\n\n- 外貌\n  - 化妆\n  - 身高\n  - 服装\n- 文字\n- 行为\n- 兴趣爱好\n\n\n## 前提\n\n我们的交流是男女交流的前提\n\n- 不要聊无关紧要的话题\n- 女生会觉得聊天就是浪费时间\n\n几种交流方法贯彻前提\n\n- 赞美：我对你感兴趣  [[Appreciation|life.communication.appreciation]]\n- 夸大的赞美：夸张化 搞笑 土味情话\n- 推拉：赞美+说不喜欢的点\n  - 会挑战女人，容易收到废测\n\n\n\n\n# question\n\n1. 我哪一点最吸引你？\n2. 描述一下我的味道。\n3. 对我的第一印象是什么样的？\n4. 你第一次吻我之前在想些什么？\n5. 我第一次把你约出来的时候你考虑过拒绝我吗？\n6. 初恋时你多大？\n7. 我做过的哪件事很让你生气？\n8. 告诉我，你是何时发觉爱上我的？\n9. 最想去哪个地方旅行？\n10. 将来想生活在哪个城市？\n11. 我使你难堪过吗？\n12. 如果你能够改变我的一个方面，那会是什么呢？\n13. 如果你打算问我一个问题，你会问什么？\n14. 你是如何察觉我在生气的？\n15. 你觉得我能够伤害你最深的一件事会是什么？\n16. 我做的哪道菜你已经吃厌了？\n17. 如果我想在餐桌上给你一个惊喜，你希望是哪道菜呢？\n18. 你想要的完美爱情是什么样的？\n19. 的有想过你30岁之后的人生会是什么样子么？\n20. 将来你想把你的房子装修成欧式田园风还是极简风？\n\n1. 喜欢什么运动\n2. 喜欢什么花\n3. 喜欢什么食物\n4. 喜欢什么穿衣风格\n5. 喜欢看什么书，最喜欢的作者是谁\n6. 喜欢什么电影/音乐  \n7. 平时一个人的时候，喜欢干什么\n8. 一般有什么心事  \n9. 星座话题（如果不信，就不要聊）\n10. 喜欢什么游戏\n\n1. 你喜欢什么样的工作环境？\n2. 工作上有什么新鲜事情？\n3. 老板人怎么样？\n4. 是否对自己的工作满意？\n5. 压力大不大？\n6. 下班之后一般喜欢吃什么？\n7. 自己做饭？\n8. 平常去哪儿玩？\n9. 你喜欢看什么电影？\n10. 最想去哪个城市工作？\n\n1. 你认为是性还是感情维持着一段完美的恋情？\n2. 如果你的朋友偷腥，你会让他的伴侣知道吗？\n3. 描述一下你心中完美的约会。\n4. 什么会让你挥剑斩情丝？\n5. 你认为在恋爱中谁会占主导地位，为什么？\n6. 一个人不在家，另一个人独自在家，你会怎么想？\n7. 你认为男人的爱与女人的爱是不同的吗？\n8. 作为女性，你认为男性最有必要知道的是什么？\n9. 你对彼此忠诚的定义是什么？\n10. 给爱情下个定义。\n\n11. 你相信一见钟情吗？\n12. 浪漫的度假作为你生活方式的一部分，你有何感受？\n13. 一个男生最吸引你的部位是哪里？\n14. 你会因为一个什么样的小细节而对一个男人动心？\n15. 你有想过将来会有几个孩子吗？\n16. 想要养什么样的宠物？养几只？\n17. 如果让你重新选择，你想做男生还是女生？\n18. 喜欢独处么？\n19. 你愿意信任我么？\n20. 在什么样的情况下，你会放弃原则？\n\n1. 你认为钱最重要的功能是？\n2. 你是如何学到作为女性所应具备的品质的？\n3. 你心中完美的婚礼是什么样子的？\n4. 如果金钱不再是目标，你最大的追求会是什么？\n5. 如果你中了彩票，会去做什么呢？\n6. 你认为谎言有度吗？\n7.你父母对你做过性启蒙吗？或者你自学的？\n8. 你对自己未来三年五年的规划（或者可以一起规划一下你们的未来）\n9. 可以告诉我支持你的信念是什么吗？\n10. 你最欣赏谁？为什么？\n11. 当你陷入困境时会向谁请教？\n12. 你是如何压住怒火的？它造成过麻烦吗？\n13. 如果你打算写本书，你会写些什么呢？\n14. 如果可能，你最想住在哪儿？为什么？\n15. 如果你中了彩票，还会继续上班吗？\n16. 当你对某人有偏见时，你是怎么想的？\n17. 你最好的朋友是谁？为什么？\n18. 你是如何选择现在这项事业的？\n19. 现实一点的说，什么事情会让你快乐一整天？\n20. 你做过的最无私的是哪件事？\n21. 你相信世上有鬼吗？\n22. 你今后12个月中的目标是什么？打算如何实现？\n23. 你对自己的受教育程度满意吗？\n24. 你曾犯下的最大的错误是什么？它是如何改变你人生的？\n25. 如果你捡到一个钱包，你会怎么做？\n26. 最近读了哪本书？阅读它主要的原因是什么？\n27. 当你感到沮丧时，你会做些什么，行为会因此有何不同？你又是如何克服沮丧的呢？\n28. 是否实现过年初制定的目标？\n29. 希望改变自己的什么？\n30. 你家最大的“公开的秘密”是？\n31. 你认为动物有灵魂吗？\n32. 不涉及职业和婚姻的状况，描述一下你自己。\n33. 你人生中最重要的事是？\n34. 最让你感到羞耻的事是什么？为什么？\n35. 你生命中最早的记忆是什么？\n36. 你养大过宠物吗？最爱哪一只？\n37. 你最害怕什么？\n38. 如果你得独自为自己的生活负责，不能指望任何人，你的生活会发生哪些变化？\n39. 你最希望我向你坦白什么？\n40. 你认为何时该保守秘密？为什么？","n":0.089}}},{"i":53,"$":{"0":{"v":"Breakup","n":1},"1":{"v":"\n\n# 分手的理由\n\n- 需求没有满足\n  - Not spending enough time together\n    - Always being late\n    - Workaholic\n    - Always putting your friends first\n  - Bad Communication\n    - Not Listening\n    - Not showing interest in the conversation\n    - Not looking her in the eyes\n    - Not being interested in her life\n    - Not being able to compromise\n  - Financially unstable\n    - Not being ambitious \n    - Financially depending on her\n  - Being Unattractive\n    - Being too moody\n    - **Being an addict**\n    - **Not taking care of yourself**\n    - Bad smell\n    - Repeating old mistakes\n    - Too much bragging\n    - Not knowing how be attractive\n  - **bad sex**\n  - being unfaithful\n    - 隐藏事情\n    - 欺骗\n    - 出轨\n  - 不支持\n    - 不支持对方做的事情\n    - 不帮忙家务\n    - 期待对方做自己不想做的事情\n  - no emotion\n    - 变得无聊\n    - 没有约会\n    - 不一起笑\n    - 不感激对方有趣的一面\n    - 不对对方有激情\n    - 没有惊喜\n    - 不陪伴\n  - 不感激\n    - 忘记对方的愿望\n    - 把对方当做小孩\n    - 没有表扬\n    - 没有未来计划\n    - 没有礼物\n    - 没有郑重对待感情\n\n- 感觉自己的界限被侵犯\n  - pressure her to have sex\n  - 没有安全感\n    - 总是责怪对方\n    - 批评对方多\n    - 不道歉\n  - Abuse\n    - 限制对方\n    - 控制对方\n    - 让对方觉得自己没有价值\n    - 否定对方\n    - 拿别人比较对方\n    - 催促对方做出承诺\n  - 不尊重对方家庭\n- 对对方太好了 （没有界限感）\n  - 爱没有错，但强迫对方接受的爱，就是一种变相是控制欲，不能给对方你以为的舒适的港湾。\n  - 做所有的事情也不期待回复\n  - 不是一个挑战\n  - 没有自己的观点\n  - 可以被预见\n  - 害怕和对方争吵\n  - 让对方不尊重自己\n  - 为对方放弃一切\n\n# 走出失恋\n\n- 切断投资\n- 重新建立起新的生活。\n- 关注自己。喜欢做什么就去做","n":0.07}}},{"i":54,"$":{"0":{"v":"Basic","n":1},"1":{"v":"\n# Basic\n\n提供支持、陪伴和爱的关系有益于健康，不管是在压力状态下还是在欢乐岁月里。 相比之下，孤独并不会产生更多的压力事件，但它是压力源转化为疾病的一个危险因素。事实上，单身生活有其自身的社会和身体优势：与已婚或同居的人相比，单身者更有可能与朋友外出吃饭、去锻炼身体、去上艺术和音乐课、去听讲座、去做志愿者工作。 你不必拘泥于保持忠诚的关系。换句话说，你所需要的仅仅是保持联系。\n\n## 爱的博弈\n\n两性的基础是吸引。\n\n吸引的本质是你可以提供的价值：\n\n- 外在价值：外貌和资本，是在认识对方，建立关系上重要\n- 内在价值：情绪价值，让对方的感受，在维护关系上十分重要\n\n当两人在提供的价值不对等就会失去平衡，付出少的一方对于感情的权力更大\n\n\n## 框架理论\n\n有自己的原则！和坚持的事情。知道自己的偏好\n\n你越愿意牺牲越不在乎自己内心真实的需求和想法，但你是有血有肉的人，要学会发脾气。你的没有框架原则底线只会“宠坏”对方，并让ta觉得不值得珍惜。\n\n\n## 原则\n\n* I love you as who you are. \n* 真正的了解对方，让对方成为更好的自己很重要。\n* 在两性关系中，谁越不在乎，谁就拥有这段关系的主导权\n* focus on myself anytime\n  * set boundary and standard\n  * gain control back\n* 不是付出就有回报的\n* say what you want!\n  * confident\n  * 坚定自己\n  * **set anchor for woman**\n* have goals and put yourself first,不要太available\n  * put her to your life style 不是把我放在她的生活中\n* not always **seek approval, 有自己的观点**\n* challenge yourself **face your fears**\n* slow down, 不要show too much love\n* in sex, focus on her needs\n\n## 感觉\n\n感觉就是调动情绪，推拉的关键\n\n情绪高涨点时，升级关系，可以有肢体接触\n\n## 追求\n\n- 告白大多数会问为什么喜欢，讲其特别的点，利用细节，独一无二，描绘画面\n- 留心对方自己都没注意的需求，给惊喜。\n\n## 男女关系平衡理论 \n\n男女关系中，总有一个是处于低位的，另一个处于高位。 所有的男女关系，两个人的关系是不可能平衡的。 不同的关系，只是这种低位和高位的悬殊程度不同罢了。\n\n男女关系中，低位者总是迁就高位者。高位者有什么需要，低位者总会想办法满足他的要求，低位者总是想博得高位者的欢心，让他满意。 \n低位者比高位者更需要对方。\n\n从投资学角度来讲，低位者在恋爱中的投资比高位者多很多。可以说，低位者是以一种仰视的角度来看高位者的。高位者对低位者具有吸引力。这也就迫使低位者不断投资，去讨好高位者。在恋爱关系中，谁投资多，谁就先输了。 \n\n所以在男女关系中，是高位者在主导这段关系。 \n\n# 了解自己\n\n首先对你自己要有充分的认识，知道自己要什么想要做什么，想要成为一个什么样的人。","n":0.103}}},{"i":55,"$":{"0":{"v":"Value","n":1},"1":{"v":"\n# 价值\n\n情绪价值就是，彼此放松，哈哈大笑的开玩笑，娱乐。\n分为两个部分，第一是感受情绪，第二是带领情绪 （积极）。\n\n## 判断价值\n\n1. 女生的反应\n2. 自我赋格行为\n   1. 赋予自己资格\n   2. 低价值认同高价值\n   3. 解释 ”越优秀的人越不需要解释自己”，解释太多只会让事情变糟糕\n   4. 证明\n   5. 迎合\n\n## 损失自己价值的行为\n\n\n- 投资性行为\n  - 不断提问\n    - 你在干嘛\n    - 做什么工作\n  - 邀约女生\n  - 提要求\n    - 为什么不回消息\n- 低价值行为\n  - 表达自己的状态\n  - 如果女生对我不感兴趣，说这个也没有意义\n\n\n问就是在向别人索取信息，索取价值！回答，则是在给别人信息和价值。\n\n高情商的人会主动帮助别人，给予价值和主动付出，来增加别人对自己的好感度，别人了解自己越多，自己就越受追捧！\n\n# Hypergamy\n\n一个女人寻求比自己地位更高的男人来结婚。没有什么比这更重要的了","n":0.164}}},{"i":56,"$":{"0":{"v":"Iron_rules","n":1},"1":{"v":"\nIron Rule of Tomassi #1\n\nFrame is everything. Always be aware of the subconscious balance of whose frame in which you are operating. Always control the Frame, but resist giving the impression that you are.\n\nIron Rule of Tomassi # 2\n\nNEVER, under pain of death, honestly or dishonestly reveal the number of women you’ve slept with or explain any detail of your sexual experiences with them to a current lover.\n\nIron Rule of Tomassi #3\n\nAny woman who makes you wait for sex, or by her actions implies she is making you wait for sex; the sex is NEVER worth the wait.\n\n性是永远不值得等待的。\n\n性爱是双方自发的化学反应，而不是一个谈判的过程。\n舒适感来自于熟悉感和可预测性；这些都是明显的反诱惑的影响因素。虽然在人际关系中，舒适有它自己的优点，但它不是真正的、热情的性欲的基础。\n\nIron Rule of Tomassi #4\n\nNEVER under any circumstance live with a woman you aren’t married to or are not planning to marry in within 6 months.\n\nIron Rule of Tomassi #5\n\nNEVER allow a woman to be in control of the birth.\n\nIron Rule of Tomassi #6\n\nWomen are utterly incapable of loving a man in the way that a man expects to be loved.\n\nIn its simplicity this speaks volumes about the condition of Men. It accurately expresses a pervasive nihilism that Men must either confront and accept, or be driven insane in denial for the rest of their lives when they fail to come to terms with the disillusionment.\n\nWomen are incapable of loving men in a way that a man idealizes is possible, in a way he thinks she should be capable of.\n\n关于男人是否能确定女人什么时候不爱他的原始问题，比她所意识到的要深得多。我认为男人在服用蓝色药丸的日子里所经历的很多事情--沮丧、愤怒、否认、被剥夺，感觉他被卖给了一个幻想，而没有一个女人能做到这一点--所有这些都植根于一个基本信念，即某个女人，任何女人，在那里知道他需要如何被爱，他所要做的就是找到她，并体现出他被告知她会在他找到时对他的期望。所以他找到了一个女人，她说并向他表明她爱他，但不是以他脑海中一直以来的方式。她的爱是基于亢奋的资格和表现，而且比他被引导去相信，或说服自己，他们之间的爱应该是有条件的。她的爱似乎是两面派的，模棱两可的，而且与他长久以来被教导的，当他找到一个女人时，她会如何爱他相比，似乎太容易失去。因此，他花了他一夫一妻制的努力来 \"建立他们的关系\"，使她按照他的概念来爱他，但这从未发生。这是一场无休止的追逐，维持她的感情，遵从她的爱情观，同时偶尔努力吸引她进入他的爱情观。不断地安抚她以维持她的爱，与他希望被爱的需求感相冲突，这是一个超常的灾难配方，所以当她失去对他的爱时，他根本不知道她不再爱他。然后他的逻辑反应是重拾他们刚在一起时她对他的爱的旧条件，但现在这些都不起作用，因为它们是基于义务，而不是真正的欲望。爱，就像欲望一样，是不能谈判的。\n\n爱，就像欲望一样，只有在不被胁迫和没有义务的情况下才是合法的。男人相信为爱而爱，女人则是机会主义的爱。这并不是说两者都认同无条件的爱，而是两个性别对爱的条件不同。\n\nIron Rule of Tomassi #7\n\nIt is always time and effort better spent developing new, fresh, prospective women than it will ever be in attempting to reconstruct a failed relationship. Never root through the trash once the garbage has been dragged to the curb. You get messy, your neighbors see you do it, and what you thought was worth digging for is never as valuable as you thought it was.\n\nIron Rule of Tomassi #8\n\nAlways let a woman figure out why she wont ƒuck you, never do it for her.\n\nAn integral part of maintaining the feminine imperative as the societal imperative involves keeping women as the primary sexual selectors. As I’ve detailed in many prior comments and posts, this means that a woman’s sexual strategy necessitates that she be in as optimized a condition as her capacity (attractiveness) allows for her to choose from the best males available to satisfy that strategy.\n\nIron Rule of Tomassi #9\n\nNever Self-Deprecate under any circumstance. This is a Kiss of Death that you self-initiate and is the antithesis of the Prize Mentality. Once you’ve accepted yourself and presented yourself as a “complete douche” there’s no going back to confidence with a woman. Never appeal to a woman’s sympathies. Her sympathies are given by her own volition, never when they are begged for — women despise the obligation of sympathy. Nothing kills arousal like pity. Even if you don’t seriously consider yourself pathetic, it never serves your best interest to paint yourself as pathetic. Self-Depreciation is a misguided tool for the AFC, and not something that would even occur to an Alpha.\n","n":0.045}}},{"i":57,"$":{"0":{"v":"Framework","n":1},"1":{"v":"\n\n# 自己的框架\n\n1. 自信有担当为自己做的事情负责\n2. 守时\n3. 持续自我提升\n4. 我可以拥有对我好，可以一起玩，善良，聪明，努力，聊得来的女人\n5. 我喜欢不舒适感，这样意味着成长\n\n\n# 框架的强弱\n\n- 只考虑自己：强框架 -> 吸引力\n- 考虑对方：弱框架 -> 可得性\n\n![](/assets/images/2021-10-02-21-08-05.png)\n\n可得性太高就没有吸引了\n\n## 吵架\n\n- 吵架时是强框架\n- 之后哄对方就是弱框架\n- 这样有利于关系\n\n## 雷区\n\n1. 情绪失控：框架就丢失了\n   1. 动手打人\n   2. 骂人\n   3. 损坏物品\n   4. 威胁对方\n2. 暴露需求感\n   1. 强行亲密接触\n   2. 是降低自己吸引力的\n3. 矛盾扩大化\n\n# how\n\n将外在附着的东西全部剥离\n仅在两个对等的人格上，进行平等的交往","n":0.169}}},{"i":58,"$":{"0":{"v":"Bad_signal","n":1},"1":{"v":"\n\n# 危险的信号\n\n1. 亲密关系性质低\n2. 在一次的时候不关注我\n3. 聊天情绪变少，变得理智，没有情绪波动","n":0.447}}},{"i":59,"$":{"0":{"v":"Bad_move","n":1},"1":{"v":"\n\n# 亲密关系末日四骑士\n\n## 批评\n\n## 鄙视\n\n## 辩护\n\n说服的本质是在制造对错\n\n可你要先学会区分解释和辩护。解释，相对客观一些，有些问题也一定要沟通开，比如一些原则性问题（出轨、背叛、涉及钱的问题、对你人品的误解等）\n\n事情大小没有客观标准，**核心就是是否有利于维系关系，是否是关心对方**，让彼此心里舒服，\n\n证明第一步就是承认自己的不足。证明自己最好的工具，就是时间。\n\n## 冷战\n\n冷暴力主要是因为无法面对沟通的挫败感和无力感。\n\n如何与喜欢冷暴力的人相处的方法了——讲道理。 他冷的时候你也冷，但是不能和他一样，你要表达你为什么也不想理他（原因）以及要怎样你才会理他（需求），去讲道理，不发脾气和作闹。\n\n他愿意表达一点，哪怕是不满，你也要知道对他来说很难得，你要能迅速接上。尤其是当他表现出“消极沟通”或者想要放弃沟通的时候，一定要坚持沟通下去，坚持讲道理。无论自己心里对他说的屁屁话再窝火，也要找到合理之处，自我反思，表现出对他的认可理解，再反过来让他也要理解你。“正向反馈”，他愿意沟通或者对你好的时候你给予更加积极、热情、贴心的回应才是正确的方法。他的冷淡伤害到你的时候你也让他gun。\n\n**对方一次次选择冷暴力而不是沟通，一般都源于你给他的“负反馈”，即他对你态度好或者尝试道歉、沟通的时候你不领情；而对你态度冷淡的时候你反而贴上去跪舔示好。**\n\n","n":0.378}}},{"i":60,"$":{"0":{"v":"Attraction","n":1},"1":{"v":"\n# 吸引力\n\n影响吸引力的因素主要有：成本、价值和共振\n\n- 成本：即对方和你在一起是否费力。正因为彼此触手可及，所以才能相处起来毫不费力。挽回还有一个关键就是：和你相处起来不费力，不心烦。\n- 价值：不喜欢的人和事物反复出现在我们面前时，也可能提高你对ta的厌恶程度。所以我们往往建议你断联，或者至少一定不要持续不断地出现在对方面前、信息轰炸。刚分手时，对方还处于对你的情绪否定期，你的死缠烂打反复出现在对方面前，只会加深对方对你的厌恶。这些行为都是在降低你的吸引力和价值，让对方觉得离开你是正确的选择，你对ta真的毫无吸引力了。\n  - 吸引力价值中的关键是你能给对方带去情绪价值，让对方觉得你的存在是美好的，和你在一起比一个人过或者比别人在一起更开心幸福。\n    - 1.情绪处理能力\n    - 2.沟通能力\n    - 3.共情能力\n- 共振：在人际关系中，人们倾向于喜欢那些与ta相似的人：价值观、态度、兴趣、背景等等。每多一个相似的地方都可能提高那个人对你的好感度。\n\n很多人已经懂了建设吸引力的方法，能引起对方的关注，但是聊天依然找不到话题，感情没有办法进一步升温或者长期持续的吸引力。\n\n这就需要去寻找更多的相似性，创造更多的交集和共同话题。想象自己成为ta才能懂得ta。理解比吸引更加难得和重要。吸引力只是开关而已。\n\n理想男性（适合约会或者恋爱的伴侣）通常是那些**自信、坚定、随和、心思细腻、没有攻击性的男性**，而不是严苛、控制欲强、过于安静、害羞和顺从的男性。换句话说，女性更喜欢一个有声望的男性而不是控制欲强的男性；\n\n## 不吸引人的点\n\n- 嫉妒 \n  - 它就像是在对女人说：“我感觉到了来自其他男人的威胁和压力，在内心深处，我觉得配不上你”\n  - 如何应对这样的状况呢？其实你只需要拥有这样的心态就够了：“如果把其他男人跟我放到一起比较，我会比他们更优秀！”你可以更开放一些，让女友去跟任何她想要交流的男人讲话或正常交往。\n- 控制欲\n  - 一个有控制欲的男人，在他的内心深处也同样觉得自己是配不上对方的。所以他才认为要想办法控制住她，让她继续留在他的身边。\n  - 同理，你越想把她抓紧，她就越想摆脱你的掌控。这也是人类的本能反应：我们都会去反抗那些试图控制我们的人。\n- 过于放低自己的位置\n  - 女人需要一个能够为她提供生存价值，并且拥有自尊的男人。一旦你将她摆到一个极高的或比你高很多的位置，并且开始将她的需要置于你的需要之上时，她可能就不再对你感兴趣了。她也不会再尊重你，因为她知道，你已经不能没有她。换句话说，她已经完全吃定你了，她想留就留，想走就走，不会有太多的心理压力。\n  - 我见过太多这样的男人，他们通常会这样做：喜欢女友喜欢的东西，做女友喜欢做的事情，把女友作为自己生活的中心。他们把女友放到一个极高的位置，首先去满足她的需求，然后才会去考虑自己。这样做是不对的。疼爱女友没错，但是你不能无条件的为她做所有的事情。\n- 寻求认可/肯定\n  - 如果什么事情都要向女朋友寻求肯定，同样也是一种没有安全感的行为，这种行为透露了这个男人缺乏自尊和自信。\n- 粘人\n  - 老是花时间跟女友腻在一起并不见得是件好事。我们都明白一个道理：钻石值钱是因为它的稀有性。如果你在家门口就可以捡到一块钻石，那它就没那么值钱了。\n\n## 吸引人的点\n\n- 领导力\n  - 领导女人或带领女人。\n  - 在决定做任何事情前，你的脑海里面需要有一个大致的计划，它不需要那么详细，你可以在执行中根据情况做调整。\n- 自信心\n  - “坏男人”常常会让许多女人迷恋，为什么会这样，我想了很久。直到有一天我才想明白：是他们的自信吸引了女人。坏男人之所以能够吸引女人，不是因为他们那些坏的行为，而是因为他们随时流露的毫无逻辑可言的自信。\n  - 但你千万不要把傲慢自大与自信混淆了。傲慢自大是一种伪装出来的自信，很容易被人识破。女人（尤其是美女）天生有一种特殊能力，她甚至不用跟你说话，只是通过观察和潜沟通，就可以轻易看出你是否真的自信。\n  - 女人不需要一个跟班，整天跟在她的屁股后面去做讨好她的事情。你应该拥有自己的想法和独立的价值观，而太多的男人对此都缺乏基本的认知。他们认为：如果什么事情都答应女人、无条件无下限的对女人好，女朋友就会更爱他们。\n- 上进心\n  - 一个有追求和有目标的男人具有难以想象的强大吸引力\n  - 事实已经很清楚：一个被碌碌无为的生活所拖累、没有激情和目标的人是没有任何吸引力的。更糟糕的是，他还把女朋友当成了自己的生活目标（像大多数人一样，或许你也曾经经历过，也包括我在内）。一旦发生这样的事情，分手就已经不远了，因为女人不想要一个没有上进心的男人。\n  - 不可预测，我是一个稀缺的资源\n  - 回消息的频率和质量和对方相同 https://www.youtube.com/watch?v=UYLuOt29OVQ\n\n\n# 为什么人会喜欢\n\n卡内基的建议非常简单：如果你想让人们喜欢你，就要和蔼可亲，假装你喜欢他们，假装对他们感兴趣的事情感兴趣，给他们以赞扬，要表示赞同，不要试图批评，而且要确保尽可能多地使用他们的名字，因为“普通人对自己的名字比对世界上所有其他名字更感兴趣”。换句话说，卡内基确信我们大多数人都像虚构的弗兰克 · 巴特勒；如果你想赢得我们的爱或影响我们，那么尽你所能让我们感觉良好，避免做一些让我们感到不舒服的事情。\n\n我们更喜欢具有令人愉快特征的人； 我们更喜欢同意我们意见的人，而不是不同意我们的人；我们更喜欢那些喜欢我们的人，而不是那些不喜欢我们的人；我们更多喜欢与我们合作的人，而不是与我们竞争的人；与那些批评我们的人相比，我们更喜欢那些赞美我们的人。吸引力的这些方面可以归纳为一个笼统的概括：**我们喜欢那些以最低成本为我们提供最大回报的人**。\n\n吸引力部分地取决于我们对替代品的比较水平。\n\n对我们选择朋友和爱人有深远影响的五个相对稳定的因素: 我们倾向于喜欢生活在离我们较近地方的人；我们喜欢与我们相似的人；我们喜欢那些喜欢我们的人；我们喜欢具有吸引力的人；选择的悖论\n\n## 距离接近\n\n你之所以发现某个人有吸引力并且萌生对他进行了解的可能性，往往是从他与你的生活距离开始的。近在咫尺增加了吸引力，原因却不仅仅是便利和实用。距离越近，我们就越有可能反复接触；而且，在所有其他条件相同的情况下，人们彼此之间越是熟悉就会变得越发可爱和越有吸引力。\n\n## 相似性\n\n在你看来，一个人在态度、观点和兴趣上越相似，你越喜欢他。与自己在上述方面对立的人可能也会吸引人，但最终不会走到一起。\n\n为什么感知到的相似性使人更具吸引力？至少有两个主要原因。第一，对我们大多数人来说，在重大问题上分享我们态度和观点的人都是非常聪明和体贴的，与聪明和体贴的人相处总是有益和有趣的。他们当然具有吸引力，因为他们赞同我们！第二，他们为我们的信仰提供了社会验证；也就是说，他们满足了我们感觉正确的愿望。如果我们感知到与另一个人的相似性，这就足以增强他的吸引力。\n\n## 个人特征：能力\n\n很明显，一个人越有能力，我们就会越喜欢他。所谓“能力”，指的是一系列的品质：聪明、做事的能力、明智的决定等等。\n\n被认为最有能力和最有想法的被试往往不是最受欢迎的人。为什么呢？一种可能是，尽管我们喜欢和有能力的人在一起，但是那些能力太强的人会让我们感到不舒服。他们看起来不可接近、遥不可及，这让我们看起来很糟糕（感觉可能更糟\n\n那么当看到一些人存在某些易犯错误的证据时，我们可能更喜欢他们。那么如果他们偶尔搞砸了，你可能会更喜欢他\n\n**破绽效应**：犯错误的优等生被评价为最有吸引力；犯同样错误的普通人被评价为最没有吸引力。\n\n我们从能力很强的朋友和亲戚中获得极大的满足感和自尊。接近有能力的人是值得的；我们可以向他们学习，享受他们的荣耀和成功。然而，如果他们在那些对我们而言重要的领域比我们更有能力，因此通过比较使我们感到自己无能或存在缺憾时，他们在我们心目中的吸引力便会减弱\n如果兄弟姐妹、亲密朋友和恋人在不同的领域表现卓越，他们可能会更容易保持亲密关系。\n\n### 个人特征：身体吸引力\n\n正如相似效应所表明的那样，人们倾向于在相同的吸引力水平上配对\n人们认为“美丽”的某些方面是与生俱来的，反映出人们对看起来健康、没有疾病的伴侣的偏爱。广告，连续不断的宣传攻势，旨在推销这样一种观念：瓶中女人会让我们变得更有吸引力，在社会上获得成功，从而变得快乐和完整。美貌偏见意味着没有魅力的孩子要为他们的外表付出代价\n\n美貌予人们以力量，但美貌也有一个缺点：人们会对批评自己长相漂亮的人更为苛刻。我们必须面对一个事实，那就是漂亮不仅仅是肤浅的。我们更喜欢漂亮的人，我们对他们更友好，我们认为他们比长相平平的人更温暖、更性感、更令人兴奋。此外，在不确定谁应该为不幸事件负责的模棱两可的情况下，我们倾向于假定他们是无辜的。\n\n当男性搭档认为他在和一位漂亮的女士交谈时，他会用一种能够展现她最好品质的方式和她交谈。当独立观察者听到她的谈话时，他们认为她比伴侣认为她不那么漂亮的女人更有吸引力、更自信、更活泼、更热情。这项研究为自证预言提供了一个生动而感人的例子：不管一个人的外表是否漂亮，当人们把他们当作有吸引力的人来对待时，就会把那些令人向往的品质展现出来。\n\n当我们对一个人的好感增加时，我们会发现这个人会变得更漂亮，这不仅仅是因为我们把他的长相和其他品质平均到了一个整体的评价中去了，而且是因为我们对他的感觉增强了，所以我们认为他更漂亮了。美的东西是好的，但好的东西也会变成美的。\n\n## 讨人喜欢\n\n决定我们是否喜欢某个人的最有力的因素之一，是相信某人喜欢我们。面对你热情可爱的行为，我对你的喜爱无疑会增加，反过来，我也会用更讨人喜欢的方式来表达我对你的喜爱。在随后的互动中，那些认为自己被喜欢的人表现得更讨人喜欢：他们比那些认为自己不受欢迎的人透露更多有关自己的信息，不那么提出反对意见，而且通常对他人表现得更热情、更愉快。那些认为自己被喜欢的人，事实上，后来也被另一个人喜欢；而那些认为自己不受欢迎的人，也不会被另一个人喜欢。这是自证预言的又一个例证。我们的信念，无论对错，都在塑造现实中扮演着重要的角色。\n\n此外，我们的不安全感和自我怀疑越强，我们就会越喜欢那个喜欢我们的人。\n\n对自己有安全感的人不那么“需要帮助”；也就是说，他们不太可能接受任何主动提出的建议。一个没有安全感的人会接受几乎所有表示感兴趣的人，而一个有安全感的人会更加挑剔。此外，一个没有安全感的人甚至会找一个不那么有吸引力的人来减少被拒绝的可能性。\n\n但是在约会的条件下，我们往往更容易被那些似乎只喜欢我们的人所吸引 —— 只有我，而不是所有其他成千上万的人，在等待着这样一次机会。\n\n## 选择的悖论\n\n所以现在你找到了自己的真命天子：住在你附近的某个人；他（她）和你有很多相同的价值观和信仰；这是一个喜欢你的人，而且他（她）所喜欢的人只有你；他（她）是一个长相英俊或漂亮的人。现在怎么办呢？你会说：“我找到了我的人生伴侣！抓住这个机会吧！”或者你会说：“嗯，等等 —— 这真的是最适合我的人吗？也许我很快会遇到更好的人？”\n\n人们认为拥有更多的选择总是比拥有很少的选择好，所以当你问他们时，他们总是说想要更多的选择。但是施瓦茨发现，拥有太多的选择可能会产生一个悖论：能够在多种选择中作出选择固然很好，但当所有这些选择一起妨碍我们作出任何决定时，情况就不那么好了。随着选择的增多，我们对完美的期望也越来越高，这意味着我们常常会这样想：如果我们观察得更久，是否会作出更好的选择。施瓦茨认为，由此而导致的结果是，我们变得更加挑剔，对最终的选择不会太满意；为了追求完美，我们不得不权衡和评估如此之多的选择，这让我们疲惫不堪。有时我们只是被众多的选择所麻痹，最终什么也没有做。\n\n如今，与人见面变得更容易了，因为科技可以让我们立即与更多住在我们附近的潜在伴侣联系起来，这比我们的祖父母一辈子可能遇到的人还要多。但是，就像顾客们面对果酱一样，无休止的选择也可能会导致他们不去做任何选择。\n\n不可避免的人类社会比较过程让选择悖论变得更糟，因为似乎每个人都找到了自己的梦中情人，而你却没有。我们在行动中的确存在着选择悖论：无限的选择让我们把当前的选择比作幻想。没有人能与幻想抗衡。\n\n## 赞扬和帮助\n\n消极的评价通常会增加我们对评价者的钦佩，只要他（她）所评价的不是我们自己。人类追求准确和共同理解的动机，会超越被喜欢、被欣赏、被赞美的欲望。我们当然希望得到爱和赞扬，但同样重要的是，我们也希望被了解和理解。被试更喜欢表扬他们的评价者，而不是那些消极的评价者，但他们对那些赞美可能是别有用心的评价者的喜爱程度会急剧下降、\n\n施惠，像赞扬一样，也可以被视为奖赏，我们倾向于喜欢那些施惠于我们的人。如果人们觉得有义务归还东西，他们不一定喜欢礼物；他们不喜欢从有能力施以恩惠的人那里得到好处。\n\n这句格言是：“曾经帮助过你的人，将比你自己帮助过的人更愿意帮助你。”\n\n## 得失理论 （性张力）\n\n他人积极的、有回报行为的增加对我们的影响，比那个人不断有回报的行为对我们的影响更大。我们会喜欢一个人，由于他对我们的喜欢随着时间的推移在增加，而不是一直喜欢我们善良的老弗雷德（ Fred ）或莫莉（ Molly ） —— 他们一直喜欢我们。该理论预测，在“得”情况下，你会最喜欢一个人（在这种情况下，这个人一开始讨厌你，逐渐会变得喜欢你），而在“失”的情况下，你会最不喜欢这个人（在这种情况下，这个人一开始喜欢你，逐渐开始讨厌你）。","n":0.11}}},{"i":61,"$":{"0":{"v":"Attachment","n":1},"1":{"v":"依恋关系是两性之间一个很重要的话题。因为童年和父母的关系，人们产生了4种依恋类型\n\n![](/assets/images/2021-02-16-22-31-10.png)\n\n- [[回避型依恋|life.love.attachment.avoidance]]\n- [[焦虑型依恋|life.love.attachment.preoccupied]]\n- [[安全型依恋|life.love.attachment.secure]]\n\n","n":0.5}}},{"i":62,"$":{"0":{"v":"Avoidance","n":1},"1":{"v":"\n# 回避型依恋\n\n## 核心\n\n看重自己的生活，不信任他人。很难走入亲密关系。\n\n## 表现\n\n- 专注自己的生活，不怎么考虑别人的感受\n","n":0.447}}},{"i":63,"$":{"0":{"v":"House","n":1}}},{"i":64,"$":{"0":{"v":"Order","n":1},"1":{"v":"\n我建立了一个六个步骤的问题列表，帮助你评估每样东西的相对重要性，这样你就可以更快地作出决策，继续前行。按照下面的顺序，问自己这些问题，并用“是”或“否”来回答，回答的时候尽量诚实（不要反复斟酌你的答案）。\n\n1. 它是否还能用？问问你自己：它还能不能用？如果答案是否定的，那就丢掉它。如果答案是肯定的，继续问题2。\n2. 你喜欢它吗？问问你自己：我有多大的可能性使用一样我并不喜欢的东西？如果答案是不太可能，那么就丢掉它。如果答案是有可能，继续问题3。\n3. 它是一件必备的东西，还是可选择的？对于“你不喜欢的”东西有一个特例，那就是它是必备的。类似的，可能有一些东西你很少使用，但你确实需要它们，而且很高兴能拥有它们。问问你自己：它是不是必备的，或者如果丢掉它，当我需要的时候我是否必须买另一件，而且我确实知道将来某个时间点会用上它？如果答案是“是”，那就留下它。如果不是，继续问题4。\n4. 有没有一段有价值的往事，附着在这件东西上？问问你自己：它是否有一段有价值的故事？如果答案是“否”，那就丢掉它。如果答案是“是”，继续问题5。\n5. 这段故事是否让你感觉很好？问问你自己：这段故事是不是让我感觉很好？如果不是，丢掉它。如果是，继续问题6。\n6. 这件东西与你的生活有关吗？问问你自己：它是不是仍然与我今天的生活有关？如果不是，可以丢掉。如果是，那你可以留着它。\n","n":0.378}}},{"i":65,"$":{"0":{"v":"Health","n":1}}},{"i":66,"$":{"0":{"v":"Worried","n":1},"1":{"v":"\n想太多，比较太多，感慨太多，很累的。\n\n蹒跚学步的孩子，跌到了，摔疼了。哭两声，站起来，拍拍土，继续往前走。每个人都是这样的，只是别人挫败的时候，你没看到。分心考虑太多，徒增烦恼。实在和自己较劲了，内心波动了，难受了，可以人际上求安慰。或者，干脆写下来，在日记里表达下感受，发泄一下。之后，情绪发泄完了，表达完了，把挫败的感受放下了。请把宝贵的注意力资源放在自己此时此刻能做的，能把握的事情上。比如，想追求生活的幸福，想有个好的前途。眼前，此时此刻，能做的事情有哪些，是想办法接近身边有好感的女孩子？还是把手头需要完成的工作做好？总之，把想到的，眼前能做的事尽力做了。其他，就交给时间慢慢发酵了。大概是这些。\n","n":1}}},{"i":67,"$":{"0":{"v":"Tiredness","n":1},"1":{"v":"\n疲劳的基础在于我们的身体的新陈代谢 。如果我们身体健康的话 ，每天起床彻底醒来之后是一天中最为清醒的时间 ，这是因为一晚上的休息补充了代谢的消耗 ，让我们感觉自己是全新的 。\n\n\n休息得不充分 、熬夜 ，以及其他一些身体亚健康状态 ，会阻碍代谢的补充 ，使得神经内分泌情况难以恢复到最佳状态 。这会影响人的认知能力 ，记忆 、阅读 、语言和逻辑思维能力会因此受到限制 。因此我们的大脑沉浸于某项工作的能力被削弱 ，表现为难以集中注意力 。疲劳的机制决定了伴随着我们的疲劳感出现的还有成就感降低 、对工作失去兴趣 、容易产生暴力倾向等附带效果 。因此长期高强度的加班 、三班倒等工作方式会改变人的 「性格 」 ，使人变得无趣 、无神 、无味 。\n\n\n转做不同的事情 ，新的事情要与先前的事情具有认知上的明显差异 ，不然的话达不到休息效果 ，反而造成了低效的 「多任务 」状态 。\n\n\n不难理解 ，注意力在疲劳时候受到的这些影响 ，会直接影响到我们的认知能力的表现 ，这包括反应时间的延长 、出错率的增加 、有效的持续工作时间缩短等等 。\n\n\n\n我们神经系统的疲劳耐受性会非常显著地影响我们在压力情况下的认知表现 ，从而决定一个人的 「毅力 」 「专注度 」 。可以说这个因素是 「毅力 」的生理基础 。毅力可以培养 ，但是毅力难以锻炼 ，因此是容易理解的了 。\n\n焦虑会影响专心和记忆。\n\n当焦虑超过阀值，人们可能会失去自己的自我，放弃之前的信仰。\n\n## 方法\n\n- 良好的睡眠\n- 我们更需要的是走出去，找朋友一起参与锻炼活动——跑步、爬山、游泳、骑车、瑜伽、冥想。这些事物较少涉及脑力需求，能让我们获得很好的休息，同时社会联系能让我们由于疲劳和压力产生的情绪有一个宣泄的出口。\n- 在工作时间，最好不要持续投入超过一个小时，而是每过一段时间找点别的事情休息几分钟，喝点水，起身走动一下。\n- 在疲劳感影响到我们的工作和生活时，尤其要拒绝「多线程」的工作状态，即不要同时做多个事情。因为「多任务」是非常低效的，同时又产生更多的疲劳感，其原理我们在前面章节中已经阐述了。\n\n","n":0.134}}},{"i":68,"$":{"0":{"v":"Mindfulness","n":1},"1":{"v":"\n时刻注意自己的思想和情绪。\n\n因为情绪会像星星之火可以燎原，所以在初期就应该注意到然后扑灭。\n\n一些强烈的情绪都是从一点点开始的。\n\n注意到自己情绪的初期，之后思考如何往哪里走。都是自己可以引导的。\n\n# 练习\n\n- 呼吸\n- 做事情的时候注意到自己在做什么","n":0.5}}},{"i":69,"$":{"0":{"v":"Food","n":1}}},{"i":70,"$":{"0":{"v":"Turkish","n":1},"1":{"v":"\n# 土耳其菜\n\n今天的土耳其菜很大程度上延续了奥斯曼帝国的美食传统。正是因为奥斯曼帝国这样一个强盛一时、幅员辽阔、文化多元的帝国的存在，才有了融汇东西、菜式丰富的土耳其菜。奥斯曼帝国的统治阶层信仰伊斯兰教，说着源于中亚的突厥语以及当时通行于中东的波斯语，在政治体制和文化上，则承了很多来自东罗马的遗产，在饮食文化上同样如此。\n\n## 土耳其烤肉 kebap\n\n虽然通常称作烤肉，但土耳其式的Kebab有用碎肉制成的，有炒熟的，也有炖熟的，做法非常多样。\n\n## 其他\n\nManti：这道菜的名字来源于中文的馒头，看上去有点像中国的饺子。\n\n葡萄叶包饭（Dolma）：东地中海和中东地区自古就有制作酿蔬菜（比如茄子塞肉、青椒塞肉）的传统。\n\n土耳其披萨（Lahmacun）：数千年来，烤制的面饼一直都是中东的主食。在奥斯曼帝国兴起之前，中东就出现了放入馅料烤制的大饼，后来逐渐演变成了加入碎肉、蔬菜、香料烤制的薄饼Lahmacun（但不加芝士）。Lahmacun看上去有点像以前流行的土家掉渣饼，关于其起源，有土耳其和亚美尼亚两种说法。\n\n![](/assets/images/2021-09-10-18-15-38.png)\n\n土耳其皮塔饼（Pide）:Pide是另一种被俗称为土耳其披萨的面饼。Pide起源于中东的皮塔饼，土耳其的Pide一般做成潜艇型，肉类、洋葱和芝士是其中常见的馅料，类似的馅饼在巴尔干和高加索也很流行。\n\n![](/assets/images/2021-09-10-18-15-57.png)\n\n土耳其软糖（Lokum）：土耳其软糖是土耳其最有代表性的甜点之一。\n\n![](/assets/images/2021-09-10-18-16-17.png)\n\n果仁蜜饼（Baklava）：这是种用坚果、糖浆、油酥等制成的层次丰富的甜点。","n":0.447}}},{"i":71,"$":{"0":{"v":"China","n":1}}},{"i":72,"$":{"0":{"v":"Cooking","n":1}}},{"i":73,"$":{"0":{"v":"Communication","n":1},"1":{"v":"\n# 分享\n\n- 经常主动地分享知识和资源，并且不求回报，这是大有裨益的。\n\n# 朋友\n\n- “接触老朋友是建立联系的有效方式，你已经了解这些人，所以这并不难，”巴克说。 “那些人可以向更多人介绍你。”如果您想与某人保持朋友关系，请至少每两周一次建立一次联系。制作和保持朋友需要时间，最好的方法是将它放在你的日历上\n\n# 两性\n\n女性的沟通是隐蔽的，男性的沟通是公开的。男人传达信息，女人传达感觉。在涉及信息时，男性优先考虑内容，女性优先考虑背景。在过去的四分之一个世纪里，女性化所造成的一个巨大的混淆是这种期望，即女性和男性一样理性，一样倾向于分析解决问题。这是一种平等主义心态的结果，它误导男性相信女性的沟通方式与男性没有区别。这并不是要贬低女性本身是精通问题解决的人，但它违背了女性如何设定一个专门的女性沟通形式。\n\n你不需要通灵来理解女性的隐秘交流，你需要的是观察力。这往往需要一种大多数男人根本没有的耐心，所以他们把女人写成两面派、善变或纵容，如果这个名字适合的话。隐蔽的交流使我们感到沮丧，就像公开的交流使妇女感到沮丧一样。\n\n只要女人仍然是不可知的、随机的、非理性的生物，男人不可能希望理解（但总是可以原谅），她们就可以不受阻碍地实现她们的目标。\n\n女人享受交流的过程，而不是被传递的信息。这不是一个需要解决的问题，主要是沟通。当一个傻瓜一下子向她提供所有的东西时，我们会想，是的，神秘感消失了，他不再是一个挑战，她为什么会感兴趣？这是真的，但好奇心消失的原因是没有更多的潜力来刺激交流的需要或她的想象力。\n当女人为她们的目的服务时，她们并不排斥使用公开的交流方式。\n\n用你的行为进行沟通。永远不要公开地告诉女人任何事情。让她自己得出你想要的结论。她的想象力是你游戏工具箱中最好的工具。学习如何使用它。\n\n这是一般受挫的笨蛋的最大失败：他们把自己的一切都吐出来，把自己的全部真相透露给女人，错误地认为女人渴望这种真相，作为他们亲密关系或持久承诺的资格基础。学习\n\n女人永远不希望完全披露。间接沟通是有效游戏的基础。","n":0.378}}},{"i":74,"$":{"0":{"v":"Story_telling","n":1},"1":{"v":"\n1：细节。一个故事要让他听起来像是真的，必须得有细节。比如：“我躺在床上，被子都没有盖（细节）。然后拿出手机瞄了一眼，我还清楚的记得那时候是凌晨3点15分（细节）。接着我翻了一个身。。。。。。”\n\n\n2：展示价值（可选）。故事是最好的让人了解你的方式。比如你想要让对方知道你很有钱。你可以直接的说：“我是个土豪。”\n\n当然你也可以讲一个故事：“我最近惨死了，前两天车被别人撞了一下，今天他打电话给我让我去签一份协议。我心想，修个车还签什么破协议。结果我一看，上面写着如果部件在运输过程中遭到损坏。要自行承担。我那个时候才知道，这破车的零件只能从意大利进口。国内买不到。哎，苦逼的我这几个月没车开了。”\n\n\n如此，别人自然知道你开的是好车。而且很有钱。\n\n\n3：起伏。平淡的故事没有人爱听。这就需要你有一定编剧的能力。如果没有，那不妨讲出来之前先编排好吧。\n\n举个例子：“你知道吗？昨天有个妹纸咨询我，她说她男朋友的那里太小，只有牙膏那么大。我一听就怒了。和她说，你别天真了好么？有牙膏那么大已经很大啦！！结果她弱弱的说，你见过宾馆的牙膏么。。。。”\n\n\n\n4： 创造世界画面，背景。这就像是在布景，你的故事最好需要有画面感。不然人们会索然无味。很多小说可以很好的做到这一点。\n\n比如：“二楼的空间并不大，零零散散的摆了几张桌子。余光告诉我，有几个身材火辣的美女正坐在这里吃饭。我没敢抬头扫视四周，默默的跟在哥们后面走到一个空餐桌面前坐下。\n\n　　坐定之后我抬起头。在我的斜对面，两点钟方向有一桌三个女生组成的小团体。其中一个女生面对我。\n\n　　作为一个心理健康的死娘炮，我惯性的瞄了她几眼。\n\n　　黄色的中分，很平顺。一身清凉至极的露肩装。露出圆润滑腻的珍珠肩。两条大长腿白的反光。脚底穿着一双透明彩丝带的玻璃凉鞋。足踝浑圆线条优美，十个脚趾头上丹蔻朱红，抹着鲜艳的指甲油。”\n\n\n\n相信你已经可以想象到小说想要描述的画面了。\n\n\n\n5：加入感情。一个好的故事没有一个好的述说方式也是行不通的。试想，如果机器人瓦力没有感情，它大概不会有那么多的粉丝。\n","n":0.707}}},{"i":75,"$":{"0":{"v":"Presuade","n":1},"1":{"v":"\n1. feature\n2. advantages\n3. benefit","n":0.5}}},{"i":76,"$":{"0":{"v":"Presentation","n":1},"1":{"v":"\n1. Stick to what you know. Presentations fail when you try to present yourself as an expert on something you aren’t.\n2. Tell stories, and don’t bother scripting them. Stories are easy to remember so you won’t mess them up. Script your transitions, and you’ll be set.\n3. Practice more than you think you need to. Long, boring practice is what sets professional speakers apart from amateurs.\n4. Chunk your speeches. Don’t get stuck thinking you have to work through it in a linear fashion.\n5. Slow your brain down. When your brain is moving too fast, you start to stumble on your words.\n6. Don’t wander. The temptation to step off the trail will be high. Once you do, it will be difficult to come back.\n7. Always save a few moments for your pre-talk calming routine. Never go on stage without doing this first.\n8. Ignore your mistakes. Context is more important than perfect delivery. If you mess up, keep going.\nRemember the audience wants you to succeed. Everything is easier when you remember everyone is on your side.","n":0.076}}},{"i":77,"$":{"0":{"v":"Logic","n":1},"1":{"v":"\n![](/assets/images/2021-05-03-21-59-25.png)\n\n![](/assets/images/2021-05-03-21-59-33.png)\n\n![](/assets/images/2021-05-03-21-59-44.png)\n\n![](/assets/images/2021-05-03-21-59-51.png)\n\n![](/assets/images/2021-05-03-21-59-58.png)\n\n• 壹：列你想说的东西\n• 写下你的目标，是影响思维，还是影响行为，具体是什么\n• 写下你的对象关心的东西，浓缩成你的论点（把没有的都删掉）\n ","n":0.5}}},{"i":78,"$":{"0":{"v":"Phone","n":1},"1":{"v":"\n打电话时说的第一个字：\n喂 第二声\n\n打电话时的第二句话：\n您现在说话方便不？\n\n打电话时尽量少说口头语：\n不用 嗯 啊 哦 用是的，好的，明白\n\n重要的事项学会复述、确认：\n您刚才说的这几点，不知我理解的对不对\n\n等着对方先挂电话：\n\n耐心等\n    \n轻轻挂","n":0.378}}},{"i":79,"$":{"0":{"v":"Listener","n":1},"1":{"v":"\n绝大多数时候，人们闲聊的最大驱动力并不是想交流意见拓宽思路。他们只是想表达自己。进而求得认同。\n\n# 倾听者的需求\n\n第一个方法，就是了解你说话对象的需求，这个就是所谓的情商，知道别人要什么。\n\n第二，了解人类的共同需求.其实我们是一样的，有一些需求是人类的共同需求。比如我们需要被人爱，需要安全感，这些都是我们需要的东西，所以两种情况出发，可以帮助你去思考对方需要什么。\n\n感受得到越多，情绪的传达和接收就越容易到位\n\n# 换位思考\n\n\n第一个方法，叫做**观察自己觉得厌恶跟不舒服的时刻**，大部分人都是正常人，你身上有一部分是人类共性，你要学会观察自己，就是别人跟你说什么话的时候，你会觉得特别不爽。别人开什么玩笑，你会特别难堪，这些你都应该记下来，大概需要记多久，其实半年到一年的时间，就可以了。\n\n比如你从 20 岁开始，有意识做这件事情，你记到 21 岁就会发现，在这一年当中，你就会把一个人在说话上所能遭受的不舒服情况遇个差不多，在以后的人生当中，不过是重复这些场景而已。\n\n所以你要学会去观察跟记录自己觉得厌恶、不舒服的时刻，然后记得这些话是你绝对不能跟别人讲的，这是换位思考的第一个方法。\n\n第二个方法，就是**通过提问和反馈**。其实很多时候，对方的需求是可以直接问出来的，你大胆去问就可以。很多时候你不正面问，靠猜，就越猜越错，话越说越错。\n\n而且更多时候，你要去观察对方的反馈，你不要怕说错话，说错话了对方给你一个不好的反馈，你就记得下一次不要这么说，所以你要把对方的反馈给记下来“我这次跟别人开了一个玩笑，感觉别人特别不开心，那么以后这个玩笑，我绝对不可以再开”。\n\n\n第三个方法，就是**收集第三者证据**。平时你会看到很多人发朋友圈，也会看到你的朋友发微博，他们会在朋友圈跟微博当中吐槽很多，他们在生活当中不舒服的时刻，甚至你会看到一篇文章会吐槽作者跟他朋友之间的一些事情。\n\n其实这些都是你应该注意起来的，就是说什么话，别人会不高兴，通过这三方面的收集，收集自己觉得厌恶、不舒服的时刻，去提问和收集对方的反馈，收集第三人的证据，通过这种收集下来，你会发现你真的不会说太多令人不舒服的话了，你的情商真的会提高。\n\n## 方法\n\n当我们可以展开讲讲，别人就更容易站在自己的角度去想象和思考\n而不是翻来覆去的，只有简单描述和抱怨的时候\n\n就不会满脑子疑问——“所以呢？”\n可以知道关键的细节——“原来是这样！”\n\n当我们可以让别人展开讲讲，我们就可以更好地理解对方的情绪\n而不是只有简单的回应和等待\n\n就不会满脑子疑问——“这有什么好说的？”\n可以从更丰富的细节中找到共鸣——“对对对，就是这样”","n":0.354}}},{"i":80,"$":{"0":{"v":"Hard","n":1},"1":{"v":"\n# 艰难的对话\n\n\n## 批评别人的话\n\n第一个步骤，让对方先说，你为什么会这么做？你当时是怎么想的？\n\n先让对方充分去说原因、理由跟做事过程，说完了之后，你从中挑出不对的环节做个替换。比如「你朋友不开心，你不一定要陪他去网吧，你可以陪他去打球的。你为什么一定要在网吧彻夜不回，这样让大家都很担心。」\n\n你可以通过他的充分陈述，抓住其中的错误环节。第二个步骤，给出建议和替代的方法。\n\n最后一个步骤，对他表达出期待，这个方法可厉害了，就是你批评完他之后「你不应该这么做，你应该那么做」。然后你对对方表达出你的期待「我之所以这么说，是因为我对你太看好了，我觉得你一定能够做好的。」\n\n这种话非常有魔力，通过我们这样批评别人，第一个步骤，让对方去做充分陈述；第二，找出错误环节做出建议，给出替代的方法；第三，表达对对方的期待。\n\n通过样三个步骤，你就会把一个本来会让别人不高兴的批评，变成一个让别人听了之后感觉不错，甚至感觉很好，并且自愿去改正的一段话。\n\n## 反对\n\n我们反对一个人，人家肯定是不会开心的，人家肯定不会欢迎你反对他，很少有人真心实意喜欢被别人反对他，反对的话应该怎么说？\n\n两个步骤，第一个步骤，先合理化对方的感受；第二个步骤，从自己的经历和角度出发，再去提反对意见。 \n\n举个例子，比如 A 跟她男朋友吵架了，决定回去把她男朋友给砍了，然后你反对这么做。\n\n你记得先去合理化对方的感受，千万不要把他的行为给合理化。如果人家做这个行为是合理的，那你就不好反对了，所以你先去合理他的感受「你的男朋友那么过分，所以你这么愤怒」。\n\n接下来讲：「在这样一个愤怒的情况下，你这么想，我是理解的。」合理化对方的感受。就是对方提了一个方案，你不同意，然后你应该说「从你的经历出发，能提出这个方案，我觉得是很合理的。」把它变成一个主观合理的东西。\n\n这是我们做的第一步，就是从主观上先合理对方。\n\n你再从自己的经历跟角度出发，去提出反对意见「我反对你，并不是说你就是错的，你说的话都是没用的，只是说从我自己的经历，从我自己所见过的证据来说，这样做更合理。」\n\n其实这样的反对，对方就比较容易接受了，因为被反对的时候，最痛苦的就是你认为我说的话都是没用的，因为你的才是会被采用的，你觉得你说的才是对的。\n\n所以我们在反对的时候，其实最重要的一个步骤，就是从主观上，去合理化对方的观点，而且我们也向对方表达了「我反对你，并不是因为我代表正义，代表正确，而是从我自己的经历跟角度出发，我觉得这样的观点，或者这样的解决方案，可能更好一些。」\n\n以上，就是反对的话应该怎么说。\n\n## 说服\n\n你说服一个人，对方也会不舒服的，没有人喜欢被说服，因为说服就意味着对方是弱势的，对方被你征服了。\n\n所以说服别人有快感，但是被说服的人没有快感，那我们应该怎么说服别人？两个方法。\n\n第一个方法，先让一步，再进一步。\n\n比如你希望别人 100 块钱买你这个东西，你上来先不要提 100 块，你先提 120 块买不买，然后对方直接把你给拒绝否定了，你再去提 100 块，对方这时候答应的概率就会增大。\n\n所以在日常生活当中，我们想说服一个人的时候，先让一步，让对方去否定你一次，让他获得快感，然后你再进一步去征服对方，这样的话，他的感受就不会有那么差了。\n\n还有说服的时候，要按照三个环节去说服，我们要先讲道理，再讲利益，最后讲情感，以情感结束是最好的，因为以情感结束，对方的痛感最低，如果你以道理结束的话，对方就会觉得「我被你说服，岂不是因为我没有道理」。\n\n所以大家明白这个顺序的意义，就是先讲道理。再讲利益，最后讲情感。 \n\n## 请求\n\n我请别人帮我一个忙，那我等于是让别人付出，我这句话并没有给对方什么价值，就让对方来帮我去扫地，这时候应该怎么说，把请求变成一个价值很高的话？\n\n首先，你绝对不能用祈使句，我们讲了，你说的这句话「你帮我扫地」对对方来说，一点价值都没有，你还用祈使句，那岂不是对方会讨厌死你吗？应该怎么说？三种方式，可以把请求变成一个价值很高的话。\n\n第一种方式，叫做如果你要这么做的话，会出现什么好的结果。\n\n「如果你可以帮我扫扫地的话，我们家一定会特别干净的，我们俩在里面肯定会特别开心的。」\n\n这是第一种说法，叫做如果你要这么做的话，出现的好的结果是什么。\n\n第二种请求的方式，叫做非你不可，只有你能帮我扫地，别人都不行。\n\n这种非你不可的感觉，也会让对方得到满足，也会给对方提供价值，所以这个方式也是可以用的。\n\n还有第三种话，当然就是感谢，提前把你的感谢说出来「帮我扫地，谢谢你了。」其实等于是你把有价值的话，附加在没价值的话上了，也会让你的请求变得好一些。\n\n这是请求的三种方式。\n\n## 安慰\n\n安慰风险可高了，如果你比对方好，一场考试你考好了她没考好，你去安慰她，这个风险特别高，你很容易引起对方的消极感受。\n\n即便你没有比对方好，由于被安慰的人，一般是处于一个情绪不稳定的情况之下，你不知道他要什么，而且他的感受可能一会这样，一会那样，很难满足他的需求，很难给他提供价值的。\n\n所以安慰本身是一个风险很高的话，大家千万不要随便去安慰别人，觉得我安慰你，我是来给你提供价值了，我怎么就不能随便说了。不行的，安慰风险很高。 \n\n我们在安慰的时候，应该注意什么？\n\n第一，不要上来就分享自己的经历跟感受，很多人安慰别人的时候，喜欢讲：「你这个情况，我也遇到过」，然后了 15 分钟，这样会让对方感受特别差。\n\n因为他失去了注意力，他的痛苦是需要被关注的，如果他失去了这种关注的话，他会不开心。\n\n所以安慰别人的时候，最忌讳的就是上来讲一大堆自己的经历跟感受。\n\n第二，不要上来就提建议。因为安慰的人处于一个很弱的心理水平，如果你上来就给他提建议的话，他就进一步觉得自己很弱，感受很不好，好像你行，我不行一样，所以上来不要去提建议。\n\n第三，就是一定要去肯定跟支持对方的感受，这种话是永远不会出错的。 \n\n比如对方离婚了，很伤心，你应该去支持对方的感受：「遇到这种情况，肯定是会伤心的，我觉得你这个伤心是无可厚非的，肯定会特别难受，换了谁不难受。」这种话就叫做肯定跟支持对方的感受。\n\n在安慰别人的时候，最容易犯什么错误？忽略对方感受。\n\n我给大家讲两种情况，你就能感受到一个人在安慰别人的时候会犯什么错误了。\n\n比如 A 家的小狗丢了，B 就跟他说：「不是什么事，没关系。」我们安慰别人的时候，是不是经常说「没关系」，但「没关系」这个话其实特别冒犯别人。\n\n「怎么就没关系了？我的感受就那么不应该？我就是觉得这个情景下应该难过，你告诉我没关系？」\n\n其实「没关系」这种话，都是没有支持对方的感受，会让人不舒服。所以「没关系」这种话我们是不能说的，我们一定要学会肯定跟支持对方的感受。\n\n还有一种情况，就是别人考不好很难过，你上来跟别人讲：「考不好不应该难过的。」你没有说「没关系」，你跟别人讲「不应该难过，应该开心，因为考不好你才知道自己什么地方有问题，才能改正进步。」\n\n这种比「没关系」更严重，直接点出了不应该，这两种情况都会引起别人的消极感受。\n\n所以我们在安慰别人的时候，**一定要学会肯定跟支持对方的感受「你此刻的情绪，都是对的，都是应该的。」这样的话，他会觉得很安慰**。\n\n还有最后一个方法，如果你真的不知道说什么，你不妨在行动上关心她。「我也不知道说什么，那我就去帮你买点吃的。」\n\n所以这也是一个很好的方法，也是直接提供价值的一个方法。\n\n这是第五种风险高的话应该怎么说，叫做安慰。\n\n## 拒绝\n\n拒绝别人，肯定是风险很高的，肯定是不提供价值的，肯定别人是不爱听的，应该怎么做？\n\n第一个步骤，理解对方的困境：「我知道你现在遭遇了经济上的困难，这时候肯定需要借钱。」\n\n第二个步骤，如果可能的话，找出拒绝他之后对他好的方面。\n\n比如「你这次来找我帮忙，我觉得不应该帮你的，因为我要帮你的话，你在这个方面永远都学不会自己应该怎么做，我觉得你这时候应该自己解决这个问题，这样的话对你更好。」\n\n但是这种话，对方一般都不接受，没关系，上来就来第三个步骤了。\n\n第三个步骤，告对方什么情况下，自己一定会提供帮助。\n\n「如果你下一次还解决不了这个问题的话，我一定会帮你的。」或者说：「借钱这个事我帮不了，但是如果你需要人的话，我一定去。」\n\n这样的话，你的拒绝就等于在最后又为对方提供了价值，不会让对方那么难以接受了。\n\n这是三个步骤，第一，理解对方的困境，对方来找你帮忙，其实他是把自己的姿态放低了，所以你要理解他的困境，帮助他把这个姿态给提高上来「一般人碰到你这个问题，都会来找人帮忙」。第二个步骤，拒绝之后，找出对他好的方面，如果可以的话告诉他。第三个方面，表明自己在什么情况下，一定会提供帮助。\n\n在这，我们需要注意一点，就是你一定要强调出自己的不变。很多时候，你拒绝别人说的很模糊，这种模糊会让对方觉得，你本来是可以帮他的，就是不帮他。\n\n所以在这三个环节之前，或者在最后一个环节之前，你要找出一个机会去强调自己哪里不方便，所以才不帮他的。一定要清晰地说出自己不便的状况，一定要说，不说的话效果不好，说出来之后，你再可以说最后一步，我现在不方便，什么情况下一定会帮你的。\n\n还有一种方法，就是我不告诉你在什么情况下一定会帮你，但是我可以找出其他的解决方案，帮你解决这个问题。 \n\n比如我有朋友来找我借钱，我有自己的不便之处，我告诉他我确实不能借这个钱，然后我给他介绍了一个做小额贷款的朋友，其实这也是帮他找到了解决办法。\n\n这种拒绝也没有那么难受，因为拒绝本身是非常伤人的，如果你不想失去这个朋友的话，一定要有拒绝的智慧，因为本身别人就是把姿态放低了，来找你帮忙，然后你还把他拒绝，等于进一步把它的姿态再踩下去。\n\n所以如果不处理好拒绝的话，是很影响感情的。\n\n","n":0.189}}},{"i":81,"$":{"0":{"v":"Gift","n":1},"1":{"v":"\n真诚第一原则！！\n\n送礼物的原因\n\n\t1. 把感情具体化的一种方式，是个愉悦的过程\n\t2. 送礼物的人看重礼物的交换价值\n\t3. 收礼物的人看重礼物的实用价值\n\n错误的做法\n\n\t1. 惊喜，希望意想不到，没有十足的把握不要送惊喜\n\t2. 鲜花是即使享受的礼物，收到的满足会稍纵即逝，\n\t3. 实物，价值交换，可能被替换，容易被忘掉\n\t4. 反映对方特点，没必要，送礼品卡也是一种选择\n\t5. 手工制作，准备时间长，时间成本大，但是收礼物的人不会理会，\n\t6. 酷的，其实只是满足自己的需求而已\n\t\n正确的做法\n\n\t1. 相对贵的，简单直观感受到价格\n\t2. 不舍得买，超过自己消费能力的。从个人的愧疚变成享受\n\t3. TA需要的（购物车里的） 不是我需要ta有的\n\t4. 长期价值的礼物（菜谱..）\n\t5. 体验类的礼物（外餐，郊游，影响深刻）\n\n提高礼物的附加值\n\n\t1. 很难去的地方\n\t2. 告诉对方礼物的来由，你挑选礼物的原因\n","n":0.236}}},{"i":82,"$":{"0":{"v":"Chat","n":1},"1":{"v":"\n1. 态度   友好的沟通态度  看对方的反应 想社交的心态\n2. 情绪    释放自己的情绪  表达别人可以接受的情绪  寒暄之后表达情绪（夸张的语言表达情绪）\n3. 想法  表达内心对于事物的看法\n\n# 技巧\n\n1. 提醒自己要多发问——发问是会聊天的一种手段吧。即使在讲自己的故事，多说”你觉得呢？“ ”换你你会这样做吗？“也会让别人更有参与感，更加舒服呢。这样也避免了自己非常傻的滔滔不绝……\n2. 即使再不认同对方，永远也不要在对话中出现讽刺和挖苦\n3. 沉默是好事，沉默是金，好好享受它。\n4. 愿意聊天的人总喜欢把话题说得更具体，而不想聊天的人则会顺着话题的方向直接概括出结论，言下之意是“我已经都知道，你不用再多说。”\n5. **下切、具体细节、表达感受、描述问题、关注过去、对照眼前、罗列现象、就事论事、开放肯定、忘却目的**、活在当下、以自我为标准。\n\n\n# 错误\n\n## 连续提问\n\n\n导致连续提问有两个原因：\n\n其一，有些男人遇到喜欢的女孩，想尽快投其所好，于是就开启提问模式，像猎人发现了猎物马上就收集猎捕信息。\n\n其二，试图用提问来逃避无话可说，我问你答短暂产生了聊得不亦乐乎的错觉。\n\n\n但实际上，连续提问是在透支社交的耐心和礼貌。正常的聊天应该是你来我往、互通有无的，你可以向别人索取信息，但也应该向别人提供信息。尽管在对话刚开始的时候人家可以出于礼节向你单方面提供一些信息，但如果你总是没有回馈，这就打破了社交的平衡，对方就会觉得跟你聊天不舒服。\n\n要想避免这个问题，可以在每次对方回答了你的问题之后，你都给予一定的响应（即自己在这个话题上的相关信息，状态或感受）\n\n## 不说自己\n\n聊天的主要作用应该是让双方互相了解，但很多男人都认为自己的生活没什么值得说的，他们更喜欢谈论对方或者第三方。虽说这样也不是不能展示自己，比如你有独特的表达方式，但能达到这个境界的人毕竟凤毛鳞爪。\n\n正确的做法是在回答时多用状态+感受\n\n## 情感过度\n\n情感过度就是你在聊天中传递出来的情感超出了你们现有关系，从而让对方觉得别扭。\n\n\n情感过度的表现形式分为两种，一种是过于细致琐碎的状态表达，比如我今天做什么吃什么买什么看什么，事无巨细唠唠叨叨，但你忘了别人也许对这些根本不感兴趣；一种是过分强烈的感受表达，比如男孩对一个刚刚认识的女孩说“今天满脑子想的都是你”，但他意识不到女孩可能会因此觉得尴尬。\n\n情感过度的原因有两点：1，追求表达的极致效果，恨不得每句话都一语惊人直捣芳心。2，对真诚的错误理解，认为真诚就是把自己做的和想的毫无保留地告诉对方。但人际关系是在平衡中的推进，单方面的冒进反而会破坏稳定\n\n## 随意评价\n\n随意评价包括对别人的情绪、意愿、能力、性格、角色进行不由分说的主观判定，产生的原因往往是当事者为了说出有趣的话题，自己先去设定一个前提，然后再想象伸延去表达一个意义。但问题是这个前提常常与事实不符，并且还是指向对方的，这就给别人自以为是的感觉。\n\n“用客观事实淡化主观意愿”，讲一些客观事实。 而随意评价的人干的事情就属于——“用主观判断覆盖客观事实”，正好是反其道行之。","n":0.204}}},{"i":83,"$":{"0":{"v":"Body","n":1},"1":{"v":"\n1. 手放在嘴中间：我不买账，不想听你说\n2. 女性把手放脸边，45度，assessment behavior 看你说的对不对\n3. 握手时升高音调，表明欺骗\n4. Cheat wife: 表现的比平时更好\n5. 女性听靠视觉，男性听靠听觉，一般并排坐：靠近男性有一定的角度，靠近女性direct\n6. 握手\n    a. 伸手\n    b. Use direct eye contact\n    c. Show your teeth, smile\n    d. Give verbal greeting\n7. 握手的时候左手比较积极，运动：表达喜欢\n8. 倾听：tell me about yourself, tell me more about yourself\n9. Head nodding: 男性表示同意，女性只是表达理解，不一定同意\n10. Head tilting better listener\n11. 二郎腿，如果男性之前坐，后来放下，说明达成协议机会很大\n女性坐在椅子上，往前坐，说明有兴趣","n":0.149}}},{"i":84,"$":{"0":{"v":"Basic","n":1},"1":{"v":"\n# 原则\n\n- 说话的本质其实是一场**交易**，这些话其实都在跟倾听者做交易\n- 沟通 = 结果+情绪和人际关系\n- 描述事情从他人的角度来讲\n- 作为一个倾听者，更容易给别人价值。如果我在听的时候，再给对方一些很好的反馈「你说得真棒，你说得真好」，这个反馈更增大了对方的积极感受，这时候很容易给别人留下好印象。\n- 我们应该多说一些**价值高的话**。比如表扬、感谢，还有承诺等等，这些都是价值比较高的话，这些话都会让别人觉得从你的话当中获得了价值，平时我们可能会忽略这些话的表达。\n  - 说话价值理论有什么意义？它可以成为你说话的一个底层逻辑，可以指导你说话的方向。\n  - 你以后说了一些话，自己可以去判断一下，这段话有给对方价值吗？如果没有的话，对方为什么要听？\n  - 用这样一个标准去衡量，你会发现很多话可能都是无用、无聊的话，就不必要说了。很多时候你的话没有给人家价值，你还剥夺了人家，还造成了人家的不愉快，当然你就不会受对方欢迎了。\n\n\n# 无意义的谈话\n\n1. 就是无用、无聊。你在每一次跟别人说话的时候，都想想，你说这段话对别人有用吗？有什么用？或者你说的这段话，让别人开心吗？别人会不会觉得无聊？\n\n无用、无聊的话，就是典型的无价值谈话，别人听到之后，其实不会有什么不适感受，但由于付出了成本，他会觉得不耐烦。 \n\n比如我是一个听众，如果我听到演讲者在台上讲「我有点紧张，我不知道应该说什么」这种话，我就会觉得是无用、无聊的话。\n\n因为你说这段话，除了缓解自己的紧张之外，对我来说没有任何意义，没有任何用，这种无用、无聊的话就不要说。\n\n所以你想想看，自己说的哪些话，无用、无聊。\n\n2. 无价值谈话的典型，叫做直接引起对方消极感受。\n\n比如你跟对方说你这个月的工资不发了，这不仅是无价值了，这是从对方身上要东西了，所以对方肯定会不高兴。\n\n还有很多冒犯的话，都是会引起对方的消极感受。\n\n还有一些话其实给了对方价值，但是就是会引起对方消极感受，比如批评的话。\n\n「我未来是为了你好」，其实这句话对方也不欢迎。\n\n注意，我们今天说的说话技巧，只从一个角度去考评你的说话行还是不行，就是受不受欢迎，所以批评的话也不被对方欢迎。\n\n3. 就是提示对方未来风险。\n\n比如我当着 A 说了 B 的坏话，其实我并没有说 A，我并没有剥夺 A 的什么东西，可能你说 B 的坏话，会提示 A 未来有风险，就是我能对着你说他的坏话，我也能对着别人说你的坏话。","n":0.18}}},{"i":85,"$":{"0":{"v":"Askquestions","n":1},"1":{"v":"\n1. 封闭式  节省时间 控制谈话方向 但是信息有限\n2. 开放式   信息全面 但是浪费时间","n":0.354}}},{"i":86,"$":{"0":{"v":"Appreciation","n":1},"1":{"v":"\n# 赞美\n\n第一点，具体。你要跟他讲哪里好，越具体越好，因为在表扬这个事情上，可信度高很重要。\n\n「你人真好」就不如说「你今天做的某一个事，真的让我觉得你特别善良。」\n\n如果你真的找不出什么具体的地方表扬他的话，你可以用这种话来表扬他：「你这个人的个性就是这样的。」\n\n这种个性化的认可，也会让对方觉得你的话效果好，价值很高。\n\n所以这个方法，叫做认可对方的个性，要学会说这种话，可信度很高，因为个性就意味着跟别人不一样。\n\n在表扬这个方面，总之大家就记得，可信度高很重要。\n\n\n## tip\n\n外表的认同和赞扬，她的发型妆容配饰服装鞋子包甚至脸上动的部位，都是我的话题，延伸后表情、肢体语言，关键点在于两点：细节，以及发现其他男人未曾发现的点。\n\n在聊天过程中可以抓住女生的一个隐形价值点进行认同肯定，例如女生的独立、聪慧、善良等。\n\n# 感谢\n\n「我谢谢你」是可以的，感谢的时候可以加上表扬，效果更佳：「你这个人怎么这么棒，你怎么这么厉害。」\n\n所以感谢可以加表扬，感谢也可以加承诺：「如果下一次你来找我，我一定帮你。」也是为对方提供了价值。\n\n这是感谢的话应该怎么说，两种方式，感谢加表扬，效果好；第二种方式，就是感谢家承诺，效果好。\n\n1. 具体化\n2. 从否定到肯定\n3. 指出他人的变化\n4. 信任","n":0.354}}},{"i":87,"$":{"0":{"v":"Car","n":1}}},{"i":88,"$":{"0":{"v":"Punishment","n":1},"1":{"v":"\n# 收到罚单的处理方法\n\n1、认罪、交罚款；\n2、不认罪、申诉；\n3、认罪、但是找个理由求情，希望法官减少甚至撤销罚款。\n\n# 罚单\n\n![](/assets/images/2021-11-06-15-45-13.png)\n\n第一项为 Ciation Number : Ciation number 是这张罚单的罚单号，你可以根据此号码在 DMV 系统里查询具体罚单信息。\n\n第二项为 Violation Code : 这一项是写书面声明 Written Declaration 最重要的一项，你要根据警察在上面书写的交通法编码具体了解你违反了哪像法律法规，法律的具体内容规定又是什么，因此才可以知道怎样为自己进行有效的无罪辩护。常见的 Violation Code 包括 22349,22350 超速；22450 Stop Sign 未停等。\n\n第三项为 Court Date : 这一日期是你的出庭日期，在这个时间之前的任意一天，都可以选择递交 Written Declaration。\n\n第四项为 Court Address : 这一地址为你应上庭的法院地址，一般也为你上交书面辩护的地方。\n\n","n":0.167}}},{"i":89,"$":{"0":{"v":"Writter_declaration","n":1},"1":{"v":"\n![](/assets/images/2021-11-06-15-45-59.png)\n\n第一项为固定标题结尾 : 标题结尾请按照模板的具体内容，一字不差地摘抄上去哟！这是法院规定的开头结尾，记得写好打印出来之后，在最下方签字并标上书写日期。\n\n开头：I plead Not Guilty to violating citation code. Please review my statement as evidence below:\n\n结尾：Please dismiss my citation in the interest of justice. I declare under penalty of per jury under the laws of the State of Californiathat the foregoing is true and correct.\n\n第二项为场景陈述模板 : 这一项记得对当时的开车场景进行具体描述。如哪年哪月大约几点，天气交通状况，以及当时是否有其他人同你一起在车内等情况，并描述自己是如何被警察 pull over 等等，细节越细，可信度就越高。\n\n第三项为法律条款: 这一项就要根据你的 ticket 上面的 violation code 来进行分情况叙述啦！首先的建议为摘抄一遍这条法律条款的原文，然后根据法律条款里的规定进行咬！文！嚼！字！对，没错！就是使劲儿抓它的叙述漏洞！如果你认为你的英文水平不够，没关系，google “how to fight violation code xxxx”，总有一波好心大神在网站上造福人类~\n\n第四项为固定说法模板: 这一固定说法写在事实陈述段落的最后一句，Therefore, based upon the evidences I listed, I do not think I violate California traffic code xxxx.\n\n除去书面申诉，其他任何你认为有帮助解释被 Pull over 时交通情景的照片、图表、医生假条以及视频等任何形式的证据都可以成为呈堂证供，随 written declaration 一起上交给法院。\n\n# 流程\n\n进入法院后，首先前往 Traffic Clerk‘s Office 进行排队，等待窗口人员办理业务。\n\n轮到你后，请向办公人员递交罚单、驾照并且记得说 “Can I request the form of Trial by Written Declaration? ”，随后工作人员便会帮助你查询罚单信息，获取表格。\n\n交保释金，领取收据\n虽然 Trial By Written Declaration 是完全免费的，但是在你申请获取表格时，仍需要首先支付 Bail 也就是保释金。保释金的数额是罚单的罚款，但是放心，一但最后法官判定是 Not Guilty，这一笔保释金会立即以支票的形式退还给你~ 所以前往法院时，不要忘记准备一张个人支票。\n\n按照办公人员的要求填写好个人支票上交后，你就会领到表格开始填写啦！\n\n![](/assets/images/2021-11-06-15-47-21.png)\n\n第一项为法院填写项，你不用填任何信息！ \n\n第二项为辅助证据项：如果有准备除 Statements of Facts 以外的照片、图表、医生证明等额外证据，需要在这里进行勾选。\n\n第二页需要填写自己的姓名，以及邮寄地址 (一定要填写收信地址哟！之后的判决结果以及退还的支票都会退还给这个地址)，在Statements of Facts 那里书写 “Please Review Attachment 1” 等字样，最后签名标注当天日期。并把所有已经准备的证据和书写申辩放在标的最后，交给工作人员。\n\n等待法院判决结果\n法院一般会在递交书面申请书后的一个半月至两个月内给出判决结果，会以信件的形式邮寄给你，所以请记得注意查收哟！\n\n法院判决结果为 Not Guilty，那么恭喜你，怎样交出去的钱，就怎么样收回来！如果结果为减少罚款金额或者仍未全额付款，没关系，你还可以选择上庭申诉以此来拖延时间。\n\n以支票形式退换保释金\n如果法官的判决结果为 Not Guilty 无罪，那么你将在收到法官判决书的 1-2 星期收到法院给你寄来的保释金退款支票。注意，支票并不是和判决书一起，所以请耐心等待，你的支票分分钟回到你的口袋~\n\n","n":0.087}}},{"i":90,"$":{"0":{"v":"Development","n":1}}},{"i":91,"$":{"0":{"v":"Web","n":1},"1":{"v":"\n\n# whole picture\n\nuser request -> server -> Database\n\n## How request get to server\n\n1. Network layer\n2. Network protocl\n3. Load balancing\n\n\n## How server organize together\n\n1. Distributed System\n","n":0.2}}},{"i":92,"$":{"0":{"v":"Tools","n":1}}},{"i":93,"$":{"0":{"v":"Zsh","n":1},"1":{"v":"# install\n\n```\nbrew install zsh\n```\n\noh-my-zsh\n\n```\nwget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | sh\n```\n\n## themes\n\nclone到  ~/.oh-my-zsh/themes\n修改`~/.zshrc` ZSH_THEME=\" \"\n\n- git clone --depth=1 https://github.com/romkatv/powerlevel10k.git ${ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom}/themes/powerlevel10k\n- powerlevel10k/powerlevel10k\n\n## plugin\n\n- autojump \n  - brew install autojump\n- zsh-autosuggestions\n  - git clone git://github.com/zsh-users/zsh-autosuggestions $ZSH_CUSTOM/plugins/zsh-autosuggestions\n- zsh-syntax-highlighting\n  - git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting\n- bat\n  - add syntax in cat\n- sudo\n  - type esc esc twice to add sudo\n## tip\n\n- 在当前目录下输入 .. 或 ... ，或直接输入当前目录名都可以跳转，你甚至不再需要输入 cd 命令了。\n- 目录浏览和跳转：输入 d，即可列出你在这个会话里访问的目录列表，输入列表前的序号，即可直接跳转。\n- 命令参数补全。键入 kill <tab> 就会列出所有的进程名和对应的进程号\n- 通配符搜索：ls -l **/*.sh，可以递归显示当前目录下的 shell 文件，文件少时可以代替 find。使用 **/ 来递归搜索\n- zsh_stats: Get a list of the top 20 commands and how many times they have been run.\n- take: Create a new directory and change to it, will create intermediate directories as required.\n- x / extract: Extract an archive (supported types: tar.{bz2,gz,xz,lzma}, bz2, rar, gz, tar, tbz2, tgz, zip, Z, 7z).\n- osx\n\n## alias \n\n| Flag | Description                                    |\n| ---- | ---------------------------------------------- |\n| L    | print each alias in the form of calls to alias |\n| g    | list or define global aliases                  |\n| m    | print aliases matching specified pattern       |\n| r    | list or define regular aliases                 |\n| s    | list or define suffix aliases                  |\n\n## Directory\n| Flag  | Description                           |\n| ----- | ------------------------------------- |\n| ..    | cd ..                                 |\n| ...   | cd ../..                              |\n| ....  | cd ../../..                           |\n| ..... | cd ../../../..                        |\n| /     | cd /                                  |\n| ~     | cd ~                                  |\n| md    | mkdir -p                              |\n| rd    | rmdir                                 |\n| d     | dirs -v (lists last used directories) |\n\n## osx\n| Flag        | Description                                         |\n| ----------- | --------------------------------------------------- |\n| tab         | Open the current directory in a new tab             |\n| split_tab   | Split the current terminal tab horizontally         |\n| vsplit_tab  | Split the current terminal tab vertically           |\n| ofd         | Open the current directory in a Finder window       |\n| pfd         | Return the path of the frontmost Finder window      |\n| pfs         | Return the current Finder selection                 |\n| cdf         | cd to the current Finder directory                  |\n| pushdf      | pushd to the current Finder directory               |\n| pxd         | Return the current Xcode project directory          |\n| cdx         | cd to the current Xcode project directory           |\n| quick-look  | Quick-Look a specified file                         |\n| man-preview | Open a specified man page in Preview app            |\n| showfiles   | Show hidden files in Finder                         |\n| hidefiles   | Hide the hidden files in Finder                     |\n| itunes      | DEPRECATED. Use music from macOS Catalina on        |\n| music       | Control Apple Music. Use music -h for usage details |\n| spotify     | Control Spotify and search by artist, album, track… |\n| rmdsstore   | Remove .DS_Store files recursively in a directory   |","n":0.049}}},{"i":94,"$":{"0":{"v":"Vim","n":1},"1":{"v":"\n# move\n\n- h,j,k,l\n- w,b,e\n- G: go to top\n- gg: go to end\n- { }, skip a block of code\n- V: select line\n- ctrl-v: select block of code (same column)\n- ^: begin line, $: end of line \n- t/f + char: go to the specific char in the line\n- %: go to specific parenthese\n- *: search for other instance\n\n# change\n\n- u: undo\n- ctrl+r: redo\n- yy: Copy line\n- p: paste below\n- P: paste above\n- dd\n- dw\n- D: delete to the end of line \n- o: insert line below\n- O: insert line above\n- c: change \n- x: delete char\n- ~: change the case of char \n- r: replace char\n- > < : 增加缩小缩进\n- yt+char:复制到那个char\n\n# search\n\n替换改行的第一个old单词为new\n:s/old/new\n\n替换改行的所有old单词为new\n:s/old/new/g\n\n替换两个# 之间的单词\n`:#,#s/old/new/g`\n\n替换文件中所有的单词\n:%s/old/new/g\n\n每一个替换之前都需要确认的话，在命令末尾加一个 c\n:%s/old/new/gc\n\n\n# Config\n\n## basic\n\n- filetype on  \n  - \" Enable type file detection. Vim will be able to try to detect the type of file in use.\n- filetype plugin on\n- filetype indent on\n- syntax on\n- set number\n  - show line number\n- set cursorline\n  - Highlight cursor line underneath the cursor horizontally.\n- set shiftwidth=4\n- set tabstop=4\n- set hlsearch\n- set incsearch\n    - While searching though a file incrementally highlight matching characters as you type.\n- set showmatch\n  - Show matching words during a search.\n- set history=1000\n  - Set the commands to save in history default number is 20.\n- set wildmenu\n  - Enable auto completion menu after pressing TAB.\n- set wildmode=list:longest\n- set wildignore=*.docx,*.jpg,*.png,*.gif,*.pdf,*.pyc,*.exe,*.flv,*.img,*.xlsx\n- set ttyfast\n- set showmode\n- set encoding=utf-8\n- \n## status bar\n\n```\n\" STATUS LINE ------------------------------------------------------------ {{{\n\n\" Clear status line when vimrc is reloaded.\nset statusline=\n\n\" Status line left side.\nset statusline+=\\ %F\\ %M\\ %Y\\ %R\n\n\" Use a divider to separate the left side from the right side.\nset statusline+=%=\n\n\" Status line right side.\nset statusline+=\\ ascii:\\ %b\\ hex:\\ 0x%B\\ row:\\ %l\\ col:\\ %c\\ percent:\\ %p%%\n\n\" Show the status on the second to last line.\nset laststatus=2\n\n\" }}}\n```\n\n%F – Display the full path of the current file.\n\n%M – Modified flag shows if file is unsaved.\n\n%Y – Type of file in the buffer.\n\n%R – Displays the read-only flag.\n\n%b – Shows the ASCII/Unicode character under cursor.\n\n0x%B – Shows the hexadecimal character under cursor.\n\n%l – Display the row number.\n\n%c – Display the column number.\n\n%p%% – Show the cursor percentage from the top of the file.\n## key mapping\n\nmap_mode <what_you_type> <what_is_executed>\n\nnnoremap – Allows you to map keys in normal mode.\ninoremap – Allows you to map keys in insert mode.\nvnoremap – Allows you to map keys in visual mode.\n\n## use\n\n- add `~/.vimrc`\n- load `:so %`","n":0.051}}},{"i":95,"$":{"0":{"v":"Tmux","n":1},"1":{"v":"\n# basic concept\n\n\n在Tmux逻辑中，需要分清楚Server > Session > Window > Pane这个大小和层级顺序是极其重要的，直接关系到工作效率：\n\n- Server：是整个tmux的后台服务。有时候更改配置不生效，就要使用tmux kill-server来重启tmux。\n- Session：是tmux的所有会话。我之前就错把这个session当成窗口用，造成了很多不便里。一般只要保存一个session就足够了。\n- Window：相当于一个工作区，包含很多分屏，可以针对每种任务分一个Window。如下载一个Window，编程一个window。\n- Pane：是在Window里面的小分屏。最常用也最好用\n\n# common command \n\n```bash\n\n#启动新session：\n$ tmux [new -s 会话名 -n 窗口名]\n\n#恢复session：\n$ tmux at [-t 会话名]\n\n#列出所有sessions：\n$ tmux ls\n\n#关闭session：\n$ tmux kill-session -t 会话名\n\n#关闭整个tmux服务器：\n$ tmux kill-server\n\n# 列出所有快捷键，及其对应的 Tmux 命令\n$ tmux list-keys\n\n# 列出所有 Tmux 命令及其参数\n$ tmux list-commands\n\n# 列出当前所有 Tmux 会话的信息\n$ tmux info\n\n# 重新加载当前的 Tmux 配置\n$ tmux source-file ~/.tmux.conf\n```\n\n## system\n\n| 前缀   | 指令   | 描述                                   |\n| ------ | ------ | -------------------------------------- |\n| Ctrl+b | ?      | 显示快捷键帮助文档                     |\n| Ctrl+b | d      | 断开当前会话                           |\n| Ctrl+b | D      | 选择要断开的会话                       |\n| Ctrl+b | Ctrl+z | 挂起当前会话                           |\n| Ctrl+b | r      | 强制重载当前会话                       |\n| Ctrl+b | s      | 显示会话列表用于选择并切换             |\n| Ctrl+b | :      | 进入命令行模式，此时可直接输入ls等命令 |\n| Ctrl+b | [      | 进入复制模式，按q退出                  |\n| Ctrl+b | ]      | 粘贴复制模式中复制的文本               |\n| Ctrl+b | ~      | 列出提示信息缓存                       |\n\n## window\n\n| 前缀   | 指令 | 描述                                     |\n| ------ | ---- | ---------------------------------------- |\n| Ctrl+b | c    | 新建窗口                                 |\n| Ctrl+b | &    | 关闭当前窗口                             |\n| Ctrl+b | 0~9  | 切换到指定窗口                           |\n| Ctrl+b | p    | 切换到上一窗口                           |\n| Ctrl+b | n    | 切换到下一窗口                           |\n| Ctrl+b | w    | 打开窗口列表，用于且切换窗口             |\n| Ctrl+b | ,    | 重命名当前窗口                           |\n| Ctrl+b | .    | 修改当前窗口编号（适用于窗口重新排序）   |\n| Ctrl+b | f    | 快速定位到窗口（输入关键字匹配窗口名称） |\n\n## panel\n\n| 前缀   | 指令        | 描述                                                           |\n| ------ | ----------- | -------------------------------------------------------------- |\n| Ctrl+b | \"           | 当前面板上下一分为二，下侧新建面板                             |\n| Ctrl+b | %           | 当前面板左右一分为二，右侧新建面板                             |\n| Ctrl+b | x           | 关闭当前面板（关闭前需输入y or n确认）                         |\n| Ctrl+b | z           | 最大化当前面板，再重复一次按键后恢复正常（v1.8版本新增）       |\n| Ctrl+b | !           | 将当前面板移动到新的窗口打开（原窗口中存在两个及以上面板有效） |\n| Ctrl+b | ;           | 切换到最后一次使用的面板                                       |\n| Ctrl+b | q           | 显示面板编号，在编号消失前输入对应的数字可切换到相应的面板     |\n| Ctrl+b | {           | 向前置换当前面板                                               |\n| Ctrl+b | }           | 向后置换当前面板                                               |\n| Ctrl+b | Ctrl+o      | 顺时针旋转当前窗口中的所有面板                                 |\n| Ctrl+b | 方向键      | 移动光标切换面板                                               |\n| Ctrl+b | o           | 选择下一面板                                                   |\n| Ctrl+b | 空格键      | 在自带的面板布局中循环切换                                     |\n| Ctrl+b | Alt+方向键  | 以5个单元格为单位调整当前面板边缘                              |\n| Ctrl+b | Ctrl+方向键 | 以1个单元格为单位调整当前面板边缘（Mac下                       |\n| Ctrl+b | t           | 显示时钟                                                       |\n\n# config\n\n- set-option -g mouse on\n  - 支持鼠标\n- 状态栏\n\n```\nset -g base-index 1           # start windows numbering at 1\nset -g status-utf8 on # 状态栏支持utf8\nset -g status-interval 1 # 状态栏刷新时间\nset -g status-justify left # 状态栏列表左对齐\nsetw -g monitor-activity on # 非当前窗口有内容更新时在状态栏通知\nset -g set-titles on          # set terminal title\nset -wg window-status-format \" #I #W \" # 状态栏窗口名称格式\nset -wg window-status-current-format \" #I:#W#F \" # 状态栏当前窗口名称格式(#I：序号，#w：窗口名称，#F：间隔符)\nset -wg window-status-separator \"\" # 状态栏窗口名称之间的间隔\n```\n- vim 模式\n\n```\n# vi模式，v开始选择，y 复制选择内容到剪贴板\n# Use vim bindings\nsetw -g mode-keys vi\n```\n\n- 调整窗口大小\n\n```\n# ctrl + k/j/h/l 调整pane大小\n# resize pane\nbind -r ^k resizep -U 10 # upward (prefix Ctrl+k)\nbind -r ^j resizep -D 10 # downward (prefix Ctrl+j)\nbind -r ^h resizep -L 10 # to the left (prefix Ctrl+h)\nbind -r ^l resizep -R 10 # to the right (prefix Ctrl+l)\n```\n\n```\nbind r source-file ~/.tmux.conf \\; display '~/.tmux.conf sourced'\nset -g prefix2 C-a                        # GNU-Screen compatible prefix\nbind C-a send-prefix -2\n```\n\n\n# good one\n\n- https://github.com/gpakosz/.tmux\n\n# save tmux session\n\n- https://github.com/tmux-plugins/tmux-continuum","n":0.047}}},{"i":96,"$":{"0":{"v":"Service_mesh","n":1},"1":{"v":"\n[reference](https://philcalcado.com/2017/08/03/pattern_service_mesh.html)\n\nA service mesh is a dedicated infrastructure layer for handling service-to-service communication. It’s responsible for the reliable delivery of requests through the complex topology of services that comprise a modern, cloud native application. In practice, the service mesh is typically implemented as an array of lightweight network proxies that are deployed alongside application code, without the application needing to be aware.\n\n![](/assets/images/2021-05-06-22-27-43.png)\n\nIn such model, each of your services will have a companion proxy sidecar. Given that services communicate with each other only through the sidecar proxy, we end up with a deployment similar to the diagram below:\n\n![](/assets/images/2021-05-06-22-27-11.png)\n\n下面以 Istio 为例讲解 Service Mesh 如何工作，后续文章将会详解 Istio 如何在 Kubernetes 中工作。\n\n1. Sidecar（Istio 中使用 Envoy 作为 sidecar 代理）将服务请求路由到目的地址，根据请求中的参数判断是到生产环境、测试环境还是 staging 环境中的服务（服务可能同时部署在这三个环境中），是路由到本地环境还是公有云环境？所有的这些路由信息可以动态配置，可以是全局配置也可以为某些服务单独配置。这些配置是由服务网格的控制平面推送给各个 sidecar 的，\n2. 当 sidecar 确认了目的地址后，将流量发送到相应服务发现端点，在 Kubernetes 中是 service，然后 service 会将服务转发给后端的实例。\n3. Sidecar 根据它观测到最近请求的延迟时间，选择出所有应用程序的实例中响应最快的实例。\n4. Sidecar 将请求发送给该实例，同时记录响应类型和延迟数据。\n5. 如果该实例挂了、不响应了或者进程不工作了，sidecar 会将把请求发送到其他实例上重试。\n6. 如果该实例持续返回 error，sidecar 会将该实例从负载均衡池中移除，稍后再周期性得重试。\n7.如果请求的截止时间已过，sidecar 主动标记该请求为失败，而不是再次尝试添加负载。\n8. SIdecar 以 metric 和分布式追踪的形式捕获上述行为的各个方面，这些追踪信息将发送到集中 metric 系统。\n","n":0.085}}},{"i":97,"$":{"0":{"v":"Hugo","n":1},"1":{"v":"\n# hugo template\n\n基于[go html template](https://pkg.go.dev/text/template)\n\n## variables\n\n```go\n{{ .Title }}\n{{ $address }}\n{{ $address := \"123 Main St.\" }}\n```\n\n## functions\n\n```go\n{{ FUNCTION ARG1 ARG2 .. }}\n{{ add 1 2 }}\n```\n\n## include\n\n```go\n{{ partial \"header.html\" . }}\n{{ template \"_internal/opengraph.html\" . }}\n```\n\n## logic\n\n```go\n// iteration\n{{ range $array }}\n    {{ . }} <!-- The . represents an element in $array -->\n{{ end }}\n\n{{ range $elem_val := $array }}\n    {{ $elem_val }}\n{{ end }}\n\n{{ range $elem_index, $elem_val := $array }}\n   {{ $elem_index }} -- {{ $elem_val }}\n{{ end }}\n\n{{ range $array }}\n    {{ . }}\n{{else}}\n    <!-- This is only evaluated if $array is empty -->\n{{ end }}\n// condition\n{{ with .Params.title }}\n    <h4>{{ . }}</h4>\n{{ end }}\n\n{{ with .Param \"description\" }}\n    {{ . }}\n{{ else }}\n    {{ .Summary }}\n{{ end }}\n\n{{ if (isset .Params \"description\") }}\n    {{ index .Params \"description\" }}\n{{ else }}\n    {{ .Summary }}\n{{ end }}\n\n{{ if (and (or (isset .Params \"title\") (isset .Params \"caption\")) (isset .Params \"attr\")) }}\n```\n\n## pipes\n\n```go\n\n{{ (seq 1 5) | shuffle }}\n{{ index .Params \"disqus_url\" | html }}\n```\n\n## context\n\nThe most easily overlooked concept to understand about Go Templates is that {{ . }} always refers to the current context.\n\nIn the top level of your template, this will be the data set made available to it.\nInside of an iteration, however, it will have the value of the current item in the loop; i.e., {{ . }} will no longer refer to the data available to the entire page.\n\n\n`$` to access global context\n```go\n<ul>\n{{ range .Params.tags }}\n  <li>\n    <a href=\"/tags/{{ . | urlize }}\">{{ . }}</a>\n            - {{ $.Site.Title }}\n  </li>\n{{ end }}\n</ul>\n```\n\n## whitespace\n\n```go\n<div>\n  {{- .Title -}}\n</div>\n\n<div>Hello, World!</div>\n```","n":0.062}}},{"i":98,"$":{"0":{"v":"Configeration_management","n":1},"1":{"v":"\n# CM\n\nThe software configuration management (SCM) process is looked upon by practitioners as the best solution to handling changes in software projects. It identifies the functional and physical attributes of software at various points in time, and performs systematic control of changes to the identified attributes for the purpose of maintaining software integrity and traceability throughout the software development life cycle.\n\nThe SCM process further defines the need to trace changes, and the ability to verify that the final delivered software has all of the planned enhancements that are supposed to be included in the release. It identifies four procedures that must be defined for each software project to ensure that a sound SCM process is implemented. They are:\n\nConfiguration identification\nConfiguration control\nConfiguration status accounting\nConfiguration audits\nThese terms and definitions change from standard to standard, but are essentially the same.\n\nConfiguration identification is the process of identifying the attributes that define every aspect of a configuration item. A configuration item is a product (hardware and/or software) that has an end-user purpose. These attributes are recorded in configuration documentation and baselined. Baselining an attribute forces formal configuration change control processes to be effected in the event that these attributes are changed.\nConfiguration change control is a set of processes and approval stages required to change a configuration item's attributes and to re-baseline them.\nConfiguration status accounting is the ability to record and report on the configuration baselines associated with each configuration item at any moment of time.\nConfiguration audits are broken into functional and physical configuration audits. They occur either at delivery or at the moment of effecting the change. A functional configuration audit ensures that functional and performance attributes of a configuration item are achieved, while a physical configuration audit ensures that a configuration item is installed in accordance with the requirements of its detailed design documentation.\n","n":0.058}}},{"i":99,"$":{"0":{"v":"Chef","n":1},"1":{"v":"\n# chef \n\n- 环境管理\n- 以自动化的方式进行服务器环境初始化或变更工作\n\n## environment\n\nChef环境由三个部分组成：Chef server，Workstation, Node（Client）。\n\nChef server是Chef环境的中枢，其中存储了基础设施环境的信息。你可以使用开源Chef server，也可以使用Chef官方提供的商业服务：Enterprise Chef。\n\nWorkstation是你的工作台，一般情况下就是你的开发机器。你会在Workstation中创建cookbook，并且上传到Chef server，以及其他与Chef相关的工作。\n\n一个Node就是你基础设施环境中的一台服务器，也就是你用Chef来管理的机器。\n\n一个Node可以是一台物理机器，一个虚拟机，也可以是cloud环境中的一个instance，甚至是你网络环境中的一个交换机或路由器。\n\n如果你想要在Node上部署环境，那么Node会与Chef server进行交互获取信息，并在Node上执行环境初始化操作。\n\n## recipe\n\n\n每个cookbook都会包含一到多个recipe（默认是default.rb）。一个recipe就是实现cookbook所描述场景的步骤。看以下这个简单的recipe：\n```\npackage 'apache2' do\n  action :install\nend\n\nservice 'apache2' do\n  action [ :enable, :start ]\nend\n\ncookbook_file '/var/www/index.html' do\n  source 'index.html'\n  mode '0644'\nend\n```\n\n可以看出这个recipe分为三个步骤，分别是安装apache2、启动apache2、拷贝文件。\n\n## resource和provider\n\nresource就是recipe中的配置项，可以是package、service、bash等等。provider就是为这些resource提供实现的程序。以编程语言来描述的话，resource定义了接口，provider提供了不同平台的实现。","n":0.177}}},{"i":100,"$":{"0":{"v":"Cicd","n":1},"1":{"v":"\nContinuous Integration and continuous Delivery (CI/CD) is a set of software practices and techniques that enable the frequent release of small batches of code changes, with extensive visibility and traceability. It typically involves the creation of a largely automated pipeline that orchestrates the build, test and deployment of software across staged environments, ultimately leading to deployment in production.\n\nCI\n\nDuring this process, developers identify bugs at early stages of the development cycle, fix them, and test in an iterative manner. Every time there is a new code change or a bug fix, the build or code compilation process takes place in the developer's private workspace. The developer then integrates the changes into the main code base. Depending on the size of the development team, these multiple builds could be running in parallel. Shorter build times lead to developer creativity that can breed innovation.\n\nCD\n\nAfter the build process and packaging in the CI phase, the final build package is automatically deployed for user acceptance testing before it is released to production. More and more modern applications are running as microservices and containers as the unit of deployment on a platform. The platforms could be any public-cloud environment or containers for platform-as-a-service like Red Hat OpenShift or Pivotal Cloud Foundry. As containers are portable, platform is synonymous with standard operating system like Red Hat, Ubuntu, and others, abstracting the cores and memory required at application run time\n\nContinuous Deployment - refers a system that allows deployment of every new changes that comes in source code from a developer.\nContinuous Delivery - refers the automation of entire software release process.\n\none example with github action [link](https://medium.com/@michaelekpang/creating-a-ci-cd-pipeline-using-github-actions-b65bb248edfe)\n\n## fb \n\n[video](https://www.youtube.com/watch?v=qN6BiLzZGfs)","n":0.061}}},{"i":101,"$":{"0":{"v":"Chef","n":1},"1":{"v":"\nChef is a powerful automation platform that transforms infrastructure into code. Chef is a tool for which you write scripts that are used to automate processes.\n\nChef Server: The Chef Server is the central store of your infrastructure’s configuration data. The Chef Server stores the data necessary to configure your nodes and provides search, a powerful tool that allows you to dynamically drive node configuration based on data.\nChef Node: A Node is any host that is configured using Chef-client. Chef-client runs on your nodes, contacting the Chef Server for the information necessary to configure the node. Since a Node is a machine that runs the Chef-client software, nodes are sometimes referred to as “clients”.\nChef Workstation: A Chef Workstation is the host you use to modify your cookbooks and other configuration data.","n":0.088}}},{"i":102,"$":{"0":{"v":"Bash","n":1},"1":{"v":"\n# key\n\n- ctrl-a:  go to begin of line\n- ctrl-w: 删除前一个单词\n- ctrl-u: 删至行首\n- Option + Left Arrow – to move the cursor backward by a word. \n- Option + Right arrow – to move the cursor forward by a word.","n":0.16}}},{"i":103,"$":{"0":{"v":"Alfred","n":1},"1":{"v":"\n# alfred workflow\n\n\n- Triggers: Activate Alfred from a hotkey, another Alfred feature or an external source.\n- Inputs: Keyword-based objects used to perform an action, on its own or followed by a query.\n- Actions: The objects that do most of the work in your workflows; opening or revealing files and web searches, running scripts and performing commands.\n- Utilities: Utilities give you control over how your objects are connected together and how the arguments output by the previous object is passed on to the next object.\n- Outputs: Collect the information from the earlier objects in your workflow to pop up a Notification Centre message, show output in Large Type, copy to clipboard or run a script containing the result of your workflow.\n\n\n## script filter format in workflow\n\nwe need to return a json like this\n\n```\n{\n    \"items\":[\n        {\n            \"title\":xxx,\n            \"subtitle\":xxx,\n            \"arg\":\"https://xxx\"\n            \"icon\":\"xxx\"\n        }\n    ]\n}\n```\n\n## short key\n\n- option+command+c clipboard history","n":0.083}}},{"i":104,"$":{"0":{"v":"System","n":1}}},{"i":105,"$":{"0":{"v":"Virtualization","n":1},"1":{"v":"\n# VM\n\nVirtual machines are based on computer architectures and provide functionality of a physical computer. Their implementations may involve specialized hardware, software, or a combination.\n\n- System virtual machines (also termed full virtualization VMs) provide a substitute for a real machine. They provide functionality needed to execute entire operating systems. A **hypervisor** uses native execution to share and manage hardware, allowing for multiple environments which are **isolated** from one another, yet exist on the same physical machine. Modern hypervisors use hardware-assisted virtualization, virtualization-specific hardware, primarily from the host CPUs.\n- Process virtual machines are designed to execute computer programs in a platform-independent environment. A process VM provides a high-level abstraction – that of a high-level programming language (compared to the low-level ISA abstraction of the system VM). Process VMs are implemented using an interpreter; performance comparable to compiled programming languages can be achieved by the use of just-in-time compilation. JVM\n- Operating-system-level virtualization: docker.  physical server is virtualized at the operating system level, enabling multiple isolated and secure virtualized servers to run on a single physical server. The \"guest\" operating system environments share the same running instance of the operating system as the host system. Thus, the same operating system kernel is also used to implement the \"guest\" environments, and applications running in a given \"guest\" environment view it as a stand-alone system\n\nThe hypervisor sits in between the physical machine and virtual machines and provides virtualization services to the virtual machines. \n\n## How does virtualization work?\n\nSoftware called hypervisors separate the physical resources from the virtual environments—the things that need those resources. Hypervisors take your physical resources and divide them up so that virtual environments can use them.\n\n![](/assets/images/2021-05-03-15-30-39.png)\n\nResources are partitioned as needed from the physical environment to the many virtual environments. Users interact with and run computations within the virtual environment (typically called a guest machine or virtual machine). The virtual machine functions as a single data file. And like any digital file, it can be moved from one computer to another, opened in either one, and be expected to work the same.\n\nWhen the virtual environment is running and a user or program issues an instruction that requires additional resources from the physical environment, the hypervisor relays the request to the physical system and caches the changes—which all happens at close to native speed (particularly if the request is sent through an open source hypervisor based on KVM, the Kernel-based Virtual Machine).\n","n":0.05}}},{"i":106,"$":{"0":{"v":"Containerization","n":1},"1":{"v":"\n# containerization\n\ncode developed on one machine might not work perfectly fine on any other machine because of the dependencies. This problem was solved by the containerization concept. So basically, an application that is being developed and deployed is bundled and wrapped together with all its configuration files and dependencies. This bundle is called a container. Now when you wish to run the application on another system, the container is deployed which will give a bug-free environment as all the dependencies and libraries are wrapped together. Most famous containerization environments are Docker and Kubernetes.\n\n## difference between virtualization\n\nContainers provide an isolated environment for running the application. The entire user space is explicitly dedicated to the application. Any changes made inside the container is never reflected on the host or even other containers running on the same host. Containers are an abstraction of the application layer. Each container is a different application.\n\nWhereas in Virtualization, hypervisors provide an entire virtual machine to the guest(including Kernal). Virtual machines are an abstraction of the hardware layer. Each VM is a physical machine.\n\n![](/assets/images/2021-05-04-23-12-48.png)\n\n## docker\n\nDocker is a containerization platform which packages your application and all its dependencies together in the form of containers so as to ensure that your application works seamlessly in any environment, be it development, test or production. Docker containers, wrap a piece of software in a complete filesystem that contains everything needed to run: code, runtime, system tools, system libraries, etc. It wraps basically anything that can be installed on a server. This guarantees that the software will always run the same, regardless of its environment.\n\nDocker image is the source of Docker container. In other words, Docker images are used to create containers. When a user runs a Docker image, an instance of a container is created. These docker images can be deployed to any Docker environment.\n\nDocker Architecture consists of a Docker Engine which is a client-server application with three major components:\n\n- A server which is a type of long-running program called a daemon process (the docker command).\n- A REST API which specifies interfaces that programs can use to talk to the daemon and instruct it what to do.\n- A command line interface (CLI) client (the docker command).\n- The CLI uses the Docker REST API to control or interact with the Docker daemon through scripting or direct CLI commands. Many other Docker applications use the underlying API and CLI.\n\n\n![](/assets/images/2021-05-04-23-13-20.png)\n\nDocker can build images automatically by reading the instructions from a file called Dockerfile. A Dockerfile is a text document that contains all the commands a user could call on the command line to assemble an image. Using docker build, users can create an automated build that executes several command-line instructions in succession.\n\nDocker Compose is a YAML file which contains details about the services, networks, and volumes for setting up the Docker application. So, you can use Docker Compose to create separate containers, host them and get them to communicate with each other. Each container will expose a port for communicating with other containers.\n\nDocker Swarm is native clustering for Docker. It turns a pool of Docker hosts into a single, virtual Docker host. Docker Swarm serves the standard Docker API, any tool that already communicates with a Docker daemon can use Swarm to transparently scale to multiple hosts.\n\n### namespace\n\nA namespace is one of the Linux features and an important concept of containers. Namespace adds a layer of isolation in containers. Docker provides various namespaces in order to stay portable and not affect the underlying host system. Few namespace types supported by Docker – PID, Mount, IPC, User, Network\n\n### interview question\n\nWill you lose your data, when a docker container exists?\nNo, you won’t lose any data when Docker container exits. Any data that your application writes to the container gets preserved on the disk until you explicitly delete the container. The file system for the container persists even after the container halts.\n\nWhere all do you think Docker is being used?\n\nWhen asked such a question, respond by talking about applications of Docker. Docker is being used in the following areas:\n\nSimplifying configuration: Docker lets you put your environment and configuration into code and deploy it.\nCode Pipeline Management: There are different systems used for development and production. As the code travels from development to testing to production, it goes through a difference in the environment. Docker helps in maintaining the code pipeline consistency.\nDeveloper Productivity: Using Docker for development gives us two things – We’re closer to production and development environment is built faster.\nApplication Isolation: As containers are applications wrapped together with all dependencies, your apps are isolated. They can work by themselves on any hardware that supports Docker.\nDebugging Capabilities: Docker supports various debugging tools that are not specific to containers but work well with containers.\nMulti-tenancy: Docker lets you have multi-tenant applications avoiding redundancy in your codes and deployments.\nRapid Deployment: Docker eliminates the need to boost an entire OS from scratch, reducing the deployment time.\n\n\nIs it a good practice to run stateful applications on Docker?\nThe concept behind stateful applications is that they store their data onto the local file system. You need to decide to move the application to another machine, retrieving data becomes painful. I honestly would not prefer running stateful applications on Docker.\n\n What changes are expected in your docker compose file while moving it to production?\nThese are the following changes you need make to your compose file before migrating your application to the production environment:\n\nRemove volume bindings, so the code stays inside the container and cannot be changed from outside the container.\nBinding to different ports on the host.\nSpecify a restart policy\nAdd extra services like log aggregator\n\n## Kubernetes\n\nKubernetes is an open-source container management (orchestration) tool. It’s container management responsibilities include container deployment, scaling & descaling of containers & container load balancing.\n\n[reference](https://www.edureka.co/blog/what-is-kubernetes-container-orchestration)\n\n![](/assets/images/2021-05-04-23-30-50.png)","n":0.032}}},{"i":107,"$":{"0":{"v":"Understand","n":1},"1":{"v":"\n# templeate to understand the service\n\n## service context\n\n1. what does the system do\n2. who is the customer, what is their primary use case?\n3. what is the user flow for the primary use case\n4. how is the customer impacted when the system is degraded\n5. what service level objectives have set in order to achieve the desired customer experience\n6. what service level indicators do we use to measure teh experience we want to deliver\n\n## pre-game checklist\n\nbefore blueprint phase\n\n1. toolbox\n   1. runbooks\n   2. pagerduty service\n   3. datadog dashboards\n2. complete the service context\n3. verify the test environment is healthy\n4. prepare and validate load generation test\n5. prepare failure injection with Gremlin\n\n\n## gameday\n\n- roles and responsibility\n  - gameday coordinator\n  - oncall / triage engineers\n  - attendees (observe and validate the situation)\n","n":0.089}}},{"i":108,"$":{"0":{"v":"Scalability","n":1},"1":{"v":"\n# Scalability\n\ndescribe a system’s ability to cope with increased load.\n\n## Load\n\nLoad can be described with a few numbers which we call load parameters\n\nThe best choice of parameters depends on the architecture of your system\n\n## Performance\n\n- When you increase a load parameter and keep the system resources (CPU, memory, network bandwidth, etc.) unchanged, how is the performance of your system affected?\n- When you increase a load parameter, how much do you need to increase the resources if you want to keep performance unchanged?\n\n- throughput (the number of records we can process per second)\n- response time (the time between a client sending a request and receiving a response.)\n\n## scale\n\n- scaling up (**vertical scaling**, moving to a more powerful machine) \n- scaling out (**horizontal scaling**, distributing the load across multiple smaller machines).","n":0.088}}},{"i":109,"$":{"0":{"v":"Reliability","n":1},"1":{"v":"\n# Reliability\n\n- continue to work correctly\n- fault tolerate\n\n\n## Hardware faults\n\n- add redundancy\n  - Disks may be set up in a RAID configuration\n  - servers may have dual power supplies and hot-swappable CPUs\n  - datacenters may have batteries and diesel generators for backup power.\n  - When one component dies, the redundant component can take its place while the broken component is replaced.\n\n## Software errors\n\nbug, process uses up resources, service depends on slow down, cascading failures\n\n- carefully thinking about assumptions and interactions in the system\n- thorough testing, process isolation\n- allowing processes to crash and restart\n- measuring, monitoring and analyzing system behavior in production\n\n\n## human errors\n\nhumans are known to be unreliable.\n\nDesign systems in a way that minimizes opportunities for error.\n\nDecouple the places where people make the most mistakes from the places where they can cause failures. In particular, provide fully featured non-production sandbox environments where people can explore and experiment safely, using real data, without affecting real users.\n\nAllow quick and easy recovery from human errors, to minimize the impact in the case of a failure.","n":0.076}}},{"i":110,"$":{"0":{"v":"Performance","n":1},"1":{"v":"\n![](/assets/images/2021-05-03-16-22-48.png)\n[reference](http://www.brendangregg.com/linuxperf.html)\n\n## 1. uptime\n\n```\n$ uptime \n23:51:26 up 21:31, 1 user, load average: 30.02, 26.43, 19.02\n```\n\nThis is a quick way to view the load averages, which indicate the number of tasks (processes) wanting to run. On Linux systems, these numbers include processes wanting to run on CPU, as well as processes blocked in uninterruptible I/O (usually disk I/O). This gives a high level idea of resource load (or demand), but can’t be properly understood without other tools. Worth a quick look only.\nThe **three numbers are exponentially damped moving sum averages with a 1 minute, 5 minute, and 15 minute constant**. The three numbers give us some idea of how load is changing over time. For example, if you’ve been asked to check a problem server, and the 1 minute value is much lower than the 15 minute value, then you might have logged in too late and missed the issue.\nIn the example above, the load averages show a recent increase, hitting 30 for the 1 minute value, compared to 19 for the 15 minute value. That the numbers are this large means a lot of something: probably CPU demand; vmstat or mpstat will confirm, which are commands 3 and 4 in this sequence.\n\n## 2. dmesg | tail\n\n```\n$ dmesg | tail\n[1880957.563150] perl invoked oom-killer: gfp_mask=0x280da, order=0, oom_score_adj=0\n[...]\n[1880957.563400] Out of memory: Kill process 18694 (perl) score 246 or sacrifice child\n[1880957.563408] Killed process 18694 (perl) total-vm:1972392kB, anon-rss:1953348kB, file-rss:0kB\n[2320864.954447] TCP: Possible SYN flooding on port 7001. Dropping request.  Check SNMP counters.\n```\n\nThis views the last 10 system messages, if there are any. **Look for errors that can cause performance issues**. The example above includes the oom-killer, and TCP dropping a request.\nDon’t miss this step! dmesg is always worth checking.\n\nkernel会将开机信息存储在ring buffer中.您若是开机时来不及查看信息，可利用dmesg来查看。开机信息亦保存在/var/log目录中，名称为dmesg的文件里。\n\n\n\n## 3. vmstat 1\n\n```\n$ vmstat 1\nprocs ---------memory---------- ---swap-- -----io---- -system-- ------cpu-----\n r  b swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st\n34  0    0 200889792  73708 591828    0    0     0     5    6   10 96  1  3  0  0\n32  0    0 200889920  73708 591860    0    0     0   592 13284 4282 98  1  1  0  0\n32  0    0 200890112  73708 591860    0    0     0     0 9501 2154 99  1  0  0  0\n32  0    0 200889568  73712 591856    0    0     0    48 11900 2459 99  0  0  0  0\n32  0    0 200890208  73712 591860    0    0     0     0 15898 4840 98  1  1  0  0\n```\n\nShort for virtual memory stat, vmstat(8) is a commonly available tool (first created for BSD decades ago). It prints a summary of key server statistics on each line.\n\nvmstat was run with an argument of 1, **to print one second summaries**. The first line of output (in this version of vmstat) has some columns that show the average since boot, instead of the previous second. For now, skip the first line, unless you want to learn and remember which column is which.\nColumns to check:\nr: **Number of processes running on CPU and waiting for a turn.** This provides a better signal than load averages for determining CPU saturation, as it does not include I/O. To interpret: an “r” value greater than the CPU count is saturation.\nfree: **Free memory in kilobytes.** If there are too many digits to count, you have enough free memory. The “free -m” command, included as command 7, better explains the state of free memory.\nsi, so: Swap-ins and swap-outs. **If these are non-zero, you’re out of memory**.\nus, sy, id, wa, st: These are breakdowns of CPU time, on average across all CPUs. **They are user time, system time (kernel), idle, wait I/O, and stolen time** (by other guests, or with Xen, the guest’s own isolated driver domain).\nThe CPU time breakdowns will confirm if the CPUs are busy, by adding user + system time. A constant degree of wait I/O points to a disk bottleneck; this is where the CPUs are idle, because tasks are blocked waiting for pending disk I/O. You can treat wait I/O as another form of CPU idle, one that gives a clue as to why they are idle.\nSystem time is necessary for I/O processing. A high system time average, over 20%, can be interesting to explore further: perhaps the kernel is processing the I/O inefficiently.\nIn the above example, CPU time is almost entirely in user-level, pointing to application level usage instead. The CPUs are also well over 90% utilized on average. This isn’t necessarily a problem; check for the degree of saturation using the “r” column.\n\n## 4. mpstat -P ALL 1\n\n```\n$ mpstat -P ALL 1\nLinux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015  _x86_64_ (32 CPU)\n\n07:38:49 PM  CPU   %usr  %nice   %sys %iowait   %irq  %soft  %steal  %guest  %gnice  %idle\n07:38:50 PM  all  98.47   0.00   0.75    0.00   0.00   0.00    0.00    0.00    0.00   0.78\n07:38:50 PM    0  96.04   0.00   2.97    0.00   0.00   0.00    0.00    0.00    0.00   0.99\n07:38:50 PM    1  97.00   0.00   1.00    0.00   0.00   0.00    0.00    0.00    0.00   2.00\n07:38:50 PM    2  98.00   0.00   1.00    0.00   0.00   0.00    0.00    0.00    0.00   1.00\n07:38:50 PM    3  96.97   0.00   0.00    0.00   0.00   0.00    0.00    0.00    0.00   3.03\n[...]\n```\n\nThis command prints CPU time breakdowns per CPU, which can be used to **check for an imbalance**. A single hot CPU can be evidence of a single-threaded application.\n\n## 5. pidstat 1\n\n```\n$ pidstat 1\nLinux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015    _x86_64_    (32 CPU)\n\n07:41:02 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command\n07:41:03 PM     0         9    0.00    0.94    0.00    0.94     1  rcuos/0\n07:41:03 PM     0      4214    5.66    5.66    0.00   11.32    15  mesos-slave\n07:41:03 PM     0      4354    0.94    0.94    0.00    1.89     8  java\n07:41:03 PM     0      6521 1596.23    1.89    0.00 1598.11    27  java\n07:41:03 PM     0      6564 1571.70    7.55    0.00 1579.25    28  java\n07:41:03 PM 60004     60154    0.94    4.72    0.00    5.66     9  pidstat\n\n07:41:03 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command\n07:41:04 PM     0      4214    6.00    2.00    0.00    8.00    15  mesos-slave\n07:41:04 PM     0      6521 1590.00    1.00    0.00 1591.00    27  java\n07:41:04 PM     0      6564 1573.00   10.00    0.00 1583.00    28  java\n07:41:04 PM   108      6718    1.00    0.00    0.00    1.00     0  snmp-pass\n07:41:04 PM 60004     60154    1.00    4.00    0.00    5.00     9  pidstat\n```\n\nPidstat is a little like top’s per-process summary, but prints a rolling summary instead of clearing the screen. This can be useful for watching patterns over time, and also recording what you saw (copy-n-paste) into a record of your investigation.\nThe above example identifies two java processes as responsible for consuming CPU. The %CPU column is the total across all CPUs; 1591% shows that that java processes is consuming almost 16 CPUs.\n\n## 6. iostat -xz 1\n\n```\n$ iostat -xz 1\nLinux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015  _x86_64_ (32 CPU)\n\navg-cpu:  %user   %nice %system %iowait  %steal   %idle\n          73.96    0.00    3.73    0.03    0.06   22.21\n\nDevice:   rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util\nxvda        0.00     0.23    0.21    0.18     4.52     2.08    34.37     0.00    9.98   13.80    5.42   2.44   0.09\nxvdb        0.01     0.00    1.02    8.94   127.97   598.53   145.79     0.00    0.43    1.78    0.28   0.25   0.25\nxvdc        0.01     0.00    1.02    8.86   127.79   595.94   146.50     0.00    0.45    1.82    0.30   0.27   0.26\ndm-0        0.00     0.00    0.69    2.32    10.47    31.69    28.01     0.01    3.23    0.71    3.98   0.13   0.04\ndm-1        0.00     0.00    0.00    0.94     0.01     3.78     8.00     0.33  345.84    0.04  346.81   0.01   0.00\ndm-2        0.00     0.00    0.09    0.07     1.35     0.36    22.50     0.00    2.55    0.23    5.62   1.78   0.03\n[...]\n```\nThis is a great tool for understanding **block devices** (disks), both the workload applied and the resulting performance. Look for:\nr/s, w/s, rkB/s, wkB/s: These are the delivered reads, writes, read Kbytes, and write Kbytes per second to the device. Use these for workload characterization. **A performance problem may simply be due to an excessive load applied.**\nawait: The average time for the I/O in milliseconds. This is the time that the application suffers, as it includes both time queued and time being serviced. **Larger than expected average times can be an indicator of device saturation, or device problems.**\navgqu-sz: The average number of requests issued to the device. Values greater than 1 can be evidence of saturation (although devices can typically operate on requests in parallel, especially virtual devices which front multiple back-end disks.)\n%util: Device utilization. This is really a busy percent, showing the time each second that the device was doing work. Values greater than 60% typically lead to poor performance (which should be seen in await), although it depends on the device. Values close to 100% usually indicate saturation.\nIf the storage device is a logical disk device fronting many back-end disks, then 100% utilization may just mean that some I/O is being processed 100% of the time, however, the back-end disks may be far from saturated, and may be able to handle much more work.\nBear in mind that poor performing disk I/O isn’t necessarily an application issue. Many techniques are typically used to perform I/O asynchronously, so that the application doesn’t block and suffer the latency directly (e.g., read-ahead for reads, and buffering for writes).\n\n## 7. free -m\n\n```\n$ free -m\n             total       used       free     shared    buffers     cached\nMem:        245998      24545     221453         83         59        541\n-/+ buffers/cache:      23944     222053\nSwap:            0          0          0\n```\n\nThe right two columns show:\nbuffers: **For the buffer cache, used for block device I/O.**\ncached: **For the page cache, used by file systems**.\nWe just want to check that these aren’t near-zero in size, which can lead to higher disk I/O (confirm using iostat), and worse performance. The above example looks fine, with many Mbytes in each.\nThe “-/+ buffers/cache” provides less confusing values for used and free memory. Linux uses free memory for the caches, but can reclaim it quickly if applications need it. So in a way the cached memory should be included in the free memory column, which this line does. There’s even a website, linuxatemyram, about this confusion.\nIt can be additionally confusing if ZFS on Linux is used, as we do for some services, as ZFS has its own file system cache that isn’t reflected properly by the free -m columns. It can appear that the system is low on free memory, when that memory is in fact available for use from the ZFS cache as needed.\n\n## 8. sar -n DEV 1\n\n```\n$ sar -n DEV 1\nLinux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015     _x86_64_    (32 CPU)\n\n12:16:48 AM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s   %ifutil\n12:16:49 AM      eth0  18763.00   5032.00  20686.42    478.30      0.00      0.00      0.00      0.00\n12:16:49 AM        lo     14.00     14.00      1.36      1.36      0.00      0.00      0.00      0.00\n12:16:49 AM   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00\n\n12:16:49 AM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s   %ifutil\n12:16:50 AM      eth0  19763.00   5101.00  21999.10    482.56      0.00      0.00      0.00      0.00\n12:16:50 AM        lo     20.00     20.00      3.25      3.25      0.00      0.00      0.00      0.00\n12:16:50 AM   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00\n^C\n```\n\n\nUse this tool to check **network interface throughput**: rxkB/s and txkB/s, as a measure of workload, and also to check if any limit has been reached. In the above example, eth0 receive is reaching 22 Mbytes/s, which is 176 Mbits/sec (well under, say, a 1 Gbit/sec limit).\nThis version also has %ifutil for device utilization (max of both directions for full duplex), which is something we also use Brendan’s nicstat tool to measure. And like with nicstat, this is hard to get right, and seems to not be working in this example (0.00).\n\n## 9. sar -n TCP,ETCP 1\n\n```\n$ sar -n TCP,ETCP 1\nLinux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015    _x86_64_    (32 CPU)\n\n12:17:19 AM  active/s passive/s    iseg/s    oseg/s\n12:17:20 AM      1.00      0.00  10233.00  18846.00\n\n12:17:19 AM  atmptf/s  estres/s retrans/s isegerr/s   orsts/s\n12:17:20 AM      0.00      0.00      0.00      0.00      0.00\n\n12:17:20 AM  active/s passive/s    iseg/s    oseg/s\n12:17:21 AM      1.00      0.00   8359.00   6039.00\n\n12:17:20 AM  atmptf/s  estres/s retrans/s isegerr/s   orsts/s\n12:17:21 AM      0.00      0.00      0.00      0.00      0.00\n^C\n```\n\nThis is a summarized view of some key TCP metrics. These include:\nactive/s: Number of locally-initiated TCP connections per second (e.g., via connect()).\npassive/s: Number of remotely-initiated TCP connections per second (e.g., via accept()).\nretrans/s: Number of TCP retransmits per second.\nThe active and passive counts are often useful as a rough measure of server load: number of new accepted connections (passive), and number of downstream connections (active). It might help to think of active as outbound, and passive as inbound, but this isn’t strictly true (e.g., consider a localhost to localhost connection).\nRetransmits are a sign of a network or server issue; it may be an unreliable network (e.g., the public Internet), or it may be due a server being overloaded and dropping packets. The example above shows just one new TCP connection per-second.\n\n## 10. top\n\n```\n$ top\ntop - 00:15:40 up 21:56,  1 user,  load average: 31.09, 29.87, 29.92\nTasks: 871 total,   1 running, 868 sleeping,   0 stopped,   2 zombie\n%Cpu(s): 96.8 us,  0.4 sy,  0.0 ni,  2.7 id,  0.1 wa,  0.0 hi,  0.0 si,  0.0 st\nKiB Mem:  25190241+total, 24921688 used, 22698073+free,    60448 buffers\nKiB Swap:        0 total,        0 used,        0 free.   554208 cached Mem\n\n   PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND\n 20248 root      20   0  0.227t 0.012t  18748 S  3090  5.2  29812:58 java\n  4213 root      20   0 2722544  64640  44232 S  23.5  0.0 233:35.37 mesos-slave\n 66128 titancl+  20   0   24344   2332   1172 R   1.0  0.0   0:00.07 top\n  5235 root      20   0 38.227g 547004  49996 S   0.7  0.2   2:02.74 java\n  4299 root      20   0 20.015g 2.682g  16836 S   0.3  1.1  33:14.42 java\n     1 root      20   0   33620   2920   1496 S   0.0  0.0   0:03.82 init\n     2 root      20   0       0      0      0 S   0.0  0.0   0:00.02 kthreadd\n     3 root      20   0       0      0      0 S   0.0  0.0   0:05.35 ksoftirqd/0\n     5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0:0H\n     6 root      20   0       0      0      0 S   0.0  0.0   0:06.94 kworker/u256:0\n     8 root      20   0       0      0      0 S   0.0  0.0   2:38.05 rcu_sched\n```\n\nThe top command includes many of the metrics we checked earlier. It can be handy to run it to see if anything looks wildly different from the earlier commands, which would indicate that load is variable.\n\n\n## strace\n\n trace system calls and signals\n\n ## iotop","n":0.021}}},{"i":111,"$":{"0":{"v":"Monitor","n":1},"1":{"v":"\n# Monitor\n\n## work metrics\n\n- throughput:rps\n- success\n- error\n- performance: response time\n\n## resource metrics\n\n- utilization: percentage time that the resource is busy\n- saturation: measure of the amount of requested work that resource cannot yet service, often queued\n- errors: internal error that cannot observed in the resource produces\n- availability: represents the percentage of time that the resource responded to requests. This metric is only well-defined for resources that can be actively and regularly checked for availability.\n\n## event metrics\n\n- Changes: Internal code releases, builds, and build failures\n- Alerts: Internally generated alerts or third-party notifications\n- Scaling events: Adding or subtracting hosts","n":0.102}}},{"i":112,"$":{"0":{"v":"Maintainability","n":1},"1":{"v":"\n# Maintainability\n\n- Operability Make it easy for operations teams to keep the system running smoothly.\n- Simplicity Make it easy for new engineers to understand the system, by removing as much complexity as possible from the system. (Note this is not the same as simplicity of the user interface.) \n- Evolvability Make it easy for engineers to make changes to the system in the future, adapting it for unanticipated use cases as requirements change. Also known as extensibil‐ity, modifiability, or plasticity.\n\n\n## Operability\n\n- Monitoring the health of the system and quickly restoring service if it goes into a bad state \n- Tracking down the cause of problems, such as system failures or degraded per‐formance \n- Keeping software and platforms up to date, including security patches \n- Keeping tabs on how different systems affect each other, so that a problematic change can be avoided before it causes damage\n- Anticipating future problems and solving them before they occur (e.g., capacity planning) \n- Establishing good practices and tools for deployment, configuration manage‐ment, and more \n- Performing complex maintenance tasks, such as moving an application from one platform to another \n- Maintaining the security of the system as configuration changes are made \n- Defining processes that make operations predictable and help keep the produc‐tion environment stable \n- Preserving the organization’s knowledge about the system, even as individual people come and go\n\n\n- Providing visibility into the runtime behavior and internals of the system, with good monitoring \n- Providing good support for automation and integration with standard tools \n- Avoiding dependency on individual machines (allowing machines to be taken down for maintenance while the system as a whole continues running uninter‐rupted) \n- Providing good documentation and an easy-to-understand operational model (“If I do X, Y will happen”) \n- Providing good default behavior, but also giving administrators the freedom to override defaults when needed \n- Self-healing where appropriate, but also giving administrators manual control over the system state when needed \n- Exhibiting predictable behavior, minimizing surprises","n":0.055}}},{"i":113,"$":{"0":{"v":"File_system","n":1},"1":{"v":"\n[[Io|dendron://my_note/development.computer.io]]\n\nthe in-memory data structure vnode is just an inode cache that stores information about the file(typically inode stores in the disk) so that it can be accessed more quickly.\n\n![](/assets/images/2021-05-11-19-41-30.png)\n\n# file system\n\n![](/assets/images/2021-05-11-19-43-14.png)\n\n- The boot block occupies the beginning of a file system, typically the first sector, and may contain the bootstrap code that is read into the machine to boot, or initialize, the operating system. Although only one boot block is needed to boot the system, every file system has a (possibly empty) boot block.\n\n- The super block describes the state of a file system — how large it is, how many files it can store, where to find free space on the file system, and other information.\n\n- The mode list is a list of Modes that follows the super block in the file system. Administrators specify the size of the Mode list when configuring a file system. The kernel references Modes by index into the Mode list. One Mode is the root mode of the file system: it is the Mode by which the directory structure of the file system is accessible after execution of the mount system call (Section 5.14).\n\n- The data blocks start at the end of the Mode list and contain file data and administrative data. An allocated data block can belong to one and only one file in the file system.\n\n## inode\n\nModes exist in a static form on disk, and the kernel reads them into an in-core mode to manipulate them. Disk modes consist of the following fields\n\n- file owner identifier\n- file type\n- file access permission\n- access time, last modified, last accessed\n- number of links to the file\n- table of contents for the disk addresses of data in a file\n- file size\n- no path\n\n## STRUCTURE OF A REGULAR FILE\n\nthe Mode contains the table of contents to locate a file's data on disk. Since each block on a disk is addressable by number, the table of contents consists of a set of disk block numbers.\n\nFor greater flexibility, the kernel allocates file space one block at a time and allows the data in a file to be spread throughout the file system.\n\nTo access the data via the indirect block, the kernel must read the indirect block, find the appropriate direct block entry, and then read the direct block to find the data.\n\n![](/assets/images/2021-05-11-19-58-08.png)\n\n## directories\n\nA directory is a file whose data is a sequence of entries, each consisting of an mode number and the name of a file contained in the directory.\n\n![](/assets/images/2021-05-11-20-05-57.png)\n\n## ls\n\n```\n-rwxrw-r--    10    root   root 2048    Jan 13 07:11 afile.exe\n?UUUGGGOOOS   00  UUUUUU GGGGGG ####    ^-- date stamp and file name are obvious ;-)\n^ ^  ^  ^ ^    ^      ^      ^    ^\n| |  |  | |    |      |      |    \\--- File Size\n| |  |  | |    |      |      \\-------- Group Name (for example, Users, Administrators, etc)\n| |  |  | |    |      \\--------------- Owner Acct\n| |  |  | |    \\---------------------- Link count (what constitutes a \"link\" here varies)\n| |  |  | \\--------------------------- Alternative Access (blank means none defined, anything else varies)\n| \\--\\--\\----------------------------- Read, Write and Special access modes for [U]ser, [G]roup, and [O]thers (everyone else)\n\\------------------------------------- File type flag\n```\n\n## conversion of a path name to an innode\n\n![](/assets/images/2021-05-11-20-12-36.png)\n\nThe kernel does a linear search of the directory file associated with the working mode, trying to match the path name component to a directory entry name.\n\n","n":0.043}}},{"i":114,"$":{"0":{"v":"Concurrency","n":1},"1":{"v":"\n# 并发编程\n\n- 进程: 独立虚拟地址空间\n- i/o多路复用: 一个进程的上下文显示调度他们自己的逻辑流\n- 线程：运行在单一进程上下文的逻辑流，由内核控制\n\n## 进程\n\n- fork, exec, waitpid\n- 共享文件表，不共享用户地址空间，共享状态信息变得困难\n\n## I/O多路复用\n\n使用select函数，要求内核挂起进程，只有在一个或多个I/O事件发生后才将控制返回给应用程序。\n\n用作event-driven程序的基础。\n\n客户端池:\n\n- 优点：不需要切换上下文\n- 缺点：编码复杂\n\n## thread\n\n有自己的thread id, stack, PC, registers\n\n共享进程的整个虚拟地址空间。\n\n线程之间对等，无父子关系，切换上下文快。\n\npthread api\n\n- pthread_create\n- pthread_exit\n- pthread_join ：回收，阻塞，直到tid终止\n- pthread_detach: 不被其他回收，在终止时被系统回收\n\n- 共享变量\n  - 全局变量：任何线程都可以访问\n  - 本地自动变量：无static,只在自己的thread里\n  - 本地静态：线程共享，在vm里只有一个\n\n\n","n":0.171}}},{"i":115,"$":{"0":{"v":"Compute","n":1}}},{"i":116,"$":{"0":{"v":"Yarn","n":1},"1":{"v":"\n\n- YARN, which separates the resource management and processing components. The YARN-based architecture is not constrained to MapReduce.\n![](pic/yarn.jpg)\n- The **ResourceManager** tracks how many live nodes and resources are available on the cluster and coordinates what applications submitted by users should get these resources and when\n- **ApplicationMaster** is started to coordinate the execution of all tasks within the application.The ApplicationMaster and tasks that belong to its application run in resource containers controlled by the NodeManagers.\n- The **NodeManager** is a more generic and efficient version of the TaskTracker. The NodeManager has a number of dynamically created resource containers.\n\n## features\n\n- **Uberization** is the possibility to run all tasks of a MapReduce job in the ApplicationMaster's JVM if the job is small enough\n- Binary or source compatibility for MapReduce jobs written for MRv1\n- An application recovery after the restart of ResourceManager","n":0.085}}},{"i":117,"$":{"0":{"v":"Spark","n":1},"1":{"v":"\n\n- key point: efficient\n    - general execution graphs\n    - in-memory storage\n- Resilient Distributed Datasets\n    - Collections of objects spread across a cluster, stored in RAM or on disk\n    - build through parallel transformation\n    - automatically rebuild on failure \n    - It track lineage information that can be used to efficiently recompute lost data\n- DAG scheduler(Directed Acyclic Graph)\n    - job: one action for RDD\n    - stage: split in shuffle for job\n    - task: real task in executor\n    - DAG in Apache Spark is a set of Vertices and Edges, where vertices represent the RDDs and the edges represent the Operation to be applied on RDD.\n    - know the dependency for different RDD\n    - In this way, the execution plan is optimized, e.g. to minimize shuffling data around. \n    - ![](https://img-blog.csdn.net/20170427180924863?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTU2NDE3Mg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)","n":0.088}}},{"i":118,"$":{"0":{"v":"Mapreduce","n":1},"1":{"v":"\nMapReduce is a programming model for processing large amounts of data in bulk across many machines\n\nThe map and reduce functions are somewhat restricted in what they are allowed to do. They must be pure functions, which means they only use the data that is passed to them as input, they cannot perform additional database queries, and they must not have any side effects.\n\n- **what**: do parellel in map phase, do merge sort in sort, do linear in reducer\n- **why**: quick in map, slow in reduce\n- **how**: could do select, filter, min,max,sum, no avg, join is not a good operation in mapreduce, only in reduce phase.\n- sort:\n    - search in the final result\n    - mapper yield duplicated key and we need use sort to group them in one reducer \n- **problem**\n    - A single **master** process called **JobTracker**, which **coordinates** all jobs running on the cluster and **assigns** map and reduce tasks to run on the TaskTrackers\n    - A number of subordinate processes called **TaskTrackers**, which run assigned tasks and periodically report the progress to the JobTracker\n    - Hadoop was designed to run MapReduce jobs only\n    - more maps means more overhead for master to keep track of the state of computation\n    - fewer map-reduce phase","n":0.07}}},{"i":119,"$":{"0":{"v":"Container","n":1},"1":{"v":"\n\n# VM and containers\n\n- **what**: a virtualized system is a **mapping** of its interface, and all resources visible through that interface, to the interface and resources of a real system.\n- **why**: \n    - provide a way of relaxing constrains and increasing flexibility\n    - advantages\n        - multiple secure environment: system VM provides a sandbox isolates one system environment from others\n        - failure isolation\n        - mixed-os environment: one hardware support multiple OS concurrently\n        - better System Utilization: can be dynamically or statically re-configured for changing needs\n    - properties:\n        - isolation: fault, software, performance(done by scheduling)\n        - encapsulation: all VM state could be captured in a file\n        - interposition: all guest actions could be inspect, modify and deny\n- **how**: abstraction. provide a simplified interface to underlying resources. virtualization provides a different interface at the same level of abstraction.\n    - hypervisor: a co-designed firmware-software layer,use this layer to manage the virtual machines\n    - full virtualization: provide same function as the underlying physical hardware. Allow unmodified OS to execute on VM\n    - para-virtualization: provide similar function, and modify OS to cooperate with VMM. Get lower overhead and better performance.\n    - Emulation: implement same function with different intereface and functionality\n    - system VM: vmare, process VM: jvm\n    - multiprocessor system: partition(subset of the resources)-> in space(physical), in time(logical)\n    - in DS:\n        - abstract environment from resources\n        - abstract application from environment\n        - different environment no affect users\n        - migration\n        - scaling\n        - protection\n        - sharing\n\n## Containers\n\n- share part of OS\n- provide independent\n- resource share.  secure problem\n- less isolation\n\n\n# Tupperware \n\n![](/assets/images/2021-05-10-22-59-20.png)\n\n![](/assets/images/2021-05-10-23-00-53.png)\n\nresource broker for source of truth for machine info. One instance of Resource Broker (RB) is deployed to each DC. RB records whether a machine in the DC is free or assigned to an entitlement\n\n![](/assets/images/2021-05-10-23-06-16.png)\n\n![](/assets/images/2021-05-11-20-32-16.png)\n\nFigure 4 shows an overview of Twine. The Capacity Portal allows users to request or modify entitlements, which associate capacity quotas with business units deﬁned in the service accounting hierarchy. With a granted entitlement, a user deploys jobs through the front end. The scheduler manages job and task lifecycle, e.g., orchestrating a job’s software release. If a job has a TaskController, the scheduler coordinates with the TaskController to make decisions, e.g., delaying a task restart to rebuild a lost data replica ﬁrst. The allocator assigns machines to entitlements and assigns tasks to machines. ReBalancer runs asynchronously and continuously to improve the allocator’s decisions, e.g., better balancing the utilization of CPU, power, and network. Resource Broker (RB) stores machine information and unavailability events that track hardware failures and planned maintenance. DC operators schedule planned maintenance through Ops Planner. The Health Check Service (HCS) monitors machines and updates their status in RB. The agent runs on every machine to manage tasks. Sidekick switches host proﬁles as needed. Service Resource Manager (SRM) autoscales jobs in response to load changes. Conveyor is our continuous delivery system.\n\n[reference](https://www.usenix.org/system/files/osdi20-tang.pdf)","n":0.046}}},{"i":120,"$":{"0":{"v":"Code_deployment","n":1},"1":{"v":"\n# continous www push\n\n- Check out trunk\t--\t<0:01\tcheck out the most current trunk revision in WWW. \n- Build\t<0:01\t0:35\tOnce we have a version locked in, we kick off an asynchronous test run, and start doing a build. A build in this context is taking the PHP files in the repo and turning it into packages that we will actually ship to web servers. This can fail in many ways, from Hack failures, to static resources errors, to other random stuff.\n- Test\t0:10\t0:15\tThe actual work here usually finishes while the build step is running. If any test failed, we consider the step failed.\n- Try Acquiring Deploy Lock\t0:35\t<0:01\tWe don't want to push if someone hit the stop button, nor do we want multiple pushes back to back to back, so if any build is currently beyond this step (pushing or waiting), we'll mark the push phases as SKIPPED and end the push instance.\n- Push Trunkstable/c1\t0:35\t0:20\tThis basically does a twdeploy push_job which will push trunkstable. See the Tupperware UI for a list of these jobs. We do this rollout in a staged fashion. Each individual server is down for under 5 minutes.\n- Push C2\t1:10\t0:30\tNow we'll do tupperware push_job to push these jobs. This will be hit by 1% (soon 2%) of users, so we have a system called Presholds which may pause the push if some metrics look bad enough (logspew, fatals, latency, servers not coming back up). If enough jobs get paused in this way, we'll revert c2 and fail the push.\n- Verify C2\t1:40\t0:25\tNow we wait again. This time we want employees and alerts to have a chance to notice c2 is broken. At the end of this 15 minute window we check for any alerts with the `blocks_c3_push` tag. If any are found we'll fail the job.\n- Push C3\t1:50\t0:30\tThis behaves exactly like pushing c2, it also has presholds. Naturally there are different Tupperware jobs.\n- Done\t2:20\t--\tOnce this finishes, we're done and another build can try and grab the deploy lock!","n":0.055}}},{"i":121,"$":{"0":{"v":"Processing","n":1}}},{"i":122,"$":{"0":{"v":"Pe_domain","n":1},"1":{"v":"\n# Monitoring\n\n# Logging \n\n# Alerting\n\n# Automation","n":0.408}}},{"i":123,"$":{"0":{"v":"Libra","n":1},"1":{"v":"\n# libra production\n\nstep 1: \n\n- single docker image + deploy on AWS ECS\n- pre-generated key\n- run majority\n\nstep 2:\n\n- better isolation between components\n- tooling support\n- moved to Kubernetes\n- run multiple cloud\n- minimum validator architecture\n\n![](/assets/images/2021-04-21-09-59-53.png)\n\nstep 3:\n\n- security enhancement\n  - store keys in vault\n- production deployment\n  - isolating the validator network\n  - provide public access\n\n![](/assets/images/2021-04-21-10-08-06.png)\n\nstep 4:\n\n- tooling support\n- support backup and restore\n- operational readiness\n\n\nstep 5:\n\n- storm, DR\n- runbook\n- training\n- falut tolerance policy\n- support diversity deployment","n":0.118}}},{"i":124,"$":{"0":{"v":"Network","n":1},"1":{"v":"\n# OSI\n\n- [[Application|development.network.applicationlayer]]\n- Presentation\n- Session\n- [[Transport|development.network.transportlayer]]\n- [[Netwrok|development.network.networklayer]]\n- [[Link|development.network.linklayer]]\n- [[Pysical|development.network.physicallayer]]\n\n![](/assets/images/2021-05-14-09-29-00.png)\n\n# network type\n\n- circuit switching\n  - dedicated circuit per call, no sharing, setup required\n  - network bandwidth divided into pieces: FDM, TDM\n- packet switching\n  - each packet use full bandwidth\n  - move hop-at-a-time, get complete packet before forwarding\n  - statistical multiplexing\n  - store-and-forward.\n  - L bits, R bps throughput, take L/R seconds to transmit","n":0.127}}},{"i":125,"$":{"0":{"v":"Transportlayer","n":1},"1":{"v":"\n# transport layer\n\ntcp/udp\n\n- end-to-end, broke whole messages to segments\n- connection-oriented service: reliable delivery, error detection, congestion control, flow control\n- connectionless service: best effort delivery\n\n\n![](/assets/images/2021-03-25-16-41-46.png)\n\n- mission: **Logical** connection, between applications running on different hosts\n- Logical communication = as if the applications were directly connected\n    - scope: between applications\n    - addressing mechanism: multiplex, port numbers bound to an application, 16-bit unsigned number\n    - data types: segment\n- responsibilities: \n    - **multiplex** messages/de..  end host run **mulitple** applications -> addressing\n    - break data to segments and re-assembly\n        - segmentation, broken into segments\n    - connection setup and state management and tear down\n    - TCP: reliability guarantee\n    - Transport layer adds header with additional information (port numbers, ...)\n  \n","n":0.094}}},{"i":126,"$":{"0":{"v":"Udp","n":1},"1":{"v":"\n# udp\n\n- advantages/disadvantages\n    - adv:\n        - connectionless: no connection establishment, thus no additional delay\n        - fast: no handshake\n        - each segment handled independently\n        - Very simple: no state to maintain\n        - Segment header is small\n    - dis\n        - segments may be lost\n        - may out-of-order\n        - no congestion control\n        - There are no guarantees with UDP.\n- segment format\n    - source port, dest port, length(**whole segment** at least 8 byte(header size)), checksum, application data\n- reliability assumptions\n    - Often used for **streaming** multimedia apps \n    - Loss tolerant\n    - **Rate sensitive** (timeliness)\n    - Reliability can be added at app layer\n\n\n","n":0.101}}},{"i":127,"$":{"0":{"v":"Tcp","n":1},"1":{"v":"\n# TCP\n\n- point-to-point / reliable / in-order byte stream / pipelined: sliding windows\n- full duplex data: bi-directional data flow\n- connection-oriented: handshaking (exchange of control messages) initializes sender & receiver state before data exchange\n- Both sides have buffers\n- Flow Control\n- Congestion Control\n\n## connection and tear down\n\n- establish: setup state before exchanging data segements\n  - step1: send SYN segment and specifies initial seq#, no data\n  - why random sn? an earlier incarnation of the same connection can interfere with a later one\n  - step2: server respond with SYNACK segment, allocates buffers and specifies initial seq#\n  - step3: replies with ACK, may contain data\n  - if host receive with SYN to a closed port, responds with a RST segments \n- teardown: free up state \n  - step1: send TCP FIN to server\n  - step2: server responds with ACK and closed, send FIN\n  - step3: client receives FIN, replies with ACK , wait \n  - why? possible ACK lost\n  - Client may open the same connection again (same pair of port #s) \n  - then Receives FIN from earlier incarnation of connection\n  - so Immediately initiate closing of the later incarnation\n  - Step 4: server receives ACK, closes connection\n\n\n## RDT\n\n  - TCP creates RDT service on top of IP’s unreliable service\n    - Pipelined segments \n    - Cumulative acks\n    - Retransmission timer\n  - Retransmissions are triggered by:\n    - timeout events \n    - duplicate acks\n  - Initially, we consider simplified TCP sender:\n    - ignore duplicate acks\n    - ignore flow control, congestion control\n    - assume RTT is estimated somehow\n  - SN : byte stream “number” of first byte in segment’s data\n  - ACKs: seq # of next byte expected from other side\n    - **cumulative** ACK: acknowledges bytes up to the first missing byte in the stream\n  - Data received from app:\n    - Create segment\n    - seq# is byte-stream number of first data byte in segment\n    - Send, if allowed by congestion & flow-control\n    - start timer if not already running (think of timer as for oldest unacked segment)\n    - expiration interval: TimeOutInterva\n  -  Timeout:\n    -  retransmit segment that caused timeout\n    -  restart timer\n  - ACK received:\n    -  If acknowledges previously unACKed segments\n    -  update what is known to be ACKed\n    -  start timer if there are outstanding segments\n  - fast retransmit\n    - If segment is lost, there will likely be many duplicate ACKs\n    - If sender receives 3 duplicate ACKs, it supposes that segment after ACKed data was lost: resend segment before timer expires： voodoo constant\n\n![[development.network.reliable_data_transfer]]\n## Flow control\n\n- mission: Sender won’t overflow the **receiver’s buffer** by transmitting too much, too fast\n  - matching the send rate to the receiving app’s drain rate\n  - operation:\n- mechanism\n    - RcvWindow = RcvBuffer - [ LastByteRcvd - LastByteRead ] (assume discard out of order)\n    - Receiver advertises spare room by including value of RcvWindow in ACK segment\n    - Gives sender permission to send this much\n\n- congwin: how much data allowed in-flight at any time, >= LastByteSent-LastByteAcked\n    - **rate = congwin/RTT**\n- sender perceive congestion: timeout / 3 duplicate ACKs\n- self-clocking nature: use ACK to trigger its increase in congestion window size\n- interaction of various phases \n  - When CongWin is below Threshold, window grows exponentially (slow-start phase)\n  - When CongWin is above Threshold, window grows linearly (congestion-avoidance phase)\n  - When a triple duplicate ACK occurs, Threshold set to CongWin/2 and CongWin set to Threshold. Window grows linearly\n  - When timeout occurs, Threshold set to CongWin/2 and CongWin is set to 1 MSS. Enters slow-start phase\n- slow start\n  - start with MSS = 1, increase exponentially, done by increasing CongWin by 1MSS for every ACK received\n  - With Slow Start, no bandwidth wasted on retransmission\n  - end: first lost event\n- congestion avoidance\n    - start: first lost event\n        - cut CongWin in half after a loss event\n        - Continue probing for usable bandwidth\n    - Reno: after 3 dup, cancel slow start, cut half CongWin, grows linearly\n        - after timeout, set ssthrehold to half, skip ss, fast recovery.\n        - fast retransmit:  after 3 dup\n    - Tahoe: after loss event, congwin set to 1, enter slow start\n- how TCP sets timeout values.\n    - longer than RTT. \n    - too short, premature timeout, unnecessary retransmissions\n    - too long, slow reaction to segment loss\n    - need to measure RTT for baseline\n\n","n":0.038}}},{"i":128,"$":{"0":{"v":"Transit","n":1},"1":{"v":"\n## Peering\n\n![](/assets/images/2021-03-25-16-50-29.png)\n\n![](/assets/images/2021-03-25-16-52-09.png)\n\n## FNA\n\n![](/assets/images/2021-03-25-16-50-00.png)\n\n## network types\n\n![](/assets/images/2021-03-25-16-52-47.png)","n":0.447}}},{"i":129,"$":{"0":{"v":"Synctime","n":1},"1":{"v":"\n\n1. SYNCHRONIZING PHYSICAL TIME: central server\n1. time server and distributed to nodes. Latency between transfer could be a problem.\n    - 估计来回的时间\n    - 注意不要回到过去\n    - 可以miss tick放慢时间\n2. 没有一个标准时间的话，就设立一个master询问每个client时间，average.调整时间是原来的两倍。\n3. BERKELEY ALGORITHM: server向所有人请求时间，算入RTT，average，返回client，注意drift可能是原来的两倍。\n3. logical time: 保证顺序。高时间不可能导致低时间的任务发生。\n4. LAMPORT LOGICAL TIME: happened before\n    - The counter is incremented before each event.\n    - The message should carry the new (incremented) timestamp.\n    - 维护全局index，不能处理接受和发送的问题\n    - If two events have no message exchange, Lamport logical time cannot tell which one happened first\n    - 可能出现无法处理因果的情况\n5. google truetime: compares itself with others, twice drift\n6. Cristian's Algorithm is one approach to synchronizing physical clocks using a time server.","n":0.102}}},{"i":130,"$":{"0":{"v":"Sessionlayer","n":1},"1":{"v":"\n\n![](/assets/images/2021-03-25-16-43-26.png)\n\n- rpc","n":0.707}}},{"i":131,"$":{"0":{"v":"Rpc","n":1},"1":{"v":"\n1. REMOTE PROCEDURE CALL: REPLACE COMMUNICATION VIA THE STACK WITH THE NETWORK\n    - A type of client/server communication\n    - Attempts to make remote procedure calls look like local ones\n2. problem:\n    - Calling and called procedures run on different machines, with different address spaces\n    - Must convert to local representation of data\n    - Machines and network can fail\n3. STUBS: OBTAINING TRANSPARENCY\n    - Client stub\n        - Marshalsargumentsintomachine-independentformat\n        - Sendsrequesttoserver\n        - Waits for response\n        - Unmarshals result and returns to caller\n    - Server stub\n        - Unmarshals arguments and builds stack frame \n        - Calls procedure\n        - Server stub marshals results and sends reply\n4. RFC makes a user defined header to a entire empty server library and user can filled them in.\n5. 写个接口让程序员调用服务器上的方法就像本地一样\n6. 通过编码和解码传输参数，遇到大小端的问题的话，可以采用语言将数据包装，这样就和地址顺序无关了。\n7. 存在的问题是：如果调用失败，可能是server或者网络的问题，无法排查。解决方式可以是在server保证最多一次request，出现第二次也返回第一次的reply \n8. 同步方法：1. 只进行一次rpc，允行完再ack 2. 两次rpc，收到请求ack，运行完ack","n":0.089}}},{"i":132,"$":{"0":{"v":"Reliable_data_transfer","n":1},"1":{"v":"\n# RDT\n\n## possible failure\n\nbit-errors, lossy, duplicate delivery , out-of-order delivery\n\n## methods\n\n- checksums: bit error \n- receiver feedback: bit error, ACK/NACK， Cumulative acknowledgments(I have received all packets with sequence numbers up to but not including sn.) allow acknowledgment of numerous packets at a time. They can be useful in pipelined protocols. 可能lost\n- retransmission : Sender sends another copy of segment, detect loss and allows for duplicate seg\n- sequence numbers : Distinguish between old and new, Gaps let receiver detect lost segment, find duplicate packets，restoring the transmitted order. have to be a bounded # bits\n- timer expiration: Segment or receiver feedback is lost (sender: Resends a packet after a timer fires. Sends a new packet after an acknowledgment (positive) arrives.)\n- window:Control sending of multiple segments, allow for reuse of sequence numbers, also allow for pipeling segments\n\n## protocols\n\n### Stop-n-Wait\n\n - Simplest Protocol that will handle bit errors and segment loss\n    - use: checksum, ack, sn, timers\n    - 1 bit for sequence number\n    - ![](/assets/images/2021-04-03-23-06-30.png)\n    - ![](/assets/images/2021-04-03-23-07-36.png)\n    - 为了解决checksum返回的时候有问题。可能ack会lost。带来的问题就是可能重复发几次。所以需要seq num\n    - ![](/assets/images/2021-04-03-23-08-48.png)\n    - 计时发送，看指定时间能否达到response, 没seq num. 接收者不能知道是否是重发。LOST ACK和lost segment对于发送方式一样的\n\n\n## Go Back N\n       \n- sliding window: A mechanism to control multiple, in-flight segments without overwhelming receiver, Sender is allowed to transmit N segments without waiting for an ACK\n- “window” of up to N, consecutive unACKed segments allowed\n- Sets a **timer** for each in-flight segment\n- timeout(n): retransmit segment n and all **higher** seq# segments in window\n- sender:\n  - Sender places a k-bit seq# in header\n  - “window” of up to N, consecutive unACKed segments allowed\n  - Sets a timer for each in-flight segment\n  - timeout(n): retransmit segment n and **all higher** seq# segments in window\n  - ACK(n): ACKs all segments up to, including seq# n (Cumulative ACK)\n- receiver: ACK-only: always send ACK for correctly-received segment with **highest in-order seq**, Receipt of out-of-order segment just discard and send with highest in-order seq \n    - May generate duplicate ACKs\n    - Why discard segs received out-of-order： Don’t want to buffer them, going to be re-sent anyway\n- A single segment error can cause many segments to be retransmitted\n\n## Selective Repeat\n\n  - Receiver individually ACKs all correctly received segments\n  - Buffers segs for eventual in-order delivery\n  - Sender only resends segments for which ACK not received\n  - Sets timer for each segment\n  - Sender window of N consecutive seq#s\n  - Limits seq # s of sent, but unACKed segs\n  - ![](/assets/images/2021-04-03-23-12-02.png)\n  - issues: both side have varying view, receiver window移动了，但是发送端没收到ack， 会重传。\n  - sequence number的space至少是2^k 个，k是window的大小","n":0.05}}},{"i":133,"$":{"0":{"v":"Queue","n":1},"1":{"v":"\n# queue theory\n\n- performance evaluation\n  - $\\lambda$ average arrival rate, packets per second\n  - $\\mu$ average service rate, packets servered per second\n  - $c$ number of servers\n  - $\\rho = \\lambda/c\\mu$ traffic congestion in servers\n    - if >1 averge exceeds service capability\n    - if = 1 randomness prevents queue from emptying\n  - $p_n$ is probability of a particular number n customers in the system\n  - expected number in system: $L = \\sum(n p_n)$\n  - expected number in queue: $L = \\sum_{n=c+1}((n-c) p_n)$\n  - time : $T = T_q + S$ time in queue + service time\n  - **little law**\n    - $W = E[T] W_q = E[T_q]$ mean waiting time in system\n    - $L = \\lambda W$ \n    - $E[T] = E[T_q] + E[S]$ to get $W = W_q + 1/\\mu$\n    - expected servered people: $E[N_s] = L-L_q = \\lambda(W-W_q) = \\lambda(1/\\mu) = \\lambda/\\mu$\n    - $c = 1, r = \\rho , L-L_q = \\sum_{n=1} np- \\sum_{n=1} (n-1)p = \\sum_{n=1} p_n =  1-p_0=\\rho$\n  - busy probability\n    - for G/G/c system, $E[N_s] = r$\n    - $P_b = \\rho$ one server being busy brobability\n    - ...\n\n- rate transition diagrams\n  - a type of continuous-time Markov chain\n  - $(\\lambda_n+\\mu_n)p_n =(\\lambda_{n-1}+\\mu_{n-1})p_{n-1}+(\\lambda_{n+1}+\\mu_{n+1})p_{n+1}$\n  - $p_3 = \\frac{\\lambda_2 \\lambda_1 \\lambda_0}{\\mu_3 \\mu_2 \\mu_1} p_0 $\n  - $p_n = \\prod_{i=1}^n\\frac{\\lambda_{i-1}}{\\mu_i}$\n\n- M/M/1 system\n  - Exponentially distributed \n    - interarrival time $TI(t)=\\lambda e^{-\\lambda t}$\n    - service time $TI(t)=\\mu e^{-\\mu t}$\n  - if all $\\mu$ and $\\lambda$ equal get $p_n = p_0 (\\frac{\\lambda}{\\mu})^n$\n  - $p_0 = 1-\\rho$ - > $p_n = (1-\\rho)\\rho^n$","n":0.063}}},{"i":134,"$":{"0":{"v":"Programming","n":1},"1":{"v":"\n\n# basic\n\n- socket: `ip:port`\n  - 客户端： port是由内核自动分配的\n  - server端：port是和服务对应的\n- 一个连接是一个socket pair\n\n\n![](/assets/images/2021-05-03-20-17-16.png)","n":0.302}}},{"i":135,"$":{"0":{"v":"Problem","n":1},"1":{"v":"\n# problem happened in the network\n\n## data loss\n\n## delay\n\n- processing, time spent in router, check bit error, determine output link\n- queueing, depends on congestion level\n- transmission delay: L/R bits/ bps\n- propagation delay: d/s (length/2*10^8)\n- $\\lambda$ = avg packet arrival rate(pts/s), traffic intensity: $L \\lambda /R$ value -> 1, delay becomlarge.\n- nodal delay = $d_{proc}+d_{queue}+d_{trans}+d_{prop}$\n\n### measurement\n\n- tracerouter algo:\n   - for all router i:\n        - send three packets to router i \n        - router i will return packets to sender\n        - measure transmission and reply interval","n":0.109}}},{"i":136,"$":{"0":{"v":"Physicallayer","n":1},"1":{"v":"\n![](/assets/images/2021-03-25-15-54-22.png)","n":1}}},{"i":137,"$":{"0":{"v":"Networklayer","n":1},"1":{"v":"\n# network layer\n\nip\n\n**transfer packets across links**, addressing scale to large networks, routing protocol determines best paths across the network\n\n\n## IP\n\naddressing mechanism: IP ADDRESS \n\n- No call setup at network layer\n- Packets are forwarded using address of the destination host\n- Packets are forwarded independently\n- Packets between same source-dest pair may take different paths\n- addressing\n  - Each end-host has unique address\n  - Forwarding table maps addresses to outgoing link\n\n### packet\n\n- data types: packet\n  - On sending side, encapsulate segment into packets\n  - Transmit the packet through the network\n  - Network layer protocols exist on all routers (and hosts) for this purpose\n  - On receiving side, deliver packets to transport layer\n\n### routing\n\n- Routing (Control Plane)\n    - **Involves all routers in a network**\n    -  Creates a **forwarding** table to determine end-to-end paths taken by packets\n    -  Uses routing algorithms\n- Forwarding (Data Plane)\n    - Move packets from router’s incoming interface to appropriate outgoing interface\n    - An action in a single router\n    - use forwarding table\n- Connection Setup: setup route states before sending packets\n\n### format\n\n- packet-handling operations at each router\n    - forward with destination of address\n    - forward independently\n- format\n    - Version specifies IPv4\n    - Header length (in 32-bit words)\n    - Type of Service\n    - Datagram length (Header + data) 20bytes+data\n    - ID, Flags, Offset: Used for fragmentation at router\n        - 1 DF Don't fragament\n        - 2 MF more fragament\n        - ID unique\n    - Time-to-Live: Decremented at each router, Datagram dropped if zero\n    - Protocol\n        - Used by receiver to determine which transport protocol should get packet\n    - Header checksum: Calculated only on header\n        - Must be recomputed at each router: because ttl changes\n    - use checksum because other protocol maybe involved\n    - Data: Encapsulated TCP/UDP segment . ICMP data\n\n### ipv4\n\n- prefix notation: range of subnet 128.2.101.64/26\n    - 6 bit free\n    - example: 223.1.17.0/25 for /24 half, 223.1.17.128/26 for 64, 223.1.17.192/26 for 64\n- forwarding tables:\n    - put prefix matching in destination prefix\n    - match the leading bits of destination address to the longest listed prefix: **longest matching prefix rule**\n- CIDR classless interdomain routing\n\n\n![](/assets/images/2021-03-25-16-00-27.png)\n\n![](/assets/images/2021-03-25-16-14-19.png)\n\n\n### ICMP\n\n- single ip packet\n    - no reliability\n    - type/ code for echo/unreachable....\n- traceroute:\n    - send nth udp segments has TTL of n\n    - replies with ICMP time exceeded\n- is a network-layer protocol\n    - Messages used for communication between routers and end-hosts\n    - Messages sent in an IP packet - Just like a UDP segment\n    - Messages require special processing by the IP layer software on each router\n\n### forwarding table\n\ndijkstra\n\n![](/assets/images/2021-04-11-21-58-17.png)\n\n- 每次更新新加入的点到未加入点的距离。每次从未加入点中选一个距离到已加入的set里\b最小的\n  - short path tree\n  - use dijkstra's to get routing table\n  - O(n^2)\n\nbellman-ford\n\n- Each node periodically sends its own distance vector estimates to neighbors\n- When a node x receives a new DV estimate from a neighbor v, uses B-F\n- Dx(y) ←minv{c(x,v)+Dv(y)} for each y ∈ N\n- The estimate Dx(y) converges to the actual dx(y) for minor, natural conditions\n\n## AS\n\n- A collection of physical networks with a unif\n    - ISP, A Corporate network, A Campus networ\n- An AS may get an AS number (ASN)\n    - ASNs represent units of routing policy\n- AS can have one/many/none ASN\n\n\n## BGP\n\n- function\n    - Obtain network reachability information from neighboring AS\n    - Propagate the reachability information to all routers internal to the AS\n    - Determine “good” routes to subnets based on the reachability information and on AS policy\n    - Advertise its existence to the rest of the Internet!\n- Uses path vector routing algorithm\n- Is heavily policy-based\n- Principles of Operation\n    - A BGP session is established between routers (TCP)\n    - exchange route UPDATE messages while connection is ALIVE\n    - message\n        - open： set up session\n        - keepalive: confirms liveness to neighbor\n        - notificatoin: signals an error before\n        - UPDATE: Primary message to communicate information about routes\n            - Announce or withdraw routes\n            - Route = prefix + path attributes\n    - eBGP runs between ASes\n    - iBGP within AS\n\n\n![](/assets/images/2021-03-25-16-16-40.png)\n\n![](/assets/images/2021-03-25-16-18-44.png)\n\n![](/assets/images/2021-03-25-16-20-16.png)\n\n![](/assets/images/2021-03-25-16-22-51.png)\n\n![](/assets/images/2021-03-25-16-28-17.png)\n\n## DHCP\n\n- Dynamic Host Configuration Protocol (IP)\n- information carried: a pool of IP addresses, a repository of network details\n    -  Provides these details upon request or by default\n- methods of communication : broadcast, Send to 255.255.255.255, UDP, port 67\n- leases : Used for dynamic allocation, Solution for control of when an address can be given to another client\n    - Server allows use of addr for a set period, Client will need to reacquire permission before lease period expires(automatically)\n- message format:\n    - type: discover, offer, request, ack, release\n    - xid: Random transaction value (client 发，用于定位client)\n    - chaddr: client hardware identifier\n    - siaddr: server’s IP address\n    - yiaddr: “your” address\n    - options: lots of optional parameters\n- the discovery process\n    - broadcast first, Multiple servers may respond\n    - Client chooses whichever offer it wishes\n    - DHCP Request / Ack is repeated to renew a lease\n\n\n## NAT\n\n- Network Address Translation\n    - router manage a subnet\n    - map one address space to another\n- benefits\n    - Work-around to the impending exhaustion of IP addresses  \n    -  Also allows for simple address allocation for the subnet\n    - “Security”: internal network structure obscured\n- objections\n    - IPv6 should be used to solve addressing problem\n    - Objection 2: Violates end-to-end principle\n    - Objection 3: Routers shouldn’t process packets higher than network layer\n    - Objection 4: Using port numbers to address hosts\n- operations\n    - hosts on private network use \"non-routable\" ip addresses (10.0.0.0/8 172.16.0.0/16 192.168.0.0/16)\n    - these addresses are not unique, restricted to the private subnet\n    - Router shows a single external IP address\n    - Translation table maps external IP / port combinations to internal IP / port\n    - rewrite all packets in each direction, changing based on translation table\n        - Other fixes also needed to the packet\n    -  Packet Fix-up\n        - Fix checksums\n        - Router must do more than simply change address/port values\n- port forwarding.\n    - NAT Address Translation Table\n    - Translation table is normally initialized by internal traffic\n    - Port forwarding specifies values ahead of time\n\n\n# tool\n\n- ping: send one packets and cal RTT\n- traceroute: will send 3 packets to each router it.","n":0.032}}},{"i":138,"$":{"0":{"v":"Loadbalance","n":1},"1":{"v":"\n# load balance \n\n\n把一系列task分给不同的机器。\n\n- 静态\n  - it does not take into account the state of the system for the distribution of tasks\n  - are easy to set up and extremely efficient in the case of fairly regular tasks\n- 动态\n  - take into account the current load of each of the computing units\n  - tasks can be moved dynamically from an overloaded node to an underloaded node in order to receive faster processing\n\n## proxy\n\n- Client-side random load balancing: deliver a list of server IPs to the client, and then to have client randomly select the IP from the list on each connection\n  - the method of delivery of list of IPs to the client can vary\n- Server-side load balancers\n  - The load balancer forwards requests to one of the \"backend\" servers\n  - load balancers are implemented in high-availability pairs which may also replicate session persistence data if required by the specific application\n\n- presistence\n  -  important issue when operating a load-balanced service is how to handle information that must be kept across the multiple requests in a user's session. \n  -  One basic solution to the session data issue is to send all requests in a user session consistently to the same backend server.\n  -  Assignment to a particular server might be based on a username, client IP address, or be random.\n  -  use memcache to save session info\n  -  a simple but efficient approach is to store the per-session data in the browser itself: cookie\n     -  or URL rewriting\n\n\n### forward\n\n前向代理作为客户端的代理，将从互联网上获取的资源返回给一个或多个的客户端，服务端（如Web服务器）只知道代理的IP地址而不知道客户端的IP地址\nForward proxies ensure that websites never communicate directly with a user\n\n![](/assets/images/2021-05-03-22-38-13.png)\n### reverse\n\n反向代理是作为服务器端（如Web服务器）的代理使用，而不是客户端。反向代理是供很多客户端都通过它间接访问不同后端服务器上的资源，而不需要知道这些后端服务器的存在，而以为所有资源都来自于这个反向代理服务器。\nreverse proxies ensure that users would not communicate directly with a back-end server.\n![](/assets/images/2021-05-03-22-39-21.png)\n\nA reverse proxy server is a type of proxy server that typically sits behind the firewall in a private network and directs client requests to the appropriate backend server. A reverse proxy provides an additional level of abstraction and control to ensure the smooth flow of network traffic between clients and servers.\n\n## DNS  \n\n- round-robin DNS: multiple IP addresses are associated with a single domain name\n- [DNS delegation](https://en.wikipedia.org/wiki/Load_balancing_(computing)#DNS_delegation): delegate www.example.org as a sub-domain whose zone is served by each of the same servers that are serving the web site. This technique works particularly well where individual servers are spread geographically on the Internet. ","n":0.052}}},{"i":139,"$":{"0":{"v":"Linklayer","n":1},"1":{"v":"\n# data link layer\n\nethernet, wifi, fiber, telephony\n\ntransfer frames: ethernet, PPP, MAC address (add size, error correction codes)\n\n- Inserts framing info to denote frame boundaries\n- Inserts control, addressing and error correction info in header\n- Detects transmission errors on link. May retransmit frames\n- Activation, maintenance, & deactivation of link connection\n\n\n![](/assets/images/2021-03-25-15-55-22.png)\n![](/assets/images/2021-03-25-15-56-16.png)\n\n![](/assets/images/2021-03-25-15-58-20.png)\n\n- mission: transfer frames from one node, over a link\n- scope: Service received from physical layer is the ability to move a bit across the link\n    - A packet is transferred by different link protocols over different links\n    - Each data link protocol provides different services\n- addressing mechanism:MAC\n- data types : frame\n- responsibilities/services\n    - Framing:  encapsulate datagram into frame, adding header, trailer; identify source, destination with addresses • Different from IP \naddresses!!\n    - Link access: use medium access control (MAC) protocol\n    - Error Detection\n    - Error Correction\n    - Reliable Delivery: critical for wireless links ➙ high error rates\n\n## CSMA/CD\n\n- Carrier Sense: Listen before talking Multiple Access: Broadcast Medium\n- Collision Detection: Listen as you talk. If you hear someone else, be quiet\n- Capturing a Channel: If no other station initiates transmission during this period, sender has captured the channel. t = tprop\n- **Ethernet** is the most famous example\n- Before transmitting, listen\n- If channel is sensed idle, send the frame \n-  Else, defer transmission a random time\n- If collision is detected, abort transmission \n- reduces channel wastage\n- **Min transmission time must be long enough for collisions to propagate**\n- Length of the packet >= 2 * Tp * Bandwidth of the link worst case\n\n\n## ARP\n\n- mission: Translate a network-layer address (IP) to a link-layer address (MAC), Similar to DNS\n- frame fields:\n  - Sender Ethernet and IP address\n  - Target Ethernet and IP address\n- transmission mechanism\n    - Sent in an Ethernet frame to a broadcast address\n    - ARP Reply takes the same form\n    - broadcast request, if some one know, reply\n    - if in another subnet, sent datagram to router \n- caching\n    - Each Ethernet adapter uses a table to keep track of known mappings between IP addresses and Ethernet MAC Addrs\n    - When given IP address, ARP looks in ARP table and returns corresponding MAC address\n        - If IP not in table, queue frame and broadcast ARP request\n- security\n    - ARP frames are not authenticateds\n    - May be spoofed by a malicious entity\n    - May be proxied by design\n- gratuitous use\n    - ARP can be an “announcement” protocol\n    - Can send an ARP frame just to update other node’s ARP tables\n    - Set target address and sender address to the same value\n\n\n## csma/ca\n\n- CSMA / Collision Avoidance\n- 1. Listen for a specified time (DIFS) If medium is not free:\n    - 1. Exponential Backoff (下次请求的时间)\n- If medium is free:\n    - Transmit entire frame\n    - Await ACK frame （AP send ACK to sender）\n    - If no ACK, then Exponential Backoff\n- ACK\n    - protects against bit errors\n    - Receiver only sends ACK if frame passes CRC\n- Exponential Backoff\n    -  Each node chooses a random number \n    -  Max size increases from round to round\n    -  Can be modeled as a counter (wait time)\n        -  Decremented during any idle time\n        -  Put on hold if another node transmits and for a short time afterwards (SIFS)\n        -  When zero, the counting station may transmit","n":0.043}}},{"i":140,"$":{"0":{"v":"Component","n":1},"1":{"v":"\n# component\n\n## edge\n\n- hosts running applications: end system\n- client and server\n- p2p model\n- service: connection-oritented service, connectionless service\n\n## core\n\n- routers, interconnected networks\n\n## business\n\n- Tier 1 ISP: big network company in each country, Internet backbone providers\n    - direct connect with other tier 1\n    - connected to large number of tier-2\n    - international in coverage\n    - do not buy transit from another provider\n    - vertically intergrated: sell services to customers,\n    - no single tier-1 ISP can reach the whole Internet, it only peer with Tier-1\n- Tier 2 ISP:\n    - customers of Tier-1, provider of customers, peers with other tier-2\n    - why buy transit from tier-1 provide:\n        - usually reginal network and have limited resource\n        - need route traffic through Tier-1 ISP to reach a large protion of network\n    - why tie2 peer with each other\n        - exchanging traffic with a peer, reduce money\n        - improve performance\n- open peering policy: peer with anyone possible, costs of peering have to be balanced against gains for a Tier-2 ISP.\n        - management cost: send approx equal amount of traffic to each other\n        - matinentance cost: transmission capacity to meeting point, extra equipment\n- content providers:\n    - do not sell transit\n    - 1. focus on content creation, no peering\n    - 2. large-scale players: open peering policy","n":0.069}}},{"i":141,"$":{"0":{"v":"Applicationlayer","n":1},"1":{"v":"# Application layer\n\nhttp/smtp/dns/voip\n\n![](/assets/images/2021-03-25-16-43-51.png)\n## Goals\n\n- relaiable data transfer\n- high throughput\n- timing guarantees\n\n## http\n\n访问一个网址发生了什么\n\n1. The HTTP client process initiates a TCP connection to the server www.someSchool.edu on port number 80, which is the default port number for HTTP. Associated with the TCP connection, there will be a socket at the client and a socket at the server. 建立tcp\n\n2. The HTTP client sends an HTTP request message to the server via its socket. The request message includes the path name /someDepartment/home.index. (We will discuss HTTP messages in some detail below.) 发送请求\n\n3. The HTTP server process receives the request message via its socket, retrieves the object /someDepartment/home.index from its storage (RAM or disk), encapsulates the object in an HTTP response message, and sends the response message to the client via its socket. 返回请求\n\n4. The HTTP server process tells TCP to close the TCP connection. (But TCP doesn’t actually terminate the connection until it knows for sure that the client has received the response message intact.) 关闭tcp\n\n5. The HTTP client receives the response message. The TCP connection terminates. The message indicates that the encapsulated object is an HTML file. The client extracts the file from the response message, examines the HTML file, and finds references to the 10 JPEG objects. 关闭\n\n6. The first four steps are then repeated for each of the referenced JPEG objects.\n\n![](/assets/images/2021-03-14-19-59-53.png)\n\n\n### message format\n\n- message format:\n  - hypertext transfer protocol\n  - web's appliation layer protocol\n  - client/server model\n  - 2 type: requests from client to server and responses\n  - requests and response\n  - startline:request line (Method SP Request-URI SP HTTP-Version CRLF) | status line\n    - GET /index HTTP/1.1\n    - HTTP/1.1 200 OK\n  - zero or more headers: provide metadata about request or response:datas/times, application info,caching control,**host** must on requests\n  - an empty line\n  - message body\n  - request methods:\n  - GET: retrieve an object: conditional GET/ Partial GET\n  - HEAD: retrieve metadata about object\n  - OPTIONS: request info about the capabilities\n  - POST: upload data to server\n  - status code\n  - 1XX informational\n  - 2XX success\n  - 3XX redirection\n  - 4XX client error\n  - 5XX server error\n  - each request only retrieve one object\n\n### persistent http\n\n- persistent http\n  - reuse existing transport connection,subsequent http message between same client/server sent over open connection\n  - pipelining at application protocol level\n  - without pipeline: one RTT for each referenced object **RTT+transmission time(one object)**\n  - use pipeline: one RTT for all referenced objects\n  - reduce transport-layer connection cost\n  - reduce latency by avoid mulitple TCP slow-starts\n  - avoid bandwidth wastage and reduce all congestion\n\n### cookie\n\n![](/assets/images/2021-03-14-20-03-12.png)\n\n## DNS\n\n- mission: A directory service for the Internet\n- domain namespace: hierarchical structure\n  - type of dns ns: root/top-level domain/ authoritative/ local\n \n![](/assets/images/2021-03-14-20-07-56.png)\n\n- root server's job:\n    - what www.library.cmu.edu: go to ns for .edu\n    - know top-level domain 2.3M \n- tld ns' job: ask cmu.edu ns\n- authoritative ns: provide authoritative hostname to ip \n- local ns: resolver: act as proxy\n\n\n- Load distribution across replicated servers\n  - A name can map to multiple hosts \n  - thus multiple addresses\n  - DNS server returns all addresses \n  - but rotates ordering\n\n-  Simple query and reply mechanism, same message format, Resource Record\n-  Runs over UDP \n- * DNS did not need tcp retransmission when lost,try another ns\n  - tcp take long set-up time, query and request time need to be short\n- data used as Resource Record (RR) in query and reply messages:\n  - name(owner name), value, type, class (IN,internet), ttl\n  - A = Address \n  - ns = nameserver\n  - cname = canonical name\n  - mx = mail exchange\n- caching: once ns learns mapping, it caches mapping, timeout after ttl\n\n### tool\n\n- nslookup \n- dig\n- whois\n\n","n":0.041}}},{"i":142,"$":{"0":{"v":"Ml","n":1}}},{"i":143,"$":{"0":{"v":"Feature","n":1},"1":{"v":"\n# F3\n\n![](/assets/images/2021-06-08-14-43-00.png)\n\n![](/assets/images/2021-06-08-14-43-18.png)\n\n![](/assets/images/2021-06-08-14-44-28.png)\n\n![](/assets/images/2021-06-08-14-45-22.png)\n\n![](/assets/images/2021-06-08-14-46-19.png)\n\n![](/assets/images/2021-06-08-14-47-56.png)\n\n","n":0.707}}},{"i":144,"$":{"0":{"v":"Automl","n":1},"1":{"v":"\n\n# automl pipeline\n\n- update tagged picture\n- gcp auto ml to auto classify\n- continuous train when having more data\n\n\n\n# No code/ low code\n\n- apple\n  - Create ML\n  - at least 10 pictures pre category\n- GCP\n  - vision automl\n  - text\n  - number prediction\n- aws\n  - comprehend\n- azure\n  - ml studio\n- ludwig automl","n":0.14}}},{"i":145,"$":{"0":{"v":"Bp","n":1},"1":{"v":"\n# blueprint\n\nAds ranking model development can be represented by an execution graph. Blueprint is a solution to describe and execute such an execution graph.\n\n![](/assets/images/2021-06-25-08-02-43.png)\n\n![](/assets/images/2021-08-18-13-35-10.png)\n\n![](/assets/images/2021-08-18-13-35-55.png)\n\n![](/assets/images/2021-08-18-13-38-43.png)\n\ngoal\n\n![](/assets/images/2021-08-18-13-40-31.png)\n\n\n## IR\n\nExecution graph is represented by a data structure which we call “Intermediate Representation” or IR. IR is in JSON format.\n\n## Module\n\nWhen implementing the function execute in GMBModule, we write normal Python code, which describes what execute does.\n\n```\nclass GMBModule(BaseModule):\n    @gmb_executor_method()\n    def execute(params=...):\n        process(params)\n```\n\n- When execution_mode = IR_GENERATION: calling execute(params=...) generates an IR which encodes the fact that the function execute will be called with params remotely later.\n- When execution_mode = IR_EXECUTION: calling execute(params=...) executes process(params)\n\n### edge between module\n\n```\nmodule_a = GMBModule()\nmodule_b = GMBModule2()\nmodule_a.execute()\nmodule_b.set_params(params=module_a.get_result())\nmodule_b.execute()\nresult = module_b.get_result()\n```\n## core\n\n![](/assets/images/2021-08-18-13-53-29.png)\n\n## BPS\n\n![](/assets/images/2021-08-18-13-52-15.png)\n\n\n![](/assets/images/2021-08-18-13-57-03.png)\n\n## AIR\n\n![](/assets/images/2021-08-18-14-02-44.png)","n":0.095}}},{"i":146,"$":{"0":{"v":"Database","n":1}}},{"i":147,"$":{"0":{"v":"Zippydb","n":1},"1":{"v":"\n# zippydb\n\nfb internal distributed key-value databse\n\nsingle node based on rockdb\n\n## arch\n\nZippyDB servers can be mapped to the roles in the Multi-Paxos protocol as follows:\n\nPrimary server = proposer/leader + acceptor + learner\nSecondary server = acceptor + learner\nFollower server = learner (An ordinary ZippyDB user may safely skip the details of the mapping above, as it is only intended to map terminology for readers who are familiar with Paxos.)\n\n## write \n\n![](/assets/images/2021-04-05-17-12-35.png)\n\n## read\n\n![](/assets/images/2021-04-05-17-13-08.png)\n\n## primary failover\n\nWhen the primary fails, Zeus detects the failure through lost heartbeats and notifies ShardManager. ShardManager chooses a most appropriate secondary and sends it a message to convert it into a new primary. \n\nSpecifically in this example, it is possible that, right before server X crashed, server X and server Y worked together to accept a write and server X has already sent the \"write-success\" response back to the client, but that write has not yet reached server Z. This is because server X and server Y form a majority and hence can accept a write without waiting for the \"accepted\" confirmation from server Z. Actually, server Z may never get the \"accept\" notification for this write from server X before server X crashed, e.g., due to slow network between server X and server Z. In this case, after server Z becomes the new primary, it needs to contact server Y to recover the missing write. The prepare phase of the Paxos protocol guarantees that the new primary will correctly discover all those missing writes, so long as only a minority of the replicas have failed.\nAfter bringing its local replica up-to-date, the new primary (server Z in this example) starts to handle reads and writes as normal. As shown in the figure below, the write path executes the following steps in sequence:\n\n1. When the client wants to send a new \"Put()\" request, the ServiceRouter library linked into the client notices that ShardManager has changed the shard's primary assignment, and automatically routes the request to the new primary (server Z).\n2. Server Z asks both server X and server Y to \"accept\" the write.\n3. Server Z gets the \"accepted\" confirmation from server Y, but gets no confirmation from server X.\n4. Since server Z collects a majority votes for the write (one from itself and another from server Y), server Z decides to commit the write and sends a \"write-success\" response back to the client. Server Z does not wait for server X to recover in order to accept the write. In other words, once server Z becomes the new primary, the failure of server X does not affect the database's availability .\n5. Server Z sends a \"commit\" message to server Y to inform server Y that an agreement has been reached on the write. This step is not shown in the figure for brevity.\n\n![](/assets/images/2021-04-05-17-15-33.png)\n\nThe process of primary fail-over takes about 10 seconds, including the time for Zeus to detect lost heartbeats from the old primary\n\n## A Failed Replica Rejoins\n\nServer X synchronizes with the new primary (server Z) to bring its local database up-to-date. It then starts to process protocol messages as normal. See the example in the figure below.\n\n![](/assets/images/2021-04-05-17-16-52.png)\n\n## Sharding and Load Balancing\n\nIn practice, each server runs a single ZippyDB process that can host multiple shards. In the figure below, each server hosts three shards: a primary for one shard, and two secondaries for two other shards. For example, server 1 hosts shard A's primary, shard D's secondary, and shard E's secondary. The three replicas of shard A are distributed across server 1 (primary), server 2 (secondary), and server 5 (secondary). ShardManager considers multiple factors in shard placement. In this figure, ShardManager places exactly one primary on each server for the purpose of load balancing, because a primary incurs a higher load than a secondary does. ShardManager may also place the different replicas of a shard across different clusters for the purpose of better fault tolerance.\n\n\n![](/assets/images/2021-04-05-17-18-35.png)\n\n## Asynchronous Replication Overview\n\n![](/assets/images/2021-04-05-17-22-52.png)\n\n![](/assets/images/2021-04-05-17-23-23.png)","n":0.039}}},{"i":148,"$":{"0":{"v":"Transaction","n":1},"1":{"v":"\n# Transaction\n\nTransaction is the **execution of a sequence of one or more operations** on a shared database to perform some higher level function. They are the basic unit of change in DBMS! It is a sequence of read and write operations. \n\nThe outcome of a transaction is either COMMIT or ABORT. If commit, all the transaction's modifications are saved to the database. If abort,  all the changes are undone so that this transaction is never happened. \n\n一种操作要么全部步骤成功，要不都失败.其中就有commit point的概念，在这之前是可以undo操作的，之后不行","n":0.113}}},{"i":149,"$":{"0":{"v":"Sql","n":1},"1":{"v":"\n# SQL Relational Model\n\nA relational database defines relationships in the form of tables.\n\n- data is organized into relations (called tables in SQL), where each relation is an unordered collection of tuples\n\nSQL programming can be effectively used to insert, search, update, delete database records.\n\n- vertically scalable: adding more power (CPU, RAM) to an existing machine.\n\n![](/assets/images/2021-03-23-23-04-33.png)\n\n- [[MySQL|development.database.sql.mysql]]\n\n## good \n\nmany-to-one, use id\n\nThe advantage of using an ID is that because it has no meaning to humans, it never needs to change: the ID can remain the same, even if the information it identifies changes. Anything that is meaningful to humans may need to change sometime in the future—and if that information is duplicated, all the redundant copies need to be updated. That incurs write overheads, and risks inconsistencies (where some copies of the information are updated but others aren’t). Removing such duplication is the key idea behind normalization in databases.\n## Problem\n\nMost application development today is done in object-oriented programming lan‐guages, which leads to a common criticism of the SQL data model: if data is stored in relational tables, an awkward translation layer is required between the objects in the application code and the database model of tables, rows, and columns. The discon‐nect between the models is sometimes called an impedance mismatch.\n\nIf you want to fetch a profile in the relational example, you need to either perform multiple queries (query each table by user_id) or perform a messy multiway join between the users table and its subordinate tables.","n":0.064}}},{"i":150,"$":{"0":{"v":"Replication","n":1},"1":{"v":"\n# leaders and followers\n\nEvery write to the database needs to be processed by every replica; otherwise, the rep‐licas would no longer contain the same data. The most common solution for this is called leader-based replication\n\n![](/assets/images/2021-05-11-21-10-46.png)\n\nAn important detail of a replicated system is whether the replication happens syn‐chronously or asynchronous\n\n![](/assets/images/2021-05-11-21-12-13.png)\n\nreplication to follower 1 is synchronous: the leader waits until follower 1 has confirmed that it received the write before reporting success to the user, and before making the write visible to other clients. The replication to follower 2 is asynchronous: the leader sends the message, but doesn’t wait for a response from the follower.\n\nThe advantage of synchronous replication is that the follower is guaranteed to have an up-to-date copy of the data that is consistent with the leader. If the leader sud‐denly fails, we can be sure that the data is still available on the follower. The disad‐vantage is that if the synchronous follower doesn’t respond (because it has crashed, or there is a network fault, or for any other reason), the write cannot be processed.\nThe leader must block all writes and wait until the synchronous replica is available again.\n\nIn practice, if you enable syn‐chronous replication on a database, it usually means that one of the followers is syn‐chronous, and the others are asynchronous. If the synchronous follower becomes unavailable or slow, one of the asynchronous followers is made synchronous. This guarantees that you have an up-to-date copy of the data on at least two nodes. This configuration is sometimes also called semi-synchronous.\n\nleader-based replication is configured to be completely asynchronous. In this case, if the leader fails and is not recoverable, any writes that have not yet been repli‐cated to followers are lost. This means that a write is not guaranteed to be durable, even if it has been confirmed to the client. However, a fully asynchronous configura‐tion has the advantage that the leader can continue processing writes, even if all of its followers have fallen behind.\n\n## Setting Up New Followers\n\n- Take a consistent snapshot of the leader’s database at some point in time\n- Copy the snapshot to the new follower node.\n-  The follower connects to the leader and requests all the data changes that have happened since the snapshot was taken\n-  When the follower has processed the backlog of data changes since the snapshot, we say it has caught up. It can now continue to process data changes from the leader as they happen.\n\n## fail-over \n\nfollower\n\nOn its local disk, each follower keeps a log of the data changes it has received from the leader. If a follower crashes and is restarted, or if the network between the leader and the follower is temporarily interrupted, the follower can recover quite easily: from its log, it knows the last transaction that was processed before the fault occurred\n\nleader\n\n- Determining that the leader has failed. There is no foolproof way of detecting what has gone wrong, so most systems simply use a timeout: nodes frequently bounce messages back and forth between each other, and if a node doesn’t respond for some period of tim\n- Choosing a new leader. This could be done through an election process (where the leader is chosen by a majority of the remaining replicas), or a new leader could be appointed by a previously elected controller node. The best candidate for leadership is usually the replica with the most up-to-date data changes from the old leader\n- Reconfiguring the system to use the new leader. Clients now need to send their write requests to the new leader\n\n# Implementation of Replication Logs\n\n## Write-ahead log (WAL) shipping\n\nthe log is an append-only sequence of bytes containing all writes to the database. We can use the exact same log to build a replica on another node: besides writing the log to disk, the leader also sends it across the network to its followers.\n\n. The main disadvantage is that the log describes the data on a very low level: a WAL con‐tains details of which bytes were changed in which disk blocks. This makes replica‐tion closely coupled to the storage engine. If the database changes its storage format from one version to another, it is typically not possible to run different versions of the database software on the leader and the followers.\n\n\n## Logical (row-based) log replication\n\nAn alternative is to use different log formats for replication and for the storage engine, which allows the replication log to be decoupled from the storage engine internals. This kind of replication log is called a logical log, to distinguish it from the storage engine’s (physical) data representation.\n\nA logical log for a relational database is usually a sequence of records describing writes to database tables at the granularity of a row: \n\n• For an inserted row, the log contains the new values of all columns.\n• For a deleted row, the log contains enough information to uniquely identify the row that was deleted. Typically this would be the primary key, but if there is no primary key on the table, the old values of all columns need to be logged.\n• For an updated row, the log contains enough information to uniquely identify the updated row, and the new values of all columns (or at least the new values of all columns that changed)","n":0.034}}},{"i":151,"$":{"0":{"v":"Redis","n":1},"1":{"v":"\n# 介绍\n\nRedis是一个使用ANSI C编写的开源、支持网络、基于内存、分布式、可选持久性的键值对存储数据库。\n\n\nRedis支持不同无序、有序的列表，无序、有序的集合间的交集、并集等高级服务器端原子操作。\n\nRedis通常将全部的数据存储在内存中。2.4版本后可配置为使用虚拟内存，一部分数据集存储在硬盘上，但这个特性废弃了。\n\n目前通过两种方式实现持久化：\n\n使用快照，一种半持久耐用模式。不时的将数据集以异步方式从内存以RDB格式写入硬盘。\n1.1版本开始使用更安全的AOF格式替代，一种只能追加的日志类型。将数据集修改操作记录起来。Redis能够在后台对只可追加的记录进行修改，从而避免日志的无限增长。\n\nhttps://zh.wikipedia.org/wiki/Redis","n":0.577}}},{"i":152,"$":{"0":{"v":"Partition","n":1},"1":{"v":"\n- NAÏVE TABLE PARTITIONING: Each node stores one and only table.\n- HORIZONTAL PARTITIONING: Split a table's tuples into disjoint subsets. Choose column(s) that divides the database equally in terms of size, load, or usage. (Hash Partitioning, Range Partitioning)\n\n\n# Partitioning of Key-Value Data\n\nOne way of partitioning is to assign a continuous range of keys (from some mini‐mum to some maximum) to each partition. The partition boundaries might be chosen manually by an administrator, or the data‐base can choose them automatically. Within each partition, we can keep keys in sorted order. This has the advantage that range scans are easy, and you can treat the key as a concatenated index in order to fetch several related records in one query\n\nanother way is to use hash of key to partition, reduce the risk of skew and hot spots. by using the hash of the key for partitioning we lose a nice property of key-range partitioning: the ability to do efficient range queries. Keys that were once adjacent are now scattered across all the partitions, so their sort order is lost\n\n## secondary index\n\n[[Pattern|development.cloud.database.pattern#index table]]\n\nRather than each partition having its own secondary index (a local index), we can construct a global index that covers data in all partitions. The advantage of a global (term-partitioned) index over a document-partitioned index is that it can make reads more efficient: rather than doing scatter/gather over all partitions, a client only needs to make a request to the partition containing the term that it wants.\n\n## rebalancing\n\nsimple solution: create many more partitions than there are nodes, and assign several partitions to each node\n\n![](/assets/images/2021-05-11-20-57-57.png)\n\n## routing\n\n![](/assets/images/2021-05-11-20-59-11.png)","n":0.062}}},{"i":153,"$":{"0":{"v":"Nosql","n":1},"1":{"v":"\n# nosql\n\nNoSQL is a non-relational DMS, that does not require a fixed schema, avoids joins, and is easy to scale. \n\nNoSQL database is used for distributed data stores with humongous data storage needs\n\nNoSQL databases can be document based, key-value pairs, graph databases.\n\n- horizontally scalable (more machines)\n- use dynamic schema for unstructured data.\n\n![](/assets/images/2021-03-23-23-04-33.png)\n\n\nhere are several driving forces behind the adoption of NoSQL databases, including: \n\n- A need for greater **scalability** than relational databases can easily achieve, includ‐ing very large datasets or very high write throughput \n- A widespread preference for free and open source software over commercial database products \n- Specialized query operations that are not well supported by the relational model \n- Frustration with the restrictiveness of relational schemas, and a desire for a **more dynamic and expressive data model**\n\n## bad \n\n- one-to-many structure\n- access hard\n- hard to keep consistent if many-to-many\n- not need join\n\n## good\n\nA document is usually stored as a single continuous string, encoded as JSON, XML, or a binary variant thereof (such as MongoDB’s BSON). If your application often needs to access the entire document (for example, to render it on a web page), there is a performance advantage to this storage locality.\n\nSchema flexibility in the document model\n\n# cassandra\n\nSetting up Cassandra is quite simple and the maintenance is automatically done. The platform is quite fast even when it is scaled up or a node is added. Cassandra also takes care of re-syncing, balancing or distribution of data. The platform is known to provide high velocity random read writes compared to other NoSQL platforms since it has columnar storage capability and distributed decentralized architecture.\n\nFlexible Sparse & Wide Column requirements talk about capability to increase your columns as and when you need. It is suitable only in those cases where secondary index needs are less, which means you have it absolutely de-normalized. In other words all information is available to serve a specific query and does not go across multiple tables to get server specific client query.\n\nIt is important to know that Cassandra is suitable with non-group by kind of models. For applications that have requirement of group-by functionality, Cassandra would not be the right system to choose. This also includes bringing in secondary indexes, which will result into overall performance of system going down.\n\n very high velocity of random read & writes & wide column requirements.\n\n与BigTable和其模仿者HBase不同，Cassandra的数据并不存储在分布式文件系统如GFS或HDFS中，而是直接存于本地。与BigTable一样，Cassandra也是日志型数据库，即把新写入的数据存储在内存的Memtable中并通过磁盘中的CommitLog来做持久化，内存填满后将数据按照key的顺序写进一个只读文件SSTable中，每次读取数据时将所有SSTable和内存中的数据进行查找和合并。这种系统的特点是写入比读取更快，因为写入一条数据是顺序计入commit log中，不需要随机读取磁盘以及搜索。\n\n集群没有master的概念，所有节点都是同样的角色，彻底避免了整个系统的单点问题导致的不稳定性，集群间的状态同步通过Gossip协议来进行P2P的通信。每个节点都把数据存储在本地，每个节点都接受来自客户端的请求。每次客户端随机选择集群中的一个节点来请求数据，对应接受请求的节点将对应的key在一致性哈希的环上定位是哪些节点应该存储这个数据，将请求转发到对应的节点上，并将对应若干节点的查询反馈返回给客户端。\n\n在一致性、可用性和分区耐受能力（CAP）的折衷问题上，Cassandra和Dynamo一样比较灵活。Cassandra的每个keyspace可配置一行数据会写入多少个节点(设这个数为N)，来保证数据不因为机器宕机或磁盘损坏而丢失数据，即保证了CAP中的P。用户在读写数据时可以指定要求成功写到多少个节点才算写入成功(设为W)，以及成功从多少个节点读取到了数据才算成功(设为R)。可推理得出，当W+R>N时，读到的数据一定是上一次写入的，即维护了强一致性，确保了CAP中的C。当W+R<=N时，数据是最终一致性因为存在一段时间可能读到的并不是最新版的数据。当W=N或R=N时，意味着系统只要有一个节点无响应或宕机，就有一部分数据无法成功写或者读，即失去了CAP中的可用性A。因此，大多数系统中，都将N设为3，W和R设为QUORUM，即“过半数”——在N为3时QUORUM是2。\n## partition\n- ring techonology.\n- hash round off\n- hash value used assign key to nodes\n\n## replication\n- rack unware: data at next N-1\n- rack aware: use zookeeper to choose a leader to tell nodes the range they replica for\n- datacenter aware: datacenter level\n\n## gossip protocol\n\n- Periodic, Pairwise, inter-node communication.\n- Random selection of peers.\n- Example – Node A wish to search for pattern in data\n    - Round 1 – Node A searches locally and then gossips with node B. \n    - Round 2 – Node A,B gossips with C and D.\n    - Round 3 – Nodes A,B,C and D gossips with 4 other nodes ......\n- Round by round doubling makes protocol very robust.\n\n## Local Persistence\n\n- Write operations happens in 2 steps\n    - Write to commit log in local disk of the node\n    - Update in-memory data structure.\n- Read operation\n    - Looks up in-memory ds first before looking up files on disk.\n    - Uses Bloom- Filter (summarization of keys in file store in memory) to avoid looking up files that do not contain the key.\n\n# HBase\n\nHBase是Apache Hadoop项目的一个子项目，是Google BigTable的一个克隆，与Cassandra一样，它们都使用了BigTable的列族式的数据模型，但是：\n\nCassandra只有一种节点，而HBase有多种不同角色，除了处理读写请求的region server之外，其架构在一套完整的HDFS分布式文件系统之上，并需要ZooKeeper来同步集群状态，部署上Cassandra更简单。\nCassandra的数据一致性策略是可配置的，可选择是强一致性还是性能更高的最终一致性；而HBase总是强一致性的。\nCassandra通过一致性哈希来决定一行数据存储在哪些节点，靠概率上的平均来实现负载均衡；而HBase每段数据(region)只有一个节点负责处理，由master来动态分配一个region是否大到需要拆分成两个，同时会将过热的节点上的一些region动态的分配给负载较低的节点，因此实现动态的负载均衡。\n因为每个region同时只能有一个节点处理，一旦这个节点无响应，在系统将这个节点的所有region转移到其他节点之前这些数据便无法读写，加上master也只有一个节点，备用master的恢复也需要时间，因此HBase在一定程度上有单点问题；而Cassandra无单点问题。\nCassandra的读写性能优于HBase[17]。","n":0.042}}},{"i":154,"$":{"0":{"v":"Logging","n":1},"1":{"v":"\n\n- **what**:recording events as they occur.\n- **why**: need to use log to restore\n- **how**: combine with checkpoint, periodically checkpoint to save complete state. increment log to maintain updates from that state.\n    - synchronous logging: spend so many time to recovery\n    - asynchronous: log buffered in memory, reduce overhead, but leave log entries vulnerable to loss.\n        - GDV, global dependency vectors\n        - interval is how many messages I got since beginning\n        - if someone vector is bigger than the original one, it means it is inconsistence\n- **problem**: we can use prune log to reduce playback time\n    - it may resend messages that having negative effects on system. Use incarnation numbers to enable recipients to do the same.\n    - expensive in times\n\n\n## checkpoint\n\n\n- **what**: \bused to restore state. \n- **why**:for global consistent copy.\n- **how**: set point, **freezing** the system,no write to maintain consistency. inbound messages will not frozen but write into buffer.\n    - uncoordinated checkpoint: \n        - periodically recorded its state\n        - need recovery line to recover\n    - coordinated checkpoints:\n        - record message sequences: know who sent us message since last checkpoint\n        - synchronized clocks, add timestamp in all messages and act as a sequence number;:\n- **problem**: freeze\n- incarnation number: restarted will +1, use this to distinguish whether I should accept this message.","n":0.069}}},{"i":155,"$":{"0":{"v":"LSM","n":1},"1":{"v":"\n\n## LSM\n\nhttp://www.benstopford.com/2015/02/14/log-structured-merge-trees/\n\n1. idea: collect and batch updates in memory. 放满buffer再写入。\b\b删除的时候\b先放到tombstone里，再删除。\n2. merge 的\b想法：使用bloom filter在query的时候可以知道这个文件会不会在里面。在merge update可以prune tree。在merge的时候删tombstone。\n3. LSMT，memory里的数据结构是C0，disk里的是C1\n    1. fill memory\n    2. spill to disk. use SSTables(连续key value pair) and SSIndexes(key index pair) support random access \n    3. Index and bloom filter in memory\n    4. merge perform comaction\n    5. write-ahead logs to aid recovery\n    6. C0 is smaller and entirely resident in memory, whereas C1 is resident on disk. New records are inserted into the memory-resident C0 component. If the insertion causes the C0 component to exceed a certain size threshold, a contiguous segment of entries is removed from C0 and merged into C1 on disk.\n\nhttp://distributeddatastore.blogspot.com/2013/08/cassandra-sstable-storage-format.html)\n\n\n\n## Bloom Filter\n\n- **what**: one bit per hash function consumed per key. ignore collision. use bit to reprensent exist or not.\n- **why**: secondary storage is slow to search and access\n- **whow**: use k hash function for the item and get k array, set these all in 1 and when we query this item, we will check all k array result","n":0.078}}},{"i":156,"$":{"0":{"v":"Index","n":1},"1":{"v":"\n# index\n\nIn order to efficiently find the value for a particular key in the database, we need a different data structure: an index\n\nA table index is a **replica of a subset** of a table's columns that are organized and/or sorted for efficient access using a subset of those column\n\n## B+ tree\n\n- b+ tree:\n    - **self-balancing** tree data structure that keeps data sorted and allows searches, sequential access, insertions, and deletions in O(log n).\n    - m-way search tree: every leaf node is at the same depth\n    - every node with m/2+1 <= k <= m keys, k keys, k+1 child\n    - |link(< k )|key1|link( < k2 )|key2|link3( >= k2)|...\n    - node is an array of key/value pairs, key is column, value differ based on whether the node is classified as inner nodes or leaf nodes.\n    - only stores values in leaf nodes. Inner nodes only guide the search process.\n- B+TREE DESIGN CHOICES\n    - node size\n    - Merge Threshold : maybe delay merge operation\n    - Variable Length Keys : \n    - Non-Unique Indexes : \n    - Intra-Node Search: binary search \n- optimization:\n    - prefix compression: store prefix and only store defferent substring, leaf node\n    - suffix truncation: key very different and you only need suffix to see which key to go left or right, inner node\n    - bulk insert\n    - POINTER SWIZZLING\n\n## other index\n\n- skip list\n    - dynamic order-preserving index use a sorted linked list\n    - **Multiple levels** of linked lists with extra pointers that skip over intermediate nodes.\n    - To insert a new key, **flip a coin** to decide how many levels to add the new key into. Provides approximate O(log n) search times.\n    - First logically remove a key from the index by setting a flag to tell threads to ignore.\n    - Then physically remove the key once we know that no other thread is holding the reference.\n    - pros\n        - less space\n        - no rebalance\n    - cons\n        - not disk friendly, reverse search not good\n- radix tree\n    - Represent keys as individual digits. This allows threads to examine prefixes one-by-one instead of comparing entire key.\n    - 可能的问题就是一些不好表示，比如signed int，float\n- inverted index\n    - full text search index\n","n":0.053}}},{"i":157,"$":{"0":{"v":"Graph","n":1},"1":{"v":"\n# Graph-Like Data Models\n\nA graph consists of two kinds of objects: vertices (also known as nodes or entities) and edges (also known as relationships or arcs)","n":0.196}}},{"i":158,"$":{"0":{"v":"Distributed_system","n":1},"1":{"v":"\n\n## 多个server的concurrency解决思路\n\n### Centralized Approach 中央集权\n\n- what: 直接指派一个作为中央\n- why:easy and gurante\n- how: 3 messeages per cs entry : (request, permission, done)\n- problem: central dies and threads dies in the cs\n\n### lamport timestamp\n\n- what: global pripority queue for cs. send to each node request\n- why:  every node know what happens.\n- how: 3(N-1) messeages per requests (request,reply,release)\n- problem: no falut tolerant. message may not arrive in time, especially when sending requst\n\n### Ricarti and Agrawala timestamp approach\n\n- what: combine reply and release. change global queue to voting.\n- why: reduce message number\n- how: send request to others and if other agree(not in CS, or in cs and exit will reply) will reply. Get enough vote can start. 2*(n-1) messages.\n- problem: workhorses. too much messages. Even a single failure can disable the entire system. Both timestamp approaches require more messages than a centralized approach -- and have lower fault tolerance. The centralized approach provides one single point of failure (SPF). These timestamp approaches have N SPFs.\n\n### Voting\n\n- what: send request to others, if other have voted, put it in queue. When one exit cs, it send release to others and other could handle request in the queue.\n- why: only majority agree is ok. change the way of message and queue. \n- how: break ties could use **lamport time**. break deadlock when no one win, use inqure message, and other could vote again.It sends an INQUIRE message to the candidate for who it voted. If this candidate won the election, it can just ignore the INQUIRE and RELEASE normally when done. But, if it hasn't yet entered the critical section, it gives back the vote and signals this by sending back a RELINQUISH. Upon receipt of the RELINQUISH, the voter is free to vote for the preceding request.\n- problem: less message. (3+x)(1/2 N+?) request, vote, release\n\n### voting districts\n\n- what: send message to districts, just in the same line and cloumn. \n- why: reduce message\n- how: same voting techniques. 3*(2sqrt(N)-1)\n- problem: not falut tolerant, no deadlock. one server die may change.选择多个进入cs\n\n### token ring\n\n- what: everyone know successor, and move token one by one. hold it until done cs\n- why: fault tolerance. good at high contention\n- how: if one dies with token, last one see time out and generate a new one. Under high contention, message low. Every one has limited time with token.\n- problem: not good at low contention. \n\n### raymond's algorithm\n\n- what: use tree to pass token ring. \n- why: more quick in low contention\n- how: pass by node.\n- problem: worst case, travel long\n\n### path compression\n\n- what: allow short cut to pass token ring\n- why: current_dir may out-of-date, when request happened, node can get into current_dir end and enqueue in **next** queue. \n- how: use a queue of pending request with current_dir and next. current_dir point to next waiting, next is current(with token) point to waiting.","n":0.046}}},{"i":159,"$":{"0":{"v":"Voting","n":1},"1":{"v":"\n\n## 多个server的选举策略\n\ndifference between cs:\n\n- other do not need to know who enter cs. election need other know who is coordinator.\n- fault tolerance is primary consideration in election.\n\n### bully algorithm\n\n- what: use highest number as coordinator.\n- why: easy\n- how: when coordinator dies, send election to high number, if not recieve ack, it become coo and send to others. \n- problem: assumption is not realible(network is ok and we could know who dies accurately). failure need detect accurately.\n\n### invitation algorithm\n\n- what: form group to elect one and create a large one.\n- why: communication failure and high latency. use partition to handle is the best way.\n- how: merge them partition into group. choose one in partition and merge with another and get one.\n- problem: state is not consistence among group.\n\n### ring election\n\n- what:非同步算法。find cooridator die, send election around ring, every one add itself in the message. assume highest is new and everyone get message again remove itself.\n- why: good at high contention, and less messge","n":0.079}}},{"i":160,"$":{"0":{"v":"Raft","n":1},"1":{"v":"\n\n# \b共识机制 raft\n\nmain idea is to allow a collection of machines to work as a group that can survive the failures fo some of its members.\n\n## leader election\n\n- what: in each term, elect a leader. when time out, start a new election.\n- why: one leader to recieve request and syn among all machines.\n- how: begin one election with term++, every one vote itself first and request others, if it finds other have more latest term, it will become follower.\n\n## log replication\n\n- what: append command as a log entry.\n- why: make sure everyone has same log\n- how: commit, if consistence, duplicate leader's\n- When AppendEntries consistency check fails, decrement nextIndex and try again\n- When follower overwrites inconsistent entry, it deletes all subsequent entries    \n","n":0.091}}},{"i":161,"$":{"0":{"v":"Paxos","n":1},"1":{"v":"\n\n\n# paxos\n\nA collection of process can propose values\nA consensus algorithm ensures \n\n- That a single proposal is chosen\n- The processes can learn the proposed value \n- No value is chosen if there are no proposals.\n\n- **what**: consensus probelm algorith.\n- **how**:\n    - **Prepare**:propersor sends a Prepare message containing this **proposal** to a **Quorum** of Acceptors\n    - **Promise**:If the proposal's number N is higher than any previous proposal number received from any Proposer by the Acceptor, then the Acceptor must return a **promise** to **ignore** all future proposals having a number less than N. If the Acceptor accepted a proposal at some point in the past, it must include the previous proposal number and previous value in its response to the Proposer.\n    - **Accept request**:If a Proposer receives enough promises from a Quorum of Acceptors, it needs to set a value to its proposal. If any Acceptors had previously accepted any proposal, then they'll have sent their values to the Proposer, who now must set the value of its proposal to the value associated with the highest proposal number reported by the Acceptors. The Proposer sends an **Accept Request message** to a Quorum of Acceptors with the chosen value for its proposal.\n    - **Accepted**:If an Acceptor receives an Accept Request message for a proposal N, it must accept it if and only if it has not already promised to only consider proposals having an identifier greater than N. In this case, it should register the corresponding value v and send an Accepted message to the Proposer and every Learner. Else, it can ignore the Accept Request.","n":0.062}}},{"i":162,"$":{"0":{"v":"Filesystem","n":1},"1":{"v":"\n\n# file system\n\n- **what**: a file is a unit of data organized by user. a service responsible for managing files\n- **why**: key is robust and high-throughput\n- **how**: name, access, physical allocation, security and protection, resource administration.\n\n\n## NFS and AFS\n\n1. NFS has no client caching, cliented cached anyway, central system\n2. AFS is stateful server and has cache protocol. called to have data client there is an update, their cache is invalid. Whole file semantic\n3. CODA, add replication and added weakly connected mode.\n\n# RAIDS and HDFS\n\n## Normal disk\n\n- An error-correcting code (ECC) or forward error correction (FEC) code is a process of adding **redundant** data, or parity data, to a message, such that it can be recovered by a receiver even when a number of errors (up to the capability of the code being used) were introduced, either during the process of transmission, or on storage.\n- RAM could cache the data. It will only read data from disks. If there was error, disk will return nothing.\n\n## RAIDS\n\n- **what**:Redundant Array of Independent Disks,combines multiple physical disk drive components into one or more logical units for the purposes of data redundancy, performance improvement, or both.\n- **why**: more rebust, larger volume,higher throughput\n- **how**:\n    - RAID 0 它將兩个以上的磁盘並联起来，**成为一个大容量的磁盘**。在存放数据时，分段后分散儲存在这些磁盘中，因為读写時都可以并行處理，所以在所有的级别中，RAID 0的**速度**是最快的。no redundancy,just split into serveral disks\n    - RAID 1: mirroring,disk0=disk1,在一些多线程操作系统中能有很好的**读取**速度,replication，理論上读取速度等於硬盘數量的倍數，与RAID 0相同\n    - RAID 2:这是RAID 0的改良版，以汉明码（Hamming Code）的方式将数据进行编码后分割为独立的位元，并将数据分别写入硬盘中。因为在数据中加入了错误修正码（ECC，Error Correction Code），所以数据整体的容量会比原始数据大一些. log2. Have disks save error correction code for each partition.\n    - RAID3: a disk save **parity**. 採用Bit－interleaving（数据交错儲存）技術，它需要通过编码再将数据位元分割後分别存在硬盘中，而将同位元检查後单独存在一个硬盘中，但由于数据内的位元分散在不同的硬盘上，因此就算要读取一小段数据资料都可能需要所有的硬盘进行工作，所以这种规格比较适于读取大量数据时使用。\n    - RAID4:它与RAID 3不同的是它在分割时是以block为单位分别存在硬盘中\n    - RAID5:RAID Level 5是一种储存性能、数据安全和存储成本兼顾的存储解决方案。它使用的是Disk Striping（硬盘分割）技术。RAID 5至少需要三块硬碟，RAID 5不是对存储的数据进行备份，而是把数据和相对应的奇偶校验信息存储到组成RAID5的各个磁盘上，并且奇偶校验信息和相对应的数据分别存储於不同的磁盘上。**当RAID5的一个磁盘数据发生损坏後，可以利用剩下的数据和相应的奇偶校验信息去恢复被损坏的数据**。![](https://en.wikipedia.org/wiki/File:RAID_5.svg)\n    - RAID6:与RAID 5相比，RAID 6增加第二个独立的奇偶校验信息块\n    - RAID10 = RAID0+RAID1\n\n## LUSTRE\n\n- **what**:a type of parallel distributed file system, generally used for large-scale cluster computing\n- **why**: used for supercomputing, network RAID\n- **how**:\n    - Files are broken into objects, very similar to stripes. These stripes can be stored by different nodes.\n    - One or more metadata servers (MDS) nodes that has one or more metadata target (MDT) devices per Lustre filesystem that stores namespace metadata, such as filenames, directories, access permissions, and file layout(different access pattern,data is small)\n    - One or more object storage server (OSS) nodes that store file data on one or more object storage target (OST) devices.(enable either OSS talk to either OST)\n    - Client(s) that access and use the data. Lustre presents all clients with a unified namespace for all of the files and data in the filesystem\n    - high performance network to transfer data and manage network to manage data\n\n## MOGILEFS\n\n- **what**:distributed filesystem\n- **why**:no editing, whole file,fast deliver to clients\n- **how**:\n    - replicated storage:it replicates objects across servers. The number of replicas is associated with the class of the file, so, for example, photos might have three replicas, each, but thumbnails, which can be recreated from the original photos, might only have one replica of each. this reduces the cost of the storage by allowing less expensive components.\n    - http+MySQL:MogileFS uses HTTP to server objects from each replica, as opposed to a home-grown protocol, for portability. For the same reason, it keeps its metadata in a standard MySQL database. \n    - portable\n    - no hierachy: it maintains simple namespaces, rather than directory trees,  is much simpler and more efficient than a full-blown directory system\n\n## HDFS\n\n### assumption\n\n- failure is a norm, especially on datanode. It is used to handle streaming data. \n- emphasis is on throughput not on latency\n- large data sets\n- simple coherency model: write once and read many\n- moving computation is cheaper than moving data\n-  The good news is that it won't be edited in place. We'll just be collecting it, adding to it.\n-  \n![](/assets/images/2021-04-12-19-59-50.png)\n\n\n## namenode\n\n- **what**: master-slave architecture\n- **why**: manage namespace as coordinator, only 1\n- **how**: block to DataNodes mapping\n- data never go to namenode\n- hierarchical name space: maybe not needed, low overhead\n\n## datanode\n\n- manage storage attached to node\n- create and delete block, replicate blocks\n\n## access mode\n\n- read anywhere\n- write only at end(append)\n- no edit/random write\n\n## replication\n\n- blocks are all same size\n- fault tolerance\n- namenode managed replication\n- pipelining\n    - When a client is writing data to an HDFS file, its data is first written to a local file as explained in the previous section.\n    -  The **first** DataNode starts receiving the data in small portions (4 KB), writes each portion to its local repository and transfers that portion to the **second** DataNode in the list. The second DataNode, in turn starts receiving each portion of the data block, writes that portion to its repository and then flushes that portion to the **third** DataNode.\n    -  less bandwidth and less hot-spot","n":0.037}}},{"i":163,"$":{"0":{"v":"Concurrency","n":1},"1":{"v":"\n\n\n## concurrency control\n\nThe goal of a concurrency control is to generate an execution schedule that is equivalent to some serial execution:\n\n- serial schedule: a schedule does not interleave the actions of different transactions\n- equivalent schedules: the effect of executing two schedules are same\n- serializable schedule: a schedule is equivalent to some serial execution of transactions.\n\nThere are some problems when interleaves the operations:\n\n- Read-write conflicts (unrepeatable reads): A transaction cannot get the same value when reading the same object multiple Times.\n- Write-read conflicts(Dirty read): a transaction sees the write effects of a different transaction before that transaction committed its changes.\n- Write-Write conflicts (Lost updates): one transaction overwrites the uncommitted data of another concurrent transitions.\n\nSchedule S is **conflict serializable** if you are able to transform S into a serial schedule by **swapping consecutive non-conflicting operations** of different transactions. We could use dependency graphs to check. $T_i$ -> $T_j$ means if one operation $O_i$ of $T_i$ conflicts with an operation $O_j$ of $T_j$ and $O_i$ appears earlier in the schedule in $O_j$. A schedule is conflict serializable if and only the graph is acyclic. \n\nFor View serializable, it means if one write is overwrote by another transaction and there is no read, it is fine. It allows all conflict serializable schedules and blind writes. It is hard to enforce efficiently. It allows more schedules.\n\nFor durability. All of the changes of committed transactions must be durable (i.e., persistent) after a crash or restart. The\nDBMS can either use logging or shadow paging to ensure that all changes are durable.\n","n":0.063}}},{"i":164,"$":{"0":{"v":"Replication","n":1},"1":{"v":"\n# master-slave\n\nFor replica configurations,  Master-Replica will receive all updates and it propagates those updates to its replicas. K-safety is a threshold for determining the fault tolerance of the replicated database. The value K represents the number of replicas per data object that must exist at all times.\n\n# propagation\n\nWhen a txn commits on a replicated database, the DBMS has to decide whether it has to wait for that txn's changes to propagate to other nodes before it can send the acknowledgement to application.\n\n- Synchronous: The master sends updates to replicas and then waits for them to acknowledge that they fully applied (i.e., logged) the changes.\n- Asynchronous: The master immediately returns the acknowledgement to the client without waiting for replicas to apply the changes.\n- Semi-Synchronous:  Replicas immediately send acknowledgements without logging them\n\n## CVV\n\n1. It asks all replicas for their version number\n2. It then asks the replica with the greatest version number for the file\n3. If the servers don't agree about the files version, the client can direct the servers to update a client that is behind, or inform them of a conflict. CVVs are compared just like vector timestamps. A conflict exists if two CVVs are concurrent, because concurrent vectors indicate that each server involved has seen some changes to the file, but not all changes.","n":0.068}}},{"i":165,"$":{"0":{"v":"Recovery","n":1},"1":{"v":"\nRecovery algorithms are techniques to ensure database consistency, transaction atomicity, and durability despite failures. Recovery algorithm has two parts: actions during normal transaction, actions after a failure to recover the database.The key primitives are UNDO, the process of removing the effects of an incomplete or aborted transaction. REDO: the process of re-instating the effects of a committed transaction for durability.\n\nStorage can be volatile storage, data will be lost after powering off. Non-Volatile have data persistent after powering off. Stable storage never lose data. It could achieve approximately by using multiple storages. \n\nFailure can be transaction failure: transaction cannot complete due to some internal error and DBMS must terminate an active transaction due to an error condition. System failure is DBMS fails and system is crashed, non-volatile storage are not corrupted. Storage media failure is a disk failure and destroy parts of non-volatile storage. \n\n**Buffer pool management steal policies** will decide whether the DBMS allow an uncommitted transaction to overwrite the most recent committed value of an object in non-volatile storage. No-steal policy will not write uncommitted transaction value back to disk,  steal policy, allows the system to write modified blocks to disk even if the transactions that made those modifications have not all committed, could steal other transaction's memory. Force policy ensures that all updates made by a transaction are reflected on non-volatile\nstorage before the transaction is allowed to commit. No-force is not enforced to do this. NO-STEAL + FORCE means no redo: all committed transactions' changes are reflected in disk, no undo: all aborted transactions' changes are not written to disk. Limitation is memory because of no-steal policy.\n\nShadow paging means updates are only made in the shadow copy. When a transaction commits, atomically switch the shadow to become the new master. Disadvantages: Copying the entire page table is expensive and the commit overhead is high. Organize the database pages in a tree structure where the root is a single disk page. The root points to the master copy, updates are applied to the shadow copy. To install updates, overwrite the root so it points to the shadow, thereby swapping the master and\nshadow. For undo, it remove the shadow pages. Leave master and the DB root pointer alone. Do not need redo.\n\n**Write-Ahead Logging** means DBMS records all changes made to the db in log file before changes is made to a disk page. The log contains information to perform undo and redo. It has fast runtime performance but slow recovery time. Log records are written to disk before update is allowed to be written on disk. Transaction is committed until all its log records have been written to stable storage.Write BEGIN in the beginning, COMMITTED to make sure all log records are flushed. Log records contains tid, object id, before value(UNDO), after value(REDO). If we use NO-STEAL policy, we don't need original value, but in that way we could not undo for aborted transaction.\n\nDBMS can periodically takes a checkpoint where it flushes all buffers out to disk. The DBMS stops accepting new transactions and waits for all active transactions to complete. Flush all log records and dirty blocks currently residing in main memory to stable storage. Write a <CHECKPOINT> entry to the log and flush to stable storage.\n\nLogging schemes could be physical logging: record the changes made to a specific location in the database. Logical logging records the high operations executed by transactions. Physiological logging means log records target a single page but do not specify data organization of the page.\n\n\n## ARIES\n\nAlgorithms for Recovery and Isolation Exploiting Semantics. \n\n- WAL\n- Repeat history in redo\n- logging changes during undo\n\nIn WAL, each log record has a global unique log sequence number. Each data page contains a pageLSN, the LSN of the most recent update to that page. prevLSN: The previous LSN for the transaction. System keeps track of flushedLSN: the max LSN flushed so far. Before page i can be written to disk, we must flush log at least to the point where $pageLSN_i$ ≤ flushedLSN.\n\nTransaction commit will first write COMMIT record to log. All log records to to transaction’s COMMIT record are flushed to disk. When the commit succeeds, write a special TXN-END record to log. \n\nTransaction abort just an UNDO operation. Use prevLSN to undo transaction. Compensation Log Record, CLR describes the actions taken to undo the actions of a previous update record. It has all the fields of an update log record plus the undoNext pointer. CLRs are added to the log like any other record but they never need to be undone.\n\n1. First write ABORT record to log.\n2. Then play back updates in reverse order to remove their effects. For each update, write a CLR entry and restore old value.\n3. At end, write a TXN-END log record.\n\nBlocking checkpoints will halt the start of any new transactions and wait until all active transactions finish executing, flush dirty pages on disk.\n\nBetter one will halt new transaction and just pause transactions while the DBMS takes the checkpoint. It uses \n**Active Transaction Table (ATT)** to record active transaction and their lastLSN(most recent lsn written by transaction). Entry is removed when transaction commits or aborts. In **Dirty Page Table (DPT)**, it keeps track of pages in the buffer pool contain changes from uncommitted transactions. And there is **recLSN** field, the LSN of the log record that first caused the page to be dirty.\n\nFuzzy checkpoints allows other transactions to continue to run. Add new log records to track checkpoint boundaries, <CHECKPOINT-BEGIN>: Indicates the start of the checkpoint, <CHECKPOINT-END>: Contains the ATT + DPT.\n\nThere are three phases in ARIES.\n\nAnalysis: Read the WAL to identify dirty pages in the buffer pool and active transactions at the time of the crash.\n\n- Scan log forward from the checkpoint.\n- If you find a TXN-END record, remove its transaction from ATT.\n- All other records, add transaction to ATT with status UNDO, and on commit, change transaction status to COMMIT.\n- For UPDATE records, if page P not in DPT, add P to DPT and set its recLSN=LSN\n\nREDO: repeat history to reconstruct state at the moment of the crash. Reapply all updates (even aborted transactions) and redo CLRs:\n\n- Scan forward from log record containing smallest recLSN in PDT.\n- For each update log record or CLR with a given LSN, redo the action unless:\n\t– Affected page is not in the DPT, or\n\t– Affected page is in DPT but that record’s LSN is greater than smallest recLSN, or \n\t– Affected pageLSN (on disk) ≥ LSN.\n- To redo an action:\n\t– Reapply logged action.\n\t– Set pageLSN to log records LSN.\n\t– At the end of the redo phase, write TXN-END log records for all transactions with status “C” and remove them from the ATT.\n\nUndo Phase:\n\n- Undo All transactions active at the time of crash\n- These are all transactions with “U” status in the ATT after the Analysis phase \n- Process them in reverse LSN order using the lastLSN to speed up traversal\n- Write a CLR for every modification","n":0.029}}},{"i":166,"$":{"0":{"v":"Consistency","n":1},"1":{"v":"\n# Weak consistency\n\nAfter a write, reads may or may not see it. A best effort approach is taken.\n\nThis approach is seen in systems such as memcached. Weak consistency works well in real time use cases such as VoIP, video chat, and realtime multiplayer games. For example, if you are on a phone call and lose reception for a few seconds, when you regain connection you do not hear what was spoken during connection loss.\n\n# Eventual consistency\n\nAfter a write, reads will eventually see it (typically within milliseconds). Data is replicated asynchronously.\n\nThis approach is seen in systems such as DNS and email. Eventual consistency works well in highly available systems.\n\n# Strong consistency\n\nAfter a write, reads will see it. Data is replicated synchronously.\n\nThis approach is seen in file systems and RDBMSes. Strong consistency works well in systems that need transactions.","n":0.085}}},{"i":167,"$":{"0":{"v":"Cap","n":1},"1":{"v":"\n# CAP theorem: Consistency, Availability, Partition Tolerant. \n\nConsistency: If master says the txn committed, then it should be immediately visible on replicas. \n\nAvailability: Achieving availability in a distributed system requires that the system remains operational 100% of the time. \n\nPartition TOLERANCE means tolerance to a network partition. A network partition is when two nodes can't talk to each other, but there are clients able to talk to either one or both of those nodes.\n\n\n- By consistency we mean that all participating systems share the same view of the data.\n- By **Availability** we mean that the system is able to **respond quickly** enough for the user's needs.\n- By **Partition** tolerance we mean that, in the event of the failure or isolation of some participants, the other participants can continue to do whatever they can.\n- CA : mysql\n- CP: commuication among server to get consistence but not availability\n- PA: several servers but no consisitence\n\nNetworks aren't reliable, so you'll need to support partition tolerance. You'll need to make a software tradeoff between consistency and availability.\n\nCP - consistency and partition tolerance\nWaiting for a response from the partitioned node might result in a timeout error. CP is a good choice if your business needs require atomic reads and writes.\n\nAP - availability and partition tolerance\nResponses return the most readily available version of the data available on any node, which might not be the latest. Writes might take some time to propagate when the partition is resolved.\n\nAP is a good choice if the business needs allow for eventual consistency or when the system needs to continue working despite external errors.\n\n![](https://qph.fs.quoracdn.net/main-qimg-23a75bd8c77d030f3ca9e1fd0621c10c.webp)\n![](http://www.andrew.cmu.edu/course/14-736/applications/ln/dividework.jpg)\n![](http://www.andrew.cmu.edu/course/14-736/applications/ln/addcomm.jpg)","n":0.062}}},{"i":168,"$":{"0":{"v":"Basic","n":1},"1":{"v":"\n\n# Classical Non-Distributed Concurrency Control \n\n## spin-lock\n\n- **what**:Atomic compare-and-swap/test-and-set instructions\n- **why**: easy\n- **how**: Requires locking memory bus on multi-core/multi-processor\n- **problem**:Busy wait not good for high contention. busy-waiting, busy-looping or spinning is a technique in which a process repeatedly checks to see if a condition is true, such as whether keyboard input or a lock is available.\n\n## mutex\n\n- **what**:Semaphores, At-Most-N policies,Mutual Exclusion\n- **why**:Conceptually,manages a pool of resources.\n- **how**:\n    - P operation: Wait for resource to be available (lock s-=1)\n    - V operation: Make resource available (unlock s+=1)\n    - Deschedule (move to blocked queue) blocked thread or process \n    - Reschedule (move to ready queue) when resource available\n    - 初始s=1，s不会是负值\n\n## CONDITION VARIABLES\n\nEvent based \n\n- Wait – always waits. No predicate\n- Signal – Wake up a waiter\n- Broadcast – Wake up all waiters.","n":0.088}}},{"i":169,"$":{"0":{"v":"TOCC","n":1},"1":{"v":"\nTimestamp ordering (T/O) is an optimistic class of concurrency control protocols where the DBMS assumes that transaction conflicts are rare. DBMS instead uses timestamps to determine the serializability order of transactions. Timestamp could allocate using system lock, logical counter and hybrid.\n\nFor every database object X is tagged with timestamp of the last transaction that successfully did read/write. W-TS(X) and R-TS(X). If transaction tries to access an object “from the future”, then the DBMS aborts that transaction and restarts it.\n\nIn read operations, if $TS(T_i)$ < W-TS(X), the transaction will read a value that was already overwritten and this transaction will be rejected and abort, restart with same TS. If $TS(T_i)$ >= W-TS(X), it allows $TS(T_i)$ to read X and update R-TS(X). Depends on isolation levels, it can make a local copy of X to ensure repeatable reads for $T_i$.\n\nIn write operations, if $TS(T_i)$ < W-TS(X) or if $TS(T_i)$ < R-TS(X), it tries to write an obsolete value or the value needed is in the past. Transaction will be aborted and roll back. Else it could write X and update W-TS(X).\n\nFor Thomas Write Rule\n\nIf $TS(T_i)$ < R-TS(X), it will abort and restart. If $TS(T_i)$ < W-TS(X), ignore the write and allow transaction to continue. It make use of view serializability, deleting obsolete write operations from the transactions that issue them. \n\nThe basic timestamp ordering cannot have deadlocks because no transaction ever waits. But there is a possibility of starvation for long transactions if short transactions keep causing conflicts.\n\nIt also permits schedules that are not **recoverable**. A schedule is recoverable if transactions commit only after all transactions whose changes they read or commit. Otherwise, the DBMS cannot guarantee that transactions read data that will be restored after recovering from a crash.\n\nIssues:\n\n- High overhead from copying data to transaction’s workspace and from updating timestamps.\n- Long running transactions can get starved: The likelihood that a transaction will read something from a newer transaction increases.\n- Suffers from the timestamp allocation bottleneck on highly concurrent systems.","n":0.055}}},{"i":170,"$":{"0":{"v":"MVCC","n":1},"1":{"v":"# Multi-Version Concurrency Control\n\nThe DBMS maintains multiple physical versions of a single logical object in the database. When a transaction writes to an object, the DBMS creates a new version of that object. When a transaction reads an object, it reads the newest version that existed when the transaction started.\n\nThe key properties: Writers don’t block the readers. Readers don’t block the writers. Read-only transactions can read a consistent snapshot without acquiring locks. Timestamps are used to determine visibility. It supports time-travel queries. \n\nVersion storage will help DBMS decide how to store different physical versions of a logical object. The DBMS uses the tuple’s pointer field to create a version chain per logical tuple. Indexes always point to the head of the chain. A thread traverses chain until you find the version thats visible to you. \n\n- Append-Only Storage – New versions are appended to the same table space.\n\t- Oldest-To-Newest (O2N): Append new version to end of chain, look-ups require entire chain traversal.\n\t- Newest-To-Oldest (N2O): Head of chain is newest, look-ups are quick, but indexes need to be up- dated every version.\n- Time-Travel Storage – Old versions are copied to separate table space.\n- Delta Storage – The original values of the modified attributes are copied into a separate delta record space.\n\nGarbage Collection: The DBMS needs to remove reclaimable physical versions from the database over time. \n\n- Tuple Level Garbage Collection – Find old versions by examining tuples directly\n\t- Background Vacuuming: Separate threads periodically scan the table and look for reclaimable ver- sions, works with any version storage scheme.\n\t- Cooperative Cleaning: Worker threads identify reclaimable versions as they traverse version chain. Only works with O2N.\n- Transaction Level – Each transaction keeps track of its own read/write set. When a transaction completes, the garbage collector can use that to identify what tuples to reclaim.\n\nIndex Management: All primary key (pkey) indexes always point to version chain head. \n- Logical Pointers – Use a fixed identifier per tuple that does not change. Requires an extra indirection layer that maps the logical id to the physical location of the tuple\n- Physical Pointers – Use the physical address to the version chain head","n":0.053}}},{"i":171,"$":{"0":{"v":"ACID","n":1},"1":{"v":"\n\nACID:\n\n- Atomicity: all actions in the transaction happen or none happen.\n- Consistency: if each transaction is consistent and database is consistent in the beginning, it is guaranteed to be consistent when the transaction completes.\n- Isolation: the execution of one transaction is isolated from that of other transactions.\n- Durability: If a transaction commits, then its effects on the database persist.\n\nFor atomicity, there are two ways: shadow paging or logging. DBMS makes copies of pages and transaction make changes to those copies, only become visible when the transaction commits. DBMS could logs all actions so that it can undo the actions of aborted transactions. \n\nFor consistency, DBMS will make sure it return correct results. Database consistency means it can accurately represents the real world entity and the future transaction could see the effect of past committed transaction correctly. Transaction consistency make sure DB consistency after executing transaction.\n\nFor Isolation, transaction will not see other concurrent transaction's effect. It is equivalent to a system where transactions are executed in serial order. That's why we need concurrency control. It tells DBMS how to interleaving of operations from multiple transactions. There are two categories of concurrency control: pessimistic and optimistic. Pessimistic assume transactions will conflict, optimistic will assume conflicts are rare.\n","n":0.07}}},{"i":172,"$":{"0":{"v":"2PL","n":1},"1":{"v":"\nWe need to make all executes are correct without knowing the entire schedule ahead of time, using locks to protect database objects could make it work. **Two lock types: Shared lock and exclusive lock**. Locks are requested by transactions from the lock manager. The lock manager grants or block requests based on what locks are currently held by other transactions. Transaction will release lock when they do not need them. The lock manager updates its internal lock-table and then gives locks to waiting transactions. \n\nTwo phase locking is **pessimistic** concurrency control protocol. **The first phase is growing phase, each transaction requests the locks that it needs from the DBMS's lock manager. The second phase is shrinking phase, transaction enters this phase when it releases its first lock**. It cannot acquire new locks in this phase. The problem is **cascading aborts**(why?), when one transaction aborts, another transaction must be rolled back. Some schedule is serializable but not allowed by 2PL. S**trict 2PL means the transaction only releases exclusive-modes locks when it finishes**. Rigorous will take all lock until finishes. A schedule is strict if a value **written** by a transaction is not read or overwritten by other transactions until that transaction finishes. There is no cascading aborts here. \n\nBut it is possible to have deadlock in 2PL. A deadlock is a cycle of transactions waiting for locks to be released by each other. Deadlock detection will create a waits-for graph. Edge from $T_i$ to $T_j$ means $T_i$ is waiting $T_j$. The system will periodically check for cycles in waits-for graph and then make a decision on how to break it. When the DBMS detects a deadlock, it will select a “victim” transaction to rollback to break the cycle. DBMS can also decide the rollback length, it could just roll back.\n\nDeadlock prevention will prevent transaction waiting a transaction. Assign priorities based on timestamps, older means higher. These schemes guarantee no deadlocks because only one type of direction is allowed when waiting for a lock. When a transaction restarts, its (new) priority is its old timestamp.\n\n- Wait-Die (“Old waits for Young”): If T1 has higher priority, T1 waits for T2. Otherwise T1 aborts \n- Wound-Wait (“Young waits for Old”): If T1 has higher priority, T2 aborts. Otherwise T1 waits.\n\nWe could use a use a lock hierarchy that allow a transaction to take more coarse-grained locks in the system. Intention locks allow a **higher level node** to be locked in shared or exclusive mode without having to check all descendant nodes. If a node is in an intention mode, then **explicit locking is being done at a lower level**.\n\n\n- Intention-Shared (IS): Indicates explicit locking at a lower level with shared locks.\n- Intention-Exclusive (IX): Indicates explicit locking at a lower level with exclusive or shared locks. \n- Shared+Intention-Exclusive (SIX): The subtree rooted at that node is locked explicitly in shared mode and explicit locking is being done at a lower level with exclusive-mode locks.\n","n":0.045}}},{"i":173,"$":{"0":{"v":"2PC","n":1},"1":{"v":"\n# 2 phase commit\n\nIn two-phase commit, phase 1 is prepare, when receive commit request, it sends two all participants Ready? And wait for ok back. Then phase 2 is commit and wait for OK, then send SUCCESS to application server. If there is ABORT, it will send back to application server with ABORT and send ABORT to participants in phase 2. \n\nThe improvement is using Early Prepare Voting(using when it is the last one, return the result is the transaction result), Early Acknowledgement After Prepare (If all votes to commit a ten, it can send acknowledgement to client before phase 2 finishes). Two-Phase Commit will block if coordinator fails after the prepare message is sent, until coordinator recovers.\n\n## pharse1\n### Coordinator \n\n- Precommit (write to log and.or atomic storage)\n- Send request to all participants\n- Coordinator blocks waiting for ALL replies\n\n\n### Participant\n\n - Wait for request\n - Upon request, if ready:\n    - Precommit\n    - Send coordinator YES \n - Upon request, if not ready:\n    - Send coordinator NO\n\n## pharse2\n\n### Coordinator \n\n- This is the point of no return!\n- If all participants voted YES then send commit to each participant \n- Otherwise send ABORT to each participant\n\n\n### Participant\n\nWait for \"the word\" from the coordinator\n- If COMMIT, then COMMIT (transaction becomes visible)\n- If ABORT, then ABORT (gone for good)\n\n\nAnother real-world atomic commit protocol is three-phase commit (3PC). This protocol can reduce the amount of blocking and provide for more flexible recovery in the event of failure.\n\n\n![](http://www.andrew.cmu.edu/course/14-736/applications/ln/2pc-coord.jpg)\n![](http://www.andrew.cmu.edu/course/14-736/applications/ln/2pc-part.jpg)\n\n![](http://www.andrew.cmu.edu/course/14-736/applications/ln/3pc-coord.jpg)\n![](http://www.andrew.cmu.edu/course/14-736/applications/ln/3pc-part.jpg)\n","n":0.064}}},{"i":174,"$":{"0":{"v":"CDN","n":1},"1":{"v":"\n\n![](/assets/images/2021-03-25-17-04-36.png)\n\n![](/assets/images/2021-03-25-16-59-58.png)\n\n- FNA 只有static content， untrust environment\n- PoP point of presence\n\n![](/assets/images/2021-03-25-17-08-48.png)\n\n![](/assets/images/2021-03-25-17-12-24.png)\n\n![](/assets/images/2021-03-25-17-15-31.png)\n\n![](/assets/images/2021-03-25-17-19-05.png)\n\n\n![](/assets/images/2021-06-30-17-11-41.png)\n\n![](/assets/images/2021-06-30-17-21-16.png)\n\n![](/assets/images/2021-06-30-17-29-33.png)\n## real life\n\n- aws cloud front","n":0.258}}},{"i":175,"$":{"0":{"v":"Cache","n":1},"1":{"v":"\n# memcache\n\n![](/assets/images/2021-03-26-13-03-11.png)\n\n## memcached\n\n- **what**:使用LRU的一个巨大的hashtable。定时遗忘，high throughput\n- **why**：集合很多web server 的内存, use memory is fast and low latency\n- **how**: 出问题回disk找\n- **problem**：没有稳定的存储\n- handle common problem, much simple\n- Designed for volatile data\n    - failure: just go to disk\n    - recovery: just turn back on and wait. repopulated again\n\n# redis\n\nREmote DIctionary SErver\n\n- **what**: 支持多种数据类型，LRU，稳定存储\n- **why**: 解决同样的问题\n- **how**：定时写回disk，持久。\n    - simple client: ask any node and get redirected.(redirected may take long time)\n    - smart client: know the map, return this to the client(map maybe useless later)\n\n\n","n":0.113}}},{"i":176,"$":{"0":{"v":"Computer","n":1},"1":{"v":"\n# kernel\n\n![](/assets/images/2021-05-11-19-38-22.png)","n":0.707}}},{"i":177,"$":{"0":{"v":"Shell","n":1},"1":{"v":"\n# shell\n\n## execute\n\nshell首先检查命令是否是内部命令，若不是再检查是否是一个应用程序（这里的应用程序可以是Linux本身的实用程序，如ls和rm，也可以是购买的商业程序，如xv，或者是自由软件，如emacs）。然后shell在搜索路径里寻找这些应用程序（搜索路径就是一个能找到可执行程序的目录列表）。如果键入的命令不是一个内部命令并且在路径里没有找到这个可执行文件，将会显示一条错误信息。如果能够成功找到命令，该内部命令或应用程序将被分解为系统调用并传给Linux内核。","n":0.577}}},{"i":178,"$":{"0":{"v":"Service_management","n":1},"1":{"v":"\n# systemd\n\nsystemd allows you to create and manage services in extremely powerful and flexible ways. \n\n## Unit files\n\nIf you're creating a brand new unit file for your service, you must first come up with a name. The name you select must not collide with any existing service name.\n\nCreate your service's unit file with the \".service\" suffix in the /etc/systemd/system directory. In our example, we will be creating a /etc/systemd/system/myservice.service file.\n\nThe first thing you must identify is what type of service you will be managing. Most services should use the simple type, which means a program that runs in the foreground. If your service normally runs itself in the background, search the documentation to see if it has an option to disable that. Running in the foreground is preferred.\n\n## command \n\n- systemctl start service\n- systemctl status 命令查看一下该服务的状态\n- 终止正在运行的服务，需要执行systemctl stop命令\n\n[reference](https://www.ruanyifeng.com/blog/2016/03/systemd-tutorial-part-two.html)","n":0.085}}},{"i":179,"$":{"0":{"v":"Program","n":1},"1":{"v":"\n# how to get executable\n\n*.c -> *.i (ASCII中间文件) -> *.s (汇编) -> *.o (relocatable object file) -> ld -> prog (executable object file)\n\nlinux 调用loader把prog代码和数据复制到内存，然后转移到程序开头。\n\n","n":0.204}}},{"i":180,"$":{"0":{"v":"Linker","n":1},"1":{"v":"\n# 主要功能\n\n1. 符号解析：将符号应用和符号定义关联起来\n2. 重定位：生成从地址0开始的代码和数据节\n\n## ELF (object file)\n\nexecutable and linkable format\n\n![](/assets/images/2021-04-21-22-03-08.png)\n\n. text The machine code of the compiled program .\n\n. rodata Read-only data such as the format strings in printf statements, and jump tables for switch statements.\n\n. data Initialized global and static C variables. Local C variables are maintained at run time on the stack and do not appear in either the .data or .bss sections.\n\n. bss Uninitialized global and static C variables, along with any global or static variables that are initialized to zero. This section occupies no actual space in the pbject file; it is merely a placeholder.\n\n. symtab A symbol table with information about functions and global variables that are defined and referenced in the program. \n\n. rel.text •A list of locations in the .text section that will need to be modified **when the linker combines this object file with others**. In general, any instruction that calls an external function or references a global variable will need to be modified. On the other hand, instructions that call local functions do not need to be modified. Note that relocation information is not needed in executable object files, and is usually omitted unless the user explicitly instructs the linker to include it.\n\n. rel.data Relocation information for any **global variables** that are referenced or defined by the module. In general, any initialized global variable whose initial value is the address of a global variable or externally defined function will need to be modified.\n\n. debug A debugging symbol table with entries for local variables and typedefs defined in the program, global variables defined and referenced in the program, and the original C source file. It is only present if the compiler driver is invoked with the -g option .\n\n. line A mapping between line numbers in the original C source program and machine code instructions in' the . text section. It is only pre~~nt if the ,.compiler driver is invoked with the -g option .\n\n. strtab A string table for the symbol tables in the . symtab and . debug sections and for. the section names in the section headers. A string table is a sequence of null-terminated character strings.\n\n\n## 符号和符号表\n\n- Global symbols that are defined by module m and that can be referenced by other modules.\n- Global symbols\"that are referenced by module m but defined by some other module.\n- Local symbols that are defined and referenced exclusively by module m.\n\n在符号解析时，编译器不会报错，认为这个函数定义在其他地方，linker在链接时找不到会报错\n\nRule 1. Multiple strong symbols with the same name are not allowed.\n\nRule 2. Given a strong symbol and multiple weak symbols with the same name, choose the strong symbol.\n\nRule 3. Given multiple weak symbols with the same name, choose any of the weak symbols.\n\n## 静态库 \n\n相关函数编译为独立的目标模块，封装成单独的静态库文件。linker值复制被程序引用的目标模块，减少了可执行文件在磁盘和内存中的大小。\n\n*.a 存档文件 -> *.o 只有相关的函数\n\n![](/assets/images/2021-04-21-22-09-54.png)\n\n## 动态库\n\n目标模块在运行或加载时，可以加载到任意内存地址。在静态链接时需要加载一些symbol table\n\n![](/assets/images/2021-04-21-22-11-14.png)\n\n## 重定位\n\n- 合并节和符号定义\n- 重定位符号引用\n\n\n## executable file\n\n![](/assets/images/2021-04-21-22-12-36.png)\n\n![](/assets/images/2021-04-21-22-12-54.png)\n\nEach' program in a Linux , system runs in the context of a process with its own virtual address space. When the shell runs a program, the parent shell process forks a child process that is a duplicate of the parent. The child process invokes the loader via the execve system call. The loader deletes the child's existing virtual memory segments and creates a neW set of code, data, heap, and stack segments, The new stack and heap segments are initialized to zero. The new code and data segments are initialized to the contents of the executable file by mapping pages in the virtual address space to page-size chunks of the executable file. Finally, the loader jumps to the start address, which eventually calls the application's main routine. Aside from some header information, there is no copying of data from disk to memory during loading. The copying is deferred until the CPU referencb a mapped virtual page, at which point the operating system automatically transfers the page from disk to memory using its paging mechanism.","n":0.04}}},{"i":181,"$":{"0":{"v":"Pipeline","n":1},"1":{"v":"\n执行一条命令有以下几步\n\n1. Instruction fetch\n2. Instruction decode and register fetch\n3. Execute\n4. Memory access\n5. Register write back\n\n\n## 分支预测\n\n## 加stall避免数据race","n":0.25}}},{"i":182,"$":{"0":{"v":"Multitask","n":1}}},{"i":183,"$":{"0":{"v":"Process","n":1},"1":{"v":"\n# process\n\n![](/assets/images/2021-05-11-20-16-21.png)\n\n是执行中程序的实例，系统中的每一个程序都运行在某个进程的上下文中，上下文是由程序正确运行所需状态组成的，这个状态包括存放内存中程序的代码和数据，它的栈，通用目的寄存器的内容，程序计数器，环境变量，以及打开文件描述符的集合。每次用户通过shell输入一个可执行目标文件，shell就会创建新的进程。\n\nThe classic definition of a process is an instance of a program in execution. Each program in the system runs in the context of some process.The context consists of the state that the program needs to run correctly. This state includes the program's code and data stored in memory, its stack, the contents of its general-purpose registers, its program counter, environment variables, and the set of open file descriptors.\n\n进程是一个独立的逻辑控制流，轮流使用处理器的，每个进程执行流的一部分，然后被强占（preempted）,暂时被挂起。time slicing, concurrency\n\n每个process有私有的地址空间，代码段都从0x400000开始。\n\n内核调度一个新的进程，运行之后，它就会抢占当前进程，并使用一种上下文切换机制来将控制转移到新进程中。\n\n进程控制：获取进程id。进程有三种状态：运行，停止(suspended) 收到SIGSTOP, SIGTSTP,SIGTTIN or SIGTTOU，直到收到SIGCONT继续。终止，收到终止进程的信号，从主程序返回，调用exit函数。\n进程创建用fork， 当一个进程由于某种原因终止时，内核并不是立刻把它从系统中清除，相反进程将会，被保持在一种已经终止的状态，直到被父进程回收。waitpid 等待子进程终止。进程休眠就是sleep。\n\n加载并运行程序使用execve函数。execve调用一次从不返回。加载filename之后，调用启动代码，设置栈，将控制传递给新程序的main。\n\nthe typical difference is that **threads** (of the same process) run in a **shared memory space**, while processes run in separate memory spaces. thread有自己的tid，栈，sp，pc，general register and flag, **the code, data and heap areas are shared**\n\n\n## process control\n\n- run \n- suspend: A process stops as a result of receiving a SIGSTOP, SIGTSTP, SIGTI1N, or SIGTTOU signal, and it remains stopped until it receives a SIGCONT signal, at which point it becomes running again. \n- terminate： exit\n\n![[dendron://my_note/development.computer.call.fork]]\n## context switch\n\n![](/assets/images/2021-04-25-23-04-15.png)\n\nregisters是唯一被所有过程共享的资源，当调用时，把所有原始值压入栈中，改变寄存器的值，在返回之前从栈中弹出旧值。\n\nIt consists of the values of objects such as the general-purpose registers, the floating-point registers, the program counter, user's stack, status registers, kernel's stack, and various kernel data structures such as a page table that characterizes the address space, a process table that contains information about the current process, and a file table that contains information about the files that the process has opened.\n\nContext Switch 流程：上下文切换，第一，保存当前进程的上下文，第二，恢复某个先前被抢占的进程，被保存的上下文，第三，将控制传递给这个新恢复的进程。\n(1) saves the context of the current process, (2) restores the saved context of some previously preempted process, and (3) passes control to this newly restored process.\n \nThe context is the state that the kernel needs to restart a preempted process. It consists of the values of objects such as the **general-purpose registers, the floating-point registers, the program counter, user's stack, status registers, kernel's stack, and various kernel data structures such as a page table that characterizes the address space, a process table that contains information about the current process, and a file table that contains information about the files that the process has opened**.\n\n## zombie process\n\nZombie process\nwhat is zombie process? When does it become zombie process?\n\n当进程由于某种原因终止时，内核不会立即清除，而是保持在一种已经终止的状态直至被父进程回收，一个终止未被回收的叫zombie。用waitpid函数等待子进程终止或停止。\n\nOn Unix and Unix-like computer operating systems, a zombie process or defunct process is a process that has completed execution (via the exit system call) but **still has an entry in the process table**: it is a process in the \"Terminated state\". This occurs for child processes, where the entry is still needed to allow the parent process to read its child's exit status: once the exit status is read via the wait system call, the zombie's entry is removed from the process table and it is said to be \"reaped\".\n","n":0.049}}},{"i":184,"$":{"0":{"v":"Signal","n":1},"1":{"v":"\n# signal\n\n![](/assets/images/2021-04-25-23-16-50.png)\n\n\n**信号允许进程和内核中断其他进程**，一个信号就是一条消息，他通知进程系统中发生了一个某种类型的事件。ctrl+c 是sigint， 终止信号是sigkill，ctrlz是 sigtstp。 发送信号可以用kill函数以及内核检测到一个系统事件。sigkill和sigstop不能捕捉，忽略和修改默认行为。\n\n信号处理程序，任何进程只能收到一个信号，并处理一个信号，如果一个进程有一个带出的信号，但是有其他的信号要被接收，都不会排队等待而简单的被抛弃。临时阻塞信号可以用sigprocmask。\n\nIn eval, the parent must use sigprocmask to block SIGCHLD, SIGINT, and SIGTSTP signals before it forks the child, and then unblock these signals, again using sigprocmask after it adds the child to the job list by calling addjob. Since children inherit the blockedvectors of their parents, the child must be sure to then unblock these signals before it executes the new program. The child should also restore the default handlers for the signals that are ignored by the shell.\n\n\n","n":0.108}}},{"i":185,"$":{"0":{"v":"Memory","n":1},"1":{"v":"\n[reference](https://gywbd.github.io/posts/2016/1/segmentation-fault.html)\n\n# phycical memory\n\n\nstack（栈）是一块用于保存函数调用信息——传递的参数、每个函数的本地变量的内存区域\n\nheap（堆）是一块程序可以任意使用的内存区域，程序员有完全自由的权限对这个区域进行任何想要的操作\n\nstack部分的大小在程序运行过程中是可变的。当函数调用发生时，stack就会扩大，当函数调用结束时：之前扩大的stack就会缩小为调用之前的样子\nheap同样也是一个大小可变的区域，当程序员从heap中请求内存（malloc()）时，heap就会扩大，当这些内存被释放后（free()），heap就会缩小。\nstack和heap都是可伸缩的区域，它们处于整个地址空间中的相对位置：stack会向下扩展（由高地址到低地址），而heap则会向上扩展（由低地址到高地址）。它们都是可以自由增长的区域，只是增长的方向刚好相反。操作系统只需要检查这两个区域不会出现重叠的情况，这是它们主要的使用限制。\n\n![](/assets/images/2021-04-05-23-02-01.png)\n\n# virtaul memory\n\nThe virtual memory abstracts the details of physical memory from the application software, allows to keep only needed information in the physical memory (demand paging) and provides a mechanism for the protection and controlled sharing of data between processes.\n\n虚拟内存提供三个重要的能力，第一个把主存看作一个存储在磁盘上地址空间的高速缓存，在主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据，通过这种方式高效的使用的主存，第二点，他为每个进程提供了一致的地址空间，从而简化了内存管理，第三它保护了每个进程地址空间，不被其他进程破坏。\n\n虚拟内存其实是在磁盘上，需要用的时候放到主存里。每个虚拟地址指向一个PTE, 包含有效位以及物理页号或者磁盘地址。缓存不命中是缺页，调用缺页异常处理程序，选择一个页面换成需要的页面。之后重新启动缺页异常的指令。重新地址翻译。可以利用TLB加速地址翻译或者使用多级页表。\n\n## 缓存的工具\n\n每个字节有唯一的虚拟地址。\n\nvirutal page有三种类型\n\n- 未分配的：VM系统中未分配的页，不占任何磁盘空间\n- 缓存的：当前已缓存的在物理内存中的已分配页\n- 未缓存的：未缓存在物理内存中的已分配页\n\n![](/assets/images/2021-05-03-19-20-38.png)\n\nDRAM 比 SRAM(L1,L2,L3)慢10倍，虚拟页比较大。, DRAM caches always use write-back instead of write-through.\n\nIn write through, data is simultaneously updated to cache and memory. \nwrite back: The data is updated only in the cache and updated into the memory in later time. \n\n通过mmu, 页表(page table)判断一个虚拟页是否缓存在DRAM中的某一个地方，mmu把VP->PP\n\nPTE(page table entry) 有效位表明当前VP是否缓存在DRAM\n\n![](/assets/images/2021-05-03-19-25-39.png)\n\n页命中：如果有效，可以获得物理地址\n\n缺页：page fault，调用内核缺页处理程序。程序选择一个牺牲页，修改DRAM，把磁盘里的VP复制到DRAM，重新启动缺页的指令，把导致缺页的虚拟地址重新发到MMU，命中。\n\nThe activity of transferring a page between disk and memorf is known as swapping or paging. Pages are swapped in (paged in) from disk to DRAM, anct swapped out (paged out) from DRAM to disk\n### swap\n\n- What is swap, when will it be used?\nSwap space is located on hard drives for inactive pages in memory\nSwapping is the process whereby a page of memory is copied to the preconfigured space on the hard disk,\ncalled swap space, to free up that page of memory.\n\n- What's the situation that a process will swap\nSwap space in Linux is used when the amount of physical memory (RAM) is full.\nIf the system needs more memory resources and the RAM is full,\ninactive pages in memory are moved to the swap space.\n\n- What's the down side of swap?\nSwap space is located on hard drives, which have a slower access time than physical memory.\n \n## 内存管理\n\n不同进程里的VP可以共享一个PP。简化linking，loading，share，内存分配\n\n两个进程将私有对象映射到它们的虚拟内存的不同区域，但是共享这个对象，统一个物理副本，对于每个应设是有对象的进程，相应的所有区域的业表条目都被标记为只读，并且区域结构被标记为私有的写时复制。只要没有进程，试图修改他们自己的私有区域，他们就可以继续共享物理内存对象的一个单独副本，但是只要有一个进程，试图写私有区域内的某个页面，他就会复制一个新的，在那个里面写。\n\n## 内存保护\n\n在page table有许可位，判定这个page的访问权限。\n\n## 地址翻译 mmu\n\nMMU memory management unit.\nThe mapping between virtual address and physical address.\n\n![](/assets/images/2021-04-05-22-38-37.png)\n\n当一个用户级进程想访问一些内存，它会产生一个访问请求，MMU会把请求的虚拟地址转换为对应的物理内存地址。但是如果这个地址访问存在错误：转换后的物理地址超出了物理段的界限，或者违反了段保护权限（例如请求向只读段中写入数据），此时默认情况下操作系统会产生一个表示需要进行错误处理的信号：SIGSEGV，对这个信号的默认处理行为（default handler）是杀死（kill）这个进程，并且输出一个消息：“Segmentation fault”。\n\n![](/assets/images/2021-05-03-19-35-51.png)\n## TLB\n\n快速重编址缓冲器（Translation-lookaside Buffer : TLB）\n\n在每次虚拟内存访问时都会使用MMU，它会先从地址中提取出VPN，然后根据这个VPN查找TLB中是否有对应的VPN。如果命中（hit），它会直接返回TLB中记录的对应的物理地址，完成它的使命。如果没有命中（miss），那么它会查找进程的页表，如果对这个物理地址的访问是合法的，那么它会更新TLB，那么之后再访问这个虚拟地址，就会命中了。\n\n![](/assets/images/2021-05-03-19-36-10.png)\n\n## multi-level page table\n\n![](/assets/images/2021-05-03-19-42-35.png)\n\n## os\n\n- 不同进程共享同一个物理page\n- 写时复制，一开始指向同一个，改变一个的时候copy另一个\n\n![](/assets/images/2021-05-03-19-46-33.png)\n\n### heap\n\n![](/assets/images/2021-05-03-19-47-09.png)\n\n- malloc\n- free\n\n在头部和尾部都有a/f表示 上一个/下一个是不是allocate，常数时间合并空闲块\n\n### 垃圾收集\n\nA garbage collector is a dynamic storage allocator that automatically frees allocated blocks that are no longer needed by the program.\n\n有一些根节点可以到达堆节点\n\n![](/assets/images/2021-05-03-19-50-10.png)","n":0.059}}},{"i":186,"$":{"0":{"v":"Namespace","n":1},"1":{"v":"\n# kernal space, user space\n\n为什么Kernel和User Space 分开（因为安全啊）。为什么Kernel不能只检查User 是否有call system function的权限（因为还要检查user 是否还要touch合法的地址，参数类型等，反例是buffer overflow） \n \nKernel space is where the kernel (i.e., the core of the operating system) executes (i.e., runs) and provides its services.\n \nUser space is that set of memory locations in which user processes (i.e., everything other than the kernel) run. A process is an executing instance of a program. One of the roles of the kernel is to manage individual user processes within this space and to prevent them from interfering with each other.\n \nProcessors typically provide this capability with a mode: bit in some control register that characterizes the privileges that the process currently enjoys. When the mode bit is set, the process is running in kernel mode (sometimes called supervisor mode). A process running in kernel mode can execute any instruction in the instruction and access any memory location in the system.","n":0.083}}},{"i":187,"$":{"0":{"v":"Io","n":1},"1":{"v":"\n# file\n\nfile是一个m个字节的序列。所以I/O设备被模型化为文件，输入输出变成读和写。\n\n## 打开文件\n\napp通过要求内核打开相应文件，访问一个I/O设备，内核返回一个小的非负整数，叫做描述符。内核记录有关这个文件的信息，app只记住这个描述符。\n\n创建进程都有三个打开的文件，stdin，stdout，stderr。\n\n改变当前文件位置，对于每个打开的文件，内核保持一个文件位置k，是从文件开始的字节偏移量。通过seek设置当前位置k。\n\n## 读写文件\n\n- 读：从文件复制n>0到内存，从当前位置k增加到k+n，当到末尾，触发EOF\n- 写：从内存复制到n>0到一个文件，从k开始\n\n\n# file type\n\n- regular file: text and binary\n- directory: 包含一组link的文件，将filename link to one file。至少包括“.” and “..”\n- socket: 与另一个进程进行网络通讯\n\n\n# 数据结构\n\n![](/assets/images/2021-05-03-19-57-58.png)\n\n- 描述符表： 每个进程独立\n- 文件表：打开文件集合，所有进程共享，当前文件位置，引用计数以及指向v-node表中对应的指针\n- v-node:所有进程共享，包含stat结构中的信息\n\nfor fork\n\n![](/assets/images/2021-05-03-20-05-52.png)\n\n## 重定向\n\ndup2 复制oldfd到newfd，删除老的file table item，新的reference count+=1，老的v-node删除\n","n":0.171}}},{"i":188,"$":{"0":{"v":"Functioncall","n":1},"1":{"v":"\n# 过程\n\n1. 传递过程： 在进入过程Q时，程序计数器设置成Q的代码起始地址，然后在返回时，要把程序计数器设置为P中调用Q后面那条指令的地址。\n2. 传递数据：P必须能向Q提供一个或多个参数，Q必须向P返回一个值\n3. 分配和释放内存。在开始时Q可能需要为局部变量分配空间，而在返回前又释放这些内存。\n\n## 栈\n\n![](/assets/images/2021-04-17-17-39-13.png)\n\n1. 转移控制：把地址A压入栈，PC设置为Q的起始位置\n2. 数据传送：寄存器 %rdi，%rsi，在进入新的过程时压栈。\n3. 本地数据存在栈里","n":0.302}}},{"i":189,"$":{"0":{"v":"Exception_handle","n":1},"1":{"v":"\n# exception\n\n在控制流中的突变，用来响应处理器状态中的变化。\n\n当有事件(event),通过一张异常表的跳转表，进行了一个间接过程调用（异常），到一个专门设计用来处理这类事件的子程序（exception handler)\n\n![](/assets/images/2021-04-25-22-27-49.png)\n\n每种异常有一个异常号，到跳转表。\n\n与过程调用不同，压入栈的可能是当前指令或下一条指令。如果控制从用户->内核，项目压到内核栈而不是用户栈。\n\n## 几种exception\n\n- interrupt: 由I/O 设备信号，异步。I/O 将某个引脚电位拉高，cpu执行完发现电位上升，执行中断放异常号到总线\n- trap：将控制返回下一条，同步，提供用户与内核的系统调用。\n- fault/abort\n  - segment fault: 引用了未定义的虚拟内存区域，尝试写一个只读的文本段\n\n![](/assets/images/2021-04-25-22-34-15.png)\n![](/assets/images/2021-04-25-22-34-24.png)","n":0.267}}},{"i":190,"$":{"0":{"v":"Call","n":1},"1":{"v":"\n# system call\n\nIn computing, a system call is the programmatic way in which a computer program requests a service from the kernel of the operating system it is executed on.\n\n流程：\n\n- Application program makes a system call. When I write the program in ARM. I used SWI instruction. SWI means software interrupt exception. SWI will cause an interrupt. So the kernel will handle this interrupt. The handler is called SWI hander.\n- Stack is used to pass these arguments to the function in the kernel.\n- Each system call has a unique call number which is used by kernel to identify which system call is invoked.\n- Now the SWI handler executes a specific instruction (int 0x80). This instruction causes the processor to switch from 'User Mode' to 'Kernel Mode'\n- kernel invokes system_call() routine\n- This function saves register values onto kernel stack and does some validations like verifying system call number etc.\n- A map of system call number as key and the appropriate system call as value exists. This is called system_call_table. The handler uses this table to invoke appropriate system call service routine. It also validates the arguments if present.\n- After proper validations, the service routine performs required actions. After all these actions, service routine returns status of execution to user mode call.\n","n":0.069}}},{"i":191,"$":{"0":{"v":"Fork","n":1},"1":{"v":"\nsystem call\n\nfork函数调用一次，返回两次，并发执行，**相同但是独立的地址空间**。相同代码和数据段、堆、共享库以及用户栈，共享文件，最大区别是父和子有不同的pid。\n\n对所有fork 拓扑排序，可以得到一个输出顺序。\n\nfork为当前进程调用，是内核，为新进程创建各种数据结构，并分配给他一个唯一的pid.为了给这个新进程创建虚拟内存，它创建当前进程的mm_struct, 区域结构和页表的原样副本，他将两个进程中的每个页面都标记为只读，并将两个进程中每个区域结构都标记为私有的写时复制 copy on write。\n","n":0.378}}},{"i":192,"$":{"0":{"v":"Execve","n":1},"1":{"v":"\n加载并运行可执行目标文件，调用一次从不返回。\n\n\nexecve使用新的程序，有效替代当前程序，加载并运行，可执行目标程序需要以下几个步骤，第一点删除已存在的用户区域，第二点映射私有区域，为新程序区域创建新的区域结构。所以我现在去都是私有的，写时复制的。第三点应设共享区域。还要设置程序计数器，使之指向代码区的入口点。","n":1}}},{"i":193,"$":{"0":{"v":"Cache","n":1},"1":{"v":"\n# cache\n\n用(S, E, B, m)表示，m是计算机的位数，s是组的个数，E是每组E行，B是块的大小\n\n![](/assets/images/2021-04-21-21-54-22.png)\n\nt用来找组里的哪一行\n\ns是组索引\n\nb是块偏移\n\n中位索引可以防止数据被整体换入换出\n# buffer and cache\n\n[link](https://stackoverflow.com/questions/6345020/what-is-the-difference-between-buffer-vs-cache-memory-in-linux)\n \nBuffers are associated with a specific block device, and cover caching of filesystem metadata as well as tracking in-flight pages. The cache only contains parked file data. That is, the buffers remember what's in directories, what file permissions are, and keep track of what memory is being written from or read to for a particular block device. The cache only contains the contents of the files themselves.","n":0.115}}},{"i":194,"$":{"0":{"v":"Boot","n":1},"1":{"v":"\n# boot process\n\n![](/assets/images/2021-04-05-22-42-45.png)\n\nWhat happened when I press the power-on button of Linux operating system, i.e., what happened during the bootstrap process of Linux?\n1. BIOS\n\n- BIOS stands for Basic Input/output System\n- Performs some system integrity checks\n- Searches, loads, and executes the boot loader program.\n- It looks for boot loader in floppy, cd-rom, or hard drive. You can press a key (typically F12 of F2, but it depends on your system) during the BIOS startup to change the boot sequence.\n- Once the boot loader program is detected and loaded into the memory, BIOS gives the control to it. And the boot loader program is MBR, Master Boot Record.\n\n读取其中所存储的程序。这一程序通常知道一些直接连接在主板上的硬件(硬盘，网络接口，键盘，串口，并口)。现在大部分的BIOS允许你从软盘、光盘或者硬盘中选择一个来启动计算机。\n\n2. MBR\n- It is in the 1st sector of the bootable disk.\n- The MBR holds the information on how the logical partitions, containing file systems, are organized on that medium.\n- So MBR will tell computer to read boot loader from one specific partition.\n- Typical boot loader include GRUB, LILO.\n下一步，计算机将从你所选择的存储设备中读取起始的512个字节(bytes)。如果我们从光盘启动的话，那么计算机就会读取光盘最开始的512个字节。这512个字节叫做主引导记录MBR (master boot record)。MBR会告诉电脑从该设备的某一个分区(partition)来装载引导加载程序(boot loader)。引导加载程序储存有操作系统(OS)的相关信息，比如操作系统名称，操作系统内核 (内核)所在位置等。常用的引导加载程序有GRUB和LILO。 \n3. GRUB\n- GRUB stands for Grand Unified Bootloader. It will help us load the kernel.\nGRUB displays a splash screen, waits for few seconds, if you don’t enter anything, it loads the default kernel image as specified in the grub configuration file.\nGRUB has the knowledge of the filesystem (the older Linux loader LILO didn’t understand filesystem).\nGrub configuration file is /boot/grub/grub.conf (/etc/grub.conf is a link to this). The following is sample grub.conf of CentOS.\n\n4. Kernel\n- Kernel executes the /sbin/init program\n- Kernel will reserve some space for itself to run and use driver to detect computer hardware.\n- Then it executes init. init was the 1st program to be executed by Linux Kernel, it has the process id (PID) of 1.\n如果我们加载的是Linux内核，Linux内核开始工作。内核会首先预留自己运行所需的内存空间，然后通过驱动程序(driver)检测计算机硬件。这样，操作系统就可以知道自己有哪些硬件可用。随后，内核会启动一个init进程。它是Linux系统中的1号进程(Linux系统没有0号进程)。到此，内核就完成了在计算机启动阶段的工作，交接给init来管理。\n5. init process\n- Init will run some start up scripts. For example, configure the name of the computer, configure time zone, detect the file system, mount some hard drive, configure the network, activate raid, etc.\n- Then it will give the login dialogue box to prompt login.\n随后，init会运行一系列的初始脚本(startup scripts)，这些脚本是Linux中常见的shell scripts。这些脚本执行如下功能：\n\n设置计算机名称，时区，检测文件系统，挂载硬盘，清空临时文件，设置网络……\n当这些初始脚本，操作系统已经完全准备好了，只是，还没有人可以登录。init会给出登录(login)对话框，或者是图形化的登录界面。\n\nIn Unix-based computer operating systems, init (short for initialization) is the first process started during booting of the computer system. Init is a daemon process that continues running until the system is shut down. It is the direct or indirect ancestor of all other processes and automatically adopts all orphaned processes. Init is started by the kernel during the booting process; a kernel panic will occur if the kernel is unable to start it. Init is typically assigned process identifier 1.\n","n":0.05}}},{"i":195,"$":{"0":{"v":"Cloud","n":1}}},{"i":196,"$":{"0":{"v":"Messaging","n":1}}},{"i":197,"$":{"0":{"v":"Pattern","n":1},"1":{"v":"\n# Asynchronous Request-Reply\n\nDecouple backend processing from a frontend host, where backend processing needs to be asynchronous, but the frontend still needs a clear response.\n\nOne solution to this problem is to use HTTP polling. Polling is useful to client-side code, as it can be hard to provide call-back endpoints or use long running connections. Even when callbacks are possible, the extra libraries and services that are required can sometimes add too much extra complexity.\n\n- The client application makes a synchronous call to the API, triggering a long-running operation on the backend.\n- The API responds synchronously as quickly as possible. It returns an HTTP 202 (Accepted) status code, acknowledging that the request has been received for processing.\n- The response holds a location reference pointing to an endpoint that the client can poll to check for the result of the long running operation.\n- The API offloads processing to another component, such as a message queue.\n- While the work is still pending, the status endpoint returns HTTP 202.\n\n![](/assets/images/2021-05-10-22-21-30.png)\n\n- At some point, the work is complete and the status endpoint returns 302 (Found) redirecting to the resource.\n- The client fetches the resource at the specified URL.\n\n![](/assets/images/2021-05-10-22-21-54.png)\n\n# Claim Check\n\nSplit a large message into a claim check and a payload. Send the claim check to the messaging platform and store the payload to an external service. This pattern allows large messages to be processed, while protecting the message bus and the client from being overwhelmed or slowed down. This pattern also helps to reduce costs, as storage is usually cheaper than resource units used by the messaging platform.\n\n![](/assets/images/2021-05-10-22-26-15.png)\n\nStore the entire message payload into an external service, such as a database. Get the reference to the stored payload, and send just that reference to the message bus. The reference acts like a claim check used to retrieve a piece of luggage, hence the name of the pattern. Clients interested in processing that specific message can use the obtained reference to retrieve the payload, if needed.\n\n# Choreography\n\nHave each component of the system participate in the decision-making process about the workflow of a business transaction, instead of relying on a central point of control.\n\n![](/assets/images/2021-05-10-22-27-37.png)\n\nA client request publishes messages to a message queue. As messages arrive, they are pushed to subscribers, or services, interested in that message. Each subscribed service does their operation as indicated by the message and responds to the message queue with success or failure of the operation. In case of success, the service can push a message back to the same queue or a different message queue so that another service can continue the workflow if needed. If an operation fails, the message bus can retry that operation.\n\n\n# Competing Consumers\n\nEnable multiple concurrent consumers to process messages received on the same messaging channel. This enables a system to process multiple messages concurrently to optimize throughput, to improve scalability and availability, and to balance the workload.\n\n\n![](/assets/images/2021-05-10-22-30-54.png)\n\nThe application posts requests in the form of messages to the queue, and the consumer service instances receive messages from the queue and process them. This approach enables the same pool of consumer service instances to handle messages from any instance of the application.\n\nThis solution has the following benefits:\n\nIt provides a load-leveled system that can handle wide variations in the volume of requests sent by application instances. The queue acts as a buffer between the application instances and the consumer service instances. This can help to minimize the impact on availability and responsiveness for both the application and the service instances, as described by the Queue-based Load Leveling pattern. Handling a message that requires some long-running processing doesn't prevent other messages from being handled concurrently by other instances of the consumer service.\n\nIt improves reliability. If a producer communicates directly with a consumer instead of using this pattern, but doesn't monitor the consumer, there's a high probability that messages could be lost or fail to be processed if the consumer fails. In this pattern, messages aren't sent to a specific service instance. A failed service instance won't block a producer, and messages can be processed by any working service instance.\n\nIt doesn't require complex coordination between the consumers, or between the producer and the consumer instances. The message queue ensures that each message is delivered at least once.\n\nIt's scalable. The system can dynamically increase or decrease the number of instances of the consumer service as the volume of messages fluctuates.\n\nIt can improve resiliency if the message queue provides transactional read operations. If a consumer service instance reads and processes the message as part of a transactional operation, and the consumer service instance fails, this pattern can ensure that the message will be returned to the queue to be picked up and handled by another instance of the consumer service.\n\n# Priority Queue\n\nPrioritize requests sent to services so that requests with a higher priority are received and processed more quickly than those with a lower priority. This pattern is useful in applications that offer different service level guarantees to individual clients.\n\n![](/assets/images/2021-05-10-22-33-12.png)\n\nA queue is usually a first-in, first-out (FIFO) structure, and consumers typically receive messages in the same order that they were posted to the queue. However, some message queues support priority messaging. The application posting a message can assign a priority and the messages in the queue are automatically reordered so that those with a higher priority will be received before those with a lower priority\n\n\n# Publisher-Subscriber\n\nEnable an application to announce events to multiple interested consumers asynchronously, without coupling the senders to the receivers.\n\n![](/assets/images/2021-05-10-22-34-05.png)\n\n# Queue-Based Load Leveling\n\nUse a queue that acts as a buffer between a task and a service it invokes in order to smooth intermittent heavy loads that can cause the service to fail or the task to time out. This can help to minimize the impact of peaks in demand on availability and responsiveness for both the task and the service.\n\n![](/assets/images/2021-05-10-22-35-25.png)\n\n# Scheduler Agent Supervisor\n\nCoordinate a set of distributed actions as a single operation. If any of the actions fail, try to handle the failures transparently, or else undo the work that was performed, so the entire operation succeeds or fails as a whole. This can add resiliency to a distributed system, by enabling it to recover and retry actions that fail due to transient exceptions, long-lasting faults, and process failures.\n\n\n\n![](/assets/images/2021-05-10-22-36-25.png)\n\n- The Scheduler arranges for the steps that make up the task to be executed and orchestrates their operation. \n- The Agent contains logic that encapsulates a call to a remote service, or access to a remote resource referenced by a step in a task. \n- The Supervisor monitors the status of the steps in the task being performed by the Scheduler. It runs periodically (the frequency will be system-specific), and examines the status of steps maintained by the Scheduler. If it detects any that have timed out or failed, it arranges for the appropriate Agent to recover the step or execute the appropriate remedial action\n\n![](/assets/images/2021-05-10-22-37-41.png)\n\n# Sequential Convoy\n\nProcess a set of related messages in a defined order, without blocking processing of other groups of messages.\n\n\nPush related messages into categories within the queuing system, and have the queue listeners lock and pull only from one category, one message at a time.\n\n![](/assets/images/2021-05-10-22-38-54.png)\n\nIn the queue, messages for different categories may be interleaved, as shown in the following diagram:\n\n![](/assets/images/2021-05-10-22-39-00.png)","n":0.029}}},{"i":198,"$":{"0":{"v":"Design","n":1}}},{"i":199,"$":{"0":{"v":"Pattern","n":1},"1":{"v":"\n[reference](https://docs.microsoft.com/en-us/azure/architecture/patterns/category/design-implementation)\n\n# Ambassador\n\nCreate helper services that send network requests on behalf of a consumer service or application. An ambassador service can be thought of as an out-of-process proxy that is co-located with the client.\n\nThis pattern can be useful for offloading common client connectivity tasks such as monitoring, logging, routing, security (such as TLS), and resiliency patterns in a language agnostic way. It is often used with legacy applications, or other applications that are difficult to modify, in order to extend their networking capabilities. It can also enable a specialized team to implement those features.\n\nPut client frameworks and libraries into an external process that acts as a proxy between your application and external services. Deploy the proxy on the same host environment as your application to allow control over routing, resiliency, security features, and to avoid any host-related access restrictions. You can also use the ambassador pattern to standardize and extend instrumentation. The proxy can monitor performance metrics such as latency or resource usage, and this monitoring happens in the same host environment as the application.\n\n![](/assets/images/2021-05-09-23-18-43.png)\n\n![](/assets/images/2021-05-10-21-02-50.png)\n\n# Anti-Corruption Layer pattern\n\nThis layer translates requests that one subsystem makes to the other subsystem. Use this pattern to ensure that an application's design is not limited by dependencies on outside subsystems. \n\nIsolate the different subsystems by placing an anti-corruption layer between them. This layer translates communications between the two systems, allowing one system to remain unchanged while the other can avoid compromising its design and technological approach.\n\n![](/assets/images/2021-05-10-21-04-52.png)\n\nUse this pattern when:\n\n- A migration is planned to happen over multiple stages, but integration between new and legacy systems needs to be maintained.\n- Two or more subsystems have different semantics, but still need to communicate.\n\n# Backends for Frontends pattern\n\nCreate separate backend services to be consumed by specific frontend applications or interfaces. \n\n![](/assets/images/2021-05-10-21-16-24.png)\n\nBecause each backend is specific to one interface, it can be optimized for that interface. As a result, it will be smaller, less complex, and likely faster than a generic backend that tries to satisfy the requirements for all interfaces. Each interface team has autonomy to control their own backend and doesn't rely on a centralized backend development team. This gives the interface team flexibility in language selection, release cadence, prioritization of workload, and feature integration in their backend.\n\n# Compute Resource Consolidation pattern\n\nonsolidate multiple tasks or operations into a single computational unit. This can increase compute resource utilization, and reduce the costs and management overhead associated with performing compute processing in cloud-hosted applications.\n\nTasks can be grouped according to criteria based on the features provided by the environment and the costs associated with these features. A common approach is to look for tasks that have a similar profile concerning their scalability, lifetime, and processing requirements. Grouping these together allows them to scale as a unit. The elasticity provided by many cloud environments enables additional instances of a computational unit to be started and stopped according to the workload.\n\n# External Configuration Store pattern\n\nMove configuration information out of the application deployment package to a centralized location. This can provide opportunities for easier management and control of configuration data, and for sharing configuration data across applications and application instances.\n\nStore the configuration information in external storage, and provide an interface that can be used to quickly and efficiently read and update configuration settings. The type of external store depends on the hosting and runtime environment of the application. In a cloud-hosted scenario it's typically a cloud-based storage service, but could be a hosted database or other system.\n\nThe backing store you choose for configuration information should have an interface that provides consistent and easy-to-use access. It should expose the information in a correctly typed and structured format. The implementation might also need to authorize users’ access in order to protect configuration data, and be flexible enough to allow storage of multiple versions of the configuration\n\n![](/assets/images/2021-05-10-21-22-53.png)\n\n# Gateway Aggregation pattern\n\nUse a gateway to aggregate multiple individual requests into a single request. This pattern is useful when a client must make multiple calls to different backend systems to perform an operation.\n\n![](/assets/images/2021-05-10-21-24-17.png)\n\nThis pattern can reduce the number of requests that the application makes to backend services, and improve application performance over high-latency networks.\n\n# Gateway Offloading pattern\n\nOffload shared or specialized service functionality to a gateway proxy. This pattern can simplify application development by moving shared service functionality, such as the use of SSL certificates, from other parts of the application into the gateway.\n\nOffload some features into a gateway, particularly cross-cutting concerns such as certificate management, authentication, SSL termination, monitoring, protocol translation, or throttling.\n\nThe following diagram shows a gateway that terminates inbound SSL connections. It requests data on behalf of the original requestor from any HTTP server upstream of the gateway.\n\n![](/assets/images/2021-05-10-21-27-11.png)\n\n- Simplify the development of services by removing the need to distribute and maintain supporting resources, such as web server certificates and configuration for secure websites. Simpler configuration results in easier management and scalability and makes service upgrades simpler.\n\n- Allow dedicated teams to implement features that require specialized expertise, such as security. This allows your core team to focus on the application functionality, leaving these specialized but cross-cutting concerns to the relevant experts.\n\n- Provide some consistency for request and response logging and monitoring. Even if a service is not correctly instrumented, the gateway can be configured to ensure a minimum level of monitoring and logging.\n\n# Gateway Routing pattern\n\nRoute requests to multiple services using a single endpoint. This pattern is useful when you wish to expose multiple services on a single endpoint and route to the appropriate service based on the request.\n\n![](/assets/images/2021-05-10-21-30-11.png)\n\nWith this pattern, the client application only needs to know about and communicate with a single endpoint. If a service is consolidated or decomposed, the client does not necessarily require updating. It can continue making requests to the gateway, and only the routing changes.\n\n# Leader Election pattern\n\nCoordinate the actions performed by a collection of collaborating instances in a distributed application by electing one instance as the leader that assumes responsibility for managing the others. This can help to ensure that instances don't conflict with each other, cause contention for shared resources, or inadvertently interfere with the work that other instances are performing.\n\nThe system must provide a robust mechanism for selecting the leader. This method has to cope with events such as network outages or process failures. In many solutions, the subordinate task instances monitor the leader through some type of heartbeat method, or by polling. If the designated leader terminates unexpectedly, or a network failure makes the leader unavailable to the subordinate task instances, it's necessary for them to elect a new leader.\n\n\nThere are several strategies for electing a leader among a set of tasks in a distributed environment, including:\n\n- Selecting the task instance with the lowest-ranked instance or process ID.\n- Racing to acquire a shared, distributed mutex. The first task instance that acquires the mutex is the leader. However, the system must ensure that, if the leader terminates or becomes disconnected from the rest of the system, the mutex is released to allow another task instance to become the leader.\n- Implementing one of the common leader election algorithms such as the Bully Algorithm or the Ring Algorithm. These algorithms assume that each candidate in the election has a unique ID, and that it can communicate with the other candidates reliably.\n\n# Pipes and Filters pattern\n\nDecompose a task that performs complex processing into a series of separate elements that can be reused. This can improve performance, scalability, and reusability by allowing task elements that perform the processing to be deployed and scaled independently.\n\nBreak down the processing required for each stream into a set of separate components (or filters), each performing a single task. By standardizing the format of the data that each component receives and sends, these filters can be combined together into a pipeline. \n\n![](/assets/images/2021-05-10-21-37-14.png)\n\n![](/assets/images/2021-05-10-21-37-40.png)\n\n# Sidecar pattern\n\nDeploy components of an application into a separate process or container to provide isolation and encapsulation. This pattern can also enable applications to be composed of heterogeneous components and technologies.\n\n![](/assets/images/2021-05-10-22-12-00.png)\n\nAdvantages of using a sidecar pattern include:\n\nA sidecar is independent from its primary application in terms of runtime environment and programming language, so you don't need to develop one sidecar per language.\n\nThe sidecar can access the same resources as the primary application. For example, a sidecar can monitor system resources used by both the sidecar and the primary application.\n\nBecause of its proximity to the primary application, there’s no significant latency when communicating between them.\n\nEven for applications that don’t provide an extensibility mechanism, you can use a sidecar to extend functionality by attaching it as its own process in the same host or sub-container as the primary application.","n":0.027}}},{"i":200,"$":{"0":{"v":"Database","n":1}}},{"i":201,"$":{"0":{"v":"Pattern","n":1},"1":{"v":"\n# cache-aside pattern\n\nLoad data on demand into a cache from a data store. This can improve performance and also helps to maintain consistency between data held in the cache and data in the underlying data store.\n\nMany commercial caching systems provide read-through and write-through/write-behind operations. In these systems, an application retrieves data by referencing the cache. If the data isn't in the cache, it's retrieved from the data store and added to the cache. Any modifications to data held in the cache are automatically written back to the data store as well.\n\nFor caches that don't provide this functionality, it's the responsibility of the applications that use the cache to maintain the data.\n\nAn application can emulate the functionality of read-through caching by implementing the cache-aside strategy. This strategy loads data into the cache on demand. The figure illustrates using the Cache-Aside pattern to store data in the cache.\n\n\n![](/assets/images/2021-05-09-22-49-50.png)\n\n[reference](https://docs.microsoft.com/en-us/azure/architecture/patterns/cache-aside)\n\n# Command and Query Responsibility Segregation (CQRS) pattern\n\nThe Command and Query Responsibility Segregation (CQRS) pattern separates read and update operations for a data store. Implementing CQRS in your application can maximize its performance, scalability, and security. The flexibility created by migrating to CQRS allows a system to better evolve over time and prevents update commands from causing merge conflicts at the domain level.\n\n![](/assets/images/2021-05-09-22-51-59.png)\n\n- Commands should be task based, rather than data centric. (\"Book hotel room\", not \"set ReservationStatus to Reserved\").\n- Commands may be placed on a queue for asynchronous processing, rather than being processed synchronously.\n- Queries never modify the database. A query returns a DTO that does not encapsulate any domain knowledge.\n\n# Event Sourcing pattern\n\nInstead of storing just the current state of the data in a domain, use an append-only store to record the full series of actions taken on that data. The store acts as the system of record and can be used to materialize the domain objects. This can simplify tasks in complex domains, by avoiding the need to synchronize the data model and the business domain, while improving performance, scalability, and responsiveness. It can also provide consistency for transactional data, and maintain full audit trails and history that can enable compensating actions.\n\nThe Event Sourcing pattern defines an approach to handling operations on data that's driven by a sequence of events, each of which is recorded in an append-only store. Application code sends a series of events that imperatively describe each action that has occurred on the data to the event store, where they're persisted. Each event represents a set of changes to the data \n\n![](/assets/images/2021-05-09-22-54-18.png)\n\n# Index Table \n\nCreate indexes over the fields in data stores that are frequently referenced by queries. This pattern can improve query performance by allowing applications to more quickly locate the data to retrieve from a data store.\n\nIf the data store doesn't support secondary indexes, you can emulate them manually by creating your own index tables. An index table organizes the data by a specified key. Three strategies are commonly used for structuring an index table, depending on the number of secondary indexes that are required and the nature of the queries that an application performs.\n\nThe first strategy is to duplicate the data in each index table but organize it by different keys (complete denormalization). The next figure shows index tables that organize the same customer information by Town and LastName.\n\n![](/assets/images/2021-05-09-22-58-10.png)\n\nThe second strategy is to create normalized index tables organized by different keys and reference the original data by using the primary key rather than duplicating it, as shown in the following figure. The original data is called a fact table.\n\n![](/assets/images/2021-05-09-22-58-20.png)\n\nThe third strategy is to create partially normalized index tables organized by different keys that duplicate frequently retrieved fields. Reference the fact table to access less frequently accessed fields. The next figure shows how commonly accessed data is duplicated in each index table.\n\n![](/assets/images/2021-05-09-22-58-32.png)\n\n# Materialized View pattern\n\nGenerate prepopulated views over the data in one or more data stores when the data isn't ideally formatted for required query operations. This can help support efficient querying and data extraction, and improve application performance.\n\n![](/assets/images/2021-05-09-22-59-51.png)\n\n- Creating materialized views over data that's difficult to query directly, or where queries must be very complex to extract data that's stored in a normalized, semi-structured, or unstructured way.\n- Creating temporary views that can dramatically improve query performance, or can act directly as source views or data transfer objects for the UI, for reporting, or for display.\n- Supporting occasionally connected or disconnected scenarios where connection to the data store isn't always available. The view can be cached locally in this case.\n- Simplifying queries and exposing data for experimentation in a way that doesn't require knowledge of the source data format. For example, by joining different tables in one or more databases, or one or more domains in NoSQL stores, and then formatting the data to fit its eventual use.\n- Providing access to specific subsets of the source data that, for security or privacy reasons, shouldn't be generally accessible, open to modification, or fully exposed to users.\n- Bridging different data stores, to take advantage of their individual capabilities. For example, using a cloud store that's efficient for writing as the reference data store, and a relational database that offers good query and read performance to hold the materialized views.\n- When using microservices, you are recommended to keep them loosely coupled, including their data storage. Thefore, materialized views can help you consolidate data from your services. If materialized views are not appropiate in your microservices architecture or specific scenario, please consider having well-defined boundaries that align to domain driven design (DDD) and aggregate their data when requested.\n\n# Sharding pattern\n\nDivide a data store into a set of horizontal partitions or shards. This can improve scalability when storing and accessing large volumes of data.\n\n## Sharding strategies\n\nThe Lookup strategy. In this strategy the sharding logic implements a map that routes a request for data to the shard that contains that data using the shard key. \n\n![](/assets/images/2021-05-09-23-07-49.png)\n\nThe Range strategy.\n\nThis strategy groups related items together in the same shard, and orders them by shard key—the shard keys are sequential. It's useful for applications that frequently retrieve sets of items using range queries\n\n![](/assets/images/2021-05-09-23-08-04.png)\n\nThe Hash strategy. The purpose of this strategy is to reduce the chance of hotspots \n\n![](/assets/images/2021-05-09-23-11-52.png)\n\n# Static Content Hosting patter\n\nDeploy static content to a cloud-based storage service that can deliver them directly to the client. This can reduce the need for potentially expensive compute instances.\n\n# Valet Key pattern\n\nUse a token that provides clients with restricted direct access to a specific resource, in order to offload data transfer from the application. This is particularly useful in applications that use cloud-hosted storage systems or queues, and can minimize cost and maximize scalability and performance.\n\nYou need to resolve the problem of controlling access to a data store where the store can't manage authentication and authorization of clients. One typical solution is to restrict access to the data store’s public connection and provide the client with a key or token that the data store can validate.\n\nThe client uses this token to access a specific resource in the data store for only a specific period, and with specific restrictions on access permissions, as shown in the figure. After the specified period, the key becomes invalid and won't allow access to the resource.\n\n![](/assets/images/2021-05-09-23-13-56.png)\n","n":0.029}}},{"i":202,"$":{"0":{"v":"Automation","n":1}}},{"i":203,"$":{"0":{"v":"Web","n":1},"1":{"v":"\n# IFTTT\n\n\n# inoreader\n\n\n# 简阅\n\n\n# pocket\n\n# slack\n\n# telegram\n\n","n":0.378}}},{"i":204,"$":{"0":{"v":"Vscode","n":1},"1":{"v":"\n# vscode\n\n## debug\n\n1. create `launch.json`\n2. add configuration by click button\n3. add field can do more custimzation\n\n\n## keyboard shortcuts\n\n1. view -> command pattern\n2. can see the key shortcut\n3. file -> preference -> key shortcut to change \n4. command K command S show all keyshort\n5. open preference keyboard shortcut json to have personalize key binding\n\n\n## setting\n\n1. can use json to custimize setting\n2. can set language based setting\n\n\n## open a file\n\n1. `:` go to a line\n2. `@` go to a symbol\n3. `?` view command suggestion\n4. `#` go to symbol in workplace\n\n## editing\n\n1. Format On Type and Format On Paste\n2. change lauguage command K M\n3. zen mode `command K Z`\n4. new pannel `command \\`\n5. change pannel `command 1 2 3`\n6. change all occurance `ctrl shift L`\n7. `alt + click` to change select place\n8. `alt + command + 上` copy line\n9. `alt 上下` move line\n10. `ctrl comand shift 左右` group selection\n11. `F12` go to definition, `shift F12` go to reference\n\n## snippets\n\nCode > Preferences > User Snippets on macOS\n\n- [link](https://code.visualstudio.com/docs/editor/userdefinedsnippets)\n\n\n## command\n\n- `code --diff <file1> <file2>`\n- `code -n` new window\n\n\n## window\n\n- Errors and warnings ⇧⌘M\n- F8 go to the error and warning\n- navigation history window `ctrl tab`\n- navigate back `ctrl -` \n\n# tasks\n\n- write build / run task \n- command + shift + B run task\n- can config user tasks\n- can config tasks depend on other tasks","n":0.067}}},{"i":205,"$":{"0":{"v":"iPhone","n":1},"1":{"v":"\n# 捷径的使用\n\n# IFTTT\n","n":0.577}}},{"i":206,"$":{"0":{"v":"Home","n":1},"1":{"v":"\n# 树莓派\n","n":0.707}}},{"i":207,"$":{"0":{"v":"Computer","n":1},"1":{"v":"\n# automator\n\n\n# alfred\n\n# script\n\n","n":0.5}}},{"i":208,"$":{"0":{"v":"Algo","n":1},"1":{"v":"\n# 算法\n\n## 数据结构\n\n- [[数组|development.algo.array]]\n- [[哈希表|development.algo.hashmap]]\n- [[链表|development.algo.linkedlist]]\n- [[树|development.algo.tree]]\n- [[堆|development.algo.heap]]\n- [[队列|development.algo.queue]]\n- [[栈|development.algo.stack]]\n- [[图|development.algo.graph]]\n\n## 算法\n\n- [[排序|development.algo.sort]]\n- [[搜索|development.algo.search]]\n- [[动态规划|development.algo.dp]]\n- [[贪心|development.algo.greedy]]\n- [[递归|development.algo.recursive]]\n- [[哈希|development.algo.hashing]]\n- [[图搜索|development.algo.graphsearch]]\n\n1. 减治法:它利用了一个问题给定实例的解和同样问题较小实例的解之间的关系。一旦建立了这样一种关系，我们既可以自顶至下（递归）也可以自底至上地运用这种关系。\n2. 分治法：将一个问题划分为同一类型的若干子问题，子问题最好规模相同。对这些子问题求解。有必要的、合并这些子问题的解，以得到原始问题的答案。 T(n) = aT(n/b)+f(n)\n3. 变治法：变换为同样问题的一个更简单或者更方便的实例一我们称之为实例化简。变换为同样实例的不同表现——我们称之为改变表现（representation change）。变换为另一个问题的实例，这种问题的算法是已知的一—我们称之为问题化简\n4. 时空权衡。输入增强：将问题进行预处理，预构造：使用额外的空间实现更快和更方便的数据存取\n5. 动态规划\n6. 贪婪算法","n":0.186}}},{"i":209,"$":{"0":{"v":"Tree","n":1},"1":{"v":"\n# basic\n\n* Root: The node at the top of the tree.\n* Parent: When any node (except the root) has exactly one edge running upward to another node. The node above is called parent of the node.\n* Child: Any node may have one or more lines running downward to other nodes. These nodes below the given node called its children.\n* Leaf: A node that has no children is called a leaf. There can be only one root in a tree but there can be many leaves.\n* Level (Height): the level of a particular node refers to how many generations the node is from the root. The root is at level 0 and its children are at level 1 and so on.\n\n## 思想\n\n重点就是把握树的递归特性。题目要想办法改变成对于左右子树的子问题。binary tree: node with left and right child\n\n- 深度问题:\b 整棵树的深度可以看成右子树的深度与左子树的深度的最大值\n- 长度问题：左右子树最大值加上中心节点\n- 颠倒：左子树和右子树分别交换自己，最后根节点交换左右子树\n- merge:类似链表merge\n- 判断是否相同。左右子树分别判断\n- BST valid: 设定左右子树的上下限\n- 可以利用binary search 分解题目\n\n\n## 遍历\n\nAlgorithm Inorder(tree)\n\n   1. Traverse the left subtree, i.e., call Inorder(left-subtree)\n   2. Visit the root.\n   3. Traverse the right subtree, i.e., call Inorder(right-subtree)\n\nAlgorithm Preorder(tree)\n   1. Visit the root.\n   2. Traverse the left subtree, i.e., call Preorder(left-subtree)\n   3. Traverse the right subtree, i.e., call Preorder(right-subtree) \n\nAlgorithm Postorder(tree)\n   1. Traverse the left subtree, i.e., call Postorder(left-subtree)\n   2. Traverse the right subtree, i.e., call Postorder(right-subtree)\n   3. Visit the root.","n":0.07}}},{"i":210,"$":{"0":{"v":"Stack","n":1},"1":{"v":"\n# basic\n\n- 大小是固定的\n- last in first out (LIFO)\n- 可以用数组实现\n\n## 时间复杂度\n\n- O(1) insert and delete\n- O(n) search\n\n## 算法\n\n- 可以用来reverse string","n":0.229}}},{"i":211,"$":{"0":{"v":"Sort","n":1},"1":{"v":"\n# merge sort\n\n```python\ndef mergeSort(arr):\n    if len(arr) > 1:\n \n         # Finding the mid of the array\n        mid = len(arr)//2\n \n        # Dividing the array elements\n        L = arr[:mid]\n \n        # into 2 halves\n        R = arr[mid:]\n \n        # Sorting the first half\n        mergeSort(L)\n \n        # Sorting the second half\n        mergeSort(R)\n \n        i = j = k = 0\n \n        # Copy data to temp arrays L[] and R[]\n        while i < len(L) and j < len(R):\n            if L[i] < R[j]:\n                arr[k] = L[i]\n                i += 1\n            else:\n                arr[k] = R[j]\n                j += 1\n            k += 1\n \n        # Checking if any element was left\n        while i < len(L):\n            arr[k] = L[i]\n            i += 1\n            k += 1\n \n        while j < len(R):\n            arr[k] = R[j]\n            j += 1\n            k += 1\n```\n\n# quick sort\n\n```python\ndef partition(arr, low, high): \n    i = (low-1)         # index of smaller element \n    pivot = arr[high]     # pivot \n  \n    for j in range(low, high): \n  \n        # If current element is smaller than or \n        # equal to pivot \n        if arr[j] <= pivot: \n  \n            # increment index of smaller element \n            i = i+1\n            arr[i], arr[j] = arr[j], arr[i] \n  \n    arr[i+1], arr[high] = arr[high], arr[i+1] \n    return (i+1) \n  \n# The main function that implements QuickSort \n# arr[] --> Array to be sorted, \n# low  --> Starting index, \n# high  --> Ending index \n  \n# Function to do Quick sort \n  \n  \ndef quickSort(arr, low, high): \n    if len(arr) == 1: \n        return arr \n    if low < high: \n  \n        # pi is partitioning index, arr[p] is now \n        # at right place \n        pi = partition(arr, low, high) \n  \n        # Separately sort elements before \n        # partition and after partition \n        quickSort(arr, low, pi-1) \n        quickSort(arr, pi+1, high) \n```\n\n# heap sort\n\n![[dendron://my_note/development.algo.heap#heap sort]]\n\n# 拓扑排序\n\n有向图，是将G中所有顶点排成一个线性序列，使得图中任意一对顶点u和v，若边(u,v)∈E(G)，则u在线性序列中出现在v之前。\n\n- 选择一个入度为0的顶点并输出之；\n- 从图中删除此顶点及其所有出边；\n- 找下一个入度为0的点","n":0.057}}},{"i":212,"$":{"0":{"v":"Search","n":1},"1":{"v":"\n# binary search\n\n1. array 是sorted\n\n```java\n\npublic static int indexOf(int[] a, int key) {\n        int lo = 0;\n        int hi = a.length - 1;\n        while (lo <= hi) {\n            // Key is in a[lo..hi] or not present.\n            int mid = lo + (hi - lo) / 2;\n            if      (key < a[mid]) hi = mid - 1;\n            else if (key > a[mid]) lo = mid + 1;\n            else return mid;\n        }\n        return -1;\n```","n":0.12}}},{"i":213,"$":{"0":{"v":"Queue","n":1},"1":{"v":"\n# basic\n\n1. Every time add, Back index ++\n2. Every time remove item, Front index++ using an array to implement.\n3. Make sure you set index = back%cap\n4. FIFO","n":0.192}}},{"i":214,"$":{"0":{"v":"Linkedlist","n":1},"1":{"v":"\n# basic\n\n1. Advantages: dynamic access\n2. Disadvantages: **cannot random access and extra memory to save reference to next node**.\n3. 动态分配空间，只知道下个节点\n4. a sequence of node, each one contains object reference to next one\n\n## 时间复杂度\n\n- insert, delete O(1). \n- search O(n)\n\n## 思路\n\n- 递归[[development.algo.recursive]]\n- recursive one by one, each one could be the new linkedlist head: merge, reverse\n- two iterates:cycle, overlapping,delete node.\n- use dummy head to avoid checking empty: pivoting,using new node to form new list","n":0.118}}},{"i":215,"$":{"0":{"v":"Heap","n":1},"1":{"v":"\n# basic \n\n堆（英语：Heap）是计算机科学中的一种特别的完全二叉树。若是满足以下特性，即可称为堆：“给定堆中任意节点P和C，若P是C的母节点，那么P的值会小于等于（或大于等于）C的值”。若母节点的值恒小于等于子节点的值，此堆称为最小堆（min heap）；反之，若母节点的值恒大于等于子节点的值，此堆称为最大堆（max heap）。在堆中最顶端的那一个节点，称作根节点（root node），根节点本身没有母节点（parent node）\n\n## heap sort\n\n```\nprocedure heapsort(a, count) is\n    input: an unordered array a of length count\n \n    (建立推，root是最大值)\n    heapify(a, count)\n\n    (a[0:end]是堆，end到最后是排列好的))\n    end ← count - 1\n    while end > 0 do\n        swap(a[end], a[0])\n        (heap大小减一)\n        end ← end - 1\n        (the swap ruined the heap property, so restore it)\n        siftDown(a, 0, end)\n```\n\n```python\n\ndef heapify(arr, n, i):\n    largest = i  # Initialize largest as root\n    l = 2 * i + 1     # left = 2*i + 1\n    r = 2 * i + 2     # right = 2*i + 2\n \n    # See if left child of root exists and is\n    # greater than root\n    if l < n and arr[largest] < arr[l]:\n        largest = l\n \n    # See if right child of root exists and is\n    # greater than root\n    if r < n and arr[largest] < arr[r]:\n        largest = r\n \n    # Change root, if needed\n    if largest != i:\n        arr[i], arr[largest] = arr[largest], arr[i]  # swap\n \n        # Heapify the root.\n        heapify(arr, n, largest)\n \n# The main function to sort an array of given size\n \n \ndef heapSort(arr):\n    n = len(arr)\n \n    # Build a maxheap.\n    for i in range(n//2 - 1, -1, -1):\n        heapify(arr, n, i)\n \n    # One by one extract elements\n    for i in range(n-1, 0, -1):\n        arr[i], arr[0] = arr[0], arr[i]  # swap\n        heapify(arr, i, 0)\n \n```\n\n- api: heapq.heapify(x)\n- heapq.heappop(heap)","n":0.066}}},{"i":216,"$":{"0":{"v":"Hashmap","n":1},"1":{"v":"\n# basic\n\n- put value in hash slot like array\n- store keys and values, insert, delete,lookup O(1) time on average\n- key not in order\n- hash method needs to be good","n":0.186}}},{"i":217,"$":{"0":{"v":"Hashing","n":1},"1":{"v":"\n# collision\n\n\n- Static Hashing Schemes \n - linear probe hashing: find next available\n  - good for insert but bad for delete and update\n  - if non-unique key\n   - Choice #1: Separate Linked List. key point to a table save all value\n   - Choice #2: Redundant Keys: Store duplicate keys entries together in the hash table.\n - ROBIN HOOD HASHING:\n  - Variant of linear probe hashing that **steals slots from \"rich\"** keys and give them to \"poor\" keys.\n  - Each key tracks the number of positions **difference** its **optimal** position in the table.\n  - no grantee better, avoid worst case\n - cuckoo hashing\n  - Use multiple hash tables with different hash functions.\n  - ping pong, 出现collision去另一个\n  - 如果两个都collision，选一个替换，把被替换的放在另一个table里\n  - If we find a cycle, then we can rebuild the entire hash tables with new hash functions.\n- Dynamic Hashing Schemes\n - chained hashing: use linkedlist\n  - grow infinitely because you just keep adding new buckets to the linked list.\n - extendible hashing\n  - split buckets \n  - local depth: 就是之前没分的长度\n - linear hashing\n  - Maintain a pointer that tracks the next bucket to split. \n  - When any bucket overflows, split the bucket at the pointer location.\n\n## python dict\n\n- 存hash|key|value，每次都是看hash和key是不是一样\n- [处理collusion](https://stackoverflow.com/questions/9010222/why-can-a-python-dict-have-multiple-keys-with-the-same-hash)\n  - 出现collision，看`j = ((5*j) + 1) mod 2**i` 下一个是不是空的，是的话就放进去","n":0.069}}},{"i":218,"$":{"0":{"v":"Graphsearch","n":1},"1":{"v":"\n\n# BFS\n\n```python\ndef BFS(self, s):\n \n    # Mark all the vertices as not visited\n    visited = [False] * (max(self.graph) + 1)\n\n    # Create a queue for BFS\n    queue = []\n\n    # Mark the source node as \n    # visited and enqueue it\n    queue.append(s)\n    visited[s] = True\n\n    while queue:\n\n        # Dequeue a vertex from \n        # queue and print it\n        s = queue.pop(0)\n        print (s, end = \" \")\n\n        # Get all adjacent vertices of the\n        # dequeued vertex s. If a adjacent\n        # has not been visited, then mark it\n        # visited and enqueue it\n        for i in self.graph[s]:\n            if visited[i] == False:\n                queue.append(i)\n                visited[i] = True\n \n\n```\n# DFS\n\n```python\ndef DFSUtil(self, v, visited):\n \n    # Mark the current node as visited\n    # and print it\n    visited.add(v)\n    print(v, end=' ')\n \n    # Recur for all the vertices\n    # adjacent to this vertex\n    for neighbour in self.graph[v]:\n        if neighbour not in visited:\n            self.DFSUtil(neighbour, visited)\n \n# The function to do DFS traversal. It uses\n# recursive DFSUtil()\ndef DFS(self, v):\n\n    # Create a set to store visited vertices\n    visited = set()\n\n    # Call the recursive helper function\n    # to print DFS traversal\n    self.DFSUtil(v, visited)\n\n```\n\n# 最短路径算法\n\n单点最短路径算法： bellman-ford 算法，基本思路就是每次更新从起点到v的距离，如果起点到u再到v的路程短，那么就更新。\n\n```\n for i from 1 to size(vertices)-1:\n       for each edge (u, v) with weight w in edges:\n           if distance[u] + w < distance[v]:\n               distance[v] := distance[u] + w\n```\n\nDijkstra’s 算法，这也是单点最短路径算法，基本思路是每次从q中取最小的节点，之后更新从该点到其他的点的距离。\n\n```\nfunction Dijkstra(G, w, s)\n    for each vertex v in V[G]        // 初始化\n           d[v] := infinity           // 將各點的已知最短距離先設成無窮大\n    d[s] := 0                        // 因为出发点到出发点间不需移动任何距离，所以可以直接将s到s的最小距离设为0\n     S := empty set\n     Q := set of all vertices\n     while Q is not an empty set      // Dijkstra演算法主體\n        u := Extract_Min(Q)\n        S.append(u)\n        for each edge outgoing from u as (u,v)\n            if d[v] > d[u] + w(u,v)  // 拓展边（u,v）。w(u,v)为从u到v的路径长度。\n                d[v] := d[u] + w(u,v)  // 更新路径长度到更小的那个和值。\n```\n\n# A*","n":0.059}}},{"i":219,"$":{"0":{"v":"Graph","n":1},"1":{"v":"\n# basic\n\n## bfs\n## dfs\n## min distance","n":0.408}}},{"i":220,"$":{"0":{"v":"Dp","n":1},"1":{"v":"\n# basic\n\n- the original problem can be solved relatively easy once solution to the sub problem are available\n- subproblems can be cached\n- when you have to make **choices** to arrive solution\n- counting and decision problem\n- build bottom up","n":0.162}}},{"i":221,"$":{"0":{"v":"Array","n":1},"1":{"v":"\n# Basic\n\n- 数据集比较小\n- 数据的大小可以预测\n- 数据是连续存储的，速度快\n\n## 时间复杂度\n\n1. Addition and search worst O(N)\n2. Removal also O(N)\n\n## static和dynamic 数组\n\n- static是系统preallocate好大小，不能改变\n- dynamic是系统分配好，之后会根据情况进行变化，java里的ArrayList是1.5*","n":0.236}}}]}
