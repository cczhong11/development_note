{"pageProps":{"note":{"id":"cki43m8kwb6iflb2de61itq","title":"LLM","desc":"","updated":1757213819234,"created":1678338043210,"custom":{},"fname":"development.ml.LLM","type":"note","vault":{"fsPath":"repos/dendron-aws-vault","remote":{"type":"git","url":"https://github.com/cczhong11/my_note.git"},"name":"my_note"},"contentHash":"6826f99cc5cd03c2661c0a953d3fe6a9","links":[],"anchors":{},"children":["s07zvgrc9ml2ld5difpj0jg","pzsuculkyms2gvuotyaykab","9cp08wuyd7t35jzracxxqbv","vlbjb19104pkzyg8nmai5pa","282jaazafck51k0dd93k6wu","82undztzy7arc9g53jgjoas","orvk6ml0kophjt1oddyzcs7","qzhktnz6o28v08msov6iph3","mtcseghv7a6x4cqeoyqxgrv"],"parent":"09d9081f-3dff-453d-8488-7d2344cc8895","data":{}},"body":"<h1 id=\"llm\">LLM<a aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#llm\"></a></h1>\n<p>大语言模型是一种基于深度学习技术的自然语言处理模型，它能够学习和生成自然语言文本。大语言模型通常由多层神经网络组成，可以根据历史文本数据预测下一个单词或一段文本的概率。大语言模型的应用包括语言翻译、问答系统、自动摘要、语音识别等领域。其中最著名的大语言模型是Google的BERT、OpenAI的GPT-3等。大语言模型的优点是可以在大规模数据上进行训练，支持生成高质量的自然语言文本，但是也存在一些问题，比如需要大量的计算资源和数据、对于少见的单词或短语容易出现错误等。</p>\n<ol>\n<li>AI 技术栈概览\n•\t应用开发层：如何使用大模型（如 GPT、PaLM 等），构建 Agent，聚焦 Prompt Engineering 与 Context Engineering。\n•\t模型开发层：涉及模型的训练、微调、评估及部署。\n•\t基础设施层：包括 Serving Infra、数据管理（Data Ops）与模型运行监控（Monitoring）。</li>\n</ol>\n<p>⸻</p>\n<ol start=\"2\">\n<li>应用开发层（Application Development）\n<ol>\n<li>大模型使用\n•\t选型：接口调用 vs. 本地部署\n•\t性能与成本权衡</li>\n<li>Agent 设计\n•\t单任务 Agent vs. 多任务 Agent\n•\t模块化思路：Planner → Executor → Verifier</li>\n<li>Prompt Engineering\n•\t技术手段：零样本、少样本、链式思维（Chain-of-Thought）\n•\t动态上下文筛选与检索增强（Retrieval-Augmented Generation）</li>\n<li>Context Engineering\n•\t上下文窗口管理\n•\t长文档检索与摘要拼接</li>\n</ol>\n</li>\n</ol>\n<p>⸻</p>\n<ol start=\"3\">\n<li>模型开发层（Model Development）</li>\n</ol>\n<p>3.1 数据来源与处理\n•\tCommon Crawl / C4：大规模互联网网页抓取数据集，涵盖多语种\n•\tDomain-Specific Corpora：如医学（PubMed）、法律（CourtListener）、金融（SEC filings）等\n•\t开源语料：Wikipedia、OpenWebText、The Pile\n•\t数据清洗与预处理：去重、过滤低质量、子词切分（BPE/WordPiece）</p>\n<p>3.2 模型架构（Transformer）\n•\t核心思想：自注意力（Self-Attention）\n•\tAttention 公式（LaTeX）：\n<span class=\"math math-inline\"><span class=\"katex-error\" title=\"ParseError: KaTeX parse error: Can&#x27;t use function &#x27;$&#x27; in math mode at position 89: …d_k}}\\Bigr)\\,V $̲  • Q, K, V 分别为…\" style=\"color:#cc0000\">\\mathrm{Attention}(Q, K, V) = \\mathrm{softmax}\\Bigl(\\frac{QK^\\top}{\\sqrt{d_k}}\\Bigr)\\,V $  • Q, K, V 分别为查询（Query）、键（Key）、值（Value）矩阵  • $\\sqrt{d_k}</span></span> 为缩放因子\n•\t多头注意力（Multi-Head Attention）：并行多组 Q,K,V，再拼接投影\n•\t位置编码（Positional Encoding）：Sin/Cos 或可学习向量\n•\t前馈网络：两层线性层 + 激活（GELU/ReLU）\n•\t残差连接 &#x26; LayerNorm</p>\n<p>3.3 模型训练与微调</p>\n<pre><code>1.\t预训练（Pre-Training）\n•\t自监督目标：Masked Language Modeling（如 BERT）／自回归（如 GPT）\n•\t大规模分布式训练：数据并行 + 模型并行\n2.\t微调（Fine-Tuning）\n•\t全量微调 vs. 参数高效方法（PEFT）\n•\tLoRA、Adapter、Prefix-Tuning\n•\t强化学习 + 人类反馈（RLHF）\n</code></pre>\n<p>3.4 模型评估\n•\t自动化指标：Perplexity、BLEU、ROUGE、F1\n•\t基准测试：GLUE、SuperGLUE、MMLU、SQuAD\n•\t人类评估：流畅度、相关性、安全性</p>\n<p>3.5 模型服务（Serving）\n•\t推理框架：TensorFlow Serving、TorchServe、NVIDIA Triton\n•\t优化手段：量化（Quantization）、剪枝（Pruning）、蒸馏（Distillation）、ONNX\n•\t高可用设计：负载均衡、水平扩展、冷/热启动</p>\n<p>⸻</p>\n<ol start=\"4\">\n<li>基础设施层（Infra）\n<ol>\n<li>Serving Infra\n•\tKubernetes + Helm 部署\n•\t服务网格（Istio）</li>\n<li>数据管理（Data Ops）\n•\t版本控制：DVC、Git-LFS\n•\t元数据管理：MLflow、Weights &#x26; Biases</li>\n<li>监控与告警\n•\t指标收集：Prometheus\n•\t可视化：Grafana\n•\t日志与追踪：ELK Stack、Jaeger</li>\n</ol>\n</li>\n</ol>\n<hr>\n<strong>Children</strong>\n<ol>\n<li><a href=\"/notes/qzhktnz6o28v08msov6iph3\">Evaluation</a></li>\n<li><a href=\"/notes/mtcseghv7a6x4cqeoyqxgrv\">Model</a></li>\n<li><a href=\"/notes/s07zvgrc9ml2ld5difpj0jg\">agent</a></li>\n<li><a href=\"/notes/pzsuculkyms2gvuotyaykab\">instructGPT</a></li>\n<li><a href=\"/notes/9cp08wuyd7t35jzracxxqbv\">llama</a></li>\n<li><a href=\"/notes/vlbjb19104pkzyg8nmai5pa\">machine_memory</a></li>\n<li><a href=\"/notes/282jaazafck51k0dd93k6wu\">memory</a></li>\n<li><a href=\"/notes/82undztzy7arc9g53jgjoas\">tool</a></li>\n<li><a href=\"/notes/orvk6ml0kophjt1oddyzcs7\">transformer</a></li>\n</ol>","noteIndex":{"id":"0f1b48c7-3a25-4016-83a5-15864d7803ad","title":"Development","vault":{"fsPath":"repos/dendron-aws-vault","remote":{"type":"git","url":"https://github.com/cczhong11/my_note.git"},"name":"my_note"},"type":"note","desc":"","links":[{"from":{"fname":"root","id":"c95dc4f5-23db-45e7-a15b-64582a183ccc","vaultName":"my_note"},"type":"backlink","position":{"start":{"line":8,"column":3,"offset":63},"end":{"line":8,"column":21,"offset":81},"indent":[]},"value":"development"}],"anchors":{},"fname":"development","updated":1618381238346,"created":1612940782409,"parent":null,"children":["400115e9-30f7-4a13-9776-db059bc9cd42","xsX5v3ZsyJ0i6gf9","1bc3b45a-b6f4-4150-87d3-5bd5b6eb8c24","6cea4852-6e7c-4140-b476-85c07b48a642","a40ef849-d301-4d74-a778-e6d9469dfb5d","09d9081f-3dff-453d-8488-7d2344cc8895","p11phg7nb10yw0wck1fyagq","92917ea3-452e-48dc-875e-5cd0002041db","2e151826-cb22-4d89-8ce0-71dad7204ce8","baa39444-0da9-4c55-8df7-2a6f8f787fa4","q4um3bc3st86ilkkvdjom6x","62daf50d-a39e-463f-aabd-be53790281fd","3524d0a7-be73-45d6-847e-c970f5c1c760","eac0f243-05b3-4b95-bec3-848e33edbc40","zrjuka02gkzrqxt5djp2aws"],"data":{},"custom":{"nav_order":0,"permalink":"/"},"body":"\n","contentHash":"38357962f5a50c6fd7d318dfa66bea90"},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"previewV2Enabled":false,"enablePreviewV2":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":false,"leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2,"vaultSelectionModeOnCreate":"smart"}},"insertNote":{"initialValue":"templates"},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"randomNote":{},"copyNoteLink":{"aliasMode":"title"},"templateHierarchy":"template"},"workspace":{"dendronVersion":"0.90.0","vaults":[{"fsPath":"repos/dendron-aws-vault","remote":{"type":"git","url":"https://github.com/cczhong11/my_note.git"},"name":"my_note"},{"fsPath":"vault"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":true,"maxPreviewsCached":10,"maxNoteLength":204800,"enableUserTags":true,"enableHashTags":true,"task":{"name":"","dateFormat":"","addBehavior":"childOfCurrent","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link","taskCompleteStatus":["done","x"]},"enableEditorDecorations":true,"enableHandlebarTemplates":true,"enableFullHierarchyNoteTitle":false,"enablePersistentHistory":false},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"automaticallyShowPreview":false},"publishing":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"siteHierarchies":["development","life"],"writeStubs":false,"siteRootDir":"docs","seo":{"title":"my_note","description":"Personal knowledge space"},"github":{"enableEditLink":true,"editLinkText":"Edit this page on GitHub","editBranch":"main","editViewMode":"tree"},"enableSiteLastModified":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"enableTaskNotes":true,"enablePrettyLinks":true,"searchMode":"lookup","enableMermaid":true,"siteUrl":"https://notes.tczhong.com","siteFaviconPath":"favicon.ico","siteIndex":"development"}}},"__N_SSG":true}