[{"doc":"This page has not yet sprouted","title":"This page has not yet sprouted","hpath":"403","content":"[Dendron](https://dendron.so/) (the tool used to generate this site) lets authors selective publish content. You will see this page whenever you click on a link to an unpublished page\n\n![](https://foundation-prod-assetspublic53c57cce-8cpvgjldwysl.s3-us-west-2.amazonaws.com/assets/images/not-sprouted.png)","url":"https://notes.tczhong.com/notes/403.html","relUrl":"notes/403.html"},{"doc":"Development","title":"Development","hpath":"development","content":"\n","url":"https://notes.tczhong.com","relUrl":"/"},{"doc":"Web","title":"Web","hpath":"development.web","content":"\n\n# whole picture\n\nuser request -> server -> Database\n\n## How request get to server\n\n1. Network layer\n2. Network protocl\n3. Load balancing\n\n\n## How server organize together\n\n1. Distributed System\n","url":"https://notes.tczhong.com/notes/eac0f243-05b3-4b95-bec3-848e33edbc40.html","relUrl":"notes/eac0f243-05b3-4b95-bec3-848e33edbc40.html"},{"doc":"Tools","title":"Tools","hpath":"development.tools","content":"\n","url":"https://notes.tczhong.com/notes/3524d0a7-be73-45d6-847e-c970f5c1c760.html","relUrl":"notes/3524d0a7-be73-45d6-847e-c970f5c1c760.html"},{"doc":"Vim","title":"Vim","hpath":"development.tools.vim","content":"\n# move\n\n- h,j,k,l\n- w,b,e\n- G: go to top\n- gg: go to end\n- { }, skip a block of code\n- V: select line\n- ctrl-v: select block of code (same column)\n- ^: begin line, $: end of line \n- t/f + char: go to the specific char in the line\n- %: go to specific parenthese\n- *: search for other instance\n\n# change\n\n- u: undo\n- ctrl+r: redo\n- yy: Copy line\n- p: paste below\n- P: paste above\n- dd\n- dw\n- D: delete to the end of line \n- o: insert line below\n- O: insert line above\n- c: change \n- x: delete char\n- ~: change the case of char \n- r: replace char\n- > < : 增加缩小缩进\n- yt+char:复制到那个char\n\n# search\n\n替换改行的第一个old单词为new\n:s/old/new\n\n替换改行的所有old单词为new\n:s/old/new/g\n\n替换两个#之间的单词\n:#,#s/old/new/g\n\n替换文件中所有的单词\n:%s/old/new/g\n\n每一个替换之前都需要确认的话，在命令末尾加一个 c\n:%s/old/new/gc","url":"https://notes.tczhong.com/notes/8657885d-85f1-4df2-a678-d60714edb004.html","relUrl":"notes/8657885d-85f1-4df2-a678-d60714edb004.html"},{"doc":"Bash","title":"Bash","hpath":"development.tools.bash","content":"\n# key\n\n- ctrl-a:  go to begin of line\n- ctrl-w: 删除前一个单词\n- ctrl-u: 删至行首\n- Option + Left Arrow – to move the cursor backward by a word. \n- Option + Right arrow – to move the cursor forward by a word.","url":"https://notes.tczhong.com/notes/d4d0e457-c67c-4dc8-bddd-113b4fb3bdfe.html","relUrl":"notes/d4d0e457-c67c-4dc8-bddd-113b4fb3bdfe.html"},{"doc":"System","title":"System","hpath":"development.system","content":"\n","url":"https://notes.tczhong.com/notes/62daf50d-a39e-463f-aabd-be53790281fd.html","relUrl":"notes/62daf50d-a39e-463f-aabd-be53790281fd.html"},{"doc":"Virtualization","title":"Virtualization","hpath":"development.system.virtualization","content":"\n# VM\n\nVirtual machines are based on computer architectures and provide functionality of a physical computer. Their implementations may involve specialized hardware, software, or a combination.\n\n- System virtual machines (also termed full virtualization VMs) provide a substitute for a real machine. They provide functionality needed to execute entire operating systems. A **hypervisor** uses native execution to share and manage hardware, allowing for multiple environments which are **isolated** from one another, yet exist on the same physical machine. Modern hypervisors use hardware-assisted virtualization, virtualization-specific hardware, primarily from the host CPUs.\n- Process virtual machines are designed to execute computer programs in a platform-independent environment. A process VM provides a high-level abstraction – that of a high-level programming language (compared to the low-level ISA abstraction of the system VM). Process VMs are implemented using an interpreter; performance comparable to compiled programming languages can be achieved by the use of just-in-time compilation. JVM\n- Operating-system-level virtualization: docker.  physical server is virtualized at the operating system level, enabling multiple isolated and secure virtualized servers to run on a single physical server. The \"guest\" operating system environments share the same running instance of the operating system as the host system. Thus, the same operating system kernel is also used to implement the \"guest\" environments, and applications running in a given \"guest\" environment view it as a stand-alone system\n\n## How does virtualization work?\n\nSoftware called hypervisors separate the physical resources from the virtual environments—the things that need those resources. Hypervisors take your physical resources and divide them up so that virtual environments can use them.\n\n![](/assets/images/2021-05-03-15-30-39.png)\n\nResources are partitioned as needed from the physical environment to the many virtual environments. Users interact with and run computations within the virtual environment (typically called a guest machine or virtual machine). The virtual machine functions as a single data file. And like any digital file, it can be moved from one computer to another, opened in either one, and be expected to work the same.\n\nWhen the virtual environment is running and a user or program issues an instruction that requires additional resources from the physical environment, the hypervisor relays the request to the physical system and caches the changes—which all happens at close to native speed (particularly if the request is sent through an open source hypervisor based on KVM, the Kernel-based Virtual Machine).","url":"https://notes.tczhong.com/notes/cd3ae684-36e9-4c66-af36-7b2891db3cde.html","relUrl":"notes/cd3ae684-36e9-4c66-af36-7b2891db3cde.html"},{"doc":"Understand","title":"Understand","hpath":"development.system.understand","content":"\n# templeate to understand the service\n\n## service context\n\n1. what does the system do\n2. who is the customer, what is their primary use case?\n3. what is the user flow for the primary use case\n4. how is the customer impacted when the system is degraded\n5. what service level objectives have set in order to achieve the desired customer experience\n6. what service level indicators do we use to measure teh experience we want to deliver\n\n## pre-game checklist\n\nbefore blueprint phase\n\n1. toolbox\n   1. runbooks\n   2. pagerduty service\n   3. datadog dashboards\n2. complete the service context\n3. verify the test environment is healthy\n4. prepare and validate load generation test\n5. prepare failure injection with Gremlin\n\n\n## gameday\n\n- roles and responsibility\n  - gameday coordinator\n  - oncall / triage engineers\n  - attendees (observe and validate the situation)\n","url":"https://notes.tczhong.com/notes/3a5260a3-2387-484f-a8ad-e072c37424dd.html","relUrl":"notes/3a5260a3-2387-484f-a8ad-e072c37424dd.html"},{"doc":"Scalability","title":"Scalability","hpath":"development.system.scalability","content":"\n# Scalability\n\ndescribe a system’s ability to cope with increased load.\n\n## Load\n\nLoad can be described with a few numbers which we call load parameters\n\nThe best choice of parameters depends on the architecture of your system\n\n## Performance\n\n- When you increase a load parameter and keep the system resources (CPU, memory, network bandwidth, etc.) unchanged, how is the performance of your system affected?\n- When you increase a load parameter, how much do you need to increase the resources if you want to keep performance unchanged?\n\n- throughput (the number of records we can process per second)\n- response time (the time between a client sending a request and receiving a response.)\n\n## scale\n\n- scaling up (**vertical scaling**, moving to a more powerful machine) \n- scaling out (**horizontal scaling**, distributing the load across multiple smaller machines).","url":"https://notes.tczhong.com/notes/da63a48e-f890-48b0-b051-d4e545a0e1ba.html","relUrl":"notes/da63a48e-f890-48b0-b051-d4e545a0e1ba.html"},{"doc":"Reliability","title":"Reliability","hpath":"development.system.reliability","content":"\n# Reliability\n\n- continue to work correctly\n- fault tolerate\n\n\n## Hardware faults\n\n- add redundancy\n  - Disks may be set up in a RAID configuration\n  - servers may have dual power supplies and hot-swappable CPUs\n  - datacenters may have batteries and diesel generators for backup power.\n  - When one component dies, the redundant component can take its place while the broken component is replaced.\n\n## Software errors\n\nbug, process uses up resources, service depends on slow down, cascading failures\n\n- carefully thinking about assumptions and interactions in the system\n- thorough testing, process isolation\n- allowing processes to crash and restart\n- measuring, monitoring and analyzing system behavior in production\n\n\n## human errors\n\nhumans are known to be unreliable.\n\nDesign systems in a way that minimizes opportunities for error.\n\nDecouple the places where people make the most mistakes from the places where they can cause failures. In particular, provide fully featured non-production sandbox environments where people can explore and experiment safely, using real data, without affecting real users.\n\nAllow quick and easy recovery from human errors, to minimize the impact in the case of a failure.","url":"https://notes.tczhong.com/notes/fd1119d4-0dd2-4f17-bcfa-2018e269d7cc.html","relUrl":"notes/fd1119d4-0dd2-4f17-bcfa-2018e269d7cc.html"},{"doc":"Performance","title":"Performance","hpath":"development.system.performance","content":"\n![](/assets/images/2021-05-03-16-22-48.png)\n[reference](http://www.brendangregg.com/linuxperf.html)\n\n## 1. uptime\n\n```\n$ uptime \n23:51:26 up 21:31, 1 user, load average: 30.02, 26.43, 19.02\n```\n\nThis is a quick way to view the load averages, which indicate the number of tasks (processes) wanting to run. On Linux systems, these numbers include processes wanting to run on CPU, as well as processes blocked in uninterruptible I/O (usually disk I/O). This gives a high level idea of resource load (or demand), but can’t be properly understood without other tools. Worth a quick look only.\nThe **three numbers are exponentially damped moving sum averages with a 1 minute, 5 minute, and 15 minute constant**. The three numbers give us some idea of how load is changing over time. For example, if you’ve been asked to check a problem server, and the 1 minute value is much lower than the 15 minute value, then you might have logged in too late and missed the issue.\nIn the example above, the load averages show a recent increase, hitting 30 for the 1 minute value, compared to 19 for the 15 minute value. That the numbers are this large means a lot of something: probably CPU demand; vmstat or mpstat will confirm, which are commands 3 and 4 in this sequence.\n\n## 2. dmesg | tail\n\n```\n$ dmesg | tail\n[1880957.563150] perl invoked oom-killer: gfp_mask=0x280da, order=0, oom_score_adj=0\n[...]\n[1880957.563400] Out of memory: Kill process 18694 (perl) score 246 or sacrifice child\n[1880957.563408] Killed process 18694 (perl) total-vm:1972392kB, anon-rss:1953348kB, file-rss:0kB\n[2320864.954447] TCP: Possible SYN flooding on port 7001. Dropping request.  Check SNMP counters.\n```\n\nThis views the last 10 system messages, if there are any. **Look for errors that can cause performance issues**. The example above includes the oom-killer, and TCP dropping a request.\nDon’t miss this step! dmesg is always worth checking.\n\nkernel会将开机信息存储在ring buffer中.您若是开机时来不及查看信息，可利用dmesg来查看。开机信息亦保存在/var/log目录中，名称为dmesg的文件里。\n\n\n\n## 3. vmstat 1\n\n```\n$ vmstat 1\nprocs ---------memory---------- ---swap-- -----io---- -system-- ------cpu-----\n r  b swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st\n34  0    0 200889792  73708 591828    0    0     0     5    6   10 96  1  3  0  0\n32  0    0 200889920  73708 591860    0    0     0   592 13284 4282 98  1  1  0  0\n32  0    0 200890112  73708 591860    0    0     0     0 9501 2154 99  1  0  0  0\n32  0    0 200889568  73712 591856    0    0     0    48 11900 2459 99  0  0  0  0\n32  0    0 200890208  73712 591860    0    0     0     0 15898 4840 98  1  1  0  0\n```\n\nShort for virtual memory stat, vmstat(8) is a commonly available tool (first created for BSD decades ago). It prints a summary of key server statistics on each line.\n\nvmstat was run with an argument of 1, **to print one second summaries**. The first line of output (in this version of vmstat) has some columns that show the average since boot, instead of the previous second. For now, skip the first line, unless you want to learn and remember which column is which.\nColumns to check:\nr: **Number of processes running on CPU and waiting for a turn.** This provides a better signal than load averages for determining CPU saturation, as it does not include I/O. To interpret: an “r” value greater than the CPU count is saturation.\nfree: **Free memory in kilobytes.** If there are too many digits to count, you have enough free memory. The “free -m” command, included as command 7, better explains the state of free memory.\nsi, so: Swap-ins and swap-outs. **If these are non-zero, you’re out of memory**.\nus, sy, id, wa, st: These are breakdowns of CPU time, on average across all CPUs. **They are user time, system time (kernel), idle, wait I/O, and stolen time** (by other guests, or with Xen, the guest’s own isolated driver domain).\nThe CPU time breakdowns will confirm if the CPUs are busy, by adding user + system time. A constant degree of wait I/O points to a disk bottleneck; this is where the CPUs are idle, because tasks are blocked waiting for pending disk I/O. You can treat wait I/O as another form of CPU idle, one that gives a clue as to why they are idle.\nSystem time is necessary for I/O processing. A high system time average, over 20%, can be interesting to explore further: perhaps the kernel is processing the I/O inefficiently.\nIn the above example, CPU time is almost entirely in user-level, pointing to application level usage instead. The CPUs are also well over 90% utilized on average. This isn’t necessarily a problem; check for the degree of saturation using the “r” column.\n\n## 4. mpstat -P ALL 1\n\n```\n$ mpstat -P ALL 1\nLinux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015  _x86_64_ (32 CPU)\n\n07:38:49 PM  CPU   %usr  %nice   %sys %iowait   %irq  %soft  %steal  %guest  %gnice  %idle\n07:38:50 PM  all  98.47   0.00   0.75    0.00   0.00   0.00    0.00    0.00    0.00   0.78\n07:38:50 PM    0  96.04   0.00   2.97    0.00   0.00   0.00    0.00    0.00    0.00   0.99\n07:38:50 PM    1  97.00   0.00   1.00    0.00   0.00   0.00    0.00    0.00    0.00   2.00\n07:38:50 PM    2  98.00   0.00   1.00    0.00   0.00   0.00    0.00    0.00    0.00   1.00\n07:38:50 PM    3  96.97   0.00   0.00    0.00   0.00   0.00    0.00    0.00    0.00   3.03\n[...]\n```\n\nThis command prints CPU time breakdowns per CPU, which can be used to **check for an imbalance**. A single hot CPU can be evidence of a single-threaded application.\n\n## 5. pidstat 1\n\n```\n$ pidstat 1\nLinux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015    _x86_64_    (32 CPU)\n\n07:41:02 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command\n07:41:03 PM     0         9    0.00    0.94    0.00    0.94     1  rcuos/0\n07:41:03 PM     0      4214    5.66    5.66    0.00   11.32    15  mesos-slave\n07:41:03 PM     0      4354    0.94    0.94    0.00    1.89     8  java\n07:41:03 PM     0      6521 1596.23    1.89    0.00 1598.11    27  java\n07:41:03 PM     0      6564 1571.70    7.55    0.00 1579.25    28  java\n07:41:03 PM 60004     60154    0.94    4.72    0.00    5.66     9  pidstat\n\n07:41:03 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command\n07:41:04 PM     0      4214    6.00    2.00    0.00    8.00    15  mesos-slave\n07:41:04 PM     0      6521 1590.00    1.00    0.00 1591.00    27  java\n07:41:04 PM     0      6564 1573.00   10.00    0.00 1583.00    28  java\n07:41:04 PM   108      6718    1.00    0.00    0.00    1.00     0  snmp-pass\n07:41:04 PM 60004     60154    1.00    4.00    0.00    5.00     9  pidstat\n```\n\nPidstat is a little like top’s per-process summary, but prints a rolling summary instead of clearing the screen. This can be useful for watching patterns over time, and also recording what you saw (copy-n-paste) into a record of your investigation.\nThe above example identifies two java processes as responsible for consuming CPU. The %CPU column is the total across all CPUs; 1591% shows that that java processes is consuming almost 16 CPUs.\n\n## 6. iostat -xz 1\n\n```\n$ iostat -xz 1\nLinux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015  _x86_64_ (32 CPU)\n\navg-cpu:  %user   %nice %system %iowait  %steal   %idle\n          73.96    0.00    3.73    0.03    0.06   22.21\n\nDevice:   rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util\nxvda        0.00     0.23    0.21    0.18     4.52     2.08    34.37     0.00    9.98   13.80    5.42   2.44   0.09\nxvdb        0.01     0.00    1.02    8.94   127.97   598.53   145.79     0.00    0.43    1.78    0.28   0.25   0.25\nxvdc        0.01     0.00    1.02    8.86   127.79   595.94   146.50     0.00    0.45    1.82    0.30   0.27   0.26\ndm-0        0.00     0.00    0.69    2.32    10.47    31.69    28.01     0.01    3.23    0.71    3.98   0.13   0.04\ndm-1        0.00     0.00    0.00    0.94     0.01     3.78     8.00     0.33  345.84    0.04  346.81   0.01   0.00\ndm-2        0.00     0.00    0.09    0.07     1.35     0.36    22.50     0.00    2.55    0.23    5.62   1.78   0.03\n[...]\n```\nThis is a great tool for understanding **block devices** (disks), both the workload applied and the resulting performance. Look for:\nr/s, w/s, rkB/s, wkB/s: These are the delivered reads, writes, read Kbytes, and write Kbytes per second to the device. Use these for workload characterization. **A performance problem may simply be due to an excessive load applied.**\nawait: The average time for the I/O in milliseconds. This is the time that the application suffers, as it includes both time queued and time being serviced. **Larger than expected average times can be an indicator of device saturation, or device problems.**\navgqu-sz: The average number of requests issued to the device. Values greater than 1 can be evidence of saturation (although devices can typically operate on requests in parallel, especially virtual devices which front multiple back-end disks.)\n%util: Device utilization. This is really a busy percent, showing the time each second that the device was doing work. Values greater than 60% typically lead to poor performance (which should be seen in await), although it depends on the device. Values close to 100% usually indicate saturation.\nIf the storage device is a logical disk device fronting many back-end disks, then 100% utilization may just mean that some I/O is being processed 100% of the time, however, the back-end disks may be far from saturated, and may be able to handle much more work.\nBear in mind that poor performing disk I/O isn’t necessarily an application issue. Many techniques are typically used to perform I/O asynchronously, so that the application doesn’t block and suffer the latency directly (e.g., read-ahead for reads, and buffering for writes).\n\n## 7. free -m\n\n```\n$ free -m\n             total       used       free     shared    buffers     cached\nMem:        245998      24545     221453         83         59        541\n-/+ buffers/cache:      23944     222053\nSwap:            0          0          0\n```\n\nThe right two columns show:\nbuffers: **For the buffer cache, used for block device I/O.**\ncached: **For the page cache, used by file systems**.\nWe just want to check that these aren’t near-zero in size, which can lead to higher disk I/O (confirm using iostat), and worse performance. The above example looks fine, with many Mbytes in each.\nThe “-/+ buffers/cache” provides less confusing values for used and free memory. Linux uses free memory for the caches, but can reclaim it quickly if applications need it. So in a way the cached memory should be included in the free memory column, which this line does. There’s even a website, linuxatemyram, about this confusion.\nIt can be additionally confusing if ZFS on Linux is used, as we do for some services, as ZFS has its own file system cache that isn’t reflected properly by the free -m columns. It can appear that the system is low on free memory, when that memory is in fact available for use from the ZFS cache as needed.\n\n## 8. sar -n DEV 1\n\n```\n$ sar -n DEV 1\nLinux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015     _x86_64_    (32 CPU)\n\n12:16:48 AM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s   %ifutil\n12:16:49 AM      eth0  18763.00   5032.00  20686.42    478.30      0.00      0.00      0.00      0.00\n12:16:49 AM        lo     14.00     14.00      1.36      1.36      0.00      0.00      0.00      0.00\n12:16:49 AM   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00\n\n12:16:49 AM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s   %ifutil\n12:16:50 AM      eth0  19763.00   5101.00  21999.10    482.56      0.00      0.00      0.00      0.00\n12:16:50 AM        lo     20.00     20.00      3.25      3.25      0.00      0.00      0.00      0.00\n12:16:50 AM   docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00\n^C\n```\n\n\nUse this tool to check **network interface throughput**: rxkB/s and txkB/s, as a measure of workload, and also to check if any limit has been reached. In the above example, eth0 receive is reaching 22 Mbytes/s, which is 176 Mbits/sec (well under, say, a 1 Gbit/sec limit).\nThis version also has %ifutil for device utilization (max of both directions for full duplex), which is something we also use Brendan’s nicstat tool to measure. And like with nicstat, this is hard to get right, and seems to not be working in this example (0.00).\n\n## 9. sar -n TCP,ETCP 1\n\n```\n$ sar -n TCP,ETCP 1\nLinux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015    _x86_64_    (32 CPU)\n\n12:17:19 AM  active/s passive/s    iseg/s    oseg/s\n12:17:20 AM      1.00      0.00  10233.00  18846.00\n\n12:17:19 AM  atmptf/s  estres/s retrans/s isegerr/s   orsts/s\n12:17:20 AM      0.00      0.00      0.00      0.00      0.00\n\n12:17:20 AM  active/s passive/s    iseg/s    oseg/s\n12:17:21 AM      1.00      0.00   8359.00   6039.00\n\n12:17:20 AM  atmptf/s  estres/s retrans/s isegerr/s   orsts/s\n12:17:21 AM      0.00      0.00      0.00      0.00      0.00\n^C\n```\n\nThis is a summarized view of some key TCP metrics. These include:\nactive/s: Number of locally-initiated TCP connections per second (e.g., via connect()).\npassive/s: Number of remotely-initiated TCP connections per second (e.g., via accept()).\nretrans/s: Number of TCP retransmits per second.\nThe active and passive counts are often useful as a rough measure of server load: number of new accepted connections (passive), and number of downstream connections (active). It might help to think of active as outbound, and passive as inbound, but this isn’t strictly true (e.g., consider a localhost to localhost connection).\nRetransmits are a sign of a network or server issue; it may be an unreliable network (e.g., the public Internet), or it may be due a server being overloaded and dropping packets. The example above shows just one new TCP connection per-second.\n\n## 10. top\n\n```\n$ top\ntop - 00:15:40 up 21:56,  1 user,  load average: 31.09, 29.87, 29.92\nTasks: 871 total,   1 running, 868 sleeping,   0 stopped,   2 zombie\n%Cpu(s): 96.8 us,  0.4 sy,  0.0 ni,  2.7 id,  0.1 wa,  0.0 hi,  0.0 si,  0.0 st\nKiB Mem:  25190241+total, 24921688 used, 22698073+free,    60448 buffers\nKiB Swap:        0 total,        0 used,        0 free.   554208 cached Mem\n\n   PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND\n 20248 root      20   0  0.227t 0.012t  18748 S  3090  5.2  29812:58 java\n  4213 root      20   0 2722544  64640  44232 S  23.5  0.0 233:35.37 mesos-slave\n 66128 titancl+  20   0   24344   2332   1172 R   1.0  0.0   0:00.07 top\n  5235 root      20   0 38.227g 547004  49996 S   0.7  0.2   2:02.74 java\n  4299 root      20   0 20.015g 2.682g  16836 S   0.3  1.1  33:14.42 java\n     1 root      20   0   33620   2920   1496 S   0.0  0.0   0:03.82 init\n     2 root      20   0       0      0      0 S   0.0  0.0   0:00.02 kthreadd\n     3 root      20   0       0      0      0 S   0.0  0.0   0:05.35 ksoftirqd/0\n     5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0:0H\n     6 root      20   0       0      0      0 S   0.0  0.0   0:06.94 kworker/u256:0\n     8 root      20   0       0      0      0 S   0.0  0.0   2:38.05 rcu_sched\n```\n\nThe top command includes many of the metrics we checked earlier. It can be handy to run it to see if anything looks wildly different from the earlier commands, which would indicate that load is variable.","url":"https://notes.tczhong.com/notes/7ce478ac-4713-40e9-b8dd-1a45bc1c7f9d.html","relUrl":"notes/7ce478ac-4713-40e9-b8dd-1a45bc1c7f9d.html"},{"doc":"Maintainability","title":"Maintainability","hpath":"development.system.maintainability","content":"\n# Maintainability\n\n- Operability Make it easy for operations teams to keep the system running smoothly.\n- Simplicity Make it easy for new engineers to understand the system, by removing as much complexity as possible from the system. (Note this is not the same as simplicity of the user interface.) \n- Evolvability Make it easy for engineers to make changes to the system in the future, adapting it for unanticipated use cases as requirements change. Also known as extensibil‐ity, modifiability, or plasticity.\n\n\n## Operability\n\n- Monitoring the health of the system and quickly restoring service if it goes into a bad state \n- Tracking down the cause of problems, such as system failures or degraded per‐formance \n- Keeping software and platforms up to date, including security patches \n- Keeping tabs on how different systems affect each other, so that a problematic change can be avoided before it causes damage\n- Anticipating future problems and solving them before they occur (e.g., capacity planning) \n- Establishing good practices and tools for deployment, configuration manage‐ment, and more \n- Performing complex maintenance tasks, such as moving an application from one platform to another \n- Maintaining the security of the system as configuration changes are made \n- Defining processes that make operations predictable and help keep the produc‐tion environment stable \n- Preserving the organization’s knowledge about the system, even as individual people come and go\n\n\n- Providing visibility into the runtime behavior and internals of the system, with good monitoring \n- Providing good support for automation and integration with standard tools \n- Avoiding dependency on individual machines (allowing machines to be taken down for maintenance while the system as a whole continues running uninter‐rupted) \n- Providing good documentation and an easy-to-understand operational model (“If I do X, Y will happen”) \n- Providing good default behavior, but also giving administrators the freedom to override defaults when needed \n- Self-healing where appropriate, but also giving administrators manual control over the system state when needed \n- Exhibiting predictable behavior, minimizing surprises","url":"https://notes.tczhong.com/notes/5951e17d-d4f0-4d40-bdb5-84637fd9ab53.html","relUrl":"notes/5951e17d-d4f0-4d40-bdb5-84637fd9ab53.html"},{"doc":"File_system","title":"File_system","hpath":"development.system.file_system","content":"\n","url":"https://notes.tczhong.com/notes/09956453-4cbd-4f15-a4bd-b1f6c84449a4.html","relUrl":"notes/09956453-4cbd-4f15-a4bd-b1f6c84449a4.html"},{"doc":"Concurrency","title":"Concurrency","hpath":"development.system.concurrency","content":"\n# 并发编程\n\n- 进程: 独立虚拟地址空间\n- i/o多路复用: 一个进程的上下文显示调度他们自己的逻辑流\n- 线程：运行在单一进程上下文的逻辑流，由内核控制\n\n## 进程\n\n- fork, exec, waitpid\n- 共享文件表，不共享用户地址空间，共享状态信息变得困难\n\n## I/O多路复用\n\n使用select函数，要求内核挂起进程，只有在一个或多个I/O事件发生后才将控制返回给应用程序。\n\n用作event-driven程序的基础。\n\n客户端池:\n\n- 优点：不需要切换上下文\n- 缺点：编码复杂\n\n## thread\n\n有自己的thread id, stack, PC, registers\n\n共享进程的整个虚拟地址空间。\n\n线程之间对等，无父子关系，切换上下文快。\n\npthread api\n\n- pthread_create\n- pthread_exit\n- pthread_join ：回收，阻塞，直到tid终止\n- pthread_detach: 不被其他回收，在终止时被系统回收\n\n- 共享变量\n  - 全局变量：任何线程都可以访问\n  - 本地自动变量：无static,只在自己的thread里\n  - 本地静态：线程共享，在vm里只有一个\n\n\n","url":"https://notes.tczhong.com/notes/a072f1a5-d9ec-4e89-a252-24c945125dc0.html","relUrl":"notes/a072f1a5-d9ec-4e89-a252-24c945125dc0.html"},{"doc":"Compute","title":"Compute","hpath":"development.system.compute","content":"\n","url":"https://notes.tczhong.com/notes/29d090f8-75e0-4755-911f-d09996ce472c.html","relUrl":"notes/29d090f8-75e0-4755-911f-d09996ce472c.html"},{"doc":"Yarn","title":"Yarn","hpath":"development.system.compute.yarn","content":"\n\n- YARN, which separates the resource management and processing components. The YARN-based architecture is not constrained to MapReduce.\n![](pic/yarn.jpg)\n- The **ResourceManager** tracks how many live nodes and resources are available on the cluster and coordinates what applications submitted by users should get these resources and when\n- **ApplicationMaster** is started to coordinate the execution of all tasks within the application.The ApplicationMaster and tasks that belong to its application run in resource containers controlled by the NodeManagers.\n- The **NodeManager** is a more generic and efficient version of the TaskTracker. The NodeManager has a number of dynamically created resource containers.\n\n## features\n\n- **Uberization** is the possibility to run all tasks of a MapReduce job in the ApplicationMaster's JVM if the job is small enough\n- Binary or source compatibility for MapReduce jobs written for MRv1\n- An application recovery after the restart of ResourceManager","url":"https://notes.tczhong.com/notes/702fff31-53e3-4e74-afac-834104e504f0.html","relUrl":"notes/702fff31-53e3-4e74-afac-834104e504f0.html"},{"doc":"Spark","title":"Spark","hpath":"development.system.compute.spark","content":"\n\n- key point: efficient\n    - general execution graphs\n    - in-memory storage\n- Resilient Distributed Datasets\n    - Collections of objects spread across a cluster, stored in RAM or on disk\n    - build through parallel transformation\n    - automatically rebuild on failure \n    - It track lineage information that can be used to efficiently recompute lost data\n- DAG scheduler(Directed Acyclic Graph)\n    - job: one action for RDD\n    - stage: split in shuffle for job\n    - task: real task in executor\n    - DAG in Apache Spark is a set of Vertices and Edges, where vertices represent the RDDs and the edges represent the Operation to be applied on RDD.\n    - know the dependency for different RDD\n    - In this way, the execution plan is optimized, e.g. to minimize shuffling data around. \n    - ![](https://img-blog.csdn.net/20170427180924863?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMTU2NDE3Mg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)","url":"https://notes.tczhong.com/notes/1b397a58-59ed-40af-8f56-76fb5c6706d6.html","relUrl":"notes/1b397a58-59ed-40af-8f56-76fb5c6706d6.html"},{"doc":"Mapreduce","title":"Mapreduce","hpath":"development.system.compute.mapreduce","content":"\nMapReduce is a programming model for processing large amounts of data in bulk across many machines\n\nThe map and reduce functions are somewhat restricted in what they are allowed to do. They must be pure functions, which means they only use the data that is passed to them as input, they cannot perform additional database queries, and they must not have any side effects.\n\n- **what**: do parellel in map phase, do merge sort in sort, do linear in reducer\n- **why**: quick in map, slow in reduce\n- **how**: could do select, filter, min,max,sum, no avg, join is not a good operation in mapreduce, only in reduce phase.\n- sort:\n    - search in the final result\n    - mapper yield duplicated key and we need use sort to group them in one reducer \n- **problem**\n    - A single **master** process called **JobTracker**, which **coordinates** all jobs running on the cluster and **assigns** map and reduce tasks to run on the TaskTrackers\n    - A number of subordinate processes called **TaskTrackers**, which run assigned tasks and periodically report the progress to the JobTracker\n    - Hadoop was designed to run MapReduce jobs only\n    - more maps means more overhead for master to keep track of the state of computation\n    - fewer map-reduce phase","url":"https://notes.tczhong.com/notes/7aaf2b79-919b-41d0-9895-6a61f51a1d6b.html","relUrl":"notes/7aaf2b79-919b-41d0-9895-6a61f51a1d6b.html"},{"doc":"Container","title":"Container","hpath":"development.system.compute.container","content":"\n\n# VM and containers\n\n- **what**: a virtualized system is a **mapping** of its interface, and all resources visible through that interface, to the interface and resources of a real system.\n- **why**: \n    - provide a way of relaxing constrains and increasing flexibility\n    - advantages\n        - multiple secure environment: system VM provides a sandbox isolates one system environment from others\n        - failure isolation\n        - mixed-os environment: one hardware support multiple OS concurrently\n        - better System Utilization: can be dynamically or statically re-configured for changing needs\n    - properties:\n        - isolation: fault, software, performance(done by scheduling)\n        - encapsulation: all VM state could be captured in a file\n        - interposition: all guest actions could be inspect, modify and deny\n- **how**: abstraction. provide a simplified interface to underlying resources. virtualization provides a different interface at the same level of abstraction.\n    - hypervisor: a co-designed firmware-software layer,use this layer to manage the virtual machines\n    - full virtualization: provide same function as the underlying physical hardware. Allow unmodified OS to execute on VM\n    - para-virtualization: provide similar function, and modify OS to cooperate with VMM. Get lower overhead and better performance.\n    - Emulation: implement same function with different intereface and functionality\n    - system VM: vmare, process VM: jvm\n    - multiprocessor system: partition(subset of the resources)-> in space(physical), in time(logical)\n    - in DS:\n        - abstract environment from resources\n        - abstract application from environment\n        - different environment no affect users\n        - migration\n        - scaling\n        - protection\n        - sharing\n\n## Containers\n\n- share part of OS\n- provide independent\n- resource share.  secure problem\n- less isolation","url":"https://notes.tczhong.com/notes/aca8c893-60f8-465f-bda5-31b9ae83d81a.html","relUrl":"notes/aca8c893-60f8-465f-bda5-31b9ae83d81a.html"},{"doc":"Code_deployment","title":"Code_deployment","hpath":"development.system.code_deployment","content":"\n# continous www push\n\n- Check out trunk\t--\t<0:01\tcheck out the most current trunk revision in WWW. \n- Build\t<0:01\t0:35\tOnce we have a version locked in, we kick off an asynchronous test run, and start doing a build. A build in this context is taking the PHP files in the repo and turning it into packages that we will actually ship to web servers. This can fail in many ways, from Hack failures, to static resources errors, to other random stuff.\n- Test\t0:10\t0:15\tThe actual work here usually finishes while the build step is running. If any test failed, we consider the step failed.\n- Try Acquiring Deploy Lock\t0:35\t<0:01\tWe don't want to push if someone hit the stop button, nor do we want multiple pushes back to back to back, so if any build is currently beyond this step (pushing or waiting), we'll mark the push phases as SKIPPED and end the push instance.\n- Push Trunkstable/c1\t0:35\t0:20\tThis basically does a twdeploy push_job which will push trunkstable. See the Tupperware UI for a list of these jobs. We do this rollout in a staged fashion. Each individual server is down for under 5 minutes.\n- Push C2\t1:10\t0:30\tNow we'll do tupperware push_job to push these jobs. This will be hit by 1% (soon 2%) of users, so we have a system called Presholds which may pause the push if some metrics look bad enough (logspew, fatals, latency, servers not coming back up). If enough jobs get paused in this way, we'll revert c2 and fail the push.\n- Verify C2\t1:40\t0:25\tNow we wait again. This time we want employees and alerts to have a chance to notice c2 is broken. At the end of this 15 minute window we check for any alerts with the `blocks_c3_push` tag. If any are found we'll fail the job.\n- Push C3\t1:50\t0:30\tThis behaves exactly like pushing c2, it also has presholds. Naturally there are different Tupperware jobs.\n- Done\t2:20\t--\tOnce this finishes, we're done and another build can try and grab the deploy lock!","url":"https://notes.tczhong.com/notes/74d8b2c3-120c-4f4b-b3f4-6d1e702f763e.html","relUrl":"notes/74d8b2c3-120c-4f4b-b3f4-6d1e702f763e.html"},{"doc":"Processing","title":"Processing","hpath":"development.processing","content":"\n","url":"https://notes.tczhong.com/notes/baa39444-0da9-4c55-8df7-2a6f8f787fa4.html","relUrl":"notes/baa39444-0da9-4c55-8df7-2a6f8f787fa4.html"},{"doc":"Pe_domain","title":"Pe_domain","hpath":"development.pe_domain","content":"\n# Monitoring\n\n# Logging \n\n# Alerting\n\n# Automation","url":"https://notes.tczhong.com/notes/2e151826-cb22-4d89-8ce0-71dad7204ce8.html","relUrl":"notes/2e151826-cb22-4d89-8ce0-71dad7204ce8.html"},{"doc":"Libra","title":"Libra","hpath":"development.pe_domain.libra","content":"\n# libra production\n\nstep 1: \n\n- single docker image + deploy on AWS ECS\n- pre-generated key\n- run majority\n\nstep 2:\n\n- better isolation between components\n- tooling support\n- moved to Kubernetes\n- run multiple cloud\n- minimum validator architecture\n\n![](/assets/images/2021-04-21-09-59-53.png)\n\nstep 3:\n\n- security enhancement\n  - store keys in vault\n- production deployment\n  - isolating the validator network\n  - provide public access\n\n![](/assets/images/2021-04-21-10-08-06.png)\n\nstep 4:\n\n- tooling support\n- support backup and restore\n- operational readiness\n\n\nstep 5:\n\n- storm, DR\n- runbook\n- training\n- falut tolerance policy\n- support diversity deployment","url":"https://notes.tczhong.com/notes/4149fe74-922e-4805-bef8-29ecb772a08d.html","relUrl":"notes/4149fe74-922e-4805-bef8-29ecb772a08d.html"},{"doc":"Network","title":"Network","hpath":"development.network","content":"\n# OSI\n\n- [[Application|development.network.applicationlayer]]\n- Presentation\n- Session\n- [[Transport|development.network.transportlayer]]\n- [[Netwrok|development.network.networklayer]]\n- [[Link|development.network.linklayer]]\n- [[Pysical|development.network.physicallayer]]\n\n# network type\n\n- circuit switching\n  - dedicated circuit per call, no sharing, setup required\n  - network bandwidth divided into pieces: FDM, TDM\n- packet switching\n  - each packet use full bandwidth\n  - move hop-at-a-time, get complete packet before forwarding\n  - statistical multiplexing\n  - store-and-forward.\n  - L bits, R bps throughput, take L/R seconds to transmit","url":"https://notes.tczhong.com/notes/92917ea3-452e-48dc-875e-5cd0002041db.html","relUrl":"notes/92917ea3-452e-48dc-875e-5cd0002041db.html"},{"doc":"Transportlayer","title":"Transportlayer","hpath":"development.network.transportlayer","content":"\n# transport layer\n\ntcp/udp\n\n- end-to-end, broke whole messages to segments\n- connection-oriented service: reliable delivery, error detection, congestion control, flow control\n- connectionless service: best effort delivery\n\n\n![](/assets/images/2021-03-25-16-41-46.png)\n\n- mission: **Logical** connection, between applications running on different hosts\n- Logical communication = as if the applications were directly connected\n    - scope: between applications\n    - addressing mechanism: multiplex, port numbers bound to an application, 16-bit unsigned number\n    - data types: segment\n- responsibilities: \n    - **multiplex** messages/de..  end host run **mulitple** applications -> addressing\n    - break data to segments and re-assembly\n        - segmentation, broken into segments\n    - connection setup and state management and tear down\n    - TCP: reliability guarantee\n    - Transport layer adds header with additional information (port numbers, ...)\n  \n","url":"https://notes.tczhong.com/notes/ad8989e5-cb41-4b92-8d49-57a81d93d294.html","relUrl":"notes/ad8989e5-cb41-4b92-8d49-57a81d93d294.html"},{"doc":"Udp","title":"Udp","hpath":"development.network.transportlayer.udp","content":"\n# udp\n\n- advantages/disadvantages\n    - adv:\n        - connectionless: no connection establishment, thus no additional delay\n        - fast: no handshake\n        - each segment handled independently\n        - Very simple: no state to maintain\n        - Segment header is small\n    - dis\n        - segments may be lost\n        - may out-of-order\n        - no congestion control\n        - There are no guarantees with UDP.\n- segment format\n    - source port, dest port, length(**whole segment** at least 8 byte(header size)), checksum, application data\n- reliability assumptions\n    - Often used for **streaming** multimedia apps \n    - Loss tolerant\n    - **Rate sensitive** (timeliness)\n    - Reliability can be added at app layer\n\n\n","url":"https://notes.tczhong.com/notes/9717a6f8-21da-477c-9258-5c53ec050f27.html","relUrl":"notes/9717a6f8-21da-477c-9258-5c53ec050f27.html"},{"doc":"Tcp","title":"Tcp","hpath":"development.network.transportlayer.tcp","content":"\n# TCP\n\n- point-to-point / reliable / in-order byte stream / pipelined: sliding windows\n- full duplex data: bi-directional data flow\n- connection-oriented: handshaking (exchange of control messages) initializes sender & receiver state before data exchange\n- Both sides have buffers\n- Flow Control\n- Congestion Control\n\n## connection and tear down\n\n- establish: setup state before exchanging data segements\n  - step1: send SYN segment and specifies initial seq#, no data\n  - why random sn? an earlier incarnation of the same connection can interfere with a later one\n  - step2: server respond with SYNACK segment, allocates buffers and specifies initial seq#\n  - step3: replies with ACK, may contain data\n  - if host receive with SYN to a closed port, responds with a RST segments \n- teardown: free up state \n  - step1: send TCP FIN to server\n  - step2: server responds with ACK and closed, send FIN\n  - step3: client receives FIN, replies with ACK , wait \n  - why? possible ACK lost\n  - Client may open the same connection again (same pair of port #s) \n  - then Receives FIN from earlier incarnation of connection\n  - so Immediately initiate closing of the later incarnation\n  - Step 4: server receives ACK, closes connection\n\n\n## RDT\n\n  - TCP creates RDT service on top of IP’s unreliable service\n    - Pipelined segments \n    - Cumulative acks\n    - Retransmission timer\n  - Retransmissions are triggered by:\n    - timeout events \n    - duplicate acks\n  - Initially, we consider simplified TCP sender:\n    - ignore duplicate acks\n    - ignore flow control, congestion control\n    - assume RTT is estimated somehow\n  - SN : byte stream “number” of first byte in segment’s data\n  - ACKs: seq # of next byte expected from other side\n    - **cumulative** ACK: acknowledges bytes up to the first missing byte in the stream\n  - Data received from app:\n    - Create segment\n    - seq# is byte-stream number of first data byte in segment\n    - Send, if allowed by congestion & flow-control\n    - start timer if not already running (think of timer as for oldest unacked segment)\n    - expiration interval: TimeOutInterva\n  -  Timeout:\n    -  retransmit segment that caused timeout\n    -  restart timer\n  - ACK received:\n    -  If acknowledges previously unACKed segments\n    -  update what is known to be ACKed\n    -  start timer if there are outstanding segments\n  - fast retransmit\n    - If segment is lost, there will likely be many duplicate ACKs\n    - If sender receives 3 duplicate ACKs, it supposes that segment after ACKed data was lost: resend segment before timer expires： voodoo constant\n\n![[development.network.reliable_data_transfer]]\n## Flow control\n\n- mission: Sender won’t overflow the **receiver’s buffer** by transmitting too much, too fast\n  - matching the send rate to the receiving app’s drain rate\n  - operation:\n- mechanism\n    - RcvWindow = RcvBuffer - [ LastByteRcvd - LastByteRead ] (assume discard out of order)\n    - Receiver advertises spare room by including value of RcvWindow in ACK segment\n    - Gives sender permission to send this much\n\n- congwin: how much data allowed in-flight at any time, >= LastByteSent-LastByteAcked\n    - **rate = congwin/RTT**\n- sender perceive congestion: timeout / 3 duplicate ACKs\n- self-clocking nature: use ACK to trigger its increase in congestion window size\n- interaction of various phases \n  - When CongWin is below Threshold, window grows exponentially (slow-start phase)\n  - When CongWin is above Threshold, window grows linearly (congestion-avoidance phase)\n  - When a triple duplicate ACK occurs, Threshold set to CongWin/2 and CongWin set to Threshold. Window grows linearly\n  - When timeout occurs, Threshold set to CongWin/2 and CongWin is set to 1 MSS. Enters slow-start phase\n- slow start\n  - start with MSS = 1, increase exponentially, done by increasing CongWin by 1MSS for every ACK received\n  - With Slow Start, no bandwidth wasted on retransmission\n  - end: first lost event\n- congestion avoidance\n    - start: first lost event\n        - cut CongWin in half after a loss event\n        - Continue probing for usable bandwidth\n    - Reno: after 3 dup, cancel slow start, cut half CongWin, grows linearly\n        - after timeout, set ssthrehold to half, skip ss, fast recovery.\n        - fast retransmit:  after 3 dup\n    - Tahoe: after loss event, congwin set to 1, enter slow start\n- how TCP sets timeout values.\n    - longer than RTT. \n    - too short, premature timeout, unnecessary retransmissions\n    - too long, slow reaction to segment loss\n    - need to measure RTT for baseline\n\n","url":"https://notes.tczhong.com/notes/29ec6e3f-8b45-44b1-95c0-69042790897a.html","relUrl":"notes/29ec6e3f-8b45-44b1-95c0-69042790897a.html"},{"doc":"Transit","title":"Transit","hpath":"development.network.transit","content":"\n## Peering\n\n![](/assets/images/2021-03-25-16-50-29.png)\n\n![](/assets/images/2021-03-25-16-52-09.png)\n\n## FNA\n\n![](/assets/images/2021-03-25-16-50-00.png)\n\n## network types\n\n![](/assets/images/2021-03-25-16-52-47.png)","url":"https://notes.tczhong.com/notes/deaa7fda-319a-43a5-b4da-1083f4119966.html","relUrl":"notes/deaa7fda-319a-43a5-b4da-1083f4119966.html"},{"doc":"Synctime","title":"Synctime","hpath":"development.network.synctime","content":"\n\n1. SYNCHRONIZING PHYSICAL TIME: central server\n1. time server and distributed to nodes. Latency between transfer could be a problem.\n    - 估计来回的时间\n    - 注意不要回到过去\n    - 可以miss tick放慢时间\n2. 没有一个标准时间的话，就设立一个master询问每个client时间，average.调整时间是原来的两倍。\n3. BERKELEY ALGORITHM: server向所有人请求时间，算入RTT，average，返回client，注意drift可能是原来的两倍。\n3. logical time: 保证顺序。高时间不可能导致低时间的任务发生。\n4. LAMPORT LOGICAL TIME: happened before\n    - The counter is incremented before each event.\n    - The message should carry the new (incremented) timestamp.\n    - 维护全局index，不能处理接受和发送的问题\n    - If two events have no message exchange, Lamport logical time cannot tell which one happened first\n    - 可能出现无法处理因果的情况\n5. google truetime: compares itself with others, twice drift\n6. Cristian's Algorithm is one approach to synchronizing physical clocks using a time server.","url":"https://notes.tczhong.com/notes/04532056-dd8e-4f05-b71b-b3ceb756a898.html","relUrl":"notes/04532056-dd8e-4f05-b71b-b3ceb756a898.html"},{"doc":"Sessionlayer","title":"Sessionlayer","hpath":"development.network.sessionlayer","content":"\n\n![](/assets/images/2021-03-25-16-43-26.png)\n\n- rpc","url":"https://notes.tczhong.com/notes/93d4fee1-2c80-4430-bf23-0891bbbfa8ad.html","relUrl":"notes/93d4fee1-2c80-4430-bf23-0891bbbfa8ad.html"},{"doc":"Rpc","title":"Rpc","hpath":"development.network.rpc","content":"\n1. REMOTE PROCEDURE CALL: REPLACE COMMUNICATION VIA THE STACK WITH THE NETWORK\n    - A type of client/server communication\n    - Attempts to make remote procedure calls look like local ones\n2. problem:\n    - Calling and called procedures run on different machines, with different address spaces\n    - Must convert to local representation of data\n    - Machines and network can fail\n3. STUBS: OBTAINING TRANSPARENCY\n    - Client stub\n        - Marshalsargumentsintomachine-independentformat\n        - Sendsrequesttoserver\n        - Waits for response\n        - Unmarshals result and returns to caller\n    - Server stub\n        - Unmarshals arguments and builds stack frame \n        - Calls procedure\n        - Server stub marshals results and sends reply\n4. RFC makes a user defined header to a entire empty server library and user can filled them in.\n5. 写个接口让程序员调用服务器上的方法就像本地一样\n6. 通过编码和解码传输参数，遇到大小端的问题的话，可以采用语言将数据包装，这样就和地址顺序无关了。\n7. 存在的问题是：如果调用失败，可能是server或者网络的问题，无法排查。解决方式可以是在server保证最多一次request，出现第二次也返回第一次的reply \n8. 同步方法：1. 只进行一次rpc，允行完再ack 2. 两次rpc，收到请求ack，运行完ack","url":"https://notes.tczhong.com/notes/639abe2b-7d06-4201-b6c6-e0e59d3d020e.html","relUrl":"notes/639abe2b-7d06-4201-b6c6-e0e59d3d020e.html"},{"doc":"Reliable_data_transfer","title":"Reliable_data_transfer","hpath":"development.network.reliable_data_transfer","content":"\n# RDT\n\n## possible failure\n\nbit-errors, lossy, duplicate delivery , out-of-order delivery\n\n## methods\n\n- checksums: bit error \n- receiver feedback: bit error, ACK/NACK， Cumulative acknowledgments(I have received all packets with sequence numbers up to but not including sn.) allow acknowledgment of numerous packets at a time. They can be useful in pipelined protocols. 可能lost\n- retransmission : Sender sends another copy of segment, detect loss and allows for duplicate seg\n- sequence numbers : Distinguish between old and new, Gaps let receiver detect lost segment, find duplicate packets，restoring the transmitted order. have to be a bounded # bits\n- timer expiration: Segment or receiver feedback is lost (sender: Resends a packet after a timer fires. Sends a new packet after an acknowledgment (positive) arrives.)\n- window:Control sending of multiple segments, allow for reuse of sequence numbers, also allow for pipeling segments\n\n## protocols\n\n### Stop-n-Wait\n\n - Simplest Protocol that will handle bit errors and segment loss\n    - use: checksum, ack, sn, timers\n    - 1 bit for sequence number\n    - ![](/assets/images/2021-04-03-23-06-30.png)\n    - ![](/assets/images/2021-04-03-23-07-36.png)\n    - 为了解决checksum返回的时候有问题。可能ack会lost。带来的问题就是可能重复发几次。所以需要seq num\n    - ![](/assets/images/2021-04-03-23-08-48.png)\n    - 计时发送，看指定时间能否达到response, 没seq num. 接收者不能知道是否是重发。LOST ACK和lost segment对于发送方式一样的\n\n\n## Go Back N\n       \n- sliding window: A mechanism to control multiple, in-flight segments without overwhelming receiver, Sender is allowed to transmit N segments without waiting for an ACK\n- “window” of up to N, consecutive unACKed segments allowed\n- Sets a **timer** for each in-flight segment\n- timeout(n): retransmit segment n and all **higher** seq# segments in window\n- sender:\n  - Sender places a k-bit seq# in header\n  - “window” of up to N, consecutive unACKed segments allowed\n  - Sets a timer for each in-flight segment\n  - timeout(n): retransmit segment n and **all higher** seq# segments in window\n  - ACK(n): ACKs all segments up to, including seq# n (Cumulative ACK)\n- receiver: ACK-only: always send ACK for correctly-received segment with **highest in-order seq**, Receipt of out-of-order segment just discard and send with highest in-order seq \n    - May generate duplicate ACKs\n    - Why discard segs received out-of-order： Don’t want to buffer them, going to be re-sent anyway\n- A single segment error can cause many segments to be retransmitted\n\n## Selective Repeat\n\n  - Receiver individually ACKs all correctly received segments\n  - Buffers segs for eventual in-order delivery\n  - Sender only resends segments for which ACK not received\n  - Sets timer for each segment\n  - Sender window of N consecutive seq#s\n  - Limits seq # s of sent, but unACKed segs\n  - ![](/assets/images/2021-04-03-23-12-02.png)\n  - issues: both side have varying view, receiver window移动了，但是发送端没收到ack， 会重传。\n  - sequence number的space至少是2^k 个，k是window的大小","url":"https://notes.tczhong.com/notes/c16ae2ab-1fc3-40f4-8053-a8397954d3bb.html","relUrl":"notes/c16ae2ab-1fc3-40f4-8053-a8397954d3bb.html"},{"doc":"Queue","title":"Queue","hpath":"development.network.queue","content":"\n# queue theory\n\n- performance evaluation\n  - $\\lambda$ average arrival rate, packets per second\n  - $\\mu$ average service rate, packets servered per second\n  - $c$ number of servers\n  - $\\rho = \\lambda/c\\mu$ traffic congestion in servers\n    - if >1 averge exceeds service capability\n    - if = 1 randomness prevents queue from emptying\n  - $p_n$ is probability of a particular number n customers in the system\n  - expected number in system: $L = \\sum(n p_n)$\n  - expected number in queue: $L = \\sum_{n=c+1}((n-c) p_n)$\n  - time : $T = T_q + S$ time in queue + service time\n  - **little law**\n    - $W = E[T] W_q = E[T_q]$ mean waiting time in system\n    - $L = \\lambda W$ \n    - $E[T] = E[T_q] + E[S]$ to get $W = W_q + 1/\\mu$\n    - expected servered people: $E[N_s] = L-L_q = \\lambda(W-W_q) = \\lambda(1/\\mu) = \\lambda/\\mu$\n    - $c = 1, r = \\rho , L-L_q = \\sum_{n=1} np- \\sum_{n=1} (n-1)p = \\sum_{n=1} p_n =  1-p_0=\\rho$\n  - busy probability\n    - for G/G/c system, $E[N_s] = r$\n    - $P_b = \\rho$ one server being busy brobability\n    - ...\n\n- rate transition diagrams\n  - a type of continuous-time Markov chain\n  - $(\\lambda_n+\\mu_n)p_n =(\\lambda_{n-1}+\\mu_{n-1})p_{n-1}+(\\lambda_{n+1}+\\mu_{n+1})p_{n+1}$\n  - $p_3 = \\frac{\\lambda_2 \\lambda_1 \\lambda_0}{\\mu_3 \\mu_2 \\mu_1} p_0 $\n  - $p_n = \\prod_{i=1}^n\\frac{\\lambda_{i-1}}{\\mu_i}$\n\n- M/M/1 system\n  - Exponentially distributed \n    - interarrival time $TI(t)=\\lambda e^{-\\lambda t}$\n    - service time $TI(t)=\\mu e^{-\\mu t}$\n  - if all $\\mu$ and $\\lambda$ equal get $p_n = p_0 (\\frac{\\lambda}{\\mu})^n$\n  - $p_0 = 1-\\rho$ - > $p_n = (1-\\rho)\\rho^n$","url":"https://notes.tczhong.com/notes/e6974c21-0b19-4c99-8bae-4a0470280d4d.html","relUrl":"notes/e6974c21-0b19-4c99-8bae-4a0470280d4d.html"},{"doc":"Programming","title":"Programming","hpath":"development.network.programming","content":"\n\n# basic\n\n- socket: `ip:port`\n  - 客户端： port是由内核自动分配的\n  - server端：port是和服务对应的\n- 一个连接是一个socket pair\n\n\n![](/assets/images/2021-05-03-20-17-16.png)","url":"https://notes.tczhong.com/notes/16c57356-0baf-4bbf-8313-b403f2097c20.html","relUrl":"notes/16c57356-0baf-4bbf-8313-b403f2097c20.html"},{"doc":"Problem","title":"Problem","hpath":"development.network.problem","content":"\n# problem happened in the network\n\n## data loss\n\n## delay\n\n- processing, time spent in router, check bit error, determine output link\n- queueing, depends on congestion level\n- transmission delay: L/R bits/ bps\n- propagation delay: d/s (length/2*10^8)\n- $\\lambda$ = avg packet arrival rate(pts/s), traffic intensity: $L \\lambda /R$ value -> 1, delay becomlarge.\n- nodal delay = $d_{proc}+d_{queue}+d_{trans}+d_{prop}$\n\n### measurement\n\n- tracerouter algo:\n   - for all router i:\n        - send three packets to router i \n        - router i will return packets to sender\n        - measure transmission and reply interval","url":"https://notes.tczhong.com/notes/40495a7b-c9bc-4da6-991d-8faaea8db49e.html","relUrl":"notes/40495a7b-c9bc-4da6-991d-8faaea8db49e.html"},{"doc":"Physicallayer","title":"Physicallayer","hpath":"development.network.physicallayer","content":"\n![](/assets/images/2021-03-25-15-54-22.png)","url":"https://notes.tczhong.com/notes/9d3d1d0a-476d-4bff-9434-74ebdc944f9f.html","relUrl":"notes/9d3d1d0a-476d-4bff-9434-74ebdc944f9f.html"},{"doc":"Networklayer","title":"Networklayer","hpath":"development.network.networklayer","content":"\n# network layer\n\nip\n\n**transfer packets across links**, addressing scale to large networks, routing protocol determines best paths across the network\n\n\n## IP\n\naddressing mechanism: IP ADDRESS \n\n- No call setup at network layer\n- Packets are forwarded using address of the destination host\n- Packets are forwarded independently\n- Packets between same source-dest pair may take different paths\n- addressing\n  - Each end-host has unique address\n  - Forwarding table maps addresses to outgoing link\n\n### packet\n\n- data types: packet\n  - On sending side, encapsulate segment into packets\n  - Transmit the packet through the network\n  - Network layer protocols exist on all routers (and hosts) for this purpose\n  - On receiving side, deliver packets to transport layer\n\n### routing\n\n- Routing (Control Plane)\n    - **Involves all routers in a network**\n    -  Creates a **forwarding** table to determine end-to-end paths taken by packets\n    -  Uses routing algorithms\n- Forwarding (Data Plane)\n    - Move packets from router’s incoming interface to appropriate outgoing interface\n    - An action in a single router\n    - use forwarding table\n- Connection Setup: setup route states before sending packets\n\n### format\n\n- packet-handling operations at each router\n    - forward with destination of address\n    - forward independently\n- format\n    - Version specifies IPv4\n    - Header length (in 32-bit words)\n    - Type of Service\n    - Datagram length (Header + data) 20bytes+data\n    - ID, Flags, Offset: Used for fragmentation at router\n        - 1 DF Don't fragament\n        - 2 MF more fragament\n        - ID unique\n    - Time-to-Live: Decremented at each router, Datagram dropped if zero\n    - Protocol\n        - Used by receiver to determine which transport protocol should get packet\n    - Header checksum: Calculated only on header\n        - Must be recomputed at each router: because ttl changes\n    - use checksum because other protocol maybe involved\n    - Data: Encapsulated TCP/UDP segment . ICMP data\n\n### ipv4\n\n- prefix notation: range of subnet 128.2.101.64/26\n    - 6 bit free\n    - example: 223.1.17.0/25 for /24 half, 223.1.17.128/26 for 64, 223.1.17.192/26 for 64\n- forwarding tables:\n    - put prefix matching in destination prefix\n    - match the leading bits of destination address to the longest listed prefix: **longest matching prefix rule**\n- CIDR classless interdomain routing\n\n\n![](/assets/images/2021-03-25-16-00-27.png)\n\n![](/assets/images/2021-03-25-16-14-19.png)\n\n\n### ICMP\n\n- single ip packet\n    - no reliability\n    - type/ code for echo/unreachable....\n- traceroute:\n    - send nth udp segments has TTL of n\n    - replies with ICMP time exceeded\n- is a network-layer protocol\n    - Messages used for communication between routers and end-hosts\n    - Messages sent in an IP packet - Just like a UDP segment\n    - Messages require special processing by the IP layer software on each router\n\n### forwarding table\n\ndijkstra\n\n![](/assets/images/2021-04-11-21-58-17.png)\n\n- 每次更新新加入的点到未加入点的距离。每次从未加入点中选一个距离到已加入的set里\b最小的\n  - short path tree\n  - use dijkstra's to get routing table\n  - O(n^2)\n\nbellman-ford\n\n- Each node periodically sends its own distance vector estimates to neighbors\n- When a node x receives a new DV estimate from a neighbor v, uses B-F\n- Dx(y) ←minv{c(x,v)+Dv(y)} for each y ∈ N\n- The estimate Dx(y) converges to the actual dx(y) for minor, natural conditions\n\n## AS\n\n- A collection of physical networks with a unif\n    - ISP, A Corporate network, A Campus networ\n- An AS may get an AS number (ASN)\n    - ASNs represent units of routing policy\n- AS can have one/many/none ASN\n\n\n## BGP\n\n- function\n    - Obtain network reachability information from neighboring AS\n    - Propagate the reachability information to all routers internal to the AS\n    - Determine “good” routes to subnets based on the reachability information and on AS policy\n    - Advertise its existence to the rest of the Internet!\n- Uses path vector routing algorithm\n- Is heavily policy-based\n- Principles of Operation\n    - A BGP session is established between routers (TCP)\n    - exchange route UPDATE messages while connection is ALIVE\n    - message\n        - open： set up session\n        - keepalive: confirms liveness to neighbor\n        - notificatoin: signals an error before\n        - UPDATE: Primary message to communicate information about routes\n            - Announce or withdraw routes\n            - Route = prefix + path attributes\n    - eBGP runs between ASes\n    - iBGP within AS\n\n\n![](/assets/images/2021-03-25-16-16-40.png)\n\n![](/assets/images/2021-03-25-16-18-44.png)\n\n![](/assets/images/2021-03-25-16-20-16.png)\n\n![](/assets/images/2021-03-25-16-22-51.png)\n\n![](/assets/images/2021-03-25-16-28-17.png)\n\n## DHCP\n\n- Dynamic Host Configuration Protocol (IP)\n- information carried: a pool of IP addresses, a repository of network details\n    -  Provides these details upon request or by default\n- methods of communication : broadcast, Send to 255.255.255.255, UDP, port 67\n- leases : Used for dynamic allocation, Solution for control of when an address can be given to another client\n    - Server allows use of addr for a set period, Client will need to reacquire permission before lease period expires(automatically)\n- message format:\n    - type: discover, offer, request, ack, release\n    - xid: Random transaction value (client 发，用于定位client)\n    - chaddr: client hardware identifier\n    - siaddr: server’s IP address\n    - yiaddr: “your” address\n    - options: lots of optional parameters\n- the discovery process\n    - broadcast first, Multiple servers may respond\n    - Client chooses whichever offer it wishes\n    - DHCP Request / Ack is repeated to renew a lease\n\n\n## NAT\n\n- Network Address Translation\n    - router manage a subnet\n    - map one address space to another\n- benefits\n    - Work-around to the impending exhaustion of IP addresses  \n    -  Also allows for simple address allocation for the subnet\n    - “Security”: internal network structure obscured\n- objections\n    - IPv6 should be used to solve addressing problem\n    - Objection 2: Violates end-to-end principle\n    - Objection 3: Routers shouldn’t process packets higher than network layer\n    - Objection 4: Using port numbers to address hosts\n- operations\n    - hosts on private network use \"non-routable\" ip addresses (10.0.0.0/8 172.16.0.0/16 192.168.0.0/16)\n    - these addresses are not unique, restricted to the private subnet\n    - Router shows a single external IP address\n    - Translation table maps external IP / port combinations to internal IP / port\n    - rewrite all packets in each direction, changing based on translation table\n        - Other fixes also needed to the packet\n    -  Packet Fix-up\n        - Fix checksums\n        - Router must do more than simply change address/port values\n- port forwarding.\n    - NAT Address Translation Table\n    - Translation table is normally initialized by internal traffic\n    - Port forwarding specifies values ahead of time\n\n\n# tool\n\n- ping: send one packets and cal RTT\n- traceroute: will send 3 packets to each router it.","url":"https://notes.tczhong.com/notes/6b73a39d-3aee-4ff4-8d92-39736cc4b8b3.html","relUrl":"notes/6b73a39d-3aee-4ff4-8d92-39736cc4b8b3.html"},{"doc":"Loadbalance","title":"Loadbalance","hpath":"development.network.loadbalance","content":"\n# load balance \n\n\n把一系列task分给不同的机器。\n\n- 静态\n  - it does not take into account the state of the system for the distribution of tasks\n  - are easy to set up and extremely efficient in the case of fairly regular tasks\n- 动态\n  - take into account the current load of each of the computing units\n  - tasks can be moved dynamically from an overloaded node to an underloaded node in order to receive faster processing\n\n## proxy\n\n- Client-side random load balancing: deliver a list of server IPs to the client, and then to have client randomly select the IP from the list on each connection\n  - the method of delivery of list of IPs to the client can vary\n- Server-side load balancers\n  - The load balancer forwards requests to one of the \"backend\" servers\n  - load balancers are implemented in high-availability pairs which may also replicate session persistence data if required by the specific application\n\n- presistence\n  -  important issue when operating a load-balanced service is how to handle information that must be kept across the multiple requests in a user's session. \n  -  One basic solution to the session data issue is to send all requests in a user session consistently to the same backend server.\n  -  Assignment to a particular server might be based on a username, client IP address, or be random.\n  -  use memcache to save session info\n  -  a simple but efficient approach is to store the per-session data in the browser itself: cookie\n     -  or URL rewriting\n\n## DNS  \n\n- round-robin DNS: multiple IP addresses are associated with a single domain name\n- [DNS delegation](https://en.wikipedia.org/wiki/Load_balancing_(computing)#DNS_delegation): delegate www.example.org as a sub-domain whose zone is served by each of the same servers that are serving the web site. This technique works particularly well where individual servers are spread geographically on the Internet. ","url":"https://notes.tczhong.com/notes/f5ca7595-879b-46b9-966a-5952a292fdfc.html","relUrl":"notes/f5ca7595-879b-46b9-966a-5952a292fdfc.html"},{"doc":"Linklayer","title":"Linklayer","hpath":"development.network.linklayer","content":"\n# data link layer\n\nethernet, wifi, fiber, telephony\n\ntransfer frames: ethernet, PPP, MAC address (add size, error correction codes)\n\n- Inserts framing info to denote frame boundaries\n- Inserts control, addressing and error correction info in header\n- Detects transmission errors on link. May retransmit frames\n- Activation, maintenance, & deactivation of link connection\n\n\n![](/assets/images/2021-03-25-15-55-22.png)\n![](/assets/images/2021-03-25-15-56-16.png)\n\n![](/assets/images/2021-03-25-15-58-20.png)\n\n- mission: transfer frames from one node, over a link\n- scope: Service received from physical layer is the ability to move a bit across the link\n    - A packet is transferred by different link protocols over different links\n    - Each data link protocol provides different services\n- addressing mechanism:MAC\n- data types : frame\n- responsibilities/services\n    - Framing:  encapsulate datagram into frame, adding header, trailer; identify source, destination with addresses • Different from IP \naddresses!!\n    - Link access: use medium access control (MAC) protocol\n    - Error Detection\n    - Error Correction\n    - Reliable Delivery: critical for wireless links ➙ high error rates\n\n## CSMA/CD\n\n- Carrier Sense: Listen before talking Multiple Access: Broadcast Medium\n- Collision Detection: Listen as you talk. If you hear someone else, be quiet\n- Capturing a Channel: If no other station initiates transmission during this period, sender has captured the channel. t = tprop\n- **Ethernet** is the most famous example\n- Before transmitting, listen\n- If channel is sensed idle, send the frame \n-  Else, defer transmission a random time\n- If collision is detected, abort transmission \n- reduces channel wastage\n- **Min transmission time must be long enough for collisions to propagate**\n- Length of the packet >= 2 * Tp * Bandwidth of the link worst case\n\n\n## ARP\n\n- mission: Translate a network-layer address (IP) to a link-layer address (MAC), Similar to DNS\n- frame fields:\n  - Sender Ethernet and IP address\n  - Target Ethernet and IP address\n- transmission mechanism\n    - Sent in an Ethernet frame to a broadcast address\n    - ARP Reply takes the same form\n    - broadcast request, if some one know, reply\n    - if in another subnet, sent datagram to router \n- caching\n    - Each Ethernet adapter uses a table to keep track of known mappings between IP addresses and Ethernet MAC Addrs\n    - When given IP address, ARP looks in ARP table and returns corresponding MAC address\n        - If IP not in table, queue frame and broadcast ARP request\n- security\n    - ARP frames are not authenticateds\n    - May be spoofed by a malicious entity\n    - May be proxied by design\n- gratuitous use\n    - ARP can be an “announcement” protocol\n    - Can send an ARP frame just to update other node’s ARP tables\n    - Set target address and sender address to the same value\n\n\n## csma/ca\n\n- CSMA / Collision Avoidance\n- 1. Listen for a specified time (DIFS) If medium is not free:\n    - 1. Exponential Backoff (下次请求的时间)\n- If medium is free:\n    - Transmit entire frame\n    - Await ACK frame （AP send ACK to sender）\n    - If no ACK, then Exponential Backoff\n- ACK\n    - protects against bit errors\n    - Receiver only sends ACK if frame passes CRC\n- Exponential Backoff\n    -  Each node chooses a random number \n    -  Max size increases from round to round\n    -  Can be modeled as a counter (wait time)\n        -  Decremented during any idle time\n        -  Put on hold if another node transmits and for a short time afterwards (SIFS)\n        -  When zero, the counting station may transmit","url":"https://notes.tczhong.com/notes/8c53f0c5-c632-46b3-8d06-845245e9c856.html","relUrl":"notes/8c53f0c5-c632-46b3-8d06-845245e9c856.html"},{"doc":"Component","title":"Component","hpath":"development.network.component","content":"\n# component\n\n## edge\n\n- hosts running applications: end system\n- client and server\n- p2p model\n- service: connection-oritented service, connectionless service\n\n## core\n\n- routers, interconnected networks\n\n## business\n\n- Tier 1 ISP: big network company in each country, Internet backbone providers\n    - direct connect with other tier 1\n    - connected to large number of tier-2\n    - international in coverage\n    - do not buy transit from another provider\n    - vertically intergrated: sell services to customers,\n    - no single tier-1 ISP can reach the whole Internet, it only peer with Tier-1\n- Tier 2 ISP:\n    - customers of Tier-1, provider of customers, peers with other tier-2\n    - why buy transit from tier-1 provide:\n        - usually reginal network and have limited resource\n        - need route traffic through Tier-1 ISP to reach a large protion of network\n    - why tie2 peer with each other\n        - exchanging traffic with a peer, reduce money\n        - improve performance\n- open peering policy: peer with anyone possible, costs of peering have to be balanced against gains for a Tier-2 ISP.\n        - management cost: send approx equal amount of traffic to each other\n        - matinentance cost: transmission capacity to meeting point, extra equipment\n- content providers:\n    - do not sell transit\n    - 1. focus on content creation, no peering\n    - 2. large-scale players: open peering policy","url":"https://notes.tczhong.com/notes/44747ebc-fe4d-4a52-a1ec-f196b304a9b3.html","relUrl":"notes/44747ebc-fe4d-4a52-a1ec-f196b304a9b3.html"},{"doc":"Applicationlayer","title":"Applicationlayer","hpath":"development.network.applicationlayer","content":"# Application layer\n\nhttp/smtp/dns/voip\n\n![](/assets/images/2021-03-25-16-43-51.png)\n## Goals\n\n- relaiable data transfer\n- high throughput\n- timing guarantees\n\n## http\n\n访问一个网址发生了什么\n\n1. The HTTP client process initiates a TCP connection to the server www.someSchool.edu on port number 80, which is the default port number for HTTP. Associated with the TCP connection, there will be a socket at the client and a socket at the server. 建立tcp\n\n2. The HTTP client sends an HTTP request message to the server via its socket. The request message includes the path name /someDepartment/home.index. (We will discuss HTTP messages in some detail below.) 发送请求\n\n3. The HTTP server process receives the request message via its socket, retrieves the object /someDepartment/home.index from its storage (RAM or disk), encapsulates the object in an HTTP response message, and sends the response message to the client via its socket. 返回请求\n\n4. The HTTP server process tells TCP to close the TCP connection. (But TCP doesn’t actually terminate the connection until it knows for sure that the client has received the response message intact.) 关闭tcp\n\n5. The HTTP client receives the response message. The TCP connection terminates. The message indicates that the encapsulated object is an HTML file. The client extracts the file from the response message, examines the HTML file, and finds references to the 10 JPEG objects. 关闭\n\n6. The first four steps are then repeated for each of the referenced JPEG objects.\n\n![](/assets/images/2021-03-14-19-59-53.png)\n\n\n### message format\n\n- message format:\n  - hypertext transfer protocol\n  - web's appliation layer protocol\n  - client/server model\n  - 2 type: requests from client to server and responses\n  - requests and response\n  - startline:request line (Method SP Request-URI SP HTTP-Version CRLF) | status line\n    - GET /index HTTP/1.1\n    - HTTP/1.1 200 OK\n  - zero or more headers: provide metadata about request or response:datas/times, application info,caching control,**host** must on requests\n  - an empty line\n  - message body\n  - request methods:\n  - GET: retrieve an object: conditional GET/ Partial GET\n  - HEAD: retrieve metadata about object\n  - OPTIONS: request info about the capabilities\n  - POST: upload data to server\n  - status code\n  - 1XX informational\n  - 2XX success\n  - 3XX redirection\n  - 4XX client error\n  - 5XX server error\n  - each request only retrieve one object\n\n### persistent http\n\n- persistent http\n  - reuse existing transport connection,subsequent http message between same client/server sent over open connection\n  - pipelining at application protocol level\n  - without pipeline: one RTT for each referenced object **RTT+transmission time(one object)**\n  - use pipeline: one RTT for all referenced objects\n  - reduce transport-layer connection cost\n  - reduce latency by avoid mulitple TCP slow-starts\n  - avoid bandwidth wastage and reduce all congestion\n\n### cookie\n\n![](/assets/images/2021-03-14-20-03-12.png)\n\n## DNS\n\n- mission: A directory service for the Internet\n- domain namespace: hierarchical structure\n  - type of dns ns: root/top-level domain/ authoritative/ local\n \n![](/assets/images/2021-03-14-20-07-56.png)\n\n- root server's job:\n    - what www.library.cmu.edu: go to ns for .edu\n    - know top-level domain 2.3M \n- tld ns' job: ask cmu.edu ns\n- authoritative ns: provide authoritative hostname to ip \n- local ns: resolver: act as proxy\n\n\n- Load distribution across replicated servers\n  - A name can map to multiple hosts \n  - thus multiple addresses\n  - DNS server returns all addresses \n  - but rotates ordering\n\n-  Simple query and reply mechanism, same message format, Resource Record\n-  Runs over UDP \n- * DNS did not need tcp retransmission when lost,try another ns\n  - tcp take long set-up time, query and request time need to be short\n- data used as Resource Record (RR) in query and reply messages:\n  - name(owner name), value, type, class (IN,internet), ttl\n  - A = Address \n  - ns = nameserver\n  - cname = canonical name\n  - mx = mail exchange\n- caching: once ns learns mapping, it caches mapping, timeout after ttl\n\n### tool\n\n- nslookup \n- dig\n- whois\n\n","url":"https://notes.tczhong.com/notes/a64fc89c-b245-44e9-8413-6c69bec42f92.html","relUrl":"notes/a64fc89c-b245-44e9-8413-6c69bec42f92.html"},{"doc":"Database","title":"Database","hpath":"development.database","content":"\n","url":"https://notes.tczhong.com/notes/a40ef849-d301-4d74-a778-e6d9469dfb5d.html","relUrl":"notes/a40ef849-d301-4d74-a778-e6d9469dfb5d.html"},{"doc":"Zippydb","title":"Zippydb","hpath":"development.database.zippydb","content":"\n# zippydb\n\nfb internal distributed key-value databse\n\nsingle node based on rockdb\n\n## arch\n\nZippyDB servers can be mapped to the roles in the Multi-Paxos protocol as follows:\n\nPrimary server = proposer/leader + acceptor + learner\nSecondary server = acceptor + learner\nFollower server = learner (An ordinary ZippyDB user may safely skip the details of the mapping above, as it is only intended to map terminology for readers who are familiar with Paxos.)\n\n## write \n\n![](/assets/images/2021-04-05-17-12-35.png)\n\n## read\n\n![](/assets/images/2021-04-05-17-13-08.png)\n\n## primary failover\n\nWhen the primary fails, Zeus detects the failure through lost heartbeats and notifies ShardManager. ShardManager chooses a most appropriate secondary and sends it a message to convert it into a new primary. \n\nSpecifically in this example, it is possible that, right before server X crashed, server X and server Y worked together to accept a write and server X has already sent the \"write-success\" response back to the client, but that write has not yet reached server Z. This is because server X and server Y form a majority and hence can accept a write without waiting for the \"accepted\" confirmation from server Z. Actually, server Z may never get the \"accept\" notification for this write from server X before server X crashed, e.g., due to slow network between server X and server Z. In this case, after server Z becomes the new primary, it needs to contact server Y to recover the missing write. The prepare phase of the Paxos protocol guarantees that the new primary will correctly discover all those missing writes, so long as only a minority of the replicas have failed.\nAfter bringing its local replica up-to-date, the new primary (server Z in this example) starts to handle reads and writes as normal. As shown in the figure below, the write path executes the following steps in sequence:\n\n1. When the client wants to send a new \"Put()\" request, the ServiceRouter library linked into the client notices that ShardManager has changed the shard's primary assignment, and automatically routes the request to the new primary (server Z).\n2. Server Z asks both server X and server Y to \"accept\" the write.\n3. Server Z gets the \"accepted\" confirmation from server Y, but gets no confirmation from server X.\n4. Since server Z collects a majority votes for the write (one from itself and another from server Y), server Z decides to commit the write and sends a \"write-success\" response back to the client. Server Z does not wait for server X to recover in order to accept the write. In other words, once server Z becomes the new primary, the failure of server X does not affect the database's availability .\n5. Server Z sends a \"commit\" message to server Y to inform server Y that an agreement has been reached on the write. This step is not shown in the figure for brevity.\n\n![](/assets/images/2021-04-05-17-15-33.png)\n\nThe process of primary fail-over takes about 10 seconds, including the time for Zeus to detect lost heartbeats from the old primary\n\n## A Failed Replica Rejoins\n\nServer X synchronizes with the new primary (server Z) to bring its local database up-to-date. It then starts to process protocol messages as normal. See the example in the figure below.\n\n![](/assets/images/2021-04-05-17-16-52.png)\n\n## Sharding and Load Balancing\n\nIn practice, each server runs a single ZippyDB process that can host multiple shards. In the figure below, each server hosts three shards: a primary for one shard, and two secondaries for two other shards. For example, server 1 hosts shard A's primary, shard D's secondary, and shard E's secondary. The three replicas of shard A are distributed across server 1 (primary), server 2 (secondary), and server 5 (secondary). ShardManager considers multiple factors in shard placement. In this figure, ShardManager places exactly one primary on each server for the purpose of load balancing, because a primary incurs a higher load than a secondary does. ShardManager may also place the different replicas of a shard across different clusters for the purpose of better fault tolerance.\n\n\n![](/assets/images/2021-04-05-17-18-35.png)\n\n## Asynchronous Replication Overview\n\n![](/assets/images/2021-04-05-17-22-52.png)\n\n![](/assets/images/2021-04-05-17-23-23.png)","url":"https://notes.tczhong.com/notes/40bf8bae-6748-4638-a9ea-43213edc6fb7.html","relUrl":"notes/40bf8bae-6748-4638-a9ea-43213edc6fb7.html"},{"doc":"Transaction","title":"Transaction","hpath":"development.database.transaction","content":"\n# Transaction\n\nTransaction is the **execution of a sequence of one or more operations** on a shared database to perform some higher level function. They are the basic unit of change in DBMS! It is a sequence of read and write operations. \n\nThe outcome of a transaction is either COMMIT or ABORT. If commit, all the transaction's modifications are saved to the database. If abort,  all the changes are undone so that this transaction is never happened. \n\n一种操作要么全部步骤成功，要不都失败.其中就有commit point的概念，在这之前是可以undo操作的，之后不行","url":"https://notes.tczhong.com/notes/43ab9e03-6b60-4154-9df6-b3d00d5ca47b.html","relUrl":"notes/43ab9e03-6b60-4154-9df6-b3d00d5ca47b.html"},{"doc":"Sql","title":"Sql","hpath":"development.database.sql","content":"\n# SQL Relational Model\n\nA relational database defines relationships in the form of tables.\n\n- data is organized into relations (called tables in SQL), where each relation is an unordered collection of tuples\n\nSQL programming can be effectively used to insert, search, update, delete database records.\n\n- vertically scalable: adding more power (CPU, RAM) to an existing machine.\n\n![](/assets/images/2021-03-23-23-04-33.png)\n\n- [[MySQL|development.database.sql.mysql]]\n\n## good \n\nmany-to-one, use id\n\nThe advantage of using an ID is that because it has no meaning to humans, it never needs to change: the ID can remain the same, even if the information it identifies changes. Anything that is meaningful to humans may need to change sometime in the future—and if that information is duplicated, all the redundant copies need to be updated. That incurs write overheads, and risks inconsistencies (where some copies of the information are updated but others aren’t). Removing such duplication is the key idea behind normalization in databases.\n## Problem\n\nMost application development today is done in object-oriented programming lan‐guages, which leads to a common criticism of the SQL data model: if data is stored in relational tables, an awkward translation layer is required between the objects in the application code and the database model of tables, rows, and columns. The discon‐nect between the models is sometimes called an impedance mismatch.\n\nIf you want to fetch a profile in the relational example, you need to either perform multiple queries (query each table by user_id) or perform a messy multiway join between the users table and its subordinate tables.","url":"https://notes.tczhong.com/notes/d708820b-6884-42a6-aa64-2fef1f1d0c8d.html","relUrl":"notes/d708820b-6884-42a6-aa64-2fef1f1d0c8d.html"},{"doc":"Redis","title":"Redis","hpath":"development.database.redis","content":"\n# 介绍\n\nRedis是一个使用ANSI C编写的开源、支持网络、基于内存、分布式、可选持久性的键值对存储数据库。\n\n\nRedis支持不同无序、有序的列表，无序、有序的集合间的交集、并集等高级服务器端原子操作。\n\nRedis通常将全部的数据存储在内存中。2.4版本后可配置为使用虚拟内存，一部分数据集存储在硬盘上，但这个特性废弃了。\n\n目前通过两种方式实现持久化：\n\n使用快照，一种半持久耐用模式。不时的将数据集以异步方式从内存以RDB格式写入硬盘。\n1.1版本开始使用更安全的AOF格式替代，一种只能追加的日志类型。将数据集修改操作记录起来。Redis能够在后台对只可追加的记录进行修改，从而避免日志的无限增长。\n\nhttps://zh.wikipedia.org/wiki/Redis","url":"https://notes.tczhong.com/notes/9f492704-d676-4e2e-a2e8-41256c742ef9.html","relUrl":"notes/9f492704-d676-4e2e-a2e8-41256c742ef9.html"},{"doc":"Partition","title":"Partition","hpath":"development.database.partition","content":"\n- NAÏVE TABLE PARTITIONING: Each node stores one and only table.\n- HORIZONTAL PARTITIONING: Split a table's tuples into disjoint subsets. Choose column(s) that divides the database equally in terms of size, load, or usage. (Hash Partitioning, Range Partitioning)","url":"https://notes.tczhong.com/notes/3e4896bc-c74a-42d0-94d9-3ab9e6fdacdd.html","relUrl":"notes/3e4896bc-c74a-42d0-94d9-3ab9e6fdacdd.html"},{"doc":"Nosql","title":"Nosql","hpath":"development.database.nosql","content":"\n# nosql\n\nNoSQL is a non-relational DMS, that does not require a fixed schema, avoids joins, and is easy to scale. \n\nNoSQL database is used for distributed data stores with humongous data storage needs\n\nNoSQL databases can be document based, key-value pairs, graph databases.\n\n- horizontally scalable (more machines)\n- use dynamic schema for unstructured data.\n\n![](/assets/images/2021-03-23-23-04-33.png)\n\n\nhere are several driving forces behind the adoption of NoSQL databases, including: \n\n- A need for greater **scalability** than relational databases can easily achieve, includ‐ing very large datasets or very high write throughput \n- A widespread preference for free and open source software over commercial database products \n- Specialized query operations that are not well supported by the relational model \n- Frustration with the restrictiveness of relational schemas, and a desire for a **more dynamic and expressive data model**\n\n## bad \n\n- one-to-many structure\n- access hard\n- hard to keep consistent if many-to-many\n- not need join\n\n## good\n\nA document is usually stored as a single continuous string, encoded as JSON, XML, or a binary variant thereof (such as MongoDB’s BSON). If your application often needs to access the entire document (for example, to render it on a web page), there is a performance advantage to this storage locality.\n\nSchema flexibility in the document model\n\n# cassandra\n\nSetting up Cassandra is quite simple and the maintenance is automatically done. The platform is quite fast even when it is scaled up or a node is added. Cassandra also takes care of re-syncing, balancing or distribution of data. The platform is known to provide high velocity random read writes compared to other NoSQL platforms since it has columnar storage capability and distributed decentralized architecture.\n\nFlexible Sparse & Wide Column requirements talk about capability to increase your columns as and when you need. It is suitable only in those cases where secondary index needs are less, which means you have it absolutely de-normalized. In other words all information is available to serve a specific query and does not go across multiple tables to get server specific client query.\n\nIt is important to know that Cassandra is suitable with non-group by kind of models. For applications that have requirement of group-by functionality, Cassandra would not be the right system to choose. This also includes bringing in secondary indexes, which will result into overall performance of system going down.\n\n very high velocity of random read & writes & wide column requirements.\n\n\n## partition\n- ring techonology.\n- hash round off\n- hash value used assign key to nodes\n\n## replication\n- rack unware: data at next N-1\n- rack aware: use zookeeper to choose a leader to tell nodes the range they replica for\n- datacenter aware: datacenter level\n\n## gossip protocol\n\n- Periodic, Pairwise, inter-node communication.\n- Random selection of peers.\n- Example – Node A wish to search for pattern in data\n    - Round 1 – Node A searches locally and then gossips with node B. \n    - Round 2 – Node A,B gossips with C and D.\n    - Round 3 – Nodes A,B,C and D gossips with 4 other nodes ......\n- Round by round doubling makes protocol very robust.\n\n## Local Persistence\n\n- Write operations happens in 2 steps\n    - Write to com⇒mit log in local disk of the node\n    - Update in-memory data structure.\n- Read operation\n    - Looks up in-memory ds first before looking up files on disk.\n    - Uses Bloom- Filter (summarization of keys in file store in memory) to avoid looking up files that do not contain the key.","url":"https://notes.tczhong.com/notes/310bc708-c6a7-49d2-9c96-e24204aa3771.html","relUrl":"notes/310bc708-c6a7-49d2-9c96-e24204aa3771.html"},{"doc":"Logging","title":"Logging","hpath":"development.database.logging","content":"\n\n- **what**:recording events as they occur.\n- **why**: need to use log to restore\n- **how**: combine with checkpoint, periodically checkpoint to save complete state. increment log to maintain updates from that state.\n    - synchronous logging: spend so many time to recovery\n    - asynchronous: log buffered in memory, reduce overhead, but leave log entries vulnerable to loss.\n        - GDV, global dependency vectors\n        - interval is how many messages I got since beginning\n        - if someone vector is bigger than the original one, it means it is inconsistence\n- **problem**: we can use prune log to reduce playback time\n    - it may resend messages that having negative effects on system. Use incarnation numbers to enable recipients to do the same.\n    - expensive in times\n\n\n## checkpoint\n\n\n- **what**: \bused to restore state. \n- **why**:for global consistent copy.\n- **how**: set point, **freezing** the system,no write to maintain consistency. inbound messages will not frozen but write into buffer.\n    - uncoordinated checkpoint: \n        - periodically recorded its state\n        - need recovery line to recover\n    - coordinated checkpoints:\n        - record message sequences: know who sent us message since last checkpoint\n        - synchronized clocks, add timestamp in all messages and act as a sequence number;:\n- **problem**: freeze\n- incarnation number: restarted will +1, use this to distinguish whether I should accept this message.","url":"https://notes.tczhong.com/notes/845553c3-4d26-4e76-ab6d-e3a5bbb195fe.html","relUrl":"notes/845553c3-4d26-4e76-ab6d-e3a5bbb195fe.html"},{"doc":"LSM","title":"LSM","hpath":"development.database.logging.LSM","content":"\n\n## LSM\n\nhttp://www.benstopford.com/2015/02/14/log-structured-merge-trees/\n\n1. idea: collect and batch updates in memory. 放满buffer再写入。\b\b删除的时候\b先放到tombstone里，再删除。\n2. merge 的\b想法：使用bloom filter在query的时候可以知道这个文件会不会在里面。在merge update可以prune tree。在merge的时候删tombstone。\n3. LSMT，memory里的数据结构是C0，disk里的是C1\n    1. fill memory\n    2. spill to disk. use SSTables(连续key value pair) and SSIndexes(key index pair) support random access \n    3. Index and bloom filter in memory\n    4. merge perform comaction\n    5. write-ahead logs to aid recovery\n    6. C0 is smaller and entirely resident in memory, whereas C1 is resident on disk. New records are inserted into the memory-resident C0 component. If the insertion causes the C0 component to exceed a certain size threshold, a contiguous segment of entries is removed from C0 and merged into C1 on disk.\n\nhttp://distributeddatastore.blogspot.com/2013/08/cassandra-sstable-storage-format.html)\n\n\n\n## Bloom Filter\n\n- **what**: one bit per hash function consumed per key. ignore collision. use bit to reprensent exist or not.\n- **why**: secondary storage is slow to search and access\n- **whow**: use k hash function for the item and get k array, set these all in 1 and when we query this item, we will check all k array result","url":"https://notes.tczhong.com/notes/c54dc5a8-42db-4a75-a182-c6c55f2c0c1d.html","relUrl":"notes/c54dc5a8-42db-4a75-a182-c6c55f2c0c1d.html"},{"doc":"Index","title":"Index","hpath":"development.database.index","content":"\n# index\n\nIn order to efficiently find the value for a particular key in the database, we need a different data structure: an index\n\nA table index is a **replica of a subset** of a table's columns that are organized and/or sorted for efficient access using a subset of those column\n\n## B+ tree\n\n- b+ tree:\n    - **self-balancing** tree data structure that keeps data sorted and allows searches, sequential access, insertions, and deletions in O(log n).\n    - m-way search tree: every leaf node is at the same depth\n    - every node with m/2+1 <= k <= m keys, k keys, k+1 child\n    - |link(< k )|key1|link( < k2 )|key2|link3( >= k2)|...\n    - node is an array of key/value pairs, key is column, value differ based on whether the node is classified as inner nodes or leaf nodes.\n    - only stores values in leaf nodes. Inner nodes only guide the search process.\n- B+TREE DESIGN CHOICES\n    - node size\n    - Merge Threshold : maybe delay merge operation\n    - Variable Length Keys : \n    - Non-Unique Indexes : \n    - Intra-Node Search: binary search \n- optimization:\n    - prefix compression: store prefix and only store defferent substring, leaf node\n    - suffix truncation: key very different and you only need suffix to see which key to go left or right, inner node\n    - bulk insert\n    - POINTER SWIZZLING\n\n## other index\n\n- skip list\n    - dynamic order-preserving index use a sorted linked list\n    - **Multiple levels** of linked lists with extra pointers that skip over intermediate nodes.\n    - To insert a new key, **flip a coin** to decide how many levels to add the new key into. Provides approximate O(log n) search times.\n    - First logically remove a key from the index by setting a flag to tell threads to ignore.\n    - Then physically remove the key once we know that no other thread is holding the reference.\n    - pros\n        - less space\n        - no rebalance\n    - cons\n        - not disk friendly, reverse search not good\n- radix tree\n    - Represent keys as individual digits. This allows threads to examine prefixes one-by-one instead of comparing entire key.\n    - 可能的问题就是一些不好表示，比如signed int，float\n- inverted index\n    - full text search index\n","url":"https://notes.tczhong.com/notes/e9b41a55-1699-4313-b816-b74e374b5840.html","relUrl":"notes/e9b41a55-1699-4313-b816-b74e374b5840.html"},{"doc":"Graph","title":"Graph","hpath":"development.database.graph","content":"\n# Graph-Like Data Models\n\nA graph consists of two kinds of objects: vertices (also known as nodes or entities) and edges (also known as relationships or arcs)","url":"https://notes.tczhong.com/notes/df62a0e7-2b47-475a-b6f8-666ff23c2a1b.html","relUrl":"notes/df62a0e7-2b47-475a-b6f8-666ff23c2a1b.html"},{"doc":"Distributed_system","title":"Distributed_system","hpath":"development.database.distributed_system","content":"\n\n## 多个server的concurrency解决思路\n\n### Centralized Approach 中央集权\n\n- what: 直接指派一个作为中央\n- why:easy and gurante\n- how: 3 messeages per cs entry : (request, permission, done)\n- problem: central dies and threads dies in the cs\n\n### lamport timestamp\n\n- what: global pripority queue for cs. send to each node request\n- why:  every node know what happens.\n- how: 3(N-1) messeages per requests (request,reply,release)\n- problem: no falut tolerant. message may not arrive in time, especially when sending requst\n\n### Ricarti and Agrawala timestamp approach\n\n- what: combine reply and release. change global queue to voting.\n- why: reduce message number\n- how: send request to others and if other agree(not in CS, or in cs and exit will reply) will reply. Get enough vote can start. 2*(n-1) messages.\n- problem: workhorses. too much messages. Even a single failure can disable the entire system. Both timestamp approaches require more messages than a centralized approach -- and have lower fault tolerance. The centralized approach provides one single point of failure (SPF). These timestamp approaches have N SPFs.\n\n### Voting\n\n- what: send request to others, if other have voted, put it in queue. When one exit cs, it send release to others and other could handle request in the queue.\n- why: only majority agree is ok. change the way of message and queue. \n- how: break ties could use **lamport time**. break deadlock when no one win, use inqure message, and other could vote again.It sends an INQUIRE message to the candidate for who it voted. If this candidate won the election, it can just ignore the INQUIRE and RELEASE normally when done. But, if it hasn't yet entered the critical section, it gives back the vote and signals this by sending back a RELINQUISH. Upon receipt of the RELINQUISH, the voter is free to vote for the preceding request.\n- problem: less message. (3+x)(1/2 N+?) request, vote, release\n\n### voting districts\n\n- what: send message to districts, just in the same line and cloumn. \n- why: reduce message\n- how: same voting techniques. 3*(2sqrt(N)-1)\n- problem: not falut tolerant, no deadlock. one server die may change.选择多个进入cs\n\n### token ring\n\n- what: everyone know successor, and move token one by one. hold it until done cs\n- why: fault tolerance. good at high contention\n- how: if one dies with token, last one see time out and generate a new one. Under high contention, message low. Every one has limited time with token.\n- problem: not good at low contention. \n\n### raymond's algorithm\n\n- what: use tree to pass token ring. \n- why: more quick in low contention\n- how: pass by node.\n- problem: worst case, travel long\n\n### path compression\n\n- what: allow short cut to pass token ring\n- why: current_dir may out-of-date, when request happened, node can get into current_dir end and enqueue in **next** queue. \n- how: use a queue of pending request with current_dir and next. current_dir point to next waiting, next is current(with token) point to waiting.","url":"https://notes.tczhong.com/notes/00876989-d1a6-423c-96c5-efc3b87de2b4.html","relUrl":"notes/00876989-d1a6-423c-96c5-efc3b87de2b4.html"},{"doc":"Voting","title":"Voting","hpath":"development.database.distributed_system.voting","content":"\n\n## 多个server的选举策略\n\ndifference between cs:\n\n- other do not need to know who enter cs. election need other know who is coordinator.\n- fault tolerance is primary consideration in election.\n\n### bully algorithm\n\n- what: use highest number as coordinator.\n- why: easy\n- how: when coordinator dies, send election to high number, if not recieve ack, it become coo and send to others. \n- problem: assumption is not realible(network is ok and we could know who dies accurately). failure need detect accurately.\n\n### invitation algorithm\n\n- what: form group to elect one and create a large one.\n- why: communication failure and high latency. use partition to handle is the best way.\n- how: merge them partition into group. choose one in partition and merge with another and get one.\n- problem: state is not consistence among group.\n\n### ring election\n\n- what:非同步算法。find cooridator die, send election around ring, every one add itself in the message. assume highest is new and everyone get message again remove itself.\n- why: good at high contention, and less messge","url":"https://notes.tczhong.com/notes/3bab31a7-f26c-4fa5-9f2d-cc9f851f5b38.html","relUrl":"notes/3bab31a7-f26c-4fa5-9f2d-cc9f851f5b38.html"},{"doc":"Raft","title":"Raft","hpath":"development.database.distributed_system.voting.raft","content":"\n\n# \b共识机制 raft\n\nmain idea is to allow a collection of machines to work as a group that can survive the failures fo some of its members.\n\n## leader election\n\n- what: in each term, elect a leader. when time out, start a new election.\n- why: one leader to recieve request and syn among all machines.\n- how: begin one election with term++, every one vote itself first and request others, if it finds other have more latest term, it will become follower.\n\n## log replication\n\n- what: append command as a log entry.\n- why: make sure everyone has same log\n- how: commit, if consistence, duplicate leader's\n- When AppendEntries consistency check fails, decrement nextIndex and try again\n- When follower overwrites inconsistent entry, it deletes all subsequent entries    \n","url":"https://notes.tczhong.com/notes/bd602fde-8745-4f5d-8cfa-2c4511870238.html","relUrl":"notes/bd602fde-8745-4f5d-8cfa-2c4511870238.html"},{"doc":"Paxos","title":"Paxos","hpath":"development.database.distributed_system.voting.paxos","content":"\n\n\n# paxos\n\nA collection of process can propose values\nA consensus algorithm ensures \n\n- That a single proposal is chosen\n- The processes can learn the proposed value \n- No value is chosen if there are no proposals.\n\n- **what**: consensus probelm algorith.\n- **how**:\n    - **Prepare**:propersor sends a Prepare message containing this **proposal** to a **Quorum** of Acceptors\n    - **Promise**:If the proposal's number N is higher than any previous proposal number received from any Proposer by the Acceptor, then the Acceptor must return a **promise** to **ignore** all future proposals having a number less than N. If the Acceptor accepted a proposal at some point in the past, it must include the previous proposal number and previous value in its response to the Proposer.\n    - **Accept request**:If a Proposer receives enough promises from a Quorum of Acceptors, it needs to set a value to its proposal. If any Acceptors had previously accepted any proposal, then they'll have sent their values to the Proposer, who now must set the value of its proposal to the value associated with the highest proposal number reported by the Acceptors. The Proposer sends an **Accept Request message** to a Quorum of Acceptors with the chosen value for its proposal.\n    - **Accepted**:If an Acceptor receives an Accept Request message for a proposal N, it must accept it if and only if it has not already promised to only consider proposals having an identifier greater than N. In this case, it should register the corresponding value v and send an Accepted message to the Proposer and every Learner. Else, it can ignore the Accept Request.","url":"https://notes.tczhong.com/notes/bc457b1e-f08c-4a05-b4a1-6f08eb7ba8cf.html","relUrl":"notes/bc457b1e-f08c-4a05-b4a1-6f08eb7ba8cf.html"},{"doc":"Filesystem","title":"Filesystem","hpath":"development.database.distributed_system.filesystem","content":"\n\n# file system\n\n- **what**: a file is a unit of data organized by user. a service responsible for managing files\n- **why**: key is robust and high-throughput\n- **how**: name, access, physical allocation, security and protection, resource administration.\n\n\n## NFS and AFS\n\n1. NFS has no client caching, cliented cached anyway, central system\n2. AFS is stateful server and has cache protocol. called to have data client there is an update, their cache is invalid. Whole file semantic\n3. CODA, add replication and added weakly connected mode.\n\n# RAIDS and HDFS\n\n## Normal disk\n\n- An error-correcting code (ECC) or forward error correction (FEC) code is a process of adding **redundant** data, or parity data, to a message, such that it can be recovered by a receiver even when a number of errors (up to the capability of the code being used) were introduced, either during the process of transmission, or on storage.\n- RAM could cache the data. It will only read data from disks. If there was error, disk will return nothing.\n\n## RAIDS\n\n- **what**:Redundant Array of Independent Disks,combines multiple physical disk drive components into one or more logical units for the purposes of data redundancy, performance improvement, or both.\n- **why**: more rebust, larger volume,higher throughput\n- **how**:\n    - RAID 0 它將兩个以上的磁盘並联起来，**成为一个大容量的磁盘**。在存放数据时，分段后分散儲存在这些磁盘中，因為读写時都可以并行處理，所以在所有的级别中，RAID 0的**速度**是最快的。no redundancy,just split into serveral disks\n    - RAID 1: mirroring,disk0=disk1,在一些多线程操作系统中能有很好的**读取**速度,replication，理論上读取速度等於硬盘數量的倍數，与RAID 0相同\n    - RAID 2:这是RAID 0的改良版，以汉明码（Hamming Code）的方式将数据进行编码后分割为独立的位元，并将数据分别写入硬盘中。因为在数据中加入了错误修正码（ECC，Error Correction Code），所以数据整体的容量会比原始数据大一些. log2. Have disks save error correction code for each partition.\n    - RAID3: a disk save **parity**. 採用Bit－interleaving（数据交错儲存）技術，它需要通过编码再将数据位元分割後分别存在硬盘中，而将同位元检查後单独存在一个硬盘中，但由于数据内的位元分散在不同的硬盘上，因此就算要读取一小段数据资料都可能需要所有的硬盘进行工作，所以这种规格比较适于读取大量数据时使用。\n    - RAID4:它与RAID 3不同的是它在分割时是以block为单位分别存在硬盘中\n    - RAID5:RAID Level 5是一种储存性能、数据安全和存储成本兼顾的存储解决方案。它使用的是Disk Striping（硬盘分割）技术。RAID 5至少需要三块硬碟，RAID 5不是对存储的数据进行备份，而是把数据和相对应的奇偶校验信息存储到组成RAID5的各个磁盘上，并且奇偶校验信息和相对应的数据分别存储於不同的磁盘上。**当RAID5的一个磁盘数据发生损坏後，可以利用剩下的数据和相应的奇偶校验信息去恢复被损坏的数据**。![](https://en.wikipedia.org/wiki/File:RAID_5.svg)\n    - RAID6:与RAID 5相比，RAID 6增加第二个独立的奇偶校验信息块\n    - RAID10 = RAID0+RAID1\n\n## LUSTRE\n\n- **what**:a type of parallel distributed file system, generally used for large-scale cluster computing\n- **why**: used for supercomputing, network RAID\n- **how**:\n    - Files are broken into objects, very similar to stripes. These stripes can be stored by different nodes.\n    - One or more metadata servers (MDS) nodes that has one or more metadata target (MDT) devices per Lustre filesystem that stores namespace metadata, such as filenames, directories, access permissions, and file layout(different access pattern,data is small)\n    - One or more object storage server (OSS) nodes that store file data on one or more object storage target (OST) devices.(enable either OSS talk to either OST)\n    - Client(s) that access and use the data. Lustre presents all clients with a unified namespace for all of the files and data in the filesystem\n    - high performance network to transfer data and manage network to manage data\n\n## MOGILEFS\n\n- **what**:distributed filesystem\n- **why**:no editing, whole file,fast deliver to clients\n- **how**:\n    - replicated storage:it replicates objects across servers. The number of replicas is associated with the class of the file, so, for example, photos might have three replicas, each, but thumbnails, which can be recreated from the original photos, might only have one replica of each. this reduces the cost of the storage by allowing less expensive components.\n    - http+MySQL:MogileFS uses HTTP to server objects from each replica, as opposed to a home-grown protocol, for portability. For the same reason, it keeps its metadata in a standard MySQL database. \n    - portable\n    - no hierachy: it maintains simple namespaces, rather than directory trees,  is much simpler and more efficient than a full-blown directory system\n\n## HDFS\n\n### assumption\n\n- failure is a norm, especially on datanode. It is used to handle streaming data. \n- emphasis is on throughput not on latency\n- large data sets\n- simple coherency model: write once and read many\n- moving computation is cheaper than moving data\n-  The good news is that it won't be edited in place. We'll just be collecting it, adding to it.\n-  \n![](/assets/images/2021-04-12-19-59-50.png)\n\n\n## namenode\n\n- **what**: master-slave architecture\n- **why**: manage namespace as coordinator, only 1\n- **how**: block to DataNodes mapping\n- data never go to namenode\n- hierarchical name space: maybe not needed, low overhead\n\n## datanode\n\n- manage storage attached to node\n- create and delete block, replicate blocks\n\n## access mode\n\n- read anywhere\n- write only at end(append)\n- no edit/random write\n\n## replication\n\n- blocks are all same size\n- fault tolerance\n- namenode managed replication\n- pipelining\n    - When a client is writing data to an HDFS file, its data is first written to a local file as explained in the previous section.\n    -  The **first** DataNode starts receiving the data in small portions (4 KB), writes each portion to its local repository and transfers that portion to the **second** DataNode in the list. The second DataNode, in turn starts receiving each portion of the data block, writes that portion to its repository and then flushes that portion to the **third** DataNode.\n    -  less bandwidth and less hot-spot","url":"https://notes.tczhong.com/notes/1f47041a-df34-437a-9e59-c4ed0fd44232.html","relUrl":"notes/1f47041a-df34-437a-9e59-c4ed0fd44232.html"},{"doc":"Concurrency","title":"Concurrency","hpath":"development.database.concurrency","content":"\n\n\n## concurrency control\n\nThe goal of a concurrency control is to generate an execution schedule that is equivalent to some serial execution:\n\n- serial schedule: a schedule does not interleave the actions of different transactions\n- equivalent schedules: the effect of executing two schedules are same\n- serializable schedule: a schedule is equivalent to some serial execution of transactions.\n\nThere are some problems when interleaves the operations:\n\n- Read-write conflicts (unrepeatable reads): A transaction cannot get the same value when reading the same object multiple Times.\n- Write-read conflicts(Dirty read): a transaction sees the write effects of a different transaction before that transaction committed its changes.\n- Write-Write conflicts (Lost updates): one transaction overwrites the uncommitted data of another concurrent transitions.\n\nSchedule S is **conflict serializable** if you are able to transform S into a serial schedule by **swapping consecutive non-conflicting operations** of different transactions. We could use dependency graphs to check. $T_i$ -> $T_j$ means if one operation $O_i$ of $T_i$ conflicts with an operation $O_j$ of $T_j$ and $O_i$ appears earlier in the schedule in $O_j$. A schedule is conflict serializable if and only the graph is acyclic. \n\nFor View serializable, it means if one write is overwrote by another transaction and there is no read, it is fine. It allows all conflict serializable schedules and blind writes. It is hard to enforce efficiently. It allows more schedules.\n\nFor durability. All of the changes of committed transactions must be durable (i.e., persistent) after a crash or restart. The\nDBMS can either use logging or shadow paging to ensure that all changes are durable.\n","url":"https://notes.tczhong.com/notes/c10c6c14-9f83-4681-8aef-74c7a20432b1.html","relUrl":"notes/c10c6c14-9f83-4681-8aef-74c7a20432b1.html"},{"doc":"Replication","title":"Replication","hpath":"development.database.concurrency.replication","content":"\n# master-slave\n\nFor replica configurations,  Master-Replica will receive all updates and it propagates those updates to its replicas. K-safety is a threshold for determining the fault tolerance of the replicated database. The value K represents the number of replicas per data object that must exist at all times.\n\n# propagation\n\nWhen a txn commits on a replicated database, the DBMS has to decide whether it has to wait for that txn's changes to propagate to other nodes before it can send the acknowledgement to application.\n\n- Synchronous: The master sends updates to replicas and then waits for them to acknowledge that they fully applied (i.e., logged) the changes.\n- Asynchronous: The master immediately returns the acknowledgement to the client without waiting for replicas to apply the changes.\n- Semi-Synchronous:  Replicas immediately send acknowledgements without logging them\n\n## CVV\n\n1. It asks all replicas for their version number\n2. It then asks the replica with the greatest version number for the file\n3. If the servers don't agree about the files version, the client can direct the servers to update a client that is behind, or inform them of a conflict. CVVs are compared just like vector timestamps. A conflict exists if two CVVs are concurrent, because concurrent vectors indicate that each server involved has seen some changes to the file, but not all changes.","url":"https://notes.tczhong.com/notes/f171bfbf-4725-432e-ab92-24eda0a9559b.html","relUrl":"notes/f171bfbf-4725-432e-ab92-24eda0a9559b.html"},{"doc":"Recovery","title":"Recovery","hpath":"development.database.concurrency.recovery","content":"\nRecovery algorithms are techniques to ensure database consistency, transaction atomicity, and durability despite failures. Recovery algorithm has two parts: actions during normal transaction, actions after a failure to recover the database.The key primitives are UNDO, the process of removing the effects of an incomplete or aborted transaction. REDO: the process of re-instating the effects of a committed transaction for durability.\n\nStorage can be volatile storage, data will be lost after powering off. Non-Volatile have data persistent after powering off. Stable storage never lose data. It could achieve approximately by using multiple storages. \n\nFailure can be transaction failure: transaction cannot complete due to some internal error and DBMS must terminate an active transaction due to an error condition. System failure is DBMS fails and system is crashed, non-volatile storage are not corrupted. Storage media failure is a disk failure and destroy parts of non-volatile storage. \n\n**Buffer pool management steal policies** will decide whether the DBMS allow an uncommitted transaction to overwrite the most recent committed value of an object in non-volatile storage. No-steal policy will not write uncommitted transaction value back to disk,  steal policy, allows the system to write modified blocks to disk even if the transactions that made those modifications have not all committed, could steal other transaction's memory. Force policy ensures that all updates made by a transaction are reflected on non-volatile\nstorage before the transaction is allowed to commit. No-force is not enforced to do this. NO-STEAL + FORCE means no redo: all committed transactions' changes are reflected in disk, no undo: all aborted transactions' changes are not written to disk. Limitation is memory because of no-steal policy.\n\nShadow paging means updates are only made in the shadow copy. When a transaction commits, atomically switch the shadow to become the new master. Disadvantages: Copying the entire page table is expensive and the commit overhead is high. Organize the database pages in a tree structure where the root is a single disk page. The root points to the master copy, updates are applied to the shadow copy. To install updates, overwrite the root so it points to the shadow, thereby swapping the master and\nshadow. For undo, it remove the shadow pages. Leave master and the DB root pointer alone. Do not need redo.\n\n**Write-Ahead Logging** means DBMS records all changes made to the db in log file before changes is made to a disk page. The log contains information to perform undo and redo. It has fast runtime performance but slow recovery time. Log records are written to disk before update is allowed to be written on disk. Transaction is committed until all its log records have been written to stable storage.Write BEGIN in the beginning, COMMITTED to make sure all log records are flushed. Log records contains tid, object id, before value(UNDO), after value(REDO). If we use NO-STEAL policy, we don't need original value, but in that way we could not undo for aborted transaction.\n\nDBMS can periodically takes a checkpoint where it flushes all buffers out to disk. The DBMS stops accepting new transactions and waits for all active transactions to complete. Flush all log records and dirty blocks currently residing in main memory to stable storage. Write a <CHECKPOINT> entry to the log and flush to stable storage.\n\nLogging schemes could be physical logging: record the changes made to a specific location in the database. Logical logging records the high operations executed by transactions. Physiological logging means log records target a single page but do not specify data organization of the page.\n\n\n## ARIES\n\nAlgorithms for Recovery and Isolation Exploiting Semantics. \n\n- WAL\n- Repeat history in redo\n- logging changes during undo\n\nIn WAL, each log record has a global unique log sequence number. Each data page contains a pageLSN, the LSN of the most recent update to that page. prevLSN: The previous LSN for the transaction. System keeps track of flushedLSN: the max LSN flushed so far. Before page i can be written to disk, we must flush log at least to the point where $pageLSN_i$ ≤ flushedLSN.\n\nTransaction commit will first write COMMIT record to log. All log records to to transaction’s COMMIT record are flushed to disk. When the commit succeeds, write a special TXN-END record to log. \n\nTransaction abort just an UNDO operation. Use prevLSN to undo transaction. Compensation Log Record, CLR describes the actions taken to undo the actions of a previous update record. It has all the fields of an update log record plus the undoNext pointer. CLRs are added to the log like any other record but they never need to be undone.\n\n1. First write ABORT record to log.\n2. Then play back updates in reverse order to remove their effects. For each update, write a CLR entry and restore old value.\n3. At end, write a TXN-END log record.\n\nBlocking checkpoints will halt the start of any new transactions and wait until all active transactions finish executing, flush dirty pages on disk.\n\nBetter one will halt new transaction and just pause transactions while the DBMS takes the checkpoint. It uses \n**Active Transaction Table (ATT)** to record active transaction and their lastLSN(most recent lsn written by transaction). Entry is removed when transaction commits or aborts. In **Dirty Page Table (DPT)**, it keeps track of pages in the buffer pool contain changes from uncommitted transactions. And there is **recLSN** field, the LSN of the log record that first caused the page to be dirty.\n\nFuzzy checkpoints allows other transactions to continue to run. Add new log records to track checkpoint boundaries, <CHECKPOINT-BEGIN>: Indicates the start of the checkpoint, <CHECKPOINT-END>: Contains the ATT + DPT.\n\nThere are three phases in ARIES.\n\nAnalysis: Read the WAL to identify dirty pages in the buffer pool and active transactions at the time of the crash.\n\n- Scan log forward from the checkpoint.\n- If you find a TXN-END record, remove its transaction from ATT.\n- All other records, add transaction to ATT with status UNDO, and on commit, change transaction status to COMMIT.\n- For UPDATE records, if page P not in DPT, add P to DPT and set its recLSN=LSN\n\nREDO: repeat history to reconstruct state at the moment of the crash. Reapply all updates (even aborted transactions) and redo CLRs:\n\n- Scan forward from log record containing smallest recLSN in PDT.\n- For each update log record or CLR with a given LSN, redo the action unless:\n\t– Affected page is not in the DPT, or\n\t– Affected page is in DPT but that record’s LSN is greater than smallest recLSN, or \n\t– Affected pageLSN (on disk) ≥ LSN.\n- To redo an action:\n\t– Reapply logged action.\n\t– Set pageLSN to log records LSN.\n\t– At the end of the redo phase, write TXN-END log records for all transactions with status “C” and remove them from the ATT.\n\nUndo Phase:\n\n- Undo All transactions active at the time of crash\n- These are all transactions with “U” status in the ATT after the Analysis phase \n- Process them in reverse LSN order using the lastLSN to speed up traversal\n- Write a CLR for every modification","url":"https://notes.tczhong.com/notes/7c5654e5-9a48-46cc-b5a5-e0ddf29b214e.html","relUrl":"notes/7c5654e5-9a48-46cc-b5a5-e0ddf29b214e.html"},{"doc":"Cap","title":"Cap","hpath":"development.database.concurrency.cap","content":"\n# CAP theorem: Consistency, Availability, Partition Tolerant. \n\nConsistency: If master says the txn committed, then it should be immediately visible on replicas. \n\nAvailability: Achieving availability in a distributed system requires that the system remains operational 100% of the time. \n\nPartition TOLERANCE means tolerance to a network partition. A network partition is when two nodes can't talk to each other, but there are clients able to talk to either one or both of those nodes.\n\n\n- By consistency we mean that all participating systems share the same view of the data.\n- By **Availability** we mean that the system is able to **respond quickly** enough for the user's needs.\n- By **Partition** tolerance we mean that, in the event of the failure or isolation of some participants, the other participants can continue to do whatever they can.\n- CA : mysql\n- CP: commuication among server to get consistence but not availability\n- PA: several servers but no consisitence\n\n\n![](https://qph.fs.quoracdn.net/main-qimg-23a75bd8c77d030f3ca9e1fd0621c10c.webp)\n![](http://www.andrew.cmu.edu/course/14-736/applications/ln/dividework.jpg)\n![](http://www.andrew.cmu.edu/course/14-736/applications/ln/addcomm.jpg)","url":"https://notes.tczhong.com/notes/751d1a2c-d099-4b5a-81b6-c30729e24c70.html","relUrl":"notes/751d1a2c-d099-4b5a-81b6-c30729e24c70.html"},{"doc":"Basic","title":"Basic","hpath":"development.database.concurrency.basic","content":"\n\n# Classical Non-Distributed Concurrency Control \n\n## spin-lock\n\n- **what**:Atomic compare-and-swap/test-and-set instructions\n- **why**: easy\n- **how**: Requires locking memory bus on multi-core/multi-processor\n- **problem**:Busy wait not good for high contention. busy-waiting, busy-looping or spinning is a technique in which a process repeatedly checks to see if a condition is true, such as whether keyboard input or a lock is available.\n\n## mutex\n\n- **what**:Semaphores, At-Most-N policies,Mutual Exclusion\n- **why**:Conceptually,manages a pool of resources.\n- **how**:\n    - P operation: Wait for resource to be available (lock s-=1)\n    - V operation: Make resource available (unlock s+=1)\n    - Deschedule (move to blocked queue) blocked thread or process \n    - Reschedule (move to ready queue) when resource available\n    - 初始s=1，s不会是负值\n\n## CONDITION VARIABLES\n\nEvent based \n\n- Wait – always waits. No predicate\n- Signal – Wake up a waiter\n- Broadcast – Wake up all waiters.","url":"https://notes.tczhong.com/notes/4a38d5d1-693f-46c3-8cfc-fffa59a4cb47.html","relUrl":"notes/4a38d5d1-693f-46c3-8cfc-fffa59a4cb47.html"},{"doc":"TOCC","title":"TOCC","hpath":"development.database.concurrency.TOCC","content":"\nTimestamp ordering (T/O) is an optimistic class of concurrency control protocols where the DBMS assumes that transaction conflicts are rare. DBMS instead uses timestamps to determine the serializability order of transactions. Timestamp could allocate using system lock, logical counter and hybrid.\n\nFor every database object X is tagged with timestamp of the last transaction that successfully did read/write. W-TS(X) and R-TS(X). If transaction tries to access an object “from the future”, then the DBMS aborts that transaction and restarts it.\n\nIn read operations, if $TS(T_i)$ < W-TS(X), the transaction will read a value that was already overwritten and this transaction will be rejected and abort, restart with same TS. If $TS(T_i)$ >= W-TS(X), it allows $TS(T_i)$ to read X and update R-TS(X). Depends on isolation levels, it can make a local copy of X to ensure repeatable reads for $T_i$.\n\nIn write operations, if $TS(T_i)$ < W-TS(X) or if $TS(T_i)$ < R-TS(X), it tries to write an obsolete value or the value needed is in the past. Transaction will be aborted and roll back. Else it could write X and update W-TS(X).\n\nFor Thomas Write Rule\n\nIf $TS(T_i)$ < R-TS(X), it will abort and restart. If $TS(T_i)$ < W-TS(X), ignore the write and allow transaction to continue. It make use of view serializability, deleting obsolete write operations from the transactions that issue them. \n\nThe basic timestamp ordering cannot have deadlocks because no transaction ever waits. But there is a possibility of starvation for long transactions if short transactions keep causing conflicts.\n\nIt also permits schedules that are not **recoverable**. A schedule is recoverable if transactions commit only after all transactions whose changes they read or commit. Otherwise, the DBMS cannot guarantee that transactions read data that will be restored after recovering from a crash.\n\nIssues:\n\n- High overhead from copying data to transaction’s workspace and from updating timestamps.\n- Long running transactions can get starved: The likelihood that a transaction will read something from a newer transaction increases.\n- Suffers from the timestamp allocation bottleneck on highly concurrent systems.","url":"https://notes.tczhong.com/notes/b02612ed-6fcc-49ba-bb23-c0cc6d8817fc.html","relUrl":"notes/b02612ed-6fcc-49ba-bb23-c0cc6d8817fc.html"},{"doc":"MVCC","title":"MVCC","hpath":"development.database.concurrency.MVCC","content":"# Multi-Version Concurrency Control\n\nThe DBMS maintains multiple physical versions of a single logical object in the database. When a transaction writes to an object, the DBMS creates a new version of that object. When a transaction reads an object, it reads the newest version that existed when the transaction started.\n\nThe key properties: Writers don’t block the readers. Readers don’t block the writers. Read-only transactions can read a consistent snapshot without acquiring locks. Timestamps are used to determine visibility. It supports time-travel queries. \n\nVersion storage will help DBMS decide how to store different physical versions of a logical object. The DBMS uses the tuple’s pointer field to create a version chain per logical tuple. Indexes always point to the head of the chain. A thread traverses chain until you find the version thats visible to you. \n\n- Append-Only Storage – New versions are appended to the same table space.\n\t- Oldest-To-Newest (O2N): Append new version to end of chain, look-ups require entire chain traversal.\n\t- Newest-To-Oldest (N2O): Head of chain is newest, look-ups are quick, but indexes need to be up- dated every version.\n- Time-Travel Storage – Old versions are copied to separate table space.\n- Delta Storage – The original values of the modified attributes are copied into a separate delta record space.\n\nGarbage Collection: The DBMS needs to remove reclaimable physical versions from the database over time. \n\n- Tuple Level Garbage Collection – Find old versions by examining tuples directly\n\t- Background Vacuuming: Separate threads periodically scan the table and look for reclaimable ver- sions, works with any version storage scheme.\n\t- Cooperative Cleaning: Worker threads identify reclaimable versions as they traverse version chain. Only works with O2N.\n- Transaction Level – Each transaction keeps track of its own read/write set. When a transaction completes, the garbage collector can use that to identify what tuples to reclaim.\n\nIndex Management: All primary key (pkey) indexes always point to version chain head. \n- Logical Pointers – Use a fixed identifier per tuple that does not change. Requires an extra indirection layer that maps the logical id to the physical location of the tuple\n- Physical Pointers – Use the physical address to the version chain head","url":"https://notes.tczhong.com/notes/c9e60817-ce12-4708-9fd3-4170d5933774.html","relUrl":"notes/c9e60817-ce12-4708-9fd3-4170d5933774.html"},{"doc":"ACID","title":"ACID","hpath":"development.database.concurrency.ACID","content":"\n\nACID:\n\n- Atomicity: all actions in the transaction happen or none happen.\n- Consistency: if each transaction is consistent and database is consistent in the beginning, it is guaranteed to be consistent when the transaction completes.\n- Isolation: the execution of one transaction is isolated from that of other transactions.\n- Durability: If a transaction commits, then its effects on the database persist.\n\nFor atomicity, there are two ways: shadow paging or logging. DBMS makes copies of pages and transaction make changes to those copies, only become visible when the transaction commits. DBMS could logs all actions so that it can undo the actions of aborted transactions. \n\nFor consistency, DBMS will make sure it return correct results. Database consistency means it can accurately represents the real world entity and the future transaction could see the effect of past committed transaction correctly. Transaction consistency make sure DB consistency after executing transaction.\n\nFor Isolation, transaction will not see other concurrent transaction's effect. It is equivalent to a system where transactions are executed in serial order. That's why we need concurrency control. It tells DBMS how to interleaving of operations from multiple transactions. There are two categories of concurrency control: pessimistic and optimistic. Pessimistic assume transactions will conflict, optimistic will assume conflicts are rare.\n","url":"https://notes.tczhong.com/notes/ffe0b9fd-a38b-4a6e-89cc-af369ee3e840.html","relUrl":"notes/ffe0b9fd-a38b-4a6e-89cc-af369ee3e840.html"},{"doc":"2PL","title":"2PL","hpath":"development.database.concurrency.2PL","content":"\nWe need to make all executes are correct without knowing the entire schedule ahead of time, using locks to protect database objects could make it work. **Two lock types: Shared lock and exclusive lock**. Locks are requested by transactions from the lock manager. The lock manager grants or block requests based on what locks are currently held by other transactions. Transaction will release lock when they do not need them. The lock manager updates its internal lock-table and then gives locks to waiting transactions. \n\nTwo phase locking is **pessimistic** concurrency control protocol. **The first phase is growing phase, each transaction requests the locks that it needs from the DBMS's lock manager. The second phase is shrinking phase, transaction enters this phase when it releases its first lock**. It cannot acquire new locks in this phase. The problem is **cascading aborts**(why?), when one transaction aborts, another transaction must be rolled back. Some schedule is serializable but not allowed by 2PL. S**trict 2PL means the transaction only releases exclusive-modes locks when it finishes**. Rigorous will take all lock until finishes. A schedule is strict if a value **written** by a transaction is not read or overwritten by other transactions until that transaction finishes. There is no cascading aborts here. \n\nBut it is possible to have deadlock in 2PL. A deadlock is a cycle of transactions waiting for locks to be released by each other. Deadlock detection will create a waits-for graph. Edge from $T_i$ to $T_j$ means $T_i$ is waiting $T_j$. The system will periodically check for cycles in waits-for graph and then make a decision on how to break it. When the DBMS detects a deadlock, it will select a “victim” transaction to rollback to break the cycle. DBMS can also decide the rollback length, it could just roll back.\n\nDeadlock prevention will prevent transaction waiting a transaction. Assign priorities based on timestamps, older means higher. These schemes guarantee no deadlocks because only one type of direction is allowed when waiting for a lock. When a transaction restarts, its (new) priority is its old timestamp.\n\n- Wait-Die (“Old waits for Young”): If T1 has higher priority, T1 waits for T2. Otherwise T1 aborts \n- Wound-Wait (“Young waits for Old”): If T1 has higher priority, T2 aborts. Otherwise T1 waits.\n\nWe could use a use a lock hierarchy that allow a transaction to take more coarse-grained locks in the system. Intention locks allow a **higher level node** to be locked in shared or exclusive mode without having to check all descendant nodes. If a node is in an intention mode, then **explicit locking is being done at a lower level**.\n\n\n- Intention-Shared (IS): Indicates explicit locking at a lower level with shared locks.\n- Intention-Exclusive (IX): Indicates explicit locking at a lower level with exclusive or shared locks. \n- Shared+Intention-Exclusive (SIX): The subtree rooted at that node is locked explicitly in shared mode and explicit locking is being done at a lower level with exclusive-mode locks.\n","url":"https://notes.tczhong.com/notes/445ccd09-a1fa-4ee6-b7e6-b02f7f7ad56a.html","relUrl":"notes/445ccd09-a1fa-4ee6-b7e6-b02f7f7ad56a.html"},{"doc":"2PC","title":"2PC","hpath":"development.database.concurrency.2PC","content":"\n# 2 phase commit\n\nIn two-phase commit, phase 1 is prepare, when receive commit request, it sends two all participants Ready? And wait for ok back. Then phase 2 is commit and wait for OK, then send SUCCESS to application server. If there is ABORT, it will send back to application server with ABORT and send ABORT to participants in phase 2. \n\nThe improvement is using Early Prepare Voting(using when it is the last one, return the result is the transaction result), Early Acknowledgement After Prepare (If all votes to commit a ten, it can send acknowledgement to client before phase 2 finishes). Two-Phase Commit will block if coordinator fails after the prepare message is sent, until coordinator recovers.\n\n## pharse1\n### Coordinator \n\n- Precommit (write to log and.or atomic storage)\n- Send request to all participants\n- Coordinator blocks waiting for ALL replies\n\n\n### Participant\n\n - Wait for request\n - Upon request, if ready:\n    - Precommit\n    - Send coordinator YES \n - Upon request, if not ready:\n    - Send coordinator NO\n\n## pharse2\n\n### Coordinator \n\n- This is the point of no return!\n- If all participants voted YES then send commit to each participant \n- Otherwise send ABORT to each participant\n\n\n### Participant\n\nWait for \"the word\" from the coordinator\n- If COMMIT, then COMMIT (transaction becomes visible)\n- If ABORT, then ABORT (gone for good)\n\n\nAnother real-world atomic commit protocol is three-phase commit (3PC). This protocol can reduce the amount of blocking and provide for more flexible recovery in the event of failure.\n\n\n![](http://www.andrew.cmu.edu/course/14-736/applications/ln/2pc-coord.jpg)\n![](http://www.andrew.cmu.edu/course/14-736/applications/ln/2pc-part.jpg)\n\n![](http://www.andrew.cmu.edu/course/14-736/applications/ln/3pc-coord.jpg)\n![](http://www.andrew.cmu.edu/course/14-736/applications/ln/3pc-part.jpg)\n","url":"https://notes.tczhong.com/notes/087e17c6-be99-4f2c-902a-b7abf4ba950a.html","relUrl":"notes/087e17c6-be99-4f2c-902a-b7abf4ba950a.html"},{"doc":"CDN","title":"CDN","hpath":"development.database.cdn","content":"\n\n![](/assets/images/2021-03-25-17-04-36.png)\n\n![](/assets/images/2021-03-25-16-59-58.png)\n\n- FNA 只有static content， untrust environment\n- PoP point of presence\n\n![](/assets/images/2021-03-25-17-08-48.png)\n\n![](/assets/images/2021-03-25-17-12-24.png)\n\n![](/assets/images/2021-03-25-17-15-31.png)\n\n![](/assets/images/2021-03-25-17-19-05.png)\n\n## real life\n\n- aws cloud front","url":"https://notes.tczhong.com/notes/13736958-e07c-45ce-a85d-d47c6990c994.html","relUrl":"notes/13736958-e07c-45ce-a85d-d47c6990c994.html"},{"doc":"Cache","title":"Cache","hpath":"development.database.cache","content":"\n# memcache\n\n![](/assets/images/2021-03-26-13-03-11.png)\n\n## memcached\n\n- **what**:使用LRU的一个巨大的hashtable。定时遗忘，high throughput\n- **why**：集合很多web server 的内存, use memory is fast and low latency\n- **how**: 出问题回disk找\n- **problem**：没有稳定的存储\n- handle common problem, much simple\n- Designed for volatile data\n    - failure: just go to disk\n    - recovery: just turn back on and wait. repopulated again\n\n# redis\n\nREmote DIctionary SErver\n\n- **what**: 支持多种数据类型，LRU，稳定存储\n- **why**: 解决同样的问题\n- **how**：定时写回disk，持久。\n    - simple client: ask any node and get redirected.(redirected may take long time)\n    - smart client: know the map, return this to the client(map maybe useless later)\n","url":"https://notes.tczhong.com/notes/b975629e-1af6-4118-a568-b2404da1b7fd.html","relUrl":"notes/b975629e-1af6-4118-a568-b2404da1b7fd.html"},{"doc":"Computer","title":"Computer","hpath":"development.computer","content":"\n","url":"https://notes.tczhong.com/notes/6cea4852-6e7c-4140-b476-85c07b48a642.html","relUrl":"notes/6cea4852-6e7c-4140-b476-85c07b48a642.html"},{"doc":"Shell","title":"Shell","hpath":"development.computer.shell","content":"\n# shell\n\n## execute\n\nshell首先检查命令是否是内部命令，若不是再检查是否是一个应用程序（这里的应用程序可以是Linux本身的实用程序，如ls和rm，也可以是购买的商业程序，如xv，或者是自由软件，如emacs）。然后shell在搜索路径里寻找这些应用程序（搜索路径就是一个能找到可执行程序的目录列表）。如果键入的命令不是一个内部命令并且在路径里没有找到这个可执行文件，将会显示一条错误信息。如果能够成功找到命令，该内部命令或应用程序将被分解为系统调用并传给Linux内核。","url":"https://notes.tczhong.com/notes/a2e26be6-4dac-464e-9ca3-673a10a59086.html","relUrl":"notes/a2e26be6-4dac-464e-9ca3-673a10a59086.html"},{"doc":"Service_management","title":"Service_management","hpath":"development.computer.service_management","content":"\n# systemd\n\nsystemd allows you to create and manage services in extremely powerful and flexible ways. \n\n## Unit files\n\nIf you're creating a brand new unit file for your service, you must first come up with a name. The name you select must not collide with any existing service name.\n\nCreate your service's unit file with the \".service\" suffix in the /etc/systemd/system directory. In our example, we will be creating a /etc/systemd/system/myservice.service file.\n\nThe first thing you must identify is what type of service you will be managing. Most services should use the simple type, which means a program that runs in the foreground. If your service normally runs itself in the background, search the documentation to see if it has an option to disable that. Running in the foreground is preferred.\n\n## command \n\n- systemctl start service\n- systemctl status 命令查看一下该服务的状态\n- 终止正在运行的服务，需要执行systemctl stop命令\n\n[reference](https://www.ruanyifeng.com/blog/2016/03/systemd-tutorial-part-two.html)","url":"https://notes.tczhong.com/notes/eb84e239-19ea-4347-ade0-9d0c270e9611.html","relUrl":"notes/eb84e239-19ea-4347-ade0-9d0c270e9611.html"},{"doc":"Program","title":"Program","hpath":"development.computer.program","content":"\n# how to get executable\n\n*.c -> *.i (ASCII中间文件) -> *.s (汇编) -> *.o (relocatable object file) -> ld -> prog (executable object file)\n\nlinux 调用loader把prog代码和数据复制到内存，然后转移到程序开头。\n\n","url":"https://notes.tczhong.com/notes/15ab8fe9-b553-40f5-906e-b7ae4b548ad8.html","relUrl":"notes/15ab8fe9-b553-40f5-906e-b7ae4b548ad8.html"},{"doc":"Linker","title":"Linker","hpath":"development.computer.program.linker","content":"\n# 主要功能\n\n1. 符号解析：将符号应用和符号定义关联起来\n2. 重定位：生成从地址0开始的代码和数据节\n\n## ELF (object file)\n\nexecutable and linkable format\n\n![](/assets/images/2021-04-21-22-03-08.png)\n\n. text The machine code of the compiled program .\n\n. rodata Read-only data such as the format strings in printf statements, and jump tables for switch statements.\n\n. data Initialized global and static C variables. Local C variables are maintained at run time on the stack and do not appear in either the .data or .bss sections.\n\n. bss Uninitialized global and static C variables, along with any global or static variables that are initialized to zero. This section occupies no actual space in the pbject file; it is merely a placeholder.\n\n. symtab A symbol table with information about functions and global variables that are defined and referenced in the program. \n\n. rel.text •A list of locations in the .text section that will need to be modified **when the linker combines this object file with others**. In general, any instruction that calls an external function or references a global variable will need to be modified. On the other hand, instructions that call local functions do not need to be modified. Note that relocation information is not needed in executable object files, and is usually omitted unless the user explicitly instructs the linker to include it.\n\n. rel.data Relocation information for any **global variables** that are referenced or defined by the module. In general, any initialized global variable whose initial value is the address of a global variable or externally defined function will need to be modified.\n\n. debug A debugging symbol table with entries for local variables and typedefs defined in the program, global variables defined and referenced in the program, and the original C source file. It is only present if the compiler driver is invoked with the -g option .\n\n. line A mapping between line numbers in the original C source program and machine code instructions in' the . text section. It is only pre~~nt if the ,.compiler driver is invoked with the -g option .\n\n. strtab A string table for the symbol tables in the . symtab and . debug sections and for. the section names in the section headers. A string table is a sequence of null-terminated character strings.\n\n\n## 符号和符号表\n\n- Global symbols that are defined by module m and that can be referenced by other modules.\n- Global symbols\"that are referenced by module m but defined by some other module.\n- Local symbols that are defined and referenced exclusively by module m.\n\n在符号解析时，编译器不会报错，认为这个函数定义在其他地方，linker在链接时找不到会报错\n\nRule 1. Multiple strong symbols with the same name are not allowed.\n\nRule 2. Given a strong symbol and multiple weak symbols with the same name, choose the strong symbol.\n\nRule 3. Given multiple weak symbols with the same name, choose any of the weak symbols.\n\n## 静态库 \n\n相关函数编译为独立的目标模块，封装成单独的静态库文件。linker值复制被程序引用的目标模块，减少了可执行文件在磁盘和内存中的大小。\n\n*.a 存档文件 -> *.o 只有相关的函数\n\n![](/assets/images/2021-04-21-22-09-54.png)\n\n## 动态库\n\n目标模块在运行或加载时，可以加载到任意内存地址。在静态链接时需要加载一些symbol table\n\n![](/assets/images/2021-04-21-22-11-14.png)\n\n## 重定位\n\n- 合并节和符号定义\n- 重定位符号引用\n\n\n## executable file\n\n![](/assets/images/2021-04-21-22-12-36.png)\n\n![](/assets/images/2021-04-21-22-12-54.png)\n\nEach' program in a Linux , system runs in the context of a process with its own virtual address space. When the shell runs a program, the parent shell process forks a child process that is a duplicate of the parent. The child process invokes the loader via the execve system call. The loader deletes the child's existing virtual memory segments and creates a neW set of code, data, heap, and stack segments, The new stack and heap segments are initialized to zero. The new code and data segments are initialized to the contents of the executable file by mapping pages in the virtual address space to page-size chunks of the executable file. Finally, the loader jumps to the start address, which eventually calls the application's main routine. Aside from some header information, there is no copying of data from disk to memory during loading. The copying is deferred until the CPU referencb a mapped virtual page, at which point the operating system automatically transfers the page from disk to memory using its paging mechanism.","url":"https://notes.tczhong.com/notes/33034e40-d30a-4302-8664-34ad2eeafc96.html","relUrl":"notes/33034e40-d30a-4302-8664-34ad2eeafc96.html"},{"doc":"Pipeline","title":"Pipeline","hpath":"development.computer.pipeline","content":"\n执行一条命令有以下几步\n\n1. Instruction fetch\n2. Instruction decode and register fetch\n3. Execute\n4. Memory access\n5. Register write back\n\n\n## 分支预测\n\n## 加stall避免数据race","url":"https://notes.tczhong.com/notes/abcad9be-bd03-48ca-b416-731b25cc0a2f.html","relUrl":"notes/abcad9be-bd03-48ca-b416-731b25cc0a2f.html"},{"doc":"Multitask","title":"Multitask","hpath":"development.computer.multitask","content":"\n","url":"https://notes.tczhong.com/notes/5d880b52-6a1f-48fd-b059-7b2e32c601c2.html","relUrl":"notes/5d880b52-6a1f-48fd-b059-7b2e32c601c2.html"},{"doc":"Process","title":"Process","hpath":"development.computer.multitask.process","content":"\n# process\n\n是执行中程序的实例，系统中的每一个程序都运行在某个进程的上下文中，上下文是由程序正确运行所需状态组成的，这个状态包括存放内存中程序的代码和数据，它的栈，通用目的寄存器的内容，程序计数器，环境变量，以及打开文件描述符的集合。每次用户通过shell输入一个可执行目标文件，shell就会创建新的进程。\n\nThe classic definition of a process is an instance of a program in execution. Each program in the system runs in the context of some process.The context consists of the state that the program needs to run correctly. This state includes the program's code and data stored in memory, its stack, the contents of its general-purpose registers, its program counter, environment variables, and the set of open file descriptors.\n\n进程是一个独立的逻辑控制流，轮流使用处理器的，每个进程执行流的一部分，然后被强占（preempted）,暂时被挂起。time slicing, concurrency\n\n每个process有私有的地址空间，代码段都从0x400000开始。\n\n内核调度一个新的进程，运行之后，它就会抢占当前进程，并使用一种上下文切换机制来将控制转移到新进程中。\n\n进程控制：获取进程id。进程有三种状态：运行，停止(suspended) 收到SIGSTOP, SIGTSTP,SIGTTIN or SIGTTOU，直到收到SIGCONT继续。终止，收到终止进程的信号，从主程序返回，调用exit函数。\n进程创建用fork， 当一个进程由于某种原因终止时，内核并不是立刻把它从系统中清除，相反进程将会，被保持在一种已经终止的状态，直到被父进程回收。waitpid 等待子进程终止。进程休眠就是sleep。\n\n加载并运行程序使用execve函数。execve调用一次从不返回。加载filename之后，调用启动代码，设置栈，将控制传递给新程序的main。\n\nthe typical difference is that **threads** (of the same process) run in a **shared memory space**, while processes run in separate memory spaces. thread有自己的tid，栈，sp，pc，general register and flag, **the code, data and heap areas are shared**\n\n\n## process control\n\n- run \n- suspend: A process stops as a result of receiving a SIGSTOP, SIGTSTP, SIGTI1N, or SIGTTOU signal, and it remains stopped until it receives a SIGCONT signal, at which point it becomes running again. \n- terminate： exit\n\n![[dendron://my_note/development.computer.call.fork]]\n## context switch\n\n![](/assets/images/2021-04-25-23-04-15.png)\n\nregisters是唯一被所有过程共享的资源，当调用时，把所有原始值压入栈中，改变寄存器的值，在返回之前从栈中弹出旧值。\n\nIt consists of the values of objects such as the general-purpose registers, the floating-point registers, the program counter, user's stack, status registers, kernel's stack, and various kernel data structures such as a page table that characterizes the address space, a process table that contains information about the current process, and a file table that contains information about the files that the process has opened.\n\nContext Switch 流程：上下文切换，第一，保存当前进程的上下文，第二，恢复某个先前被抢占的进程，被保存的上下文，第三，将控制传递给这个新恢复的进程。\n(1) saves the context of the current process, (2) restores the saved context of some previously preempted process, and (3) passes control to this newly restored process.\n \nThe context is the state that the kernel needs to restart a preempted process. It consists of the values of objects such as the **general-purpose registers, the floating-point registers, the program counter, user's stack, status registers, kernel's stack, and various kernel data structures such as a page table that characterizes the address space, a process table that contains information about the current process, and a file table that contains information about the files that the process has opened**.\n\n## zombie process\n\nZombie process\nwhat is zombie process? When does it become zombie process?\n\n当进程由于某种原因终止时，内核不会立即清除，而是保持在一种已经终止的状态直至被父进程回收，一个终止未被回收的叫zombie。用waitpid函数等待子进程终止或停止。\n\nOn Unix and Unix-like computer operating systems, a zombie process or defunct process is a process that has completed execution (via the exit system call) but **still has an entry in the process table**: it is a process in the \"Terminated state\". This occurs for child processes, where the entry is still needed to allow the parent process to read its child's exit status: once the exit status is read via the wait system call, the zombie's entry is removed from the process table and it is said to be \"reaped\".\n","url":"https://notes.tczhong.com/notes/68e49ff0-58d9-43fa-a47f-a0d50b88095d.html","relUrl":"notes/68e49ff0-58d9-43fa-a47f-a0d50b88095d.html"},{"doc":"Signal","title":"Signal","hpath":"development.computer.multitask.process.signal","content":"\n# signal\n\n![](/assets/images/2021-04-25-23-16-50.png)\n\n\n**信号允许进程和内核中断其他进程**，一个信号就是一条消息，他通知进程系统中发生了一个某种类型的事件。ctrl+c 是sigint， 终止信号是sigkill，ctrlz是 sigtstp。 发送信号可以用kill函数以及内核检测到一个系统事件。sigkill和sigstop不能捕捉，忽略和修改默认行为。\n\n信号处理程序，任何进程只能收到一个信号，并处理一个信号，如果一个进程有一个带出的信号，但是有其他的信号要被接收，都不会排队等待而简单的被抛弃。临时阻塞信号可以用sigprocmask。\n\nIn eval, the parent must use sigprocmask to block SIGCHLD, SIGINT, and SIGTSTP signals before it forks the child, and then unblock these signals, again using sigprocmask after it adds the child to the job list by calling addjob. Since children inherit the blockedvectors of their parents, the child must be sure to then unblock these signals before it executes the new program. The child should also restore the default handlers for the signals that are ignored by the shell.\n\n\n","url":"https://notes.tczhong.com/notes/26c24828-9284-461c-8416-4b442d49e85e.html","relUrl":"notes/26c24828-9284-461c-8416-4b442d49e85e.html"},{"doc":"Memory","title":"Memory","hpath":"development.computer.memory","content":"\n[reference](https://gywbd.github.io/posts/2016/1/segmentation-fault.html)\n\n# phycical memory\n\n\nstack（栈）是一块用于保存函数调用信息——传递的参数、每个函数的本地变量的内存区域\n\nheap（堆）是一块程序可以任意使用的内存区域，程序员有完全自由的权限对这个区域进行任何想要的操作\n\nstack部分的大小在程序运行过程中是可变的。当函数调用发生时，stack就会扩大，当函数调用结束时：之前扩大的stack就会缩小为调用之前的样子\nheap同样也是一个大小可变的区域，当程序员从heap中请求内存（malloc()）时，heap就会扩大，当这些内存被释放后（free()），heap就会缩小。\nstack和heap都是可伸缩的区域，它们处于整个地址空间中的相对位置：stack会向下扩展（由高地址到低地址），而heap则会向上扩展（由低地址到高地址）。它们都是可以自由增长的区域，只是增长的方向刚好相反。操作系统只需要检查这两个区域不会出现重叠的情况，这是它们主要的使用限制。\n\n![](/assets/images/2021-04-05-23-02-01.png)\n\n# virtaul memory\n\nThe virtual memory abstracts the details of physical memory from the application software, allows to keep only needed information in the physical memory (demand paging) and provides a mechanism for the protection and controlled sharing of data between processes.\n\n虚拟内存提供三个重要的能力，第一个把主存看作一个存储在磁盘上地址空间的高速缓存，在主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据，通过这种方式高效的使用的主存，第二点，他为每个进程提供了一致的地址空间，从而简化了内存管理，第三它保护了每个进程地址空间，不被其他进程破坏。\n\n虚拟内存其实是在磁盘上，需要用的时候放到主存里。每个虚拟地址指向一个PTE, 包含有效位以及物理页号或者磁盘地址。缓存不命中是缺页，调用缺页异常处理程序，选择一个页面换成需要的页面。之后重新启动缺页异常的指令。重新地址翻译。可以利用TLB加速地址翻译或者使用多级页表。\n\n## 缓存的工具\n\n每个字节有唯一的虚拟地址。\n\nvirutal page有三种类型\n\n- 未分配的：VM系统中未分配的页，不占任何磁盘空间\n- 缓存的：当前已缓存的在物理内存中的已分配页\n- 未缓存的：未缓存在物理内存中的已分配页\n\n![](/assets/images/2021-05-03-19-20-38.png)\n\nDRAM 比 SRAM(L1,L2,L3)慢10倍，虚拟页比较大。, DRAM caches always use write-back instead of write-through.\n\nIn write through, data is simultaneously updated to cache and memory. \nwrite back: The data is updated only in the cache and updated into the memory in later time. \n\n通过mmu, 页表(page table)判断一个虚拟页是否缓存在DRAM中的某一个地方，mmu把VP->PP\n\nPTE(page table entry) 有效位表明当前VP是否缓存在DRAM\n\n![](/assets/images/2021-05-03-19-25-39.png)\n\n页命中：如果有效，可以获得物理地址\n\n缺页：page fault，调用内核缺页处理程序。程序选择一个牺牲页，修改DRAM，把磁盘里的VP复制到DRAM，重新启动缺页的指令，把导致缺页的虚拟地址重新发到MMU，命中。\n\nThe activity of transferring a page between disk and memorf is known as swapping or paging. Pages are swapped in (paged in) from disk to DRAM, anct swapped out (paged out) from DRAM to disk\n### swap\n\n- What is swap, when will it be used?\nSwap space is located on hard drives for inactive pages in memory\nSwapping is the process whereby a page of memory is copied to the preconfigured space on the hard disk,\ncalled swap space, to free up that page of memory.\n\n- What's the situation that a process will swap\nSwap space in Linux is used when the amount of physical memory (RAM) is full.\nIf the system needs more memory resources and the RAM is full,\ninactive pages in memory are moved to the swap space.\n\n- What's the down side of swap?\nSwap space is located on hard drives, which have a slower access time than physical memory.\n \n## 内存管理\n\n不同进程里的VP可以共享一个PP。简化linking，loading，share，内存分配\n\n两个进程将私有对象映射到它们的虚拟内存的不同区域，但是共享这个对象，统一个物理副本，对于每个应设是有对象的进程，相应的所有区域的业表条目都被标记为只读，并且区域结构被标记为私有的写时复制。只要没有进程，试图修改他们自己的私有区域，他们就可以继续共享物理内存对象的一个单独副本，但是只要有一个进程，试图写私有区域内的某个页面，他就会复制一个新的，在那个里面写。\n\n## 内存保护\n\n在page table有许可位，判定这个page的访问权限。\n\n## 地址翻译 mmu\n\nMMU memory management unit.\nThe mapping between virtual address and physical address.\n\n![](/assets/images/2021-04-05-22-38-37.png)\n\n当一个用户级进程想访问一些内存，它会产生一个访问请求，MMU会把请求的虚拟地址转换为对应的物理内存地址。但是如果这个地址访问存在错误：转换后的物理地址超出了物理段的界限，或者违反了段保护权限（例如请求向只读段中写入数据），此时默认情况下操作系统会产生一个表示需要进行错误处理的信号：SIGSEGV，对这个信号的默认处理行为（default handler）是杀死（kill）这个进程，并且输出一个消息：“Segmentation fault”。\n\n![](/assets/images/2021-05-03-19-35-51.png)\n## TLB\n\n快速重编址缓冲器（Translation-lookaside Buffer : TLB）\n\n在每次虚拟内存访问时都会使用MMU，它会先从地址中提取出VPN，然后根据这个VPN查找TLB中是否有对应的VPN。如果命中（hit），它会直接返回TLB中记录的对应的物理地址，完成它的使命。如果没有命中（miss），那么它会查找进程的页表，如果对这个物理地址的访问是合法的，那么它会更新TLB，那么之后再访问这个虚拟地址，就会命中了。\n\n![](/assets/images/2021-05-03-19-36-10.png)\n\n## multi-level page table\n\n![](/assets/images/2021-05-03-19-42-35.png)\n\n## os\n\n- 不同进程共享同一个物理page\n- 写时复制，一开始指向同一个，改变一个的时候copy另一个\n\n![](/assets/images/2021-05-03-19-46-33.png)\n\n### heap\n\n![](/assets/images/2021-05-03-19-47-09.png)\n\n- malloc\n- free\n\n在头部和尾部都有a/f表示 上一个/下一个是不是allocate，常数时间合并空闲块\n\n### 垃圾收集\n\nA garbage collector is a dynamic storage allocator that automatically frees allocated blocks that are no longer needed by the program.\n\n有一些根节点可以到达堆节点\n\n![](/assets/images/2021-05-03-19-50-10.png)","url":"https://notes.tczhong.com/notes/723f785b-cdfa-43e1-ad13-785cf113e33d.html","relUrl":"notes/723f785b-cdfa-43e1-ad13-785cf113e33d.html"},{"doc":"Namespace","title":"Namespace","hpath":"development.computer.memory.namespace","content":"\n# kernal space, user space\n\n为什么Kernel和User Space 分开（因为安全啊）。为什么Kernel不能只检查User 是否有call system function的权限（因为还要检查user 是否还要touch合法的地址，参数类型等，反例是buffer overflow） \n \nKernel space is where the kernel (i.e., the core of the operating system) executes (i.e., runs) and provides its services.\n \nUser space is that set of memory locations in which user processes (i.e., everything other than the kernel) run. A process is an executing instance of a program. One of the roles of the kernel is to manage individual user processes within this space and to prevent them from interfering with each other.\n \nProcessors typically provide this capability with a mode: bit in some control register that characterizes the privileges that the process currently enjoys. When the mode bit is set, the process is running in kernel mode (sometimes called supervisor mode). A process running in kernel mode can execute any instruction in the instruction and access any memory location in the system.","url":"https://notes.tczhong.com/notes/da2027b2-1ea8-4a4a-a888-daa28f712b47.html","relUrl":"notes/da2027b2-1ea8-4a4a-a888-daa28f712b47.html"},{"doc":"Io","title":"Io","hpath":"development.computer.io","content":"\n# file\n\nfile是一个m个字节的序列。所以I/O设备被模型化为文件，输入输出变成读和写。\n\n## 打开文件\n\napp通过要求内核打开相应文件，访问一个I/O设备，内核返回一个小的非负整数，叫做描述符。内核记录有关这个文件的信息，app只记住这个描述符。\n\n创建进程都有三个打开的文件，stdin，stdout，stderr。\n\n改变当前文件位置，对于每个打开的文件，内核保持一个文件位置k，是从文件开始的字节偏移量。通过seek设置当前位置k。\n\n## 读写文件\n\n- 读：从文件复制n>0到内存，从当前位置k增加到k+n，当到末尾，触发EOF\n- 写：从内存复制到n>0到一个文件，从k开始\n\n\n# file type\n\n- regular file: text and binary\n- directory: 包含一组link的文件，将filename link to one file。至少包括“.” and “..”\n- socket: 与另一个进程进行网络通讯\n\n\n# 数据结构\n\n![](/assets/images/2021-05-03-19-57-58.png)\n\n- 描述符表： 每个进程独立\n- 文件表：打开文件集合，所有进程共享，当前文件位置，引用计数以及指向v-node表中对应的指针\n- v-node:所有进程共享，包含stat结构中的信息\n\nfor fork\n\n![](/assets/images/2021-05-03-20-05-52.png)\n\n## 重定向\n\ndup2 复制oldfd到newfd，删除老的file table item，新的reference count+=1，老的v-node删除\n","url":"https://notes.tczhong.com/notes/b1e1dad4-5179-4629-af74-208cef96a55e.html","relUrl":"notes/b1e1dad4-5179-4629-af74-208cef96a55e.html"},{"doc":"Functioncall","title":"Functioncall","hpath":"development.computer.functioncall","content":"\n# 过程\n\n1. 传递过程： 在进入过程Q时，程序计数器设置成Q的代码起始地址，然后在返回时，要把程序计数器设置为P中调用Q后面那条指令的地址。\n2. 传递数据：P必须能向Q提供一个或多个参数，Q必须向P返回一个值\n3. 分配和释放内存。在开始时Q可能需要为局部变量分配空间，而在返回前又释放这些内存。\n\n## 栈\n\n![](/assets/images/2021-04-17-17-39-13.png)\n\n1. 转移控制：把地址A压入栈，PC设置为Q的起始位置\n2. 数据传送：寄存器 %rdi，%rsi，在进入新的过程时压栈。\n3. 本地数据存在栈里","url":"https://notes.tczhong.com/notes/81649d61-4c14-43a8-84f8-654e1f07ce65.html","relUrl":"notes/81649d61-4c14-43a8-84f8-654e1f07ce65.html"},{"doc":"Exception_handle","title":"Exception_handle","hpath":"development.computer.exception_handle","content":"\n# exception\n\n在控制流中的突变，用来响应处理器状态中的变化。\n\n当有事件(event),通过一张异常表的跳转表，进行了一个间接过程调用（异常），到一个专门设计用来处理这类事件的子程序（exception handler)\n\n![](/assets/images/2021-04-25-22-27-49.png)\n\n每种异常有一个异常号，到跳转表。\n\n与过程调用不同，压入栈的可能是当前指令或下一条指令。如果控制从用户->内核，项目压到内核栈而不是用户栈。\n\n## 几种exception\n\n- interrupt: 由I/O 设备信号，异步。I/O 将某个引脚电位拉高，cpu执行完发现电位上升，执行中断放异常号到总线\n- trap：将控制返回下一条，同步，提供用户与内核的系统调用。\n- fault/abort\n  - segment fault: 引用了未定义的虚拟内存区域，尝试写一个只读的文本段\n\n![](/assets/images/2021-04-25-22-34-15.png)\n![](/assets/images/2021-04-25-22-34-24.png)","url":"https://notes.tczhong.com/notes/08a106c6-f774-4bf0-9688-07ef42de73d7.html","relUrl":"notes/08a106c6-f774-4bf0-9688-07ef42de73d7.html"},{"doc":"Call","title":"Call","hpath":"development.computer.call","content":"\n# system call\n\nIn computing, a system call is the programmatic way in which a computer program requests a service from the kernel of the operating system it is executed on.\n\n流程：\n\n- Application program makes a system call. When I write the program in ARM. I used SWI instruction. SWI means software interrupt exception. SWI will cause an interrupt. So the kernel will handle this interrupt. The handler is called SWI hander.\n- Stack is used to pass these arguments to the function in the kernel.\n- Each system call has a unique call number which is used by kernel to identify which system call is invoked.\n- Now the SWI handler executes a specific instruction (int 0x80). This instruction causes the processor to switch from 'User Mode' to 'Kernel Mode'\n- kernel invokes system_call() routine\n- This function saves register values onto kernel stack and does some validations like verifying system call number etc.\n- A map of system call number as key and the appropriate system call as value exists. This is called system_call_table. The handler uses this table to invoke appropriate system call service routine. It also validates the arguments if present.\n- After proper validations, the service routine performs required actions. After all these actions, service routine returns status of execution to user mode call.\n","url":"https://notes.tczhong.com/notes/acabdc86-1cd5-48de-a439-49686e1ced28.html","relUrl":"notes/acabdc86-1cd5-48de-a439-49686e1ced28.html"},{"doc":"Fork","title":"Fork","hpath":"development.computer.call.fork","content":"\nsystem call\n\nfork函数调用一次，返回两次，并发执行，**相同但是独立的地址空间**。相同代码和数据段、堆、共享库以及用户栈，共享文件，最大区别是父和子有不同的pid。\n\n对所有fork 拓扑排序，可以得到一个输出顺序。\n\nfork为当前进程调用，是内核，为新进程创建各种数据结构，并分配给他一个唯一的pid.为了给这个新进程创建虚拟内存，它创建当前进程的mm_struct, 区域结构和页表的原样副本，他将两个进程中的每个页面都标记为只读，并将两个进程中每个区域结构都标记为私有的写时复制 copy on write。\n","url":"https://notes.tczhong.com/notes/27148b7c-1a4b-4f57-8980-48c50e158b39.html","relUrl":"notes/27148b7c-1a4b-4f57-8980-48c50e158b39.html"},{"doc":"Execve","title":"Execve","hpath":"development.computer.call.execve","content":"\n加载并运行可执行目标文件，调用一次从不返回。\n\n\nexecve使用新的程序，有效替代当前程序，加载并运行，可执行目标程序需要以下几个步骤，第一点删除已存在的用户区域，第二点映射私有区域，为新程序区域创建新的区域结构。所以我现在去都是私有的，写时复制的。第三点应设共享区域。还要设置程序计数器，使之指向代码区的入口点。","url":"https://notes.tczhong.com/notes/4c818140-47ba-4497-a484-c80748376b45.html","relUrl":"notes/4c818140-47ba-4497-a484-c80748376b45.html"},{"doc":"Cache","title":"Cache","hpath":"development.computer.cache","content":"\n# cache\n\n用(S, E, B, m)表示，m是计算机的位数，s是组的个数，E是每组E行，B是块的大小\n\n![](/assets/images/2021-04-21-21-54-22.png)\n\nt用来找组里的哪一行\n\ns是组索引\n\nb是块偏移\n\n中位索引可以防止数据被整体换入换出\n# buffer and cache\n\n[link](https://stackoverflow.com/questions/6345020/what-is-the-difference-between-buffer-vs-cache-memory-in-linux)\n \nBuffers are associated with a specific block device, and cover caching of filesystem metadata as well as tracking in-flight pages. The cache only contains parked file data. That is, the buffers remember what's in directories, what file permissions are, and keep track of what memory is being written from or read to for a particular block device. The cache only contains the contents of the files themselves.","url":"https://notes.tczhong.com/notes/70063819-3d2a-44aa-8626-419d25eaf691.html","relUrl":"notes/70063819-3d2a-44aa-8626-419d25eaf691.html"},{"doc":"Boot","title":"Boot","hpath":"development.computer.boot","content":"\n# boot process\n\n![](/assets/images/2021-04-05-22-42-45.png)\n\nWhat happened when I press the power-on button of Linux operating system, i.e., what happened during the bootstrap process of Linux?\n1. BIOS\n\n- BIOS stands for Basic Input/output System\n- Performs some system integrity checks\n- Searches, loads, and executes the boot loader program.\n- It looks for boot loader in floppy, cd-rom, or hard drive. You can press a key (typically F12 of F2, but it depends on your system) during the BIOS startup to change the boot sequence.\n- Once the boot loader program is detected and loaded into the memory, BIOS gives the control to it. And the boot loader program is MBR, Master Boot Record.\n\n读取其中所存储的程序。这一程序通常知道一些直接连接在主板上的硬件(硬盘，网络接口，键盘，串口，并口)。现在大部分的BIOS允许你从软盘、光盘或者硬盘中选择一个来启动计算机。\n\n2. MBR\n- It is in the 1st sector of the bootable disk.\n- The MBR holds the information on how the logical partitions, containing file systems, are organized on that medium.\n- So MBR will tell computer to read boot loader from one specific partition.\n- Typical boot loader include GRUB, LILO.\n下一步，计算机将从你所选择的存储设备中读取起始的512个字节(bytes)。如果我们从光盘启动的话，那么计算机就会读取光盘最开始的512个字节。这512个字节叫做主引导记录MBR (master boot record)。MBR会告诉电脑从该设备的某一个分区(partition)来装载引导加载程序(boot loader)。引导加载程序储存有操作系统(OS)的相关信息，比如操作系统名称，操作系统内核 (内核)所在位置等。常用的引导加载程序有GRUB和LILO。 \n3. GRUB\n- GRUB stands for Grand Unified Bootloader. It will help us load the kernel.\nGRUB displays a splash screen, waits for few seconds, if you don’t enter anything, it loads the default kernel image as specified in the grub configuration file.\nGRUB has the knowledge of the filesystem (the older Linux loader LILO didn’t understand filesystem).\nGrub configuration file is /boot/grub/grub.conf (/etc/grub.conf is a link to this). The following is sample grub.conf of CentOS.\n\n4. Kernel\n- Kernel executes the /sbin/init program\n- Kernel will reserve some space for itself to run and use driver to detect computer hardware.\n- Then it executes init. init was the 1st program to be executed by Linux Kernel, it has the process id (PID) of 1.\n如果我们加载的是Linux内核，Linux内核开始工作。内核会首先预留自己运行所需的内存空间，然后通过驱动程序(driver)检测计算机硬件。这样，操作系统就可以知道自己有哪些硬件可用。随后，内核会启动一个init进程。它是Linux系统中的1号进程(Linux系统没有0号进程)。到此，内核就完成了在计算机启动阶段的工作，交接给init来管理。\n5. init process\n- Init will run some start up scripts. For example, configure the name of the computer, configure time zone, detect the file system, mount some hard drive, configure the network, activate raid, etc.\n- Then it will give the login dialogue box to prompt login.\n随后，init会运行一系列的初始脚本(startup scripts)，这些脚本是Linux中常见的shell scripts。这些脚本执行如下功能：\n\n设置计算机名称，时区，检测文件系统，挂载硬盘，清空临时文件，设置网络……\n当这些初始脚本，操作系统已经完全准备好了，只是，还没有人可以登录。init会给出登录(login)对话框，或者是图形化的登录界面。\n\nIn Unix-based computer operating systems, init (short for initialization) is the first process started during booting of the computer system. Init is a daemon process that continues running until the system is shut down. It is the direct or indirect ancestor of all other processes and automatically adopts all orphaned processes. Init is started by the kernel during the booting process; a kernel panic will occur if the kernel is unable to start it. Init is typically assigned process identifier 1.\n","url":"https://notes.tczhong.com/notes/6af427f5-61d4-4a9e-bebc-a64bfbb97b20.html","relUrl":"notes/6af427f5-61d4-4a9e-bebc-a64bfbb97b20.html"},{"doc":"Algo","title":"Algo","hpath":"development.algo","content":"\n# 算法\n\n## 数据结构\n\n- [[数组|development.algo.array]]\n- [[哈希表|development.algo.hashmap]]\n- [[链表|development.algo.linkedlist]]\n- [[树|development.algo.tree]]\n- [[堆|development.algo.heap]]\n- [[队列|development.algo.queue]]\n- [[栈|development.algo.stack]]\n- [[图|development.algo.graph]]\n\n## 算法\n\n- [[排序|development.algo.sort]]\n- [[搜索|development.algo.search]]\n- [[动态规划|development.algo.dp]]\n- [[贪心|development.algo.greedy]]\n- [[递归|development.algo.recursive]]\n- [[哈希|development.algo.hashing]]\n- [[图搜索|development.algo.graphsearch]]\n\n1. 减治法:它利用了一个问题给定实例的解和同样问题较小实例的解之间的关系。一旦建立了这样一种关系，我们既可以自顶至下（递归）也可以自底至上地运用这种关系。\n2. 分治法：将一个问题划分为同一类型的若干子问题，子问题最好规模相同。对这些子问题求解。有必要的、合并这些子问题的解，以得到原始问题的答案。 T(n) = aT(n/b)+f(n)\n3. 变治法：变换为同样问题的一个更简单或者更方便的实例一我们称之为实例化简。变换为同样实例的不同表现——我们称之为改变表现（representation change）。变换为另一个问题的实例，这种问题的算法是已知的一—我们称之为问题化简\n4. 时空权衡。输入增强：将问题进行预处理，预构造：使用额外的空间实现更快和更方便的数据存取\n5. 动态规划\n6. 贪婪算法","url":"https://notes.tczhong.com/notes/400115e9-30f7-4a13-9776-db059bc9cd42.html","relUrl":"notes/400115e9-30f7-4a13-9776-db059bc9cd42.html"},{"doc":"Tree","title":"Tree","hpath":"development.algo.tree","content":"\n# basic\n\n* Root: The node at the top of the tree.\n* Parent: When any node (except the root) has exactly one edge running upward to another node. The node above is called parent of the node.\n* Child: Any node may have one or more lines running downward to other nodes. These nodes below the given node called its children.\n* Leaf: A node that has no children is called a leaf. There can be only one root in a tree but there can be many leaves.\n* Level (Height): the level of a particular node refers to how many generations the node is from the root. The root is at level 0 and its children are at level 1 and so on.\n\n## 思想\n\n重点就是把握树的递归特性。题目要想办法改变成对于左右子树的子问题。binary tree: node with left and right child\n\n- 深度问题:\b 整棵树的深度可以看成右子树的深度与左子树的深度的最大值\n- 长度问题：左右子树最大值加上中心节点\n- 颠倒：左子树和右子树分别交换自己，最后根节点交换左右子树\n- merge:类似链表merge\n- 判断是否相同。左右子树分别判断\n- BST valid: 设定左右子树的上下限\n- 可以利用binary search 分解题目\n\n\n## 遍历\n\nAlgorithm Inorder(tree)\n\n   1. Traverse the left subtree, i.e., call Inorder(left-subtree)\n   2. Visit the root.\n   3. Traverse the right subtree, i.e., call Inorder(right-subtree)\n\nAlgorithm Preorder(tree)\n   1. Visit the root.\n   2. Traverse the left subtree, i.e., call Preorder(left-subtree)\n   3. Traverse the right subtree, i.e., call Preorder(right-subtree) \n\nAlgorithm Postorder(tree)\n   1. Traverse the left subtree, i.e., call Postorder(left-subtree)\n   2. Traverse the right subtree, i.e., call Postorder(right-subtree)\n   3. Visit the root.","url":"https://notes.tczhong.com/notes/04c802bc-7cb6-41a9-8107-43db336efdfc.html","relUrl":"notes/04c802bc-7cb6-41a9-8107-43db336efdfc.html"},{"doc":"Stack","title":"Stack","hpath":"development.algo.stack","content":"\n# basic\n\n- 大小是固定的\n- last in first out (LIFO)\n- 可以用数组实现\n\n## 时间复杂度\n\n- O(1) insert and delete\n- O(n) search\n\n## 算法\n\n- 可以用来reverse string","url":"https://notes.tczhong.com/notes/c9b60867-14a5-4b3d-b37c-3d31be7085fd.html","relUrl":"notes/c9b60867-14a5-4b3d-b37c-3d31be7085fd.html"},{"doc":"Sort","title":"Sort","hpath":"development.algo.sort","content":"\n# merge sort\n\n```python\ndef mergeSort(arr):\n    if len(arr) > 1:\n \n         # Finding the mid of the array\n        mid = len(arr)//2\n \n        # Dividing the array elements\n        L = arr[:mid]\n \n        # into 2 halves\n        R = arr[mid:]\n \n        # Sorting the first half\n        mergeSort(L)\n \n        # Sorting the second half\n        mergeSort(R)\n \n        i = j = k = 0\n \n        # Copy data to temp arrays L[] and R[]\n        while i < len(L) and j < len(R):\n            if L[i] < R[j]:\n                arr[k] = L[i]\n                i += 1\n            else:\n                arr[k] = R[j]\n                j += 1\n            k += 1\n \n        # Checking if any element was left\n        while i < len(L):\n            arr[k] = L[i]\n            i += 1\n            k += 1\n \n        while j < len(R):\n            arr[k] = R[j]\n            j += 1\n            k += 1\n```\n\n# quick sort\n\n```python\ndef partition(arr, low, high): \n    i = (low-1)         # index of smaller element \n    pivot = arr[high]     # pivot \n  \n    for j in range(low, high): \n  \n        # If current element is smaller than or \n        # equal to pivot \n        if arr[j] <= pivot: \n  \n            # increment index of smaller element \n            i = i+1\n            arr[i], arr[j] = arr[j], arr[i] \n  \n    arr[i+1], arr[high] = arr[high], arr[i+1] \n    return (i+1) \n  \n# The main function that implements QuickSort \n# arr[] --> Array to be sorted, \n# low  --> Starting index, \n# high  --> Ending index \n  \n# Function to do Quick sort \n  \n  \ndef quickSort(arr, low, high): \n    if len(arr) == 1: \n        return arr \n    if low < high: \n  \n        # pi is partitioning index, arr[p] is now \n        # at right place \n        pi = partition(arr, low, high) \n  \n        # Separately sort elements before \n        # partition and after partition \n        quickSort(arr, low, pi-1) \n        quickSort(arr, pi+1, high) \n```\n\n# heap sort\n\n![[dendron://my_note/development.algo.heap#heap sort]]\n\n# 拓扑排序\n\n有向图，是将G中所有顶点排成一个线性序列，使得图中任意一对顶点u和v，若边(u,v)∈E(G)，则u在线性序列中出现在v之前。\n\n- 选择一个入度为0的顶点并输出之；\n- 从图中删除此顶点及其所有出边；\n- 找下一个入度为0的点","url":"https://notes.tczhong.com/notes/33ed4a25-5fcf-4717-aabc-2351de2a64da.html","relUrl":"notes/33ed4a25-5fcf-4717-aabc-2351de2a64da.html"},{"doc":"Search","title":"Search","hpath":"development.algo.search","content":"\n# binary search\n\n1. array 是sorted\n\n```java\n\npublic static int indexOf(int[] a, int key) {\n        int lo = 0;\n        int hi = a.length - 1;\n        while (lo <= hi) {\n            // Key is in a[lo..hi] or not present.\n            int mid = lo + (hi - lo) / 2;\n            if      (key < a[mid]) hi = mid - 1;\n            else if (key > a[mid]) lo = mid + 1;\n            else return mid;\n        }\n        return -1;\n```","url":"https://notes.tczhong.com/notes/d57c4212-a9ad-4c5e-b94e-f3f4ff223c66.html","relUrl":"notes/d57c4212-a9ad-4c5e-b94e-f3f4ff223c66.html"},{"doc":"Queue","title":"Queue","hpath":"development.algo.queue","content":"\n# basic\n\n1. Every time add, Back index ++\n2. Every time remove item, Front index++ using an array to implement.\n3. Make sure you set index = back%cap\n4. FIFO","url":"https://notes.tczhong.com/notes/2afcf105-9cde-44ca-bb35-5e06223afac6.html","relUrl":"notes/2afcf105-9cde-44ca-bb35-5e06223afac6.html"},{"doc":"Linkedlist","title":"Linkedlist","hpath":"development.algo.linkedlist","content":"\n# basic\n\n1. Advantages: dynamic access\n2. Disadvantages: **cannot random access and extra memory to save reference to next node**.\n3. 动态分配空间，只知道下个节点\n4. a sequence of node, each one contains object reference to next one\n\n## 时间复杂度\n\n- insert, delete O(1). \n- search O(n)\n\n## 思路\n\n- 递归[[development.algo.recursive]]\n- recursive one by one, each one could be the new linkedlist head: merge, reverse\n- two iterates:cycle, overlapping,delete node.\n- use dummy head to avoid checking empty: pivoting,using new node to form new list","url":"https://notes.tczhong.com/notes/6abdd51b-1434-49ac-a1c1-58939f3c74ce.html","relUrl":"notes/6abdd51b-1434-49ac-a1c1-58939f3c74ce.html"},{"doc":"Heap","title":"Heap","hpath":"development.algo.heap","content":"\n# basic \n\n堆（英语：Heap）是计算机科学中的一种特别的完全二叉树。若是满足以下特性，即可称为堆：“给定堆中任意节点P和C，若P是C的母节点，那么P的值会小于等于（或大于等于）C的值”。若母节点的值恒小于等于子节点的值，此堆称为最小堆（min heap）；反之，若母节点的值恒大于等于子节点的值，此堆称为最大堆（max heap）。在堆中最顶端的那一个节点，称作根节点（root node），根节点本身没有母节点（parent node）\n\n## heap sort\n\n```\nprocedure heapsort(a, count) is\n    input: an unordered array a of length count\n \n    (建立推，root是最大值)\n    heapify(a, count)\n\n    (a[0:end]是堆，end到最后是排列好的))\n    end ← count - 1\n    while end > 0 do\n        swap(a[end], a[0])\n        (heap大小减一)\n        end ← end - 1\n        (the swap ruined the heap property, so restore it)\n        siftDown(a, 0, end)\n```\n\n```python\n\ndef heapify(arr, n, i):\n    largest = i  # Initialize largest as root\n    l = 2 * i + 1     # left = 2*i + 1\n    r = 2 * i + 2     # right = 2*i + 2\n \n    # See if left child of root exists and is\n    # greater than root\n    if l < n and arr[largest] < arr[l]:\n        largest = l\n \n    # See if right child of root exists and is\n    # greater than root\n    if r < n and arr[largest] < arr[r]:\n        largest = r\n \n    # Change root, if needed\n    if largest != i:\n        arr[i], arr[largest] = arr[largest], arr[i]  # swap\n \n        # Heapify the root.\n        heapify(arr, n, largest)\n \n# The main function to sort an array of given size\n \n \ndef heapSort(arr):\n    n = len(arr)\n \n    # Build a maxheap.\n    for i in range(n//2 - 1, -1, -1):\n        heapify(arr, n, i)\n \n    # One by one extract elements\n    for i in range(n-1, 0, -1):\n        arr[i], arr[0] = arr[0], arr[i]  # swap\n        heapify(arr, i, 0)\n \n```\n\n- api: heapq.heapify(x)\n- heapq.heappop(heap)","url":"https://notes.tczhong.com/notes/6b58aa5b-3039-44b3-8aee-20469ed20d10.html","relUrl":"notes/6b58aa5b-3039-44b3-8aee-20469ed20d10.html"},{"doc":"Hashmap","title":"Hashmap","hpath":"development.algo.hashmap","content":"\n# basic\n\n- put value in hash slot like array\n- store keys and values, insert, delete,lookup O(1) time on average\n- key not in order\n- hash method needs to be good","url":"https://notes.tczhong.com/notes/cfe9ff9c-87a1-45e7-8625-1b109ec59764.html","relUrl":"notes/cfe9ff9c-87a1-45e7-8625-1b109ec59764.html"},{"doc":"Hashing","title":"Hashing","hpath":"development.algo.hashing","content":"\n# collision\n\n\n- Static Hashing Schemes \n - linear probe hashing: find next available\n  - good for insert but bad for delete and update\n  - if non-unique key\n   - Choice #1: Separate Linked List. key point to a table save all value\n   - Choice #2: Redundant Keys: Store duplicate keys entries together in the hash table.\n - ROBIN HOOD HASHING:\n  - Variant of linear probe hashing that **steals slots from \"rich\"** keys and give them to \"poor\" keys.\n  - Each key tracks the number of positions **difference** its **optimal** position in the table.\n  - no grantee better, avoid worst case\n - cuckoo hashing\n  - Use multiple hash tables with different hash functions.\n  - ping pong, 出现collision去另一个\n  - 如果两个都collision，选一个替换，把被替换的放在另一个table里\n  - If we find a cycle, then we can rebuild the entire hash tables with new hash functions.\n- Dynamic Hashing Schemes\n - chained hashing: use linkedlist\n  - grow infinitely because you just keep adding new buckets to the linked list.\n - extendible hashing\n  - split buckets \n  - local depth: 就是之前没分的长度\n - linear hashing\n  - Maintain a pointer that tracks the next bucket to split. \n  - When any bucket overflows, split the bucket at the pointer location.\n\n## python dict\n\n- 存hash|key|value，每次都是看hash和key是不是一样\n- [处理collusion](https://stackoverflow.com/questions/9010222/why-can-a-python-dict-have-multiple-keys-with-the-same-hash)\n  - 出现collision，看`j = ((5*j) + 1) mod 2**i` 下一个是不是空的，是的话就放进去","url":"https://notes.tczhong.com/notes/43dac1c0-fd99-426c-93cf-73f08d70291b.html","relUrl":"notes/43dac1c0-fd99-426c-93cf-73f08d70291b.html"},{"doc":"Graphsearch","title":"Graphsearch","hpath":"development.algo.graphsearch","content":"\n\n# BFS\n\n```python\ndef BFS(self, s):\n \n    # Mark all the vertices as not visited\n    visited = [False] * (max(self.graph) + 1)\n\n    # Create a queue for BFS\n    queue = []\n\n    # Mark the source node as \n    # visited and enqueue it\n    queue.append(s)\n    visited[s] = True\n\n    while queue:\n\n        # Dequeue a vertex from \n        # queue and print it\n        s = queue.pop(0)\n        print (s, end = \" \")\n\n        # Get all adjacent vertices of the\n        # dequeued vertex s. If a adjacent\n        # has not been visited, then mark it\n        # visited and enqueue it\n        for i in self.graph[s]:\n            if visited[i] == False:\n                queue.append(i)\n                visited[i] = True\n \n\n```\n# DFS\n\n```python\ndef DFSUtil(self, v, visited):\n \n    # Mark the current node as visited\n    # and print it\n    visited.add(v)\n    print(v, end=' ')\n \n    # Recur for all the vertices\n    # adjacent to this vertex\n    for neighbour in self.graph[v]:\n        if neighbour not in visited:\n            self.DFSUtil(neighbour, visited)\n \n# The function to do DFS traversal. It uses\n# recursive DFSUtil()\ndef DFS(self, v):\n\n    # Create a set to store visited vertices\n    visited = set()\n\n    # Call the recursive helper function\n    # to print DFS traversal\n    self.DFSUtil(v, visited)\n\n```\n\n# 最短路径算法\n\n单点最短路径算法： bellman-ford 算法，基本思路就是每次更新从起点到v的距离，如果起点到u再到v的路程短，那么就更新。\n\n```\n for i from 1 to size(vertices)-1:\n       for each edge (u, v) with weight w in edges:\n           if distance[u] + w < distance[v]:\n               distance[v] := distance[u] + w\n```\n\nDijkstra’s 算法，这也是单点最短路径算法，基本思路是每次从q中取最小的节点，之后更新从该点到其他的点的距离。\n\n```\nfunction Dijkstra(G, w, s)\n    for each vertex v in V[G]        // 初始化\n           d[v] := infinity           // 將各點的已知最短距離先設成無窮大\n    d[s] := 0                        // 因为出发点到出发点间不需移动任何距离，所以可以直接将s到s的最小距离设为0\n     S := empty set\n     Q := set of all vertices\n     while Q is not an empty set      // Dijkstra演算法主體\n        u := Extract_Min(Q)\n        S.append(u)\n        for each edge outgoing from u as (u,v)\n            if d[v] > d[u] + w(u,v)  // 拓展边（u,v）。w(u,v)为从u到v的路径长度。\n                d[v] := d[u] + w(u,v)  // 更新路径长度到更小的那个和值。\n```\n\n# A*","url":"https://notes.tczhong.com/notes/650a5541-05cb-4941-a2d9-38619f0c11cb.html","relUrl":"notes/650a5541-05cb-4941-a2d9-38619f0c11cb.html"},{"doc":"Graph","title":"Graph","hpath":"development.algo.graph","content":"\n# basic\n\n## bfs\n## dfs\n## min distance","url":"https://notes.tczhong.com/notes/176ff327-cf04-4e42-89b3-c635757c7e9a.html","relUrl":"notes/176ff327-cf04-4e42-89b3-c635757c7e9a.html"},{"doc":"Dp","title":"Dp","hpath":"development.algo.dp","content":"\n# basic\n\n- the original problem can be solved relatively easy once solution to the sub problem are available\n- subproblems can be cached\n- when you have to make **choices** to arrive solution\n- counting and decision problem\n- build bottom up","url":"https://notes.tczhong.com/notes/ade6e78a-ff3d-4117-8a5d-adcede5bda9b.html","relUrl":"notes/ade6e78a-ff3d-4117-8a5d-adcede5bda9b.html"},{"doc":"Array","title":"Array","hpath":"development.algo.array","content":"\n# Basic\n\n- 数据集比较小\n- 数据的大小可以预测\n- 数据是连续存储的，速度快\n\n## 时间复杂度\n\n1. Addition and search worst O(N)\n2. Removal also O(N)\n\n## static和dynamic 数组\n\n- static是系统preallocate好大小，不能改变\n- dynamic是系统分配好，之后会根据情况进行变化，java里的ArrayList是1.5*","url":"https://notes.tczhong.com/notes/bea45ee5-a5ea-4d9a-b80b-003dd8661d7a.html","relUrl":"notes/bea45ee5-a5ea-4d9a-b80b-003dd8661d7a.html"},{"doc":"Changelog","title":"Changelog","hpath":"root.changelog","content":"","url":"https://notes.tczhong.com/notes/changelog.html","relUrl":"notes/changelog.html"}]
